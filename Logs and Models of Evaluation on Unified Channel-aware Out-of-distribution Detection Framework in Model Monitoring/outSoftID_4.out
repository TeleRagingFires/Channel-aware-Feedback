1.13.1+cu117
outSoftID
Dadicated Mode outSoftID
Dedicated Mode outSoftID
trainset len 112000 valset len 48000
New_trainset len 40000 valset len 48000
2,660,505 training parameters.

2,660,505 training parameters.

[INFO]: Epoch 1 of 200
Training
[1,   100] loss: 7.950e-04
[1,   200] loss: 6.593e-04
Validation
[1,   100] loss: 5.359e-04
[1,   200] loss: 5.359e-04
Training loss: 0.001, train NMSE: -1.944e+00
Validation loss: 0.001, valid_NMSE: -1.914e+00

Best validation loss: -1.9138257503509521

Saving best model for epoch: 1

--------------------------------------------------
[INFO]: Epoch 2 of 200
Training
[2,   100] loss: 5.384e-04
[2,   200] loss: 4.843e-04
Validation
[2,   100] loss: 4.191e-04
[2,   200] loss: 4.191e-04
Training loss: 0.001, train NMSE: -2.879e+00
Validation loss: 0.000, valid_NMSE: -3.085e+00

Best validation loss: -3.0847930908203125

Saving best model for epoch: 2

--------------------------------------------------
[INFO]: Epoch 3 of 200
Training
[3,   100] loss: 4.424e-04
[3,   200] loss: 4.172e-04
Validation
[3,   100] loss: 3.681e-04
[3,   200] loss: 3.681e-04
Training loss: 0.000, train NMSE: -3.265e+00
Validation loss: 0.000, valid_NMSE: -3.732e+00

Best validation loss: -3.7316253185272217

Saving best model for epoch: 3

--------------------------------------------------
[INFO]: Epoch 4 of 200
Training
[4,   100] loss: 3.896e-04
[4,   200] loss: 3.758e-04
Validation
[4,   100] loss: 3.320e-04
[4,   200] loss: 3.320e-04
Training loss: 0.000, train NMSE: -3.949e+00
Validation loss: 0.000, valid_NMSE: -4.242e+00

Best validation loss: -4.241912841796875

Saving best model for epoch: 4

--------------------------------------------------
[INFO]: Epoch 5 of 200
Training
[5,   100] loss: 3.538e-04
[5,   200] loss: 3.413e-04
Validation
[5,   100] loss: 3.057e-04
[5,   200] loss: 3.057e-04
Training loss: 0.000, train NMSE: -4.576e+00
Validation loss: 0.000, valid_NMSE: -4.647e+00

Best validation loss: -4.647441864013672

Saving best model for epoch: 5

--------------------------------------------------
[INFO]: Epoch 6 of 200
Training
[6,   100] loss: 3.262e-04
[6,   200] loss: 3.140e-04
Validation
[6,   100] loss: 2.844e-04
[6,   200] loss: 2.844e-04
Training loss: 0.000, train NMSE: -4.896e+00
Validation loss: 0.000, valid_NMSE: -5.033e+00

Best validation loss: -5.032502174377441

Saving best model for epoch: 6

--------------------------------------------------
[INFO]: Epoch 7 of 200
Training
[7,   100] loss: 3.010e-04
[7,   200] loss: 2.969e-04
Validation
[7,   100] loss: 2.684e-04
[7,   200] loss: 2.684e-04
Training loss: 0.000, train NMSE: -4.986e+00
Validation loss: 0.000, valid_NMSE: -5.312e+00

Best validation loss: -5.311892032623291

Saving best model for epoch: 7

--------------------------------------------------
[INFO]: Epoch 8 of 200
Training
[8,   100] loss: 2.845e-04
[8,   200] loss: 2.793e-04
Validation
[8,   100] loss: 2.542e-04
[8,   200] loss: 2.542e-04
Training loss: 0.000, train NMSE: -5.057e+00
Validation loss: 0.000, valid_NMSE: -5.591e+00

Best validation loss: -5.591106414794922

Saving best model for epoch: 8

--------------------------------------------------
[INFO]: Epoch 9 of 200
Training
[9,   100] loss: 2.703e-04
[9,   200] loss: 2.649e-04
Validation
[9,   100] loss: 2.430e-04
[9,   200] loss: 2.430e-04
Training loss: 0.000, train NMSE: -5.160e+00
Validation loss: 0.000, valid_NMSE: -5.792e+00

Best validation loss: -5.7915730476379395

Saving best model for epoch: 9

--------------------------------------------------
[INFO]: Epoch 10 of 200
Training
[10,   100] loss: 2.561e-04
[10,   200] loss: 2.551e-04
Validation
[10,   100] loss: 2.332e-04
[10,   200] loss: 2.332e-04
Training loss: 0.000, train NMSE: -5.778e+00
Validation loss: 0.000, valid_NMSE: -5.975e+00

Best validation loss: -5.974541664123535

Saving best model for epoch: 10

--------------------------------------------------
[INFO]: Epoch 11 of 200
Training
[11,   100] loss: 2.463e-04
[11,   200] loss: 2.439e-04
Validation
[11,   100] loss: 2.248e-04
[11,   200] loss: 2.248e-04
Training loss: 0.000, train NMSE: -5.831e+00
Validation loss: 0.000, valid_NMSE: -6.145e+00

Best validation loss: -6.144728183746338

Saving best model for epoch: 11

--------------------------------------------------
[INFO]: Epoch 12 of 200
Training
[12,   100] loss: 2.381e-04
[12,   200] loss: 2.347e-04
Validation
[12,   100] loss: 2.185e-04
[12,   200] loss: 2.185e-04
Training loss: 0.000, train NMSE: -6.078e+00
Validation loss: 0.000, valid_NMSE: -6.254e+00

Best validation loss: -6.2543253898620605

Saving best model for epoch: 12

--------------------------------------------------
[INFO]: Epoch 13 of 200
Training
[13,   100] loss: 2.290e-04
[13,   200] loss: 2.277e-04
Validation
[13,   100] loss: 2.105e-04
[13,   200] loss: 2.105e-04
Training loss: 0.000, train NMSE: -5.812e+00
Validation loss: 0.000, valid_NMSE: -6.417e+00

Best validation loss: -6.417102336883545

Saving best model for epoch: 13

--------------------------------------------------
[INFO]: Epoch 14 of 200
Training
[14,   100] loss: 2.226e-04
[14,   200] loss: 2.201e-04
Validation
[14,   100] loss: 2.054e-04
[14,   200] loss: 2.054e-04
Training loss: 0.000, train NMSE: -6.461e+00
Validation loss: 0.000, valid_NMSE: -6.503e+00

Best validation loss: -6.50300407409668

Saving best model for epoch: 14

--------------------------------------------------
[INFO]: Epoch 15 of 200
Training
[15,   100] loss: 2.162e-04
[15,   200] loss: 2.138e-04
Validation
[15,   100] loss: 1.998e-04
[15,   200] loss: 1.998e-04
Training loss: 0.000, train NMSE: -6.376e+00
Validation loss: 0.000, valid_NMSE: -6.620e+00

Best validation loss: -6.6197309494018555

Saving best model for epoch: 15

--------------------------------------------------
[INFO]: Epoch 16 of 200
Training
[16,   100] loss: 2.096e-04
[16,   200] loss: 2.089e-04
Validation
[16,   100] loss: 1.946e-04
[16,   200] loss: 1.946e-04
Training loss: 0.000, train NMSE: -5.980e+00
Validation loss: 0.000, valid_NMSE: -6.738e+00

Best validation loss: -6.738250732421875

Saving best model for epoch: 16

--------------------------------------------------
[INFO]: Epoch 17 of 200
Training
[17,   100] loss: 2.025e-04
[17,   200] loss: 2.055e-04
Validation
[17,   100] loss: 1.910e-04
[17,   200] loss: 1.910e-04
Training loss: 0.000, train NMSE: -6.232e+00
Validation loss: 0.000, valid_NMSE: -6.792e+00

Best validation loss: -6.792122840881348

Saving best model for epoch: 17

--------------------------------------------------
[INFO]: Epoch 18 of 200
Training
[18,   100] loss: 2.025e-04
[18,   200] loss: 1.965e-04
Validation
[18,   100] loss: 1.862e-04
[18,   200] loss: 1.862e-04
Training loss: 0.000, train NMSE: -6.922e+00
Validation loss: 0.000, valid_NMSE: -6.905e+00

Best validation loss: -6.904956817626953

Saving best model for epoch: 18

--------------------------------------------------
[INFO]: Epoch 19 of 200
Training
[19,   100] loss: 1.957e-04
[19,   200] loss: 1.940e-04
Validation
[19,   100] loss: 1.823e-04
[19,   200] loss: 1.823e-04
Training loss: 0.000, train NMSE: -6.677e+00
Validation loss: 0.000, valid_NMSE: -7.004e+00

Best validation loss: -7.003973007202148

Saving best model for epoch: 19

--------------------------------------------------
[INFO]: Epoch 20 of 200
Training
[20,   100] loss: 1.909e-04
[20,   200] loss: 1.907e-04
Validation
[20,   100] loss: 1.791e-04
[20,   200] loss: 1.791e-04
Training loss: 0.000, train NMSE: -6.740e+00
Validation loss: 0.000, valid_NMSE: -7.072e+00

Best validation loss: -7.072447776794434

Saving best model for epoch: 20

--------------------------------------------------
[INFO]: Epoch 21 of 200
Training
[21,   100] loss: 1.868e-04
[21,   200] loss: 1.869e-04
Validation
[21,   100] loss: 1.758e-04
[21,   200] loss: 1.758e-04
Training loss: 0.000, train NMSE: -7.674e+00
Validation loss: 0.000, valid_NMSE: -7.157e+00

Best validation loss: -7.15679407119751

Saving best model for epoch: 21

--------------------------------------------------
[INFO]: Epoch 22 of 200
Training
[22,   100] loss: 1.826e-04
[22,   200] loss: 1.841e-04
Validation
[22,   100] loss: 1.732e-04
[22,   200] loss: 1.732e-041.13.1+cu117
outSoftID
Dadicated Mode outSoftID
Dedicated Mode outSoftID
trainset len 112000 valset len 48000
New_trainset len 40000 valset len 48000
2,660,505 training parameters.

2,660,505 training parameters.

[INFO]: Epoch 1 of 200
Training
[1,   100] loss: 7.950e-04
[1,   200] loss: 6.592e-04
Validation
[1,   100] loss: 5.359e-04
[1,   200] loss: 5.359e-04
Training loss: 0.001, train NMSE: -1.944e+00
Validation loss: 0.001, valid_NMSE: -1.913e+00

Best validation loss: -1.913446068763733

Saving best model for epoch: 1

--------------------------------------------------
[INFO]: Epoch 2 of 200
Training
[2,   100] loss: 5.385e-04
[2,   200] loss: 4.843e-04
Validation
[2,   100] loss: 4.191e-04
[2,   200] loss: 4.191e-04
Training loss: 0.001, train NMSE: -2.881e+00
Validation loss: 0.000, valid_NMSE: -3.084e+00

Best validation loss: -3.084134578704834

Saving best model for epoch: 2

--------------------------------------------------
[INFO]: Epoch 3 of 200
Training
[3,   100] loss: 4.425e-04
[3,   200] loss: 4.173e-04
Validation
[3,   100] loss: 3.682e-04
[3,   200] loss: 3.682e-04
Training loss: 0.000, train NMSE: -3.265e+00
Validation loss: 0.000, valid_NMSE: -3.732e+00

Best validation loss: -3.7323365211486816

Saving best model for epoch: 3

--------------------------------------------------
[INFO]: Epoch 4 of 200
Training
[4,   100] loss: 3.897e-04
[4,   200] loss: 3.759e-04
Validation
[4,   100] loss: 3.321e-04
[4,   200] loss: 3.321e-04
Training loss: 0.000, train NMSE: -3.948e+00
Validation loss: 0.000, valid_NMSE: -4.241e+00

Best validation loss: -4.240767955780029

Saving best model for epoch: 4

--------------------------------------------------
[INFO]: Epoch 5 of 200
Training
[5,   100] loss: 3.539e-04
[5,   200] loss: 3.414e-04
Validation
[5,   100] loss: 3.059e-04
[5,   200] loss: 3.059e-04
Training loss: 0.000, train NMSE: -4.574e+00
Validation loss: 0.000, valid_NMSE: -4.645e+00

Best validation loss: -4.644824028015137

Saving best model for epoch: 5

--------------------------------------------------
[INFO]: Epoch 6 of 200
Training
[6,   100] loss: 3.263e-04
[6,   200] loss: 3.141e-04
Validation
[6,   100] loss: 2.845e-04
[6,   200] loss: 2.845e-04
Training loss: 0.000, train NMSE: -4.895e+00
Validation loss: 0.000, valid_NMSE: -5.030e+00

Best validation loss: -5.030478477478027

Saving best model for epoch: 6

--------------------------------------------------
[INFO]: Epoch 7 of 200
Training
[7,   100] loss: 3.010e-04
[7,   200] loss: 2.970e-04
Validation
[7,   100] loss: 2.684e-04
[7,   200] loss: 2.684e-04
Training loss: 0.000, train NMSE: -4.984e+00
Validation loss: 0.000, valid_NMSE: -5.312e+00

Best validation loss: -5.311738967895508

Saving best model for epoch: 7

--------------------------------------------------
[INFO]: Epoch 8 of 200
Training
[8,   100] loss: 2.846e-04
[8,   200] loss: 2.794e-04
Validation
[8,   100] loss: 2.543e-04
[8,   200] loss: 2.543e-04
Training loss: 0.000, train NMSE: -5.057e+00
Validation loss: 0.000, valid_NMSE: -5.590e+00

Best validation loss: -5.589601516723633

Saving best model for epoch: 8

--------------------------------------------------
[INFO]: Epoch 9 of 200
Training
[9,   100] loss: 2.703e-04
[9,   200] loss: 2.649e-04
Validation
[9,   100] loss: 2.430e-04
[9,   200] loss: 2.430e-04
Training loss: 0.000, train NMSE: -5.161e+00
Validation loss: 0.000, valid_NMSE: -5.792e+00

Best validation loss: -5.7915754318237305

Saving best model for epoch: 9

--------------------------------------------------
[INFO]: Epoch 10 of 200
Training
[10,   100] loss: 2.561e-04
[10,   200] loss: 2.551e-04
Validation
[10,   100] loss: 2.332e-04
[10,   200] loss: 2.332e-04
Training loss: 0.000, train NMSE: -5.778e+00
Validation loss: 0.000, valid_NMSE: -5.974e+00

Best validation loss: -5.973977565765381

Saving best model for epoch: 10

--------------------------------------------------
[INFO]: Epoch 11 of 200
Training
[11,   100] loss: 2.463e-04
[11,   200] loss: 2.439e-04
Validation
[11,   100] loss: 2.247e-04
[11,   200] loss: 2.247e-04
Training loss: 0.000, train NMSE: -5.834e+00
Validation loss: 0.000, valid_NMSE: -6.144e+00

Best validation loss: -6.144427299499512

Saving best model for epoch: 11

--------------------------------------------------
[INFO]: Epoch 12 of 200
Training
[12,   100] loss: 2.380e-04
[12,   200] loss: 2.346e-04
Validation
[12,   100] loss: 2.183e-04
[12,   200] loss: 2.183e-04
Training loss: 0.000, train NMSE: -6.080e+00
Validation loss: 0.000, valid_NMSE: -6.259e+00

Best validation loss: -6.259467601776123

Saving best model for epoch: 12

--------------------------------------------------
[INFO]: Epoch 13 of 200
Training
[13,   100] loss: 2.290e-04
[13,   200] loss: 2.276e-04
Validation
[13,   100] loss: 2.105e-04
[13,   200] loss: 2.105e-04
Training loss: 0.000, train NMSE: -5.814e+00
Validation loss: 0.000, valid_NMSE: -6.416e+00

Best validation loss: -6.416292190551758

Saving best model for epoch: 13

--------------------------------------------------
[INFO]: Epoch 14 of 200
Training
[14,   100] loss: 2.225e-04
[14,   200] loss: 2.201e-04
Validation
[14,   100] loss: 2.053e-04
[14,   200] loss: 2.053e-04
Training loss: 0.000, train NMSE: -6.466e+00
Validation loss: 0.000, valid_NMSE: -6.503e+00

Best validation loss: -6.5031867027282715

Saving best model for epoch: 14

--------------------------------------------------
[INFO]: Epoch 15 of 200
Training
[15,   100] loss: 2.162e-04
[15,   200] loss: 2.137e-04
Validation
[15,   100] loss: 1.997e-04
[15,   200] loss: 1.997e-04
Training loss: 0.000, train NMSE: -6.381e+00
Validation loss: 0.000, valid_NMSE: -6.623e+00

Best validation loss: -6.622759819030762

Saving best model for epoch: 15

--------------------------------------------------
[INFO]: Epoch 16 of 200
Training
[16,   100] loss: 2.095e-04
[16,   200] loss: 2.088e-04
Validation
[16,   100] loss: 1.946e-04
[16,   200] loss: 1.946e-04
Training loss: 0.000, train NMSE: -5.982e+00
Validation loss: 0.000, valid_NMSE: -6.738e+00

Best validation loss: -6.7382283210754395

Saving best model for epoch: 16

--------------------------------------------------
[INFO]: Epoch 17 of 200
Training
[17,   100] loss: 2.023e-04
[17,   200] loss: 2.054e-04
Validation
[17,   100] loss: 1.910e-04
[17,   200] loss: 1.910e-04
Training loss: 0.000, train NMSE: -6.237e+00
Validation loss: 0.000, valid_NMSE: -6.796e+00

Best validation loss: -6.796464443206787

Saving best model for epoch: 17

--------------------------------------------------
[INFO]: Epoch 18 of 200
Training
[18,   100] loss: 2.023e-04
[18,   200] loss: 1.963e-04
Validation
[18,   100] loss: 1.862e-04
[18,   200] loss: 1.862e-04
Training loss: 0.000, train NMSE: -6.924e+00
Validation loss: 0.000, valid_NMSE: -6.904e+00

Best validation loss: -6.904196739196777

Saving best model for epoch: 18

--------------------------------------------------
[INFO]: Epoch 19 of 200
Training
[19,   100] loss: 1.955e-04
[19,   200] loss: 1.938e-04
Validation
[19,   100] loss: 1.822e-04
[19,   200] loss: 1.822e-04
Training loss: 0.000, train NMSE: -6.685e+00
Validation loss: 0.000, valid_NMSE: -7.008e+00

Best validation loss: -7.0084638595581055

Saving best model for epoch: 19

--------------------------------------------------
[INFO]: Epoch 20 of 200
Training
[20,   100] loss: 1.908e-04
[20,   200] loss: 1.905e-04
Validation
[20,   100] loss: 1.789e-04
[20,   200] loss: 1.789e-04
Training loss: 0.000, train NMSE: -6.742e+00
Validation loss: 0.000, valid_NMSE: -7.078e+00

Best validation loss: -7.077959060668945

Saving best model for epoch: 20

--------------------------------------------------
[INFO]: Epoch 21 of 200
Training
[21,   100] loss: 1.866e-04
[21,   200] loss: 1.866e-04
Validation
[21,   100] loss: 1.756e-04
[21,   200] loss: 1.756e-04
Training loss: 0.000, train NMSE: -7.682e+00
Validation loss: 0.000, valid_NMSE: -7.163e+00

Best validation loss: -7.163303375244141

Saving best model for epoch: 21

--------------------------------------------------
[INFO]: Epoch 22 of 200
Training
[22,   100] loss: 1.823e-04
[22,   200] loss: 1.839e-04
Validation
[22,   100] loss: 1.730e-04
[22,   200] loss: 1.730e-04
Training loss: 0.000, train NMSE: -7.019e+00
Validation loss: 0.000, valid_NMSE: -7.203e+00

Best validation loss: -7.2031354904174805

Saving best model for epoch: 22

--------------------------------------------------
[INFO]: Epoch 23 of 200
Training
[23,   100] loss: 1.811e-04
[23,   200] loss: 1.789e-04
Validation
[23,   100] loss: 1.698e-04
[23,   200] loss: 1.698e-04
Training loss: 0.000, train NMSE: -7.123e+00
Validation loss: 0.000, valid_NMSE: -7.275e+00

Best validation loss: -7.27540397644043

Saving best model for epoch: 23

--------------------------------------------------
[INFO]: Epoch 24 of 200
Training
[24,   100] loss: 1.764e-04
[24,   200] loss: 1.769e-04
Validation
[24,   100] loss: 1.676e-04
[24,   200] loss: 1.676e-04
Training loss: 0.000, train NMSE: -7.194e+00
Validation loss: 0.000, valid_NMSE: -7.336e+00

Best validation loss: -7.335854530334473

Saving best model for epoch: 24

--------------------------------------------------
[INFO]: Epoch 25 of 200
Training
[25,   100] loss: 1.736e-04
[25,   200] loss: 1.742e-04
Validation
[25,   100] loss: 1.648e-04
[25,   200] loss: 1.648e-04
Training loss: 0.000, train NMSE: -6.649e+00
Validation loss: 0.000, valid_NMSE: -7.395e+00

Best validation loss: -7.395025253295898

Saving best model for epoch: 25

--------------------------------------------------
[INFO]: Epoch 26 of 200
Training
[26,   100] loss: 1.707e-04
[26,   200] loss: 1.707e-04
Validation
[26,   100] loss: 1.621e-04
[26,   200] loss: 1.621e-04
Training loss: 0.000, train NMSE: -7.545e+00
Validation loss: 0.000, valid_NMSE: -7.472e+00

Best validation loss: -7.471650123596191

Saving best model for epoch: 26

--------------------------------------------------
[INFO]: Epoch 27 of 200
Training
[27,   100] loss: 1.664e-04
[27,   200] loss: 1.692e-04
Validation
[27,   100] loss: 1.595e-04
[27,   200] loss: 1.595e-04
Training loss: 0.000, train NMSE: -7.657e+00
Validation loss: 0.000, valid_NMSE: -7.518e+00

Best validation loss: -7.518158435821533

Saving best model for epoch: 27

--------------------------------------------------
[INFO]: Epoch 28 of 200
Training
[28,   100] loss: 1.647e-04
[28,   200] loss: 1.647e-04
Validation
[28,   100] loss: 1.569e-04
[28,   200] loss: 1.569e-04
Training loss: 0.000, train NMSE: -7.240e+00
Validation loss: 0.000, valid_NMSE: -7.574e+00

Best validation loss: -7.573878288269043

Saving best model for epoch: 28

--------------------------------------------------
[INFO]: Epoch 29 of 200
Training
[29,   100] loss: 1.624e-04
[29,   200] loss: 1.614e-04
Validation
[29,   100] loss: 1.546e-04
[29,   200] loss: 1.546e-04
Training loss: 0.000, train NMSE: -7.439e+00
Validation loss: 0.000, valid_NMSE: -7.631e+00

Best validation loss: -7.630605220794678

Saving best model for epoch: 29

--------------------------------------------------
[INFO]: Epoch 30 of 200
Training
[30,   100] loss: 1.577e-04
[30,   200] loss: 1.601e-04
Validation
[30,   100] loss: 1.520e-04
[30,   200] loss: 1.520e-04
Training loss: 0.000, train NMSE: -7.453e+00
Validation loss: 0.000, valid_NMSE: -7.696e+00

Best validation loss: -7.695858955383301

Saving best model for epoch: 30

--------------------------------------------------
[INFO]: Epoch 31 of 200
Training
[31,   100] loss: 1.547e-04
[31,   200] loss: 1.578e-04
Validation
[31,   100] loss: 1.497e-04
[31,   200] loss: 1.497e-04
Training loss: 0.000, train NMSE: -7.652e+00
Validation loss: 0.000, valid_NMSE: -7.766e+00

Best validation loss: -7.76554012298584

Saving best model for epoch: 31

--------------------------------------------------
[INFO]: Epoch 32 of 200
Training
[32,   100] loss: 1.535e-04
[32,   200] loss: 1.541e-04
Validation
[32,   100] loss: 1.473e-04
[32,   200] loss: 1.473e-04
Training loss: 0.000, train NMSE: -7.517e+00
Validation loss: 0.000, valid_NMSE: -7.816e+00

Best validation loss: -7.815738677978516

Saving best model for epoch: 32

--------------------------------------------------
[INFO]: Epoch 33 of 200
Training
[33,   100] loss: 1.513e-04
[33,   200] loss: 1.515e-04
Validation
[33,   100] loss: 1.459e-04
[33,   200] loss: 1.459e-04
Training loss: 0.000, train NMSE: -7.813e+00
Validation loss: 0.000, valid_NMSE: -7.873e+00

Best validation loss: -7.872897148132324

Saving best model for epoch: 33

--------------------------------------------------
[INFO]: Epoch 34 of 200
Training
[34,   100] loss: 1.512e-04
[34,   200] loss: 1.477e-04
Validation
[34,   100] loss: 1.445e-04
[34,   200] loss: 1.445e-04
Training loss: 0.000, train NMSE: -7.916e+00
Validation loss: 0.000, valid_NMSE: -7.888e+00

Best validation loss: -7.888209819793701

Saving best model for epoch: 34

--------------------------------------------------
[INFO]: Epoch 35 of 200
Training
[35,   100] loss: 1.493e-04
[35,   200] loss: 1.458e-04
Validation
[35,   100] loss: 1.419e-04
[35,   200] loss: 1.419e-04
Training loss: 0.000, train NMSE: -8.256e+00
Validation loss: 0.000, valid_NMSE: -7.968e+00

Best validation loss: -7.967738628387451

Saving best model for epoch: 35

--------------------------------------------------
[INFO]: Epoch 36 of 200
Training
[36,   100] loss: 1.442e-04
[36,   200] loss: 1.467e-04
Validation
[36,   100] loss: 1.411e-04
[36,   200] loss: 1.411e-04
Training loss: 0.000, train NMSE: -8.327e+00
Validation loss: 0.000, valid_NMSE: -7.976e+00

Best validation loss: -7.975779056549072

Saving best model for epoch: 36

--------------------------------------------------
[INFO]: Epoch 37 of 200
Training
[37,   100] loss: 1.443e-04
[37,   200] loss: 1.434e-04
Validation
[37,   100] loss: 1.394e-04
[37,   200] loss: 1.394e-04
Training loss: 0.000, train NMSE: -7.971e+00
Validation loss: 0.000, valid_NMSE: -8.034e+00

Best validation loss: -8.034342765808105

Saving best model for epoch: 37

--------------------------------------------------
[INFO]: Epoch 38 of 200
Training
[38,   100] loss: 1.409e-04
[38,   200] loss: 1.433e-04
Validation
[38,   100] loss: 1.380e-04
[38,   200] loss: 1.380e-04
Training loss: 0.000, train NMSE: -8.035e+00
Validation loss: 0.000, valid_NMSE: -8.084e+00

Best validation loss: -8.084209442138672

Saving best model for epoch: 38

--------------------------------------------------
[INFO]: Epoch 39 of 200
Training
[39,   100] loss: 1.416e-04
[39,   200] loss: 1.394e-04
Validation
[39,   100] loss: 1.371e-04
[39,   200] loss: 1.371e-04
Training loss: 0.000, train NMSE: -7.912e+00
Validation loss: 0.000, valid_NMSE: -8.098e+00

Best validation loss: -8.097990036010742

Saving best model for epoch: 39

--------------------------------------------------
[INFO]: Epoch 40 of 200
Training
[40,   100] loss: 1.394e-04
[40,   200] loss: 1.383e-04
Validation
[40,   100] loss: 1.353e-04
[40,   200] loss: 1.353e-04
Training loss: 0.000, train NMSE: -8.695e+00
Validation loss: 0.000, valid_NMSE: -8.140e+00

Best validation loss: -8.140007019042969

Saving best model for epoch: 40

--------------------------------------------------
[INFO]: Epoch 41 of 200
Training
[41,   100] loss: 1.391e-04
[41,   200] loss: 1.359e-04
Validation
[41,   100] loss: 1.340e-04
[41,   200] loss: 1.340e-04
Training loss: 0.000, train NMSE: -8.275e+00
Validation loss: 0.000, valid_NMSE: -8.184e+00

Best validation loss: -8.183752059936523

Saving best model for epoch: 41

--------------------------------------------------
[INFO]: Epoch 42 of 200
Training
[42,   100] loss: 1.338e-04
[42,   200] loss: 1.374e-04
Validation
[42,   100] loss: 1.331e-04
[42,   200] loss: 1.331e-04
Training loss: 0.000, train NMSE: -8.576e+00
Validation loss: 0.000, valid_NMSE: -8.200e+00

Best validation loss: -8.19956111907959

Saving best model for epoch: 42

--------------------------------------------------
[INFO]: Epoch 43 of 200
Training
[43,   100] loss: 1.351e-04
[43,   200] loss: 1.338e-04
Validation
[43,   100] loss: 1.320e-04
[43,   200] loss: 1.320e-04
Training loss: 0.000, train NMSE: -8.262e+00
Validation loss: 0.000, valid_NMSE: -8.221e+00

Best validation loss: -8.22147274017334

Saving best model for epoch: 43

--------------------------------------------------
[INFO]: Epoch 44 of 200
Training
[44,   100] loss: 1.316e-04
[44,   200] loss: 1.339e-04
Validation
[44,   100] loss: 1.304e-04
Training loss: 0.000, train NMSE: -7.025e+00
Validation loss: 0.000, valid_NMSE: -7.211e+00

Best validation loss: -7.211165428161621

Saving best model for epoch: 22

--------------------------------------------------
[INFO]: Epoch 23 of 200
Training
[23,   100] loss: 1.809e-04
[23,   200] loss: 1.787e-04
Validation
[23,   100] loss: 1.696e-04
[23,   200] loss: 1.696e-04
Training loss: 0.000, train NMSE: -7.122e+00
Validation loss: 0.000, valid_NMSE: -7.282e+00

Best validation loss: -7.281978130340576

Saving best model for epoch: 23

--------------------------------------------------
[INFO]: Epoch 24 of 200
Training
[24,   100] loss: 1.761e-04
[24,   200] loss: 1.766e-04
Validation
[24,   100] loss: 1.674e-04
[24,   200] loss: 1.674e-04
Training loss: 0.000, train NMSE: -7.198e+00
Validation loss: 0.000, valid_NMSE: -7.342e+00

Best validation loss: -7.342108726501465

Saving best model for epoch: 24

--------------------------------------------------
[INFO]: Epoch 25 of 200
Training
[25,   100] loss: 1.733e-04
[25,   200] loss: 1.738e-04
Validation
[25,   100] loss: 1.644e-04
[25,   200] loss: 1.644e-04
Training loss: 0.000, train NMSE: -6.662e+00
Validation loss: 0.000, valid_NMSE: -7.406e+00

Best validation loss: -7.406378269195557

Saving best model for epoch: 25

--------------------------------------------------
[INFO]: Epoch 26 of 200
Training
[26,   100] loss: 1.703e-04
[26,   200] loss: 1.703e-04
Validation
[26,   100] loss: 1.619e-04
[26,   200] loss: 1.619e-04
Training loss: 0.000, train NMSE: -7.557e+00
Validation loss: 0.000, valid_NMSE: -7.478e+00

Best validation loss: -7.477907657623291

Saving best model for epoch: 26

--------------------------------------------------
[INFO]: Epoch 27 of 200
Training
[27,   100] loss: 1.660e-04
[27,   200] loss: 1.689e-04
Validation
[27,   100] loss: 1.592e-04
[27,   200] loss: 1.592e-04
Training loss: 0.000, train NMSE: -7.667e+00
Validation loss: 0.000, valid_NMSE: -7.527e+00

Best validation loss: -7.526510238647461

Saving best model for epoch: 27

--------------------------------------------------
[INFO]: Epoch 28 of 200
Training
[28,   100] loss: 1.642e-04
[28,   200] loss: 1.642e-04
Validation
[28,   100] loss: 1.564e-04
[28,   200] loss: 1.564e-04
Training loss: 0.000, train NMSE: -7.253e+00
Validation loss: 0.000, valid_NMSE: -7.584e+00

Best validation loss: -7.583747863769531

Saving best model for epoch: 28

--------------------------------------------------
[INFO]: Epoch 29 of 200
Training
[29,   100] loss: 1.620e-04
[29,   200] loss: 1.609e-04
Validation
[29,   100] loss: 1.544e-04
[29,   200] loss: 1.544e-04
Training loss: 0.000, train NMSE: -7.458e+00
Validation loss: 0.000, valid_NMSE: -7.640e+00

Best validation loss: -7.640089988708496

Saving best model for epoch: 29

--------------------------------------------------
[INFO]: Epoch 30 of 200
Training
[30,   100] loss: 1.572e-04
[30,   200] loss: 1.596e-04
Validation
[30,   100] loss: 1.516e-04
[30,   200] loss: 1.516e-04
Training loss: 0.000, train NMSE: -7.463e+00
Validation loss: 0.000, valid_NMSE: -7.709e+00

Best validation loss: -7.709197044372559

Saving best model for epoch: 30

--------------------------------------------------
[INFO]: Epoch 31 of 200
Training
[31,   100] loss: 1.543e-04
[31,   200] loss: 1.574e-04
Validation
[31,   100] loss: 1.494e-04
[31,   200] loss: 1.494e-04
Training loss: 0.000, train NMSE: -7.659e+00
Validation loss: 0.000, valid_NMSE: -7.778e+00

Best validation loss: -7.777764320373535

Saving best model for epoch: 31

--------------------------------------------------
[INFO]: Epoch 32 of 200
Training
[32,   100] loss: 1.531e-04
[32,   200] loss: 1.537e-04
Validation
[32,   100] loss: 1.469e-04
[32,   200] loss: 1.469e-04
Training loss: 0.000, train NMSE: -7.531e+00
Validation loss: 0.000, valid_NMSE: -7.827e+00

Best validation loss: -7.826623439788818

Saving best model for epoch: 32

--------------------------------------------------
[INFO]: Epoch 33 of 200
Training
[33,   100] loss: 1.509e-04
[33,   200] loss: 1.511e-04
Validation
[33,   100] loss: 1.457e-04
[33,   200] loss: 1.457e-04
Training loss: 0.000, train NMSE: -7.830e+00
Validation loss: 0.000, valid_NMSE: -7.876e+00

Best validation loss: -7.8762922286987305

Saving best model for epoch: 33

--------------------------------------------------
[INFO]: Epoch 34 of 200
Training
[34,   100] loss: 1.508e-04
[34,   200] loss: 1.474e-04
Validation
[34,   100] loss: 1.441e-04
[34,   200] loss: 1.441e-04
Training loss: 0.000, train NMSE: -7.940e+00
Validation loss: 0.000, valid_NMSE: -7.897e+00

Best validation loss: -7.897396564483643

Saving best model for epoch: 34

--------------------------------------------------
[INFO]: Epoch 35 of 200
Training
[35,   100] loss: 1.490e-04
[35,   200] loss: 1.455e-04
Validation
[35,   100] loss: 1.417e-04
[35,   200] loss: 1.417e-04
Training loss: 0.000, train NMSE: -8.265e+00
Validation loss: 0.000, valid_NMSE: -7.969e+00

Best validation loss: -7.969111442565918

Saving best model for epoch: 35

--------------------------------------------------
[INFO]: Epoch 36 of 200
Training
[36,   100] loss: 1.439e-04
[36,   200] loss: 1.463e-04
Validation
[36,   100] loss: 1.408e-04
[36,   200] loss: 1.408e-04
Training loss: 0.000, train NMSE: -8.337e+00
Validation loss: 0.000, valid_NMSE: -7.981e+00

Best validation loss: -7.980971813201904

Saving best model for epoch: 36

--------------------------------------------------
[INFO]: Epoch 37 of 200
Training
[37,   100] loss: 1.440e-04
[37,   200] loss: 1.431e-04
Validation
[37,   100] loss: 1.392e-04
[37,   200] loss: 1.392e-04
Training loss: 0.000, train NMSE: -7.988e+00
Validation loss: 0.000, valid_NMSE: -8.037e+00

Best validation loss: -8.037259101867676

Saving best model for epoch: 37

--------------------------------------------------
[INFO]: Epoch 38 of 200
Training
[38,   100] loss: 1.406e-04
[38,   200] loss: 1.430e-04
Validation
[38,   100] loss: 1.376e-04
[38,   200] loss: 1.376e-04
Training loss: 0.000, train NMSE: -8.048e+00
Validation loss: 0.000, valid_NMSE: -8.092e+00

Best validation loss: -8.091968536376953

Saving best model for epoch: 38

--------------------------------------------------
[INFO]: Epoch 39 of 200
Training
[39,   100] loss: 1.413e-04
[39,   200] loss: 1.390e-04
Validation
[39,   100] loss: 1.369e-04
[39,   200] loss: 1.369e-04
Training loss: 0.000, train NMSE: -7.920e+00
Validation loss: 0.000, valid_NMSE: -8.107e+00

Best validation loss: -8.106979370117188

Saving best model for epoch: 39

--------------------------------------------------
[INFO]: Epoch 40 of 200
Training
[40,   100] loss: 1.392e-04
[40,   200] loss: 1.380e-04
Validation
[40,   100] loss: 1.350e-04
[40,   200] loss: 1.350e-04
Training loss: 0.000, train NMSE: -8.698e+00
Validation loss: 0.000, valid_NMSE: -8.156e+00

Best validation loss: -8.156010627746582

Saving best model for epoch: 40

--------------------------------------------------
[INFO]: Epoch 41 of 200
Training
[41,   100] loss: 1.388e-04
[41,   200] loss: 1.356e-04
Validation
[41,   100] loss: 1.338e-04
[41,   200] loss: 1.338e-04
Training loss: 0.000, train NMSE: -8.287e+00
Validation loss: 0.000, valid_NMSE: -8.191e+00

Best validation loss: -8.19149398803711

Saving best model for epoch: 41

--------------------------------------------------
[INFO]: Epoch 42 of 200
Training
[42,   100] loss: 1.336e-04
[42,   200] loss: 1.372e-04
Validation
[42,   100] loss: 1.328e-04
[42,   200] loss: 1.328e-04
Training loss: 0.000, train NMSE: -8.577e+00
Validation loss: 0.000, valid_NMSE: -8.211e+00

Best validation loss: -8.210598945617676

Saving best model for epoch: 42

--------------------------------------------------
[INFO]: Epoch 43 of 200
Training
[43,   100] loss: 1.348e-04
[43,   200] loss: 1.335e-04
Validation
[43,   100] loss: 1.318e-04
[43,   200] loss: 1.318e-04
Training loss: 0.000, train NMSE: -8.269e+00
Validation loss: 0.000, valid_NMSE: -8.228e+00

Best validation loss: -8.227618217468262

Saving best model for epoch: 43

--------------------------------------------------
[INFO]: Epoch 44 of 200
Training
[44,   100] loss: 1.313e-04
[44,   200] loss: 1.336e-04
Validation
[44,   200] loss: 1.304e-04
Training loss: 0.000, train NMSE: -8.098e+00
Validation loss: 0.000, valid_NMSE: -8.278e+00

Best validation loss: -8.277691841125488

Saving best model for epoch: 44

--------------------------------------------------
[INFO]: Epoch 45 of 200
Training
[45,   100] loss: 1.287e-04
[45,   200] loss: 1.342e-04
Validation
[45,   100] loss: 1.289e-04
[45,   200] loss: 1.289e-04
Training loss: 0.000, train NMSE: -8.393e+00
Validation loss: 0.000, valid_NMSE: -8.334e+00

Best validation loss: -8.333879470825195

Saving best model for epoch: 45

--------------------------------------------------
[INFO]: Epoch 46 of 200
Training
[46,   100] loss: 1.299e-04
[46,   200] loss: 1.296e-04
Validation
[46,   100] loss: 1.283e-04
[46,   200] loss: 1.283e-04
Training loss: 0.000, train NMSE: -9.152e+00
Validation loss: 0.000, valid_NMSE: -8.349e+00

Best validation loss: -8.349163055419922

Saving best model for epoch: 46

--------------------------------------------------
[INFO]: Epoch 47 of 200
Training
[47,   100] loss: 1.278e-04
[47,   200] loss: 1.293e-04
Validation
[47,   100] loss: 1.266e-04
[47,   200] loss: 1.266e-04
Training loss: 0.000, train NMSE: -7.931e+00
Validation loss: 0.000, valid_NMSE: -8.394e+00

Best validation loss: -8.394204139709473

Saving best model for epoch: 47

--------------------------------------------------
[INFO]: Epoch 48 of 200
Training
[48,   100] loss: 1.256e-04
[48,   200] loss: 1.283e-04
Validation
[48,   100] loss: 1.263e-04
[48,   200] loss: 1.263e-04
Training loss: 0.000, train NMSE: -8.029e+00
Validation loss: 0.000, valid_NMSE: -8.370e+00
--------------------------------------------------
[INFO]: Epoch 49 of 200
Training
[49,   100] loss: 1.251e-04
[49,   200] loss: 1.262e-04
Validation
[49,   100] loss: 1.246e-04
[49,   200] loss: 1.246e-04
Training loss: 0.000, train NMSE: -8.111e+00
Validation loss: 0.000, valid_NMSE: -8.471e+00

Best validation loss: -8.47087574005127

Saving best model for epoch: 49

--------------------------------------------------
[INFO]: Epoch 50 of 200
Training
[50,   100] loss: 1.225e-04
[50,   200] loss: 1.267e-04
Validation
[50,   100] loss: 1.239e-04
[50,   200] loss: 1.239e-04
Training loss: 0.000, train NMSE: -8.390e+00
Validation loss: 0.000, valid_NMSE: -8.469e+00
--------------------------------------------------
[INFO]: Epoch 51 of 200
Training
[51,   100] loss: 1.220e-04
[51,   200] loss: 1.240e-04
Validation
[51,   100] loss: 1.231e-04
[51,   200] loss: 1.231e-04
Training loss: 0.000, train NMSE: -7.932e+00
Validation loss: 0.000, valid_NMSE: -8.528e+00

Best validation loss: -8.527763366699219

Saving best model for epoch: 51

--------------------------------------------------
[INFO]: Epoch 52 of 200
Training
[52,   100] loss: 1.200e-04
[52,   200] loss: 1.249e-04
Validation
[52,   100] loss: 1.226e-04
[52,   200] loss: 1.226e-04
Training loss: 0.000, train NMSE: -8.740e+00
Validation loss: 0.000, valid_NMSE: -8.498e+00
--------------------------------------------------
[INFO]: Epoch 53 of 200
Training
[53,   100] loss: 1.237e-04
[53,   200] loss: 1.178e-04
Validation
[53,   100] loss: 1.207e-04
[53,   200] loss: 1.207e-04
Training loss: 0.000, train NMSE: -8.687e+00
Validation loss: 0.000, valid_NMSE: -8.612e+00

Best validation loss: -8.61240005493164

Saving best model for epoch: 53

--------------------------------------------------
[INFO]: Epoch 54 of 200
Training
[54,   100] loss: 1.192e-04
[54,   200] loss: 1.205e-04
Validation
[54,   100] loss: 1.203e-04
[54,   200] loss: 1.203e-04
Training loss: 0.000, train NMSE: -8.552e+00
Validation loss: 0.000, valid_NMSE: -8.615e+00

Best validation loss: -8.615056037902832

Saving best model for epoch: 54

--------------------------------------------------
[INFO]: Epoch 55 of 200
Training
[55,   100] loss: 1.187e-04
[55,   200] loss: 1.191e-04
Validation
[55,   100] loss: 1.202e-04
[55,   200] loss: 1.202e-04
Training loss: 0.000, train NMSE: -8.641e+00
Validation loss: 0.000, valid_NMSE: -8.594e+00
--------------------------------------------------
[INFO]: Epoch 56 of 200
Training
[56,   100] loss: 1.194e-04
[56,   200] loss: 1.162e-04
Validation
[56,   100] loss: 1.186e-04
[56,   200] loss: 1.186e-04
Training loss: 0.000, train NMSE: -9.015e+00
Validation loss: 0.000, valid_NMSE: -8.682e+00

Best validation loss: -8.682384490966797

Saving best model for epoch: 56

--------------------------------------------------
[INFO]: Epoch 57 of 200
Training
[57,   100] loss: 1.155e-04
[57,   200] loss: 1.181e-04
Validation
[57,   100] loss: 1.177e-04
[57,   200] loss: 1.177e-04
Training loss: 0.000, train NMSE: -8.626e+00
Validation loss: 0.000, valid_NMSE: -8.697e+00

Best validation loss: -8.696511268615723

Saving best model for epoch: 57

--------------------------------------------------
[INFO]: Epoch 58 of 200
Training
[58,   100] loss: 1.168e-04
[58,   200] loss: 1.151e-04
Validation
[58,   100] loss: 1.174e-04
[58,   200] loss: 1.174e-04
Training loss: 0.000, train NMSE: -9.231e+00
Validation loss: 0.000, valid_NMSE: -8.676e+00
--------------------------------------------------
[INFO]: Epoch 59 of 200
Training
[59,   100] loss: 1.144e-04
[59,   200] loss: 1.153e-04
Validation
[59,   100] loss: 1.166e-04
[59,   200] loss: 1.166e-04
Training loss: 0.000, train NMSE: -9.131e+00
Validation loss: 0.000, valid_NMSE: -8.758e+00

Best validation loss: -8.758110046386719

Saving best model for epoch: 59

--------------------------------------------------
[INFO]: Epoch 60 of 200
Training
[60,   100] loss: 1.134e-04
[60,   200] loss: 1.145e-04
Validation
[60,   100] loss: 1.161e-04
[60,   200] loss: 1.161e-04
Training loss: 0.000, train NMSE: -9.335e+00
Validation loss: 0.000, valid_NMSE: -8.739e+00
--------------------------------------------------
[INFO]: Epoch 61 of 200
Training
[61,   100] loss: 1.127e-04
[61,   200] loss: 1.134e-04
Validation
[61,   100] loss: 1.160e-04
[61,   200] loss: 1.160e-04
Training loss: 0.000, train NMSE: -9.371e+00
Validation loss: 0.000, valid_NMSE: -8.730e+00
--------------------------------------------------
[INFO]: Epoch 62 of 200
Training
[62,   100] loss: 1.120e-04
[62,   200] loss: 1.126e-04
Validation
[62,   100] loss: 1.150e-04
[62,   200] loss: 1.150e-04
Training loss: 0.000, train NMSE: -8.914e+00
Validation loss: 0.000, valid_NMSE: -8.780e+00

Best validation loss: -8.780325889587402

Saving best model for epoch: 62

--------------------------------------------------
[INFO]: Epoch 63 of 200
Training
[63,   100] loss: 1.113e-04
[63,   200] loss: 1.121e-04
Validation
[63,   100] loss: 1.142e-04
[63,   200] loss: 1.142e-04
Training loss: 0.000, train NMSE: -9.205e+00
Validation loss: 0.000, valid_NMSE: -8.786e+00

Best validation loss: -8.78561782836914

Saving best model for epoch: 63

--------------------------------------------------
[INFO]: Epoch 64 of 200
Training
[64,   100] loss: 1.102e-04
[64,   200] loss: 1.110e-04
Validation
[64,   100] loss: 1.145e-04
[64,   200] loss: 1.145e-04
Training loss: 0.000, train NMSE: -9.220e+00
Validation loss: 0.000, valid_NMSE: -8.788e+00

Best validation loss: -8.787842750549316

Saving best model for epoch: 64

--------------------------------------------------
[INFO]: Epoch 65 of 200
Training
[65,   100] loss: 1.090e-04
[65,   200] loss: 1.111e-04
Validation
[65,   100] loss: 1.130e-04
[65,   200] loss: 1.130e-04
Training loss: 0.000, train NMSE: -8.552e+00
Validation loss: 0.000, valid_NMSE: -8.846e+00

Best validation loss: -8.846397399902344

Saving best model for epoch: 65

--------------------------------------------------
[INFO]: Epoch 66 of 200
Training
[66,   100] loss: 1.088e-04
[66,   200] loss: 1.097e-04
Validation
[66,   100] loss: 1.132e-04
[66,   200] loss: 1.132e-04
Training loss: 0.000, train NMSE: -9.489e+00
Validation loss: 0.000, valid_NMSE: -8.850e+00

Best validation loss: -8.850008964538574

Saving best model for epoch: 66

--------------------------------------------------
[INFO]: Epoch 67 of 200
Training
[67,   100] loss: 1.082e-04
[67,   200] loss: 1.084e-04
Validation
[67,   100] loss: 1.115e-04
[67,   200] loss: 1.115e-04
Training loss: 0.000, train NMSE: -8.941e+00
Validation loss: 0.000, valid_NMSE: -8.927e+00
[44,   100] loss: 1.303e-04
[44,   200] loss: 1.303e-04
Training loss: 0.000, train NMSE: -8.112e+00
Validation loss: 0.000, valid_NMSE: -8.285e+00

Best validation loss: -8.284933090209961

Saving best model for epoch: 44

--------------------------------------------------
[INFO]: Epoch 45 of 200
Training
[45,   100] loss: 1.285e-04
[45,   200] loss: 1.340e-04
Validation
[45,   100] loss: 1.287e-04
[45,   200] loss: 1.287e-04
Training loss: 0.000, train NMSE: -8.406e+00
Validation loss: 0.000, valid_NMSE: -8.348e+00

Best validation loss: -8.34825611114502

Saving best model for epoch: 45

--------------------------------------------------
[INFO]: Epoch 46 of 200
Training
[46,   100] loss: 1.296e-04
[46,   200] loss: 1.293e-04
Validation
[46,   100] loss: 1.281e-04
[46,   200] loss: 1.281e-04
Training loss: 0.000, train NMSE: -9.169e+00
Validation loss: 0.000, valid_NMSE: -8.355e+00

Best validation loss: -8.355064392089844

Saving best model for epoch: 46

--------------------------------------------------
[INFO]: Epoch 47 of 200
Training
[47,   100] loss: 1.276e-04
[47,   200] loss: 1.290e-04
Validation
[47,   100] loss: 1.264e-04
[47,   200] loss: 1.264e-04
Training loss: 0.000, train NMSE: -7.954e+00
Validation loss: 0.000, valid_NMSE: -8.403e+00

Best validation loss: -8.402606964111328

Saving best model for epoch: 47

--------------------------------------------------
[INFO]: Epoch 48 of 200
Training
[48,   100] loss: 1.253e-04
[48,   200] loss: 1.280e-04
Validation
[48,   100] loss: 1.259e-04
[48,   200] loss: 1.259e-04
Training loss: 0.000, train NMSE: -8.035e+00
Validation loss: 0.000, valid_NMSE: -8.385e+00
--------------------------------------------------
[INFO]: Epoch 49 of 200
Training
[49,   100] loss: 1.247e-04
[49,   200] loss: 1.260e-04
Validation
[49,   100] loss: 1.244e-04
[49,   200] loss: 1.244e-04
Training loss: 0.000, train NMSE: -8.123e+00
Validation loss: 0.000, valid_NMSE: -8.479e+00

Best validation loss: -8.479365348815918

Saving best model for epoch: 49

--------------------------------------------------
[INFO]: Epoch 50 of 200
Training
[50,   100] loss: 1.223e-04
[50,   200] loss: 1.263e-04
Validation
[50,   100] loss: 1.236e-04
[50,   200] loss: 1.236e-04
Training loss: 0.000, train NMSE: -8.407e+00
Validation loss: 0.000, valid_NMSE: -8.485e+00

Best validation loss: -8.484848022460938

Saving best model for epoch: 50

--------------------------------------------------
[INFO]: Epoch 51 of 200
Training
[51,   100] loss: 1.217e-04
[51,   200] loss: 1.238e-04
Validation
[51,   100] loss: 1.228e-04
[51,   200] loss: 1.228e-04
Training loss: 0.000, train NMSE: -7.938e+00
Validation loss: 0.000, valid_NMSE: -8.539e+00

Best validation loss: -8.53903579711914

Saving best model for epoch: 51

--------------------------------------------------
[INFO]: Epoch 52 of 200
Training
[52,   100] loss: 1.197e-04
[52,   200] loss: 1.247e-04
Validation
[52,   100] loss: 1.227e-04
[52,   200] loss: 1.227e-04
Training loss: 0.000, train NMSE: -8.746e+00
Validation loss: 0.000, valid_NMSE: -8.489e+00
--------------------------------------------------
[INFO]: Epoch 53 of 200
Training
[53,   100] loss: 1.235e-04
[53,   200] loss: 1.175e-04
Validation
[53,   100] loss: 1.206e-04
[53,   200] loss: 1.206e-04
Training loss: 0.000, train NMSE: -8.699e+00
Validation loss: 0.000, valid_NMSE: -8.621e+00

Best validation loss: -8.621484756469727

Saving best model for epoch: 53

--------------------------------------------------
[INFO]: Epoch 54 of 200
Training
[54,   100] loss: 1.190e-04
[54,   200] loss: 1.202e-04
Validation
[54,   100] loss: 1.200e-04
[54,   200] loss: 1.200e-04
Training loss: 0.000, train NMSE: -8.555e+00
Validation loss: 0.000, valid_NMSE: -8.628e+00

Best validation loss: -8.628082275390625

Saving best model for epoch: 54

--------------------------------------------------
[INFO]: Epoch 55 of 200
Training
[55,   100] loss: 1.185e-04
[55,   200] loss: 1.188e-04
Validation
[55,   100] loss: 1.200e-04
[55,   200] loss: 1.200e-04
Training loss: 0.000, train NMSE: -8.652e+00
Validation loss: 0.000, valid_NMSE: -8.611e+00
--------------------------------------------------
[INFO]: Epoch 56 of 200
Training
[56,   100] loss: 1.192e-04
[56,   200] loss: 1.160e-04
Validation
[56,   100] loss: 1.184e-04
[56,   200] loss: 1.184e-04
Training loss: 0.000, train NMSE: -9.017e+00
Validation loss: 0.000, valid_NMSE: -8.708e+00

Best validation loss: -8.708147048950195

Saving best model for epoch: 56

--------------------------------------------------
[INFO]: Epoch 57 of 200
Training
[57,   100] loss: 1.153e-04
[57,   200] loss: 1.178e-04
Validation
[57,   100] loss: 1.175e-04
[57,   200] loss: 1.175e-04
Training loss: 0.000, train NMSE: -8.638e+00
Validation loss: 0.000, valid_NMSE: -8.716e+00

Best validation loss: -8.715893745422363

Saving best model for epoch: 57

--------------------------------------------------
[INFO]: Epoch 58 of 200
Training
[58,   100] loss: 1.166e-04
[58,   200] loss: 1.148e-04
Validation
[58,   100] loss: 1.171e-04
[58,   200] loss: 1.171e-04
Training loss: 0.000, train NMSE: -9.238e+00
Validation loss: 0.000, valid_NMSE: -8.707e+00
--------------------------------------------------
[INFO]: Epoch 59 of 200
Training
[59,   100] loss: 1.142e-04
[59,   200] loss: 1.151e-04
Validation
[59,   100] loss: 1.164e-04
[59,   200] loss: 1.164e-04
Training loss: 0.000, train NMSE: -9.143e+00
Validation loss: 0.000, valid_NMSE: -8.772e+00

Best validation loss: -8.771970748901367

Saving best model for epoch: 59

--------------------------------------------------
[INFO]: Epoch 60 of 200
Training
[60,   100] loss: 1.131e-04
[60,   200] loss: 1.143e-04
Validation
[60,   100] loss: 1.160e-04
[60,   200] loss: 1.160e-04
Training loss: 0.000, train NMSE: -9.349e+00
Validation loss: 0.000, valid_NMSE: -8.759e+00
--------------------------------------------------
[INFO]: Epoch 61 of 200
Training
[61,   100] loss: 1.125e-04
[61,   200] loss: 1.132e-04
Validation
[61,   100] loss: 1.159e-04
[61,   200] loss: 1.159e-04
Training loss: 0.000, train NMSE: -9.379e+00
Validation loss: 0.000, valid_NMSE: -8.757e+00
--------------------------------------------------
[INFO]: Epoch 62 of 200
Training
[62,   100] loss: 1.118e-04
[62,   200] loss: 1.124e-04
Validation
[62,   100] loss: 1.151e-04
[62,   200] loss: 1.151e-04
Training loss: 0.000, train NMSE: -8.922e+00
Validation loss: 0.000, valid_NMSE: -8.768e+00
--------------------------------------------------
[INFO]: Epoch 63 of 200
Training
[63,   100] loss: 1.112e-04
[63,   200] loss: 1.119e-04
Validation
[63,   100] loss: 1.141e-04
[63,   200] loss: 1.141e-04
Training loss: 0.000, train NMSE: -9.208e+00
Validation loss: 0.000, valid_NMSE: -8.811e+00

Best validation loss: -8.810940742492676

Saving best model for epoch: 63

--------------------------------------------------
[INFO]: Epoch 64 of 200
Training
[64,   100] loss: 1.100e-04
[64,   200] loss: 1.108e-04
Validation
[64,   100] loss: 1.145e-04
[64,   200] loss: 1.145e-04
Training loss: 0.000, train NMSE: -9.234e+00
Validation loss: 0.000, valid_NMSE: -8.807e+00
--------------------------------------------------
[INFO]: Epoch 65 of 200
Training
[65,   100] loss: 1.087e-04
[65,   200] loss: 1.108e-04
Validation
[65,   100] loss: 1.128e-04
[65,   200] loss: 1.128e-04
Training loss: 0.000, train NMSE: -8.576e+00
Validation loss: 0.000, valid_NMSE: -8.881e+00

Best validation loss: -8.881128311157227

Saving best model for epoch: 65

--------------------------------------------------
[INFO]: Epoch 66 of 200
Training
[66,   100] loss: 1.085e-04
[66,   200] loss: 1.095e-04
Validation
[66,   100] loss: 1.130e-04
[66,   200] loss: 1.130e-04
Training loss: 0.000, train NMSE: -9.491e+00
Validation loss: 0.000, valid_NMSE: -8.862e+00
--------------------------------------------------
[INFO]: Epoch 67 of 200
Training
[67,   100] loss: 1.079e-04
[67,   200] loss: 1.082e-04
Validation
[67,   100] loss: 1.113e-04
[67,   200] loss: 1.113e-04
Training loss: 0.000, train NMSE: -8.934e+00
Validation loss: 0.000, valid_NMSE: -8.940e+00

Best validation loss: -8.939916610717773

Saving best model for epoch: 67

--------------------------------------------------

Best validation loss: -8.926806449890137

Saving best model for epoch: 67

--------------------------------------------------
[INFO]: Epoch 68 of 200
Training
[68,   100] loss: 1.072e-04
[68,   200] loss: 1.081e-04
Validation
[68,   100] loss: 1.114e-04
[68,   200] loss: 1.114e-04
Training loss: 0.000, train NMSE: -8.844e+00
Validation loss: 0.000, valid_NMSE: -8.918e+00
--------------------------------------------------
[INFO]: Epoch 69 of 200
Training
[69,   100] loss: 1.062e-04
[69,   200] loss: 1.077e-04
Validation
[69,   100] loss: 1.109e-04
[69,   200] loss: 1.109e-04
Training loss: 0.000, train NMSE: -9.042e+00
Validation loss: 0.000, valid_NMSE: -8.940e+00

Best validation loss: -8.94043254852295

Saving best model for epoch: 69

--------------------------------------------------
[INFO]: Epoch 70 of 200
Training
[70,   100] loss: 1.043e-04
[70,   200] loss: 1.079e-04
Validation
[70,   100] loss: 1.105e-04
[70,   200] loss: 1.105e-04
Training loss: 0.000, train NMSE: -8.833e+00
Validation loss: 0.000, valid_NMSE: -8.966e+00

Best validation loss: -8.965834617614746

Saving best model for epoch: 70

--------------------------------------------------
[INFO]: Epoch 71 of 200
Training
[71,   100] loss: 1.055e-04
[71,   200] loss: 1.054e-04
Validation
[71,   100] loss: 1.103e-04
[71,   200] loss: 1.103e-04
Training loss: 0.000, train NMSE: -9.550e+00
Validation loss: 0.000, valid_NMSE: -8.984e+00

Best validation loss: -8.984402656555176

Saving best model for epoch: 71

--------------------------------------------------
[INFO]: Epoch 72 of 200
Training
[72,   100] loss: 1.039e-04
[72,   200] loss: 1.057e-04
Validation
[72,   100] loss: 1.094e-04
[72,   200] loss: 1.094e-04
Training loss: 0.000, train NMSE: -9.117e+00
Validation loss: 0.000, valid_NMSE: -9.002e+00

Best validation loss: -9.00180435180664

Saving best model for epoch: 72

--------------------------------------------------
[INFO]: Epoch 73 of 200
Training
[73,   100] loss: 1.019e-04
[73,   200] loss: 1.063e-04
Validation
[73,   100] loss: 1.111e-04
[73,   200] loss: 1.111e-04
Training loss: 0.000, train NMSE: -9.117e+00
Validation loss: 0.000, valid_NMSE: -8.890e+00
--------------------------------------------------
[INFO]: Epoch 74 of 200
Training
[74,   100] loss: 1.016e-04
[74,   200] loss: 1.051e-04
Validation
[74,   100] loss: 1.088e-04
[74,   200] loss: 1.088e-04
Training loss: 0.000, train NMSE: -9.250e+00
Validation loss: 0.000, valid_NMSE: -9.021e+00

Best validation loss: -9.020583152770996

Saving best model for epoch: 74

--------------------------------------------------
[INFO]: Epoch 75 of 200
Training
[75,   100] loss: 1.028e-04
[75,   200] loss: 1.029e-04
Validation
[75,   100] loss: 1.095e-04
[75,   200] loss: 1.095e-04
Training loss: 0.000, train NMSE: -9.018e+00
Validation loss: 0.000, valid_NMSE: -8.987e+00
--------------------------------------------------
[INFO]: Epoch 76 of 200
Training
[76,   100] loss: 1.018e-04
[76,   200] loss: 1.020e-04
Validation
[76,   100] loss: 1.084e-04
[76,   200] loss: 1.084e-04
Training loss: 0.000, train NMSE: -9.097e+00
Validation loss: 0.000, valid_NMSE: -8.996e+00
--------------------------------------------------
[INFO]: Epoch 77 of 200
Training
[77,   100] loss: 1.006e-04
[77,   200] loss: 1.021e-04
Validation
[77,   100] loss: 1.073e-04
[77,   200] loss: 1.073e-04
Training loss: 0.000, train NMSE: -1.007e+01
Validation loss: 0.000, valid_NMSE: -9.093e+00

Best validation loss: -9.092529296875

Saving best model for epoch: 77

--------------------------------------------------
[INFO]: Epoch 78 of 200
Training
[78,   100] loss: 1.013e-04
[78,   200] loss: 9.989e-05
Validation
[78,   100] loss: 1.068e-04
[78,   200] loss: 1.068e-04
Training loss: 0.000, train NMSE: -9.682e+00
Validation loss: 0.000, valid_NMSE: -9.106e+00

Best validation loss: -9.106334686279297

Saving best model for epoch: 78

--------------------------------------------------
[INFO]: Epoch 79 of 200
Training
[79,   100] loss: 9.970e-05
[79,   200] loss: 1.003e-04
Validation
[79,   100] loss: 1.067e-04
[79,   200] loss: 1.067e-04
Training loss: 0.000, train NMSE: -9.141e+00
Validation loss: 0.000, valid_NMSE: -9.084e+00
--------------------------------------------------
[INFO]: Epoch 80 of 200
Training
[80,   100] loss: 9.840e-05
[80,   200] loss: 1.003e-04
Validation
[80,   100] loss: 1.062e-04
[80,   200] loss: 1.062e-04
Training loss: 0.000, train NMSE: -9.551e+00
Validation loss: 0.000, valid_NMSE: -9.106e+00
--------------------------------------------------
[INFO]: Epoch 81 of 200
Training
[81,   100] loss: 9.899e-05
[81,   200] loss: 9.789e-05
Validation
[81,   100] loss: 1.056e-04
[81,   200] loss: 1.056e-04
Training loss: 0.000, train NMSE: -9.641e+00
Validation loss: 0.000, valid_NMSE: -9.148e+00

Best validation loss: -9.148154258728027

Saving best model for epoch: 81

--------------------------------------------------
[INFO]: Epoch 82 of 200
Training
[82,   100] loss: 9.699e-05
[82,   200] loss: 9.873e-05
Validation
[82,   100] loss: 1.050e-04
[82,   200] loss: 1.050e-04
Training loss: 0.000, train NMSE: -9.685e+00
Validation loss: 0.000, valid_NMSE: -9.133e+00
--------------------------------------------------
[INFO]: Epoch 83 of 200
Training
[83,   100] loss: 9.583e-05
[83,   200] loss: 9.847e-05
Validation
[83,   100] loss: 1.047e-04
[83,   200] loss: 1.047e-04
Training loss: 0.000, train NMSE: -8.856e+00
Validation loss: 0.000, valid_NMSE: -9.170e+00

Best validation loss: -9.170373916625977

Saving best model for epoch: 83

--------------------------------------------------
[INFO]: Epoch 84 of 200
Training
[84,   100] loss: 9.623e-05
[84,   200] loss: 9.681e-05
Validation
[84,   100] loss: 1.040e-04
[84,   200] loss: 1.040e-04
Training loss: 0.000, train NMSE: -9.343e+00
Validation loss: 0.000, valid_NMSE: -9.181e+00

Best validation loss: -9.181134223937988

Saving best model for epoch: 84

--------------------------------------------------
[INFO]: Epoch 85 of 200
Training
[85,   100] loss: 9.585e-05
[85,   200] loss: 9.588e-05
Validation
[85,   100] loss: 1.034e-04
[85,   200] loss: 1.034e-04
Training loss: 0.000, train NMSE: -9.673e+00
Validation loss: 0.000, valid_NMSE: -9.215e+00

Best validation loss: -9.214612007141113

Saving best model for epoch: 85

--------------------------------------------------
[INFO]: Epoch 86 of 200
Training
[86,   100] loss: 9.399e-05
[86,   200] loss: 9.643e-05
Validation
[86,   100] loss: 1.035e-04
[86,   200] loss: 1.035e-04
Training loss: 0.000, train NMSE: -9.553e+00
Validation loss: 0.000, valid_NMSE: -9.194e+00
--------------------------------------------------
[INFO]: Epoch 87 of 200
Training
[87,   100] loss: 9.449e-05
[87,   200] loss: 9.487e-05
Validation
[87,   100] loss: 1.031e-04
[87,   200] loss: 1.031e-04
Training loss: 0.000, train NMSE: -1.071e+01
Validation loss: 0.000, valid_NMSE: -9.200e+00
--------------------------------------------------
[INFO]: Epoch 88 of 200
Training
[88,   100] loss: 9.288e-05
[88,   200] loss: 9.520e-05
Validation
[88,   100] loss: 1.018e-04
[88,   200] loss: 1.018e-04
Training loss: 0.000, train NMSE: -1.019e+01
Validation loss: 0.000, valid_NMSE: -9.277e+00

Best validation loss: -9.276525497436523

Saving best model for epoch: 88

--------------------------------------------------
[INFO]: Epoch 89 of 200
Training
[89,   100] loss: 9.384e-05
[89,   200] loss: 9.306e-05
Validation
[89,   100] loss: 1.022e-04
[89,   200] loss: 1.022e-04
Training loss: 0.000, train NMSE: -9.105e+00
Validation loss: 0.000, valid_NMSE: -9.231e+00
--------------------------------------------------
[INFO]: Epoch 90 of 200
Training
[90,   100] loss: 9.465e-05
[90,   200] loss: 9.124e-05
Validation
[90,   100] loss: 1.014e-04
[90,   200] loss: 1.014e-04
Training loss: 0.000, train NMSE: -9.748e+00
Validation loss: 0.000, valid_NMSE: -9.249e+00
--------------------------------------------------
[INFO]: Epoch 91 of 200
Training
[91,   100] loss: 9.214e-05
[91,   200] loss: 9.207e-05
Validation
[91,   100] loss: 1.010e-04
[91,   200] loss: 1.010e-04
Training loss: 0.000, train NMSE: -1.046e+01
Validation loss: 0.000, valid_NMSE: -9.279e+00

Best validation loss: -9.279369354248047
[INFO]: Epoch 68 of 200
Training
[68,   100] loss: 1.069e-04
[68,   200] loss: 1.078e-04
Validation
[68,   100] loss: 1.110e-04
[68,   200] loss: 1.110e-04
Training loss: 0.000, train NMSE: -8.860e+00
Validation loss: 0.000, valid_NMSE: -8.950e+00

Best validation loss: -8.949666023254395

Saving best model for epoch: 68

--------------------------------------------------
[INFO]: Epoch 69 of 200
Training
[69,   100] loss: 1.060e-04
[69,   200] loss: 1.075e-04
Validation
[69,   100] loss: 1.107e-04
[69,   200] loss: 1.107e-04
Training loss: 0.000, train NMSE: -9.077e+00
Validation loss: 0.000, valid_NMSE: -8.952e+00

Best validation loss: -8.952024459838867

Saving best model for epoch: 69

--------------------------------------------------
[INFO]: Epoch 70 of 200
Training
[70,   100] loss: 1.040e-04
[70,   200] loss: 1.077e-04
Validation
[70,   100] loss: 1.101e-04
[70,   200] loss: 1.101e-04
Training loss: 0.000, train NMSE: -8.851e+00
Validation loss: 0.000, valid_NMSE: -8.990e+00

Best validation loss: -8.989809036254883

Saving best model for epoch: 70

--------------------------------------------------
[INFO]: Epoch 71 of 200
Training
[71,   100] loss: 1.053e-04
[71,   200] loss: 1.052e-04
Validation
[71,   100] loss: 1.099e-04
[71,   200] loss: 1.099e-04
Training loss: 0.000, train NMSE: -9.554e+00
Validation loss: 0.000, valid_NMSE: -9.002e+00

Best validation loss: -9.00154972076416

Saving best model for epoch: 71

--------------------------------------------------
[INFO]: Epoch 72 of 200
Training
[72,   100] loss: 1.037e-04
[72,   200] loss: 1.054e-04
Validation
[72,   100] loss: 1.091e-04
[72,   200] loss: 1.091e-04
Training loss: 0.000, train NMSE: -9.145e+00
Validation loss: 0.000, valid_NMSE: -9.021e+00

Best validation loss: -9.020520210266113

Saving best model for epoch: 72

--------------------------------------------------
[INFO]: Epoch 73 of 200
Training
[73,   100] loss: 1.016e-04
[73,   200] loss: 1.061e-04
Validation
[73,   100] loss: 1.102e-04
[73,   200] loss: 1.102e-04
Training loss: 0.000, train NMSE: -9.135e+00
Validation loss: 0.000, valid_NMSE: -8.947e+00
--------------------------------------------------
[INFO]: Epoch 74 of 200
Training
[74,   100] loss: 1.013e-04
[74,   200] loss: 1.047e-04
Validation
[74,   100] loss: 1.082e-04
[74,   200] loss: 1.082e-04
Training loss: 0.000, train NMSE: -9.271e+00
Validation loss: 0.000, valid_NMSE: -9.054e+00

Best validation loss: -9.053972244262695

Saving best model for epoch: 74

--------------------------------------------------
[INFO]: Epoch 75 of 200
Training
[75,   100] loss: 1.024e-04
[75,   200] loss: 1.027e-04
Validation
[75,   100] loss: 1.093e-04
[75,   200] loss: 1.093e-04
Training loss: 0.000, train NMSE: -9.045e+00
Validation loss: 0.000, valid_NMSE: -9.009e+00
--------------------------------------------------
[INFO]: Epoch 76 of 200
Training
[76,   100] loss: 1.015e-04
[76,   200] loss: 1.017e-04
Validation
[76,   100] loss: 1.080e-04
[76,   200] loss: 1.080e-04
Training loss: 0.000, train NMSE: -9.099e+00
Validation loss: 0.000, valid_NMSE: -9.018e+00
--------------------------------------------------
[INFO]: Epoch 77 of 200
Training
[77,   100] loss: 1.003e-04
[77,   200] loss: 1.017e-04
Validation
[77,   100] loss: 1.071e-04
[77,   200] loss: 1.071e-04
Training loss: 0.000, train NMSE: -1.008e+01
Validation loss: 0.000, valid_NMSE: -9.108e+00

Best validation loss: -9.107937812805176

Saving best model for epoch: 77

--------------------------------------------------
[INFO]: Epoch 78 of 200
Training
[78,   100] loss: 1.009e-04
[78,   200] loss: 9.962e-05
Validation
[78,   100] loss: 1.064e-04
[78,   200] loss: 1.064e-04
Training loss: 0.000, train NMSE: -9.704e+00
Validation loss: 0.000, valid_NMSE: -9.136e+00

Best validation loss: -9.135651588439941

Saving best model for epoch: 78

--------------------------------------------------
[INFO]: Epoch 79 of 200
Training
[79,   100] loss: 9.948e-05
[79,   200] loss: 1.000e-04
Validation
[79,   100] loss: 1.064e-04
[79,   200] loss: 1.064e-04
Training loss: 0.000, train NMSE: -9.166e+00
Validation loss: 0.000, valid_NMSE: -9.113e+00
--------------------------------------------------
[INFO]: Epoch 80 of 200
Training
[80,   100] loss: 9.806e-05
[80,   200] loss: 1.000e-04
Validation
[80,   100] loss: 1.058e-04
[80,   200] loss: 1.058e-04
Training loss: 0.000, train NMSE: -9.560e+00
Validation loss: 0.000, valid_NMSE: -9.132e+00
--------------------------------------------------
[INFO]: Epoch 81 of 200
Training
[81,   100] loss: 9.872e-05
[81,   200] loss: 9.761e-05
Validation
[81,   100] loss: 1.053e-04
[81,   200] loss: 1.053e-04
Training loss: 0.000, train NMSE: -9.641e+00
Validation loss: 0.000, valid_NMSE: -9.180e+00

Best validation loss: -9.180231094360352

Saving best model for epoch: 81

--------------------------------------------------
[INFO]: Epoch 82 of 200
Training
[82,   100] loss: 9.671e-05
[82,   200] loss: 9.842e-05
Validation
[82,   100] loss: 1.047e-04
[82,   200] loss: 1.047e-04
Training loss: 0.000, train NMSE: -9.685e+00
Validation loss: 0.000, valid_NMSE: -9.156e+00
--------------------------------------------------
[INFO]: Epoch 83 of 200
Training
[83,   100] loss: 9.560e-05
[83,   200] loss: 9.808e-05
Validation
[83,   100] loss: 1.044e-04
[83,   200] loss: 1.044e-04
Training loss: 0.000, train NMSE: -8.869e+00
Validation loss: 0.000, valid_NMSE: -9.179e+00
--------------------------------------------------
[INFO]: Epoch 84 of 200
Training
[84,   100] loss: 9.601e-05
[84,   200] loss: 9.658e-05
Validation
[84,   100] loss: 1.037e-04
[84,   200] loss: 1.037e-04
Training loss: 0.000, train NMSE: -9.353e+00
Validation loss: 0.000, valid_NMSE: -9.204e+00

Best validation loss: -9.204010009765625

Saving best model for epoch: 84

--------------------------------------------------
[INFO]: Epoch 85 of 200
Training
[85,   100] loss: 9.564e-05
[85,   200] loss: 9.562e-05
Validation
[85,   100] loss: 1.033e-04
[85,   200] loss: 1.033e-04
Training loss: 0.000, train NMSE: -9.673e+00
Validation loss: 0.000, valid_NMSE: -9.231e+00

Best validation loss: -9.2307710647583

Saving best model for epoch: 85

--------------------------------------------------
[INFO]: Epoch 86 of 200
Training
[86,   100] loss: 9.381e-05
[86,   200] loss: 9.617e-05
Validation
[86,   100] loss: 1.037e-04
[86,   200] loss: 1.037e-04
Training loss: 0.000, train NMSE: -9.556e+00
Validation loss: 0.000, valid_NMSE: -9.197e+00
--------------------------------------------------
[INFO]: Epoch 87 of 200
Training
[87,   100] loss: 9.428e-05
[87,   200] loss: 9.466e-05
Validation
[87,   100] loss: 1.031e-04
[87,   200] loss: 1.031e-04
Training loss: 0.000, train NMSE: -1.071e+01
Validation loss: 0.000, valid_NMSE: -9.220e+00
--------------------------------------------------
[INFO]: Epoch 88 of 200
Training
[88,   100] loss: 9.270e-05
[88,   200] loss: 9.505e-05
Validation
[88,   100] loss: 1.017e-04
[88,   200] loss: 1.017e-04
Training loss: 0.000, train NMSE: -1.020e+01
Validation loss: 0.000, valid_NMSE: -9.301e+00

Best validation loss: -9.300995826721191

Saving best model for epoch: 88

--------------------------------------------------
[INFO]: Epoch 89 of 200
Training
[89,   100] loss: 9.373e-05
[89,   200] loss: 9.289e-05
Validation
[89,   100] loss: 1.019e-04
[89,   200] loss: 1.019e-04
Training loss: 0.000, train NMSE: -9.123e+00
Validation loss: 0.000, valid_NMSE: -9.256e+00
--------------------------------------------------
[INFO]: Epoch 90 of 200
Training
[90,   100] loss: 9.442e-05
[90,   200] loss: 9.105e-05
Validation
[90,   100] loss: 1.014e-04
[90,   200] loss: 1.014e-04
Training loss: 0.000, train NMSE: -9.756e+00
Validation loss: 0.000, valid_NMSE: -9.261e+00
--------------------------------------------------
[INFO]: Epoch 91 of 200
Training
[91,   100] loss: 9.204e-05
[91,   200] loss: 9.193e-05
Validation
[91,   100] loss: 1.011e-04
[91,   200] loss: 1.011e-04
Training loss: 0.000, train NMSE: -1.044e+01
Validation loss: 0.000, valid_NMSE: -9.290e+00
--------------------------------------------------
[INFO]: Epoch 92 of 200
Training
[92,   100] loss: 9.023e-05
[92,   200] loss: 9.255e-05
Validation
[92,   100] loss: 1.012e-04

Saving best model for epoch: 91

--------------------------------------------------
[INFO]: Epoch 92 of 200
Training
[92,   100] loss: 9.039e-05
[92,   200] loss: 9.272e-05
Validation
[92,   100] loss: 1.015e-04
[92,   200] loss: 1.015e-04
Training loss: 0.000, train NMSE: -9.781e+00
Validation loss: 0.000, valid_NMSE: -9.264e+00
--------------------------------------------------
[INFO]: Epoch 93 of 200
Training
[93,   100] loss: 9.150e-05
[93,   200] loss: 9.096e-05
Validation
[93,   100] loss: 1.008e-04
[93,   200] loss: 1.008e-04
Training loss: 0.000, train NMSE: -9.864e+00
Validation loss: 0.000, valid_NMSE: -9.281e+00

Best validation loss: -9.280513763427734

Saving best model for epoch: 93

--------------------------------------------------
[INFO]: Epoch 94 of 200
Training
[94,   100] loss: 8.949e-05
[94,   200] loss: 9.163e-05
Validation
[94,   100] loss: 1.001e-04
[94,   200] loss: 1.001e-04
Training loss: 0.000, train NMSE: -9.583e+00
Validation loss: 0.000, valid_NMSE: -9.325e+00

Best validation loss: -9.32547664642334

Saving best model for epoch: 94

--------------------------------------------------
[INFO]: Epoch 95 of 200
Training
[95,   100] loss: 8.950e-05
[95,   200] loss: 9.050e-05
Validation
[95,   100] loss: 1.007e-04
[95,   200] loss: 1.007e-04
Training loss: 0.000, train NMSE: -1.044e+01
Validation loss: 0.000, valid_NMSE: -9.299e+00
--------------------------------------------------
[INFO]: Epoch 96 of 200
Training
[96,   100] loss: 9.011e-05
[96,   200] loss: 8.886e-05
Validation
[96,   100] loss: 9.919e-05
[96,   200] loss: 9.919e-05
Training loss: 0.000, train NMSE: -1.007e+01
Validation loss: 0.000, valid_NMSE: -9.357e+00

Best validation loss: -9.35696029663086

Saving best model for epoch: 96

--------------------------------------------------
[INFO]: Epoch 97 of 200
Training
[97,   100] loss: 8.840e-05
[97,   200] loss: 8.957e-05
Validation
[97,   100] loss: 1.003e-04
[97,   200] loss: 1.003e-04
Training loss: 0.000, train NMSE: -1.009e+01
Validation loss: 0.000, valid_NMSE: -9.291e+00
--------------------------------------------------
[INFO]: Epoch 98 of 200
Training
[98,   100] loss: 8.854e-05
[98,   200] loss: 8.825e-05
Validation
[98,   100] loss: 9.926e-05
[98,   200] loss: 9.926e-05
Training loss: 0.000, train NMSE: -9.995e+00
Validation loss: 0.000, valid_NMSE: -9.339e+00
--------------------------------------------------
[INFO]: Epoch 99 of 200
Training
[99,   100] loss: 8.638e-05
[99,   200] loss: 8.962e-05
Validation
[99,   100] loss: 1.005e-04
[99,   200] loss: 1.005e-04
Training loss: 0.000, train NMSE: -9.538e+00
Validation loss: 0.000, valid_NMSE: -9.231e+00
--------------------------------------------------
[INFO]: Epoch 100 of 200
Training
[100,   100] loss: 8.620e-05
[100,   200] loss: 8.847e-05
Validation
[100,   100] loss: 9.800e-05
[100,   200] loss: 9.800e-05
Training loss: 0.000, train NMSE: -1.039e+01
Validation loss: 0.000, valid_NMSE: -9.378e+00

Best validation loss: -9.377582550048828

Saving best model for epoch: 100

--------------------------------------------------
[INFO]: Epoch 101 of 200
Training
[101,   100] loss: 8.535e-05
[101,   200] loss: 8.848e-05
Validation
[101,   100] loss: 9.768e-05
[101,   200] loss: 9.768e-05
Training loss: 0.000, train NMSE: -9.580e+00
Validation loss: 0.000, valid_NMSE: -9.379e+00

Best validation loss: -9.37926197052002

Saving best model for epoch: 101

--------------------------------------------------
[INFO]: Epoch 102 of 200
Training
[102,   100] loss: 8.605e-05
[102,   200] loss: 8.676e-05
Validation
[102,   100] loss: 9.728e-05
[102,   200] loss: 9.728e-05
Training loss: 0.000, train NMSE: -9.992e+00
Validation loss: 0.000, valid_NMSE: -9.401e+00

Best validation loss: -9.401227951049805

Saving best model for epoch: 102

--------------------------------------------------
[INFO]: Epoch 103 of 200
Training
[103,   100] loss: 8.597e-05
[103,   200] loss: 8.576e-05
Validation
[103,   100] loss: 9.729e-05
[103,   200] loss: 9.729e-05
Training loss: 0.000, train NMSE: -1.040e+01
Validation loss: 0.000, valid_NMSE: -9.423e+00

Best validation loss: -9.423437118530273

Saving best model for epoch: 103

--------------------------------------------------
[INFO]: Epoch 104 of 200
Training
[104,   100] loss: 8.457e-05
[104,   200] loss: 8.624e-05
Validation
[104,   100] loss: 9.748e-05
[104,   200] loss: 9.748e-05
Training loss: 0.000, train NMSE: -1.000e+01
Validation loss: 0.000, valid_NMSE: -9.385e+00
--------------------------------------------------
[INFO]: Epoch 105 of 200
Training
[105,   100] loss: 8.512e-05
[105,   200] loss: 8.473e-05
Validation
[105,   100] loss: 9.648e-05
[105,   200] loss: 9.648e-05
Training loss: 0.000, train NMSE: -9.699e+00
Validation loss: 0.000, valid_NMSE: -9.396e+00
--------------------------------------------------
[INFO]: Epoch 106 of 200
Training
[106,   100] loss: 8.457e-05
[106,   200] loss: 8.449e-05
Validation
[106,   100] loss: 9.653e-05
[106,   200] loss: 9.653e-05
Training loss: 0.000, train NMSE: -1.079e+01
Validation loss: 0.000, valid_NMSE: -9.434e+00

Best validation loss: -9.433921813964844

Saving best model for epoch: 106

--------------------------------------------------
[INFO]: Epoch 107 of 200
Training
[107,   100] loss: 8.268e-05
[107,   200] loss: 8.529e-05
Validation
[107,   100] loss: 9.618e-05
[107,   200] loss: 9.618e-05
Training loss: 0.000, train NMSE: -1.029e+01
Validation loss: 0.000, valid_NMSE: -9.448e+00

Best validation loss: -9.447670936584473

Saving best model for epoch: 107

--------------------------------------------------
[INFO]: Epoch 108 of 200
Training
[108,   100] loss: 8.370e-05
[108,   200] loss: 8.348e-05
Validation
[108,   100] loss: 9.607e-05
[108,   200] loss: 9.607e-05
Training loss: 0.000, train NMSE: -1.014e+01
Validation loss: 0.000, valid_NMSE: -9.392e+00
--------------------------------------------------
[INFO]: Epoch 109 of 200
Training
[109,   100] loss: 8.330e-05
[109,   200] loss: 8.332e-05
Validation
[109,   100] loss: 9.664e-05
[109,   200] loss: 9.664e-05
Training loss: 0.000, train NMSE: -1.070e+01
Validation loss: 0.000, valid_NMSE: -9.410e+00
--------------------------------------------------
[INFO]: Epoch 110 of 200
Training
[110,   100] loss: 8.270e-05
[110,   200] loss: 8.285e-05
Validation
[110,   100] loss: 9.492e-05
[110,   200] loss: 9.492e-05
Training loss: 0.000, train NMSE: -1.045e+01
Validation loss: 0.000, valid_NMSE: -9.472e+00

Best validation loss: -9.471634864807129

Saving best model for epoch: 110

--------------------------------------------------
[INFO]: Epoch 111 of 200
Training
[111,   100] loss: 8.233e-05
[111,   200] loss: 8.189e-05
Validation
[111,   100] loss: 9.453e-05
[111,   200] loss: 9.453e-05
Training loss: 0.000, train NMSE: -1.030e+01
Validation loss: 0.000, valid_NMSE: -9.501e+00

Best validation loss: -9.501068115234375

Saving best model for epoch: 111

--------------------------------------------------
[INFO]: Epoch 112 of 200
Training
[112,   100] loss: 8.084e-05
[112,   200] loss: 8.281e-05
Validation
[112,   100] loss: 9.445e-05
[112,   200] loss: 9.445e-05
Training loss: 0.000, train NMSE: -1.015e+01
Validation loss: 0.000, valid_NMSE: -9.465e+00
--------------------------------------------------
[INFO]: Epoch 113 of 200
Training
[113,   100] loss: 8.132e-05
[113,   200] loss: 8.134e-05
Validation
[113,   100] loss: 9.473e-05
[113,   200] loss: 9.473e-05
Training loss: 0.000, train NMSE: -1.071e+01
Validation loss: 0.000, valid_NMSE: -9.461e+00
--------------------------------------------------
[INFO]: Epoch 114 of 200
Training
[114,   100] loss: 7.995e-05
[114,   200] loss: 8.198e-05
Validation
[114,   100] loss: 9.456e-05
[114,   200] loss: 9.456e-05
Training loss: 0.000, train NMSE: -1.014e+01
Validation loss: 0.000, valid_NMSE: -9.471e+00
--------------------------------------------------
[INFO]: Epoch 115 of 200
Training
[115,   100] loss: 7.917e-05
[115,   200] loss: 8.196e-05
Validation
[115,   100] loss: 9.395e-05
[115,   200] loss: 9.395e-05
Training loss: 0.000, train NMSE: -1.034e+01
Validation loss: 0.000, valid_NMSE: -9.484e+00
--------------------------------------------------
[INFO]: Epoch 116 of 200
[92,   200] loss: 1.012e-04
Training loss: 0.000, train NMSE: -9.772e+00
Validation loss: 0.000, valid_NMSE: -9.287e+00
--------------------------------------------------
[INFO]: Epoch 93 of 200
Training
[93,   100] loss: 9.129e-05
[93,   200] loss: 9.072e-05
Validation
[93,   100] loss: 1.005e-04
[93,   200] loss: 1.005e-04
Training loss: 0.000, train NMSE: -9.878e+00
Validation loss: 0.000, valid_NMSE: -9.314e+00

Best validation loss: -9.31358814239502

Saving best model for epoch: 93

--------------------------------------------------
[INFO]: Epoch 94 of 200
Training
[94,   100] loss: 8.939e-05
[94,   200] loss: 9.144e-05
Validation
[94,   100] loss: 9.974e-05
[94,   200] loss: 9.974e-05
Training loss: 0.000, train NMSE: -9.581e+00
Validation loss: 0.000, valid_NMSE: -9.366e+00

Best validation loss: -9.366412162780762

Saving best model for epoch: 94

--------------------------------------------------
[INFO]: Epoch 95 of 200
Training
[95,   100] loss: 8.933e-05
[95,   200] loss: 9.035e-05
Validation
[95,   100] loss: 1.004e-04
[95,   200] loss: 1.004e-04
Training loss: 0.000, train NMSE: -1.047e+01
Validation loss: 0.000, valid_NMSE: -9.325e+00
--------------------------------------------------
[INFO]: Epoch 96 of 200
Training
[96,   100] loss: 8.994e-05
[96,   200] loss: 8.870e-05
Validation
[96,   100] loss: 9.900e-05
[96,   200] loss: 9.900e-05
Training loss: 0.000, train NMSE: -1.008e+01
Validation loss: 0.000, valid_NMSE: -9.385e+00

Best validation loss: -9.38454532623291

Saving best model for epoch: 96

--------------------------------------------------
[INFO]: Epoch 97 of 200
Training
[97,   100] loss: 8.833e-05
[97,   200] loss: 8.944e-05
Validation
[97,   100] loss: 9.980e-05
[97,   200] loss: 9.980e-05
Training loss: 0.000, train NMSE: -1.009e+01
Validation loss: 0.000, valid_NMSE: -9.323e+00
--------------------------------------------------
[INFO]: Epoch 98 of 200
Training
[98,   100] loss: 8.840e-05
[98,   200] loss: 8.813e-05
Validation
[98,   100] loss: 9.870e-05
[98,   200] loss: 9.870e-05
Training loss: 0.000, train NMSE: -9.992e+00
Validation loss: 0.000, valid_NMSE: -9.367e+00
--------------------------------------------------
[INFO]: Epoch 99 of 200
Training
[99,   100] loss: 8.617e-05
[99,   200] loss: 8.941e-05
Validation
[99,   100] loss: 9.989e-05
[99,   200] loss: 9.989e-05
Training loss: 0.000, train NMSE: -9.533e+00
Validation loss: 0.000, valid_NMSE: -9.288e+00
--------------------------------------------------
[INFO]: Epoch 100 of 200
Training
[100,   100] loss: 8.597e-05
[100,   200] loss: 8.833e-05
Validation
[100,   100] loss: 9.787e-05
[100,   200] loss: 9.787e-05
Training loss: 0.000, train NMSE: -1.039e+01
Validation loss: 0.000, valid_NMSE: -9.413e+00

Best validation loss: -9.413147926330566

Saving best model for epoch: 100

--------------------------------------------------
[INFO]: Epoch 101 of 200
Training
[101,   100] loss: 8.523e-05
[101,   200] loss: 8.839e-05
Validation
[101,   100] loss: 9.796e-05
[101,   200] loss: 9.796e-05
Training loss: 0.000, train NMSE: -9.588e+00
Validation loss: 0.000, valid_NMSE: -9.389e+00
--------------------------------------------------
[INFO]: Epoch 102 of 200
Training
[102,   100] loss: 8.591e-05
[102,   200] loss: 8.651e-05
Validation
[102,   100] loss: 9.703e-05
[102,   200] loss: 9.703e-05
Training loss: 0.000, train NMSE: -9.987e+00
Validation loss: 0.000, valid_NMSE: -9.439e+00

Best validation loss: -9.439302444458008

Saving best model for epoch: 102

--------------------------------------------------
[INFO]: Epoch 103 of 200
Training
[103,   100] loss: 8.581e-05
[103,   200] loss: 8.557e-05
Validation
[103,   100] loss: 9.696e-05
[103,   200] loss: 9.696e-05
Training loss: 0.000, train NMSE: -1.044e+01
Validation loss: 0.000, valid_NMSE: -9.446e+00

Best validation loss: -9.445535659790039

Saving best model for epoch: 103

--------------------------------------------------
[INFO]: Epoch 104 of 200
Training
[104,   100] loss: 8.450e-05
[104,   200] loss: 8.601e-05
Validation
[104,   100] loss: 9.721e-05
[104,   200] loss: 9.721e-05
Training loss: 0.000, train NMSE: -1.000e+01
Validation loss: 0.000, valid_NMSE: -9.418e+00
--------------------------------------------------
[INFO]: Epoch 105 of 200
Training
[105,   100] loss: 8.488e-05
[105,   200] loss: 8.460e-05
Validation
[105,   100] loss: 9.645e-05
[105,   200] loss: 9.645e-05
Training loss: 0.000, train NMSE: -9.684e+00
Validation loss: 0.000, valid_NMSE: -9.410e+00
--------------------------------------------------
[INFO]: Epoch 106 of 200
Training
[106,   100] loss: 8.432e-05
[106,   200] loss: 8.426e-05
Validation
[106,   100] loss: 9.659e-05
[106,   200] loss: 9.659e-05
Training loss: 0.000, train NMSE: -1.080e+01
Validation loss: 0.000, valid_NMSE: -9.439e+00
--------------------------------------------------
[INFO]: Epoch 107 of 200
Training
[107,   100] loss: 8.248e-05
[107,   200] loss: 8.516e-05
Validation
[107,   100] loss: 9.602e-05
[107,   200] loss: 9.602e-05
Training loss: 0.000, train NMSE: -1.030e+01
Validation loss: 0.000, valid_NMSE: -9.457e+00

Best validation loss: -9.457418441772461

Saving best model for epoch: 107

--------------------------------------------------
[INFO]: Epoch 108 of 200
Training
[108,   100] loss: 8.349e-05
[108,   200] loss: 8.322e-05
Validation
[108,   100] loss: 9.584e-05
[108,   200] loss: 9.584e-05
Training loss: 0.000, train NMSE: -1.016e+01
Validation loss: 0.000, valid_NMSE: -9.431e+00
--------------------------------------------------
[INFO]: Epoch 109 of 200
Training
[109,   100] loss: 8.314e-05
[109,   200] loss: 8.319e-05
Validation
[109,   100] loss: 9.671e-05
[109,   200] loss: 9.671e-05
Training loss: 0.000, train NMSE: -1.072e+01
Validation loss: 0.000, valid_NMSE: -9.405e+00
--------------------------------------------------
[INFO]: Epoch 110 of 200
Training
[110,   100] loss: 8.254e-05
[110,   200] loss: 8.266e-05
Validation
[110,   100] loss: 9.484e-05
[110,   200] loss: 9.484e-05
Training loss: 0.000, train NMSE: -1.044e+01
Validation loss: 0.000, valid_NMSE: -9.488e+00

Best validation loss: -9.48788833618164

Saving best model for epoch: 110

--------------------------------------------------
[INFO]: Epoch 111 of 200
Training
[111,   100] loss: 8.214e-05
[111,   200] loss: 8.167e-05
Validation
[111,   100] loss: 9.433e-05
[111,   200] loss: 9.433e-05
Training loss: 0.000, train NMSE: -1.030e+01
Validation loss: 0.000, valid_NMSE: -9.511e+00

Best validation loss: -9.51124095916748

Saving best model for epoch: 111

--------------------------------------------------
[INFO]: Epoch 112 of 200
Training
[112,   100] loss: 8.072e-05
[112,   200] loss: 8.259e-05
Validation
[112,   100] loss: 9.422e-05
[112,   200] loss: 9.422e-05
Training loss: 0.000, train NMSE: -1.020e+01
Validation loss: 0.000, valid_NMSE: -9.484e+00
--------------------------------------------------
[INFO]: Epoch 113 of 200
Training
[113,   100] loss: 8.114e-05
[113,   200] loss: 8.119e-05
Validation
[113,   100] loss: 9.448e-05
[113,   200] loss: 9.448e-05
Training loss: 0.000, train NMSE: -1.070e+01
Validation loss: 0.000, valid_NMSE: -9.479e+00
--------------------------------------------------
[INFO]: Epoch 114 of 200
Training
[114,   100] loss: 7.982e-05
[114,   200] loss: 8.184e-05
Validation
[114,   100] loss: 9.411e-05
[114,   200] loss: 9.411e-05
Training loss: 0.000, train NMSE: -1.013e+01
Validation loss: 0.000, valid_NMSE: -9.509e+00
--------------------------------------------------
[INFO]: Epoch 115 of 200
Training
[115,   100] loss: 7.891e-05
[115,   200] loss: 8.180e-05
Validation
[115,   100] loss: 9.409e-05
[115,   200] loss: 9.409e-05
Training loss: 0.000, train NMSE: -1.033e+01
Validation loss: 0.000, valid_NMSE: -9.499e+00
--------------------------------------------------
[INFO]: Epoch 116 of 200
Training
[116,   100] loss: 7.883e-05
[116,   200] loss: 8.121e-05
Validation
[116,   100] loss: 9.329e-05
[116,   200] loss: 9.329e-05
Training loss: 0.000, train NMSE: -1.020e+01
Validation loss: 0.000, valid_NMSE: -9.565e+00

Best validation loss: -9.564537048339844

Saving best model for epoch: 116

--------------------------------------------------
Training
[116,   100] loss: 7.894e-05
[116,   200] loss: 8.139e-05
Validation
[116,   100] loss: 9.355e-05
[116,   200] loss: 9.355e-05
Training loss: 0.000, train NMSE: -1.019e+01
Validation loss: 0.000, valid_NMSE: -9.531e+00

Best validation loss: -9.530942916870117

Saving best model for epoch: 116

--------------------------------------------------
[INFO]: Epoch 117 of 200
Training
[117,   100] loss: 7.922e-05
[117,   200] loss: 8.032e-05
Validation
[117,   100] loss: 9.336e-05
[117,   200] loss: 9.336e-05
Training loss: 0.000, train NMSE: -1.064e+01
Validation loss: 0.000, valid_NMSE: -9.497e+00
--------------------------------------------------
[INFO]: Epoch 118 of 200
Training
[118,   100] loss: 7.891e-05
[118,   200] loss: 7.962e-05
Validation
[118,   100] loss: 9.345e-05
[118,   200] loss: 9.345e-05
Training loss: 0.000, train NMSE: -1.018e+01
Validation loss: 0.000, valid_NMSE: -9.495e+00
--------------------------------------------------
[INFO]: Epoch 119 of 200
Training
[119,   100] loss: 7.843e-05
[119,   200] loss: 7.976e-05
Validation
[119,   100] loss: 9.321e-05
[119,   200] loss: 9.321e-05
Training loss: 0.000, train NMSE: -1.016e+01
Validation loss: 0.000, valid_NMSE: -9.474e+00
--------------------------------------------------
[INFO]: Epoch 120 of 200
Training
[120,   100] loss: 7.804e-05
[120,   200] loss: 7.932e-05
Validation
[120,   100] loss: 9.249e-05
[120,   200] loss: 9.249e-05
Training loss: 0.000, train NMSE: -1.083e+01
Validation loss: 0.000, valid_NMSE: -9.548e+00

Best validation loss: -9.547926902770996

Saving best model for epoch: 120

--------------------------------------------------
[INFO]: Epoch 121 of 200
Training
[121,   100] loss: 7.751e-05
[121,   200] loss: 7.903e-05
Validation
[121,   100] loss: 9.370e-05
[121,   200] loss: 9.370e-05
Training loss: 0.000, train NMSE: -1.006e+01
Validation loss: 0.000, valid_NMSE: -9.459e+00
--------------------------------------------------
[INFO]: Epoch 122 of 200
Training
[122,   100] loss: 7.710e-05
[122,   200] loss: 7.868e-05
Validation
[122,   100] loss: 9.296e-05
[122,   200] loss: 9.296e-05
Training loss: 0.000, train NMSE: -1.073e+01
Validation loss: 0.000, valid_NMSE: -9.524e+00
--------------------------------------------------
[INFO]: Epoch 123 of 200
Training
[123,   100] loss: 7.773e-05
[123,   200] loss: 7.743e-05
Validation
[123,   100] loss: 9.232e-05
[123,   200] loss: 9.232e-05
Training loss: 0.000, train NMSE: -1.079e+01
Validation loss: 0.000, valid_NMSE: -9.556e+00

Best validation loss: -9.555654525756836

Saving best model for epoch: 123

--------------------------------------------------
[INFO]: Epoch 124 of 200
Training
[124,   100] loss: 7.678e-05
[124,   200] loss: 7.774e-05
Validation
[124,   100] loss: 9.489e-05
[124,   200] loss: 9.489e-05
Training loss: 0.000, train NMSE: -1.009e+01
Validation loss: 0.000, valid_NMSE: -9.389e+00
--------------------------------------------------
[INFO]: Epoch 125 of 200
Training
[125,   100] loss: 7.722e-05
[125,   200] loss: 7.671e-05
Validation
[125,   100] loss: 9.194e-05
[125,   200] loss: 9.194e-05
Training loss: 0.000, train NMSE: -1.104e+01
Validation loss: 0.000, valid_NMSE: -9.515e+00
--------------------------------------------------
[INFO]: Epoch 126 of 200
Training
[126,   100] loss: 7.656e-05
[126,   200] loss: 7.663e-05
Validation
[126,   100] loss: 9.178e-05
[126,   200] loss: 9.178e-05
Training loss: 0.000, train NMSE: -1.038e+01
Validation loss: 0.000, valid_NMSE: -9.535e+00
--------------------------------------------------
[INFO]: Epoch 127 of 200
Training
[127,   100] loss: 7.629e-05
[127,   200] loss: 7.611e-05
Validation
[127,   100] loss: 9.167e-05
[127,   200] loss: 9.167e-05
Training loss: 0.000, train NMSE: -1.144e+01
Validation loss: 0.000, valid_NMSE: -9.536e+00
--------------------------------------------------
[INFO]: Epoch 128 of 200
Training
[128,   100] loss: 7.605e-05
[128,   200] loss: 7.586e-05
Validation
[128,   100] loss: 9.181e-05
[128,   200] loss: 9.181e-05
Training loss: 0.000, train NMSE: -1.077e+01
Validation loss: 0.000, valid_NMSE: -9.494e+00
--------------------------------------------------
[INFO]: Epoch 129 of 200
Training
[129,   100] loss: 7.508e-05
[129,   200] loss: 7.599e-05
Validation
[129,   100] loss: 9.125e-05
[129,   200] loss: 9.125e-05
Training loss: 0.000, train NMSE: -1.087e+01
Validation loss: 0.000, valid_NMSE: -9.535e+00
--------------------------------------------------
[INFO]: Epoch 130 of 200
Training
[130,   100] loss: 7.514e-05
[130,   200] loss: 7.557e-05
Validation
[130,   100] loss: 9.143e-05
[130,   200] loss: 9.143e-05
Training loss: 0.000, train NMSE: -1.088e+01
Validation loss: 0.000, valid_NMSE: -9.505e+00
--------------------------------------------------
[INFO]: Epoch 131 of 200
Training
[131,   100] loss: 7.367e-05
[131,   200] loss: 7.632e-05
Validation
[131,   100] loss: 9.086e-05
[131,   200] loss: 9.086e-05
Training loss: 0.000, train NMSE: -1.040e+01
Validation loss: 0.000, valid_NMSE: -9.570e+00

Best validation loss: -9.569887161254883

Saving best model for epoch: 131

--------------------------------------------------
[INFO]: Epoch 132 of 200
Training
[132,   100] loss: 7.491e-05
[132,   200] loss: 7.447e-05
Validation
[132,   100] loss: 9.074e-05
[132,   200] loss: 9.074e-05
Training loss: 0.000, train NMSE: -1.100e+01
Validation loss: 0.000, valid_NMSE: -9.546e+00
--------------------------------------------------
[INFO]: Epoch 133 of 200
Training
[133,   100] loss: 7.271e-05
[133,   200] loss: 7.565e-05
Validation
[133,   100] loss: 9.074e-05
[133,   200] loss: 9.074e-05
Training loss: 0.000, train NMSE: -1.081e+01
Validation loss: 0.000, valid_NMSE: -9.578e+00

Best validation loss: -9.577874183654785

Saving best model for epoch: 133

--------------------------------------------------
[INFO]: Epoch 134 of 200
Training
[134,   100] loss: 7.388e-05
[134,   200] loss: 7.439e-05
Validation
[134,   100] loss: 9.095e-05
[134,   200] loss: 9.095e-05
Training loss: 0.000, train NMSE: -1.092e+01
Validation loss: 0.000, valid_NMSE: -9.526e+00
--------------------------------------------------
[INFO]: Epoch 135 of 200
Training
[135,   100] loss: 7.297e-05
[135,   200] loss: 7.476e-05
Validation
[135,   100] loss: 9.044e-05
[135,   200] loss: 9.044e-05
Training loss: 0.000, train NMSE: -1.082e+01
Validation loss: 0.000, valid_NMSE: -9.582e+00

Best validation loss: -9.581764221191406

Saving best model for epoch: 135

--------------------------------------------------
[INFO]: Epoch 136 of 200
Training
[136,   100] loss: 7.269e-05
[136,   200] loss: 7.457e-05
Validation
[136,   100] loss: 9.017e-05
[136,   200] loss: 9.017e-05
Training loss: 0.000, train NMSE: -1.020e+01
Validation loss: 0.000, valid_NMSE: -9.588e+00

Best validation loss: -9.587770462036133

Saving best model for epoch: 136

--------------------------------------------------
[INFO]: Epoch 137 of 200
Training
[137,   100] loss: 7.328e-05
[137,   200] loss: 7.280e-05
Validation
[137,   100] loss: 9.018e-05
[137,   200] loss: 9.018e-05
Training loss: 0.000, train NMSE: -1.081e+01
Validation loss: 0.000, valid_NMSE: -9.568e+00
--------------------------------------------------
[INFO]: Epoch 138 of 200
Training
[138,   100] loss: 7.250e-05
[138,   200] loss: 7.328e-05
Validation
[138,   100] loss: 9.005e-05
[138,   200] loss: 9.005e-05
Training loss: 0.000, train NMSE: -1.097e+01
Validation loss: 0.000, valid_NMSE: -9.577e+00
--------------------------------------------------
[INFO]: Epoch 139 of 200
Training
[139,   100] loss: 7.231e-05
[139,   200] loss: 7.317e-05
Validation
[139,   100] loss: 9.028e-05
[139,   200] loss: 9.028e-05
Training loss: 0.000, train NMSE: -1.061e+01
Validation loss: 0.000, valid_NMSE: -9.553e+00
--------------------------------------------------
[INFO]: Epoch 140 of 200
Training
[140,   100] loss: 7.233e-05
[140,   200] loss: 7.248e-05
Validation
[140,   100] loss: 8.968e-05
[140,   200] loss: 8.968e-05
Training loss: 0.000, train NMSE: -1.124e+01
Validation loss: 0.000, valid_NMSE: -9.588e+00

Best validation loss: -9.587974548339844

Saving best model for epoch: 140

--------------------------------------------------
[INFO]: Epoch 141 of 200
[INFO]: Epoch 117 of 200
Training
[117,   100] loss: 7.904e-05
[117,   200] loss: 8.017e-05
Validation
[117,   100] loss: 9.337e-05
[117,   200] loss: 9.337e-05
Training loss: 0.000, train NMSE: -1.065e+01
Validation loss: 0.000, valid_NMSE: -9.490e+00
--------------------------------------------------
[INFO]: Epoch 118 of 200
Training
[118,   100] loss: 7.875e-05
[118,   200] loss: 7.943e-05
Validation
[118,   100] loss: 9.342e-05
[118,   200] loss: 9.342e-05
Training loss: 0.000, train NMSE: -1.019e+01
Validation loss: 0.000, valid_NMSE: -9.511e+00
--------------------------------------------------
[INFO]: Epoch 119 of 200
Training
[119,   100] loss: 7.824e-05
[119,   200] loss: 7.959e-05
Validation
[119,   100] loss: 9.312e-05
[119,   200] loss: 9.312e-05
Training loss: 0.000, train NMSE: -1.016e+01
Validation loss: 0.000, valid_NMSE: -9.494e+00
--------------------------------------------------
[INFO]: Epoch 120 of 200
Training
[120,   100] loss: 7.787e-05
[120,   200] loss: 7.904e-05
Validation
[120,   100] loss: 9.254e-05
[120,   200] loss: 9.254e-05
Training loss: 0.000, train NMSE: -1.082e+01
Validation loss: 0.000, valid_NMSE: -9.534e+00
--------------------------------------------------
[INFO]: Epoch 121 of 200
Training
[121,   100] loss: 7.739e-05
[121,   200] loss: 7.891e-05
Validation
[121,   100] loss: 9.359e-05
[121,   200] loss: 9.359e-05
Training loss: 0.000, train NMSE: -1.008e+01
Validation loss: 0.000, valid_NMSE: -9.480e+00
--------------------------------------------------
[INFO]: Epoch 122 of 200
Training
[122,   100] loss: 7.684e-05
[122,   200] loss: 7.857e-05
Validation
[122,   100] loss: 9.285e-05
[122,   200] loss: 9.285e-05
Training loss: 0.000, train NMSE: -1.074e+01
Validation loss: 0.000, valid_NMSE: -9.530e+00
--------------------------------------------------
[INFO]: Epoch 123 of 200
Training
[123,   100] loss: 7.759e-05
[123,   200] loss: 7.734e-05
Validation
[123,   100] loss: 9.214e-05
[123,   200] loss: 9.214e-05
Training loss: 0.000, train NMSE: -1.080e+01
Validation loss: 0.000, valid_NMSE: -9.557e+00
--------------------------------------------------
[INFO]: Epoch 124 of 200
Training
[124,   100] loss: 7.661e-05
[124,   200] loss: 7.762e-05
Validation
[124,   100] loss: 9.481e-05
[124,   200] loss: 9.481e-05
Training loss: 0.000, train NMSE: -1.009e+01
Validation loss: 0.000, valid_NMSE: -9.411e+00
--------------------------------------------------
[INFO]: Epoch 125 of 200
Training
[125,   100] loss: 7.696e-05
[125,   200] loss: 7.666e-05
Validation
[125,   100] loss: 9.172e-05
[125,   200] loss: 9.172e-05
Training loss: 0.000, train NMSE: -1.105e+01
Validation loss: 0.000, valid_NMSE: -9.535e+00
--------------------------------------------------
[INFO]: Epoch 126 of 200
Training
[126,   100] loss: 7.638e-05
[126,   200] loss: 7.640e-05
Validation
[126,   100] loss: 9.172e-05
[126,   200] loss: 9.172e-05
Training loss: 0.000, train NMSE: -1.041e+01
Validation loss: 0.000, valid_NMSE: -9.530e+00
--------------------------------------------------
[INFO]: Epoch 127 of 200
Training
[127,   100] loss: 7.607e-05
[127,   200] loss: 7.593e-05
Validation
[127,   100] loss: 9.154e-05
[127,   200] loss: 9.154e-05
Training loss: 0.000, train NMSE: -1.144e+01
Validation loss: 0.000, valid_NMSE: -9.535e+00
--------------------------------------------------
[INFO]: Epoch 128 of 200
Training
[128,   100] loss: 7.598e-05
[128,   200] loss: 7.578e-05
Validation
[128,   100] loss: 9.168e-05
[128,   200] loss: 9.168e-05
Training loss: 0.000, train NMSE: -1.079e+01
Validation loss: 0.000, valid_NMSE: -9.501e+00
--------------------------------------------------
[INFO]: Epoch 129 of 200
Training
[129,   100] loss: 7.503e-05
[129,   200] loss: 7.591e-05
Validation
[129,   100] loss: 9.101e-05
[129,   200] loss: 9.101e-05
Training loss: 0.000, train NMSE: -1.085e+01
Validation loss: 0.000, valid_NMSE: -9.552e+00
--------------------------------------------------
[INFO]: Epoch 130 of 200
Training
[130,   100] loss: 7.509e-05
[130,   200] loss: 7.545e-05
Validation
[130,   100] loss: 9.156e-05
[130,   200] loss: 9.156e-05
Training loss: 0.000, train NMSE: -1.087e+01
Validation loss: 0.000, valid_NMSE: -9.497e+00
--------------------------------------------------
[INFO]: Epoch 131 of 200
Training
[131,   100] loss: 7.366e-05
[131,   200] loss: 7.635e-05
Validation
[131,   100] loss: 9.075e-05
[131,   200] loss: 9.075e-05
Training loss: 0.000, train NMSE: -1.040e+01
Validation loss: 0.000, valid_NMSE: -9.579e+00

Best validation loss: -9.578848838806152

Saving best model for epoch: 131

--------------------------------------------------
[INFO]: Epoch 132 of 200
Training
[132,   100] loss: 7.471e-05
[132,   200] loss: 7.435e-05
Validation
[132,   100] loss: 9.041e-05
[132,   200] loss: 9.041e-05
Training loss: 0.000, train NMSE: -1.103e+01
Validation loss: 0.000, valid_NMSE: -9.553e+00
--------------------------------------------------
[INFO]: Epoch 133 of 200
Training
[133,   100] loss: 7.259e-05
[133,   200] loss: 7.548e-05
Validation
[133,   100] loss: 9.052e-05
[133,   200] loss: 9.052e-05
Training loss: 0.000, train NMSE: -1.082e+01
Validation loss: 0.000, valid_NMSE: -9.584e+00

Best validation loss: -9.584383010864258

Saving best model for epoch: 133

--------------------------------------------------
[INFO]: Epoch 134 of 200
Training
[134,   100] loss: 7.382e-05
[134,   200] loss: 7.420e-05
Validation
[134,   100] loss: 9.105e-05
[134,   200] loss: 9.105e-05
Training loss: 0.000, train NMSE: -1.091e+01
Validation loss: 0.000, valid_NMSE: -9.505e+00
--------------------------------------------------
[INFO]: Epoch 135 of 200
Training
[135,   100] loss: 7.291e-05
[135,   200] loss: 7.468e-05
Validation
[135,   100] loss: 9.032e-05
[135,   200] loss: 9.032e-05
Training loss: 0.000, train NMSE: -1.082e+01
Validation loss: 0.000, valid_NMSE: -9.583e+00
--------------------------------------------------
[INFO]: Epoch 136 of 200
Training
[136,   100] loss: 7.269e-05
[136,   200] loss: 7.442e-05
Validation
[136,   100] loss: 9.025e-05
[136,   200] loss: 9.025e-05
Training loss: 0.000, train NMSE: -1.020e+01
Validation loss: 0.000, valid_NMSE: -9.582e+00
--------------------------------------------------
[INFO]: Epoch 137 of 200
Training
[137,   100] loss: 7.320e-05
[137,   200] loss: 7.276e-05
Validation
[137,   100] loss: 8.987e-05
[137,   200] loss: 8.987e-05
Training loss: 0.000, train NMSE: -1.081e+01
Validation loss: 0.000, valid_NMSE: -9.577e+00
--------------------------------------------------
[INFO]: Epoch 138 of 200
Training
[138,   100] loss: 7.247e-05
[138,   200] loss: 7.319e-05
Validation
[138,   100] loss: 8.989e-05
[138,   200] loss: 8.989e-05
Training loss: 0.000, train NMSE: -1.098e+01
Validation loss: 0.000, valid_NMSE: -9.575e+00
--------------------------------------------------
[INFO]: Epoch 139 of 200
Training
[139,   100] loss: 7.234e-05
[139,   200] loss: 7.322e-05
Validation
[139,   100] loss: 9.021e-05
[139,   200] loss: 9.021e-05
Training loss: 0.000, train NMSE: -1.060e+01
Validation loss: 0.000, valid_NMSE: -9.547e+00
--------------------------------------------------
[INFO]: Epoch 140 of 200
Training
[140,   100] loss: 7.235e-05
[140,   200] loss: 7.238e-05
Validation
[140,   100] loss: 8.958e-05
[140,   200] loss: 8.958e-05
Training loss: 0.000, train NMSE: -1.125e+01
Validation loss: 0.000, valid_NMSE: -9.571e+00
--------------------------------------------------
[INFO]: Epoch 141 of 200
Training
[141,   100] loss: 7.194e-05
[141,   200] loss: 7.220e-05
Validation
[141,   100] loss: 8.934e-05
[141,   200] loss: 8.934e-05
Training loss: 0.000, train NMSE: -1.062e+01
Validation loss: 0.000, valid_NMSE: -9.582e+00
--------------------------------------------------
[INFO]: Epoch 142 of 200
Training
[142,   100] loss: 7.014e-05
[142,   200] loss: 7.348e-05
Validation
[142,   100] loss: 9.012e-05
[142,   200] loss: 9.012e-05
Training loss: 0.000, train NMSE: -1.085e+01
Validation loss: 0.000, valid_NMSE: -9.569e+00
--------------------------------------------------
[INFO]: Epoch 143 of 200
Training
[143,   100] loss: 7.229e-05
[143,   200] loss: 7.079e-05
Validation
[143,   100] loss: 8.866e-05
[143,   200] loss: 8.866e-05
Training
[141,   100] loss: 7.199e-05
[141,   200] loss: 7.227e-05
Validation
[141,   100] loss: 8.916e-05
[141,   200] loss: 8.916e-05
Training loss: 0.000, train NMSE: -1.062e+01
Validation loss: 0.000, valid_NMSE: -9.616e+00

Best validation loss: -9.615604400634766

Saving best model for epoch: 141

--------------------------------------------------
[INFO]: Epoch 142 of 200
Training
[142,   100] loss: 7.015e-05
[142,   200] loss: 7.354e-05
Validation
[142,   100] loss: 9.024e-05
[142,   200] loss: 9.024e-05
Training loss: 0.000, train NMSE: -1.086e+01
Validation loss: 0.000, valid_NMSE: -9.589e+00
--------------------------------------------------
[INFO]: Epoch 143 of 200
Training
[143,   100] loss: 7.236e-05
[143,   200] loss: 7.088e-05
Validation
[143,   100] loss: 8.894e-05
[143,   200] loss: 8.894e-05
Training loss: 0.000, train NMSE: -1.052e+01
Validation loss: 0.000, valid_NMSE: -9.603e+00
--------------------------------------------------
[INFO]: Epoch 144 of 200
Training
[144,   100] loss: 7.090e-05
[144,   200] loss: 7.171e-05
Validation
[144,   100] loss: 8.889e-05
[144,   200] loss: 8.889e-05
Training loss: 0.000, train NMSE: -1.058e+01
Validation loss: 0.000, valid_NMSE: -9.602e+00
--------------------------------------------------
[INFO]: Epoch 145 of 200
Training
[145,   100] loss: 7.050e-05
[145,   200] loss: 7.150e-05
Validation
[145,   100] loss: 8.909e-05
[145,   200] loss: 8.909e-05
Training loss: 0.000, train NMSE: -1.060e+01
Validation loss: 0.000, valid_NMSE: -9.610e+00
--------------------------------------------------
[INFO]: Epoch 146 of 200
Training
[146,   100] loss: 7.026e-05
[146,   200] loss: 7.156e-05
Validation
[146,   100] loss: 8.846e-05
[146,   200] loss: 8.846e-05
Training loss: 0.000, train NMSE: -1.095e+01
Validation loss: 0.000, valid_NMSE: -9.631e+00

Best validation loss: -9.630953788757324

Saving best model for epoch: 146

--------------------------------------------------
[INFO]: Epoch 147 of 200
Training
[147,   100] loss: 7.085e-05
[147,   200] loss: 7.029e-05
Validation
[147,   100] loss: 8.860e-05
[147,   200] loss: 8.860e-05
Training loss: 0.000, train NMSE: -1.113e+01
Validation loss: 0.000, valid_NMSE: -9.626e+00
--------------------------------------------------
[INFO]: Epoch 148 of 200
Training
[148,   100] loss: 7.062e-05
[148,   200] loss: 6.984e-05
Validation
[148,   100] loss: 8.839e-05
[148,   200] loss: 8.839e-05
Training loss: 0.000, train NMSE: -1.061e+01
Validation loss: 0.000, valid_NMSE: -9.633e+00

Best validation loss: -9.632865905761719

Saving best model for epoch: 148

--------------------------------------------------
[INFO]: Epoch 149 of 200
Training
[149,   100] loss: 7.022e-05
[149,   200] loss: 6.989e-05
Validation
[149,   100] loss: 8.852e-05
[149,   200] loss: 8.852e-05
Training loss: 0.000, train NMSE: -1.094e+01
Validation loss: 0.000, valid_NMSE: -9.628e+00
--------------------------------------------------
[INFO]: Epoch 150 of 200
Training
[150,   100] loss: 7.010e-05
[150,   200] loss: 6.978e-05
Validation
[150,   100] loss: 8.799e-05
[150,   200] loss: 8.799e-05
Training loss: 0.000, train NMSE: -1.103e+01
Validation loss: 0.000, valid_NMSE: -9.655e+00

Best validation loss: -9.655465126037598

Saving best model for epoch: 150

--------------------------------------------------
[INFO]: Epoch 151 of 200
Training
[151,   100] loss: 6.942e-05
[151,   200] loss: 6.973e-05
Validation
[151,   100] loss: 8.813e-05
[151,   200] loss: 8.813e-05
Training loss: 0.000, train NMSE: -1.062e+01
Validation loss: 0.000, valid_NMSE: -9.638e+00
--------------------------------------------------
[INFO]: Epoch 152 of 200
Training
[152,   100] loss: 6.854e-05
[152,   200] loss: 7.023e-05
Validation
[152,   100] loss: 8.807e-05
[152,   200] loss: 8.807e-05
Training loss: 0.000, train NMSE: -1.138e+01
Validation loss: 0.000, valid_NMSE: -9.627e+00
--------------------------------------------------
[INFO]: Epoch 153 of 200
Training
[153,   100] loss: 6.883e-05
[153,   200] loss: 6.922e-05
Validation
[153,   100] loss: 8.854e-05
[153,   200] loss: 8.854e-05
Training loss: 0.000, train NMSE: -1.099e+01
Validation loss: 0.000, valid_NMSE: -9.636e+00
--------------------------------------------------
[INFO]: Epoch 154 of 200
Training
[154,   100] loss: 6.821e-05
[154,   200] loss: 6.934e-05
Validation
[154,   100] loss: 8.729e-05
[154,   200] loss: 8.729e-05
Training loss: 0.000, train NMSE: -1.111e+01
Validation loss: 0.000, valid_NMSE: -9.658e+00

Best validation loss: -9.65788745880127

Saving best model for epoch: 154

--------------------------------------------------
[INFO]: Epoch 155 of 200
Training
[155,   100] loss: 6.799e-05
[155,   200] loss: 6.960e-05
Validation
[155,   100] loss: 8.709e-05
[155,   200] loss: 8.709e-05
Training loss: 0.000, train NMSE: -1.147e+01
Validation loss: 0.000, valid_NMSE: -9.690e+00

Best validation loss: -9.690413475036621

Saving best model for epoch: 155

--------------------------------------------------
[INFO]: Epoch 156 of 200
Training
[156,   100] loss: 6.754e-05
[156,   200] loss: 6.936e-05
Validation
[156,   100] loss: 8.747e-05
[156,   200] loss: 8.747e-05
Training loss: 0.000, train NMSE: -1.127e+01
Validation loss: 0.000, valid_NMSE: -9.664e+00
--------------------------------------------------
[INFO]: Epoch 157 of 200
Training
[157,   100] loss: 6.769e-05
[157,   200] loss: 6.887e-05
Validation
[157,   100] loss: 8.753e-05
[157,   200] loss: 8.753e-05
Training loss: 0.000, train NMSE: -1.068e+01
Validation loss: 0.000, valid_NMSE: -9.653e+00
--------------------------------------------------
[INFO]: Epoch 158 of 200
Training
[158,   100] loss: 6.686e-05
[158,   200] loss: 6.874e-05
Validation
[158,   100] loss: 8.714e-05
[158,   200] loss: 8.714e-05
Training loss: 0.000, train NMSE: -1.103e+01
Validation loss: 0.000, valid_NMSE: -9.650e+00
--------------------------------------------------
[INFO]: Epoch 159 of 200
Training
[159,   100] loss: 6.776e-05
[159,   200] loss: 6.772e-05
Validation
[159,   100] loss: 8.872e-05
[159,   200] loss: 8.872e-05
Training loss: 0.000, train NMSE: -1.076e+01
Validation loss: 0.000, valid_NMSE: -9.590e+00
--------------------------------------------------
[INFO]: Epoch 160 of 200
Training
[160,   100] loss: 6.726e-05
[160,   200] loss: 6.807e-05
Validation
[160,   100] loss: 8.731e-05
[160,   200] loss: 8.731e-05
Training loss: 0.000, train NMSE: -1.150e+01
Validation loss: 0.000, valid_NMSE: -9.664e+00
--------------------------------------------------
[INFO]: Epoch 161 of 200
Training
[161,   100] loss: 6.707e-05
[161,   200] loss: 6.757e-05
Validation
[161,   100] loss: 8.778e-05
[161,   200] loss: 8.778e-05
Training loss: 0.000, train NMSE: -1.098e+01
Validation loss: 0.000, valid_NMSE: -9.646e+00
--------------------------------------------------
[INFO]: Epoch 162 of 200
Training
[162,   100] loss: 6.544e-05
[162,   200] loss: 6.859e-05
Validation
[162,   100] loss: 8.719e-05
[162,   200] loss: 8.719e-05
Training loss: 0.000, train NMSE: -1.071e+01
Validation loss: 0.000, valid_NMSE: -9.667e+00
--------------------------------------------------
[INFO]: Epoch 163 of 200
Training
[163,   100] loss: 6.655e-05
[163,   200] loss: 6.739e-05
Validation
[163,   100] loss: 8.668e-05
[163,   200] loss: 8.668e-05
Training loss: 0.000, train NMSE: -1.076e+01
Validation loss: 0.000, valid_NMSE: -9.672e+00
--------------------------------------------------
[INFO]: Epoch 164 of 200
Training
[164,   100] loss: 6.669e-05
[164,   200] loss: 6.651e-05
Validation
[164,   100] loss: 8.612e-05
[164,   200] loss: 8.612e-05
Training loss: 0.000, train NMSE: -1.109e+01
Validation loss: 0.000, valid_NMSE: -9.737e+00

Best validation loss: -9.737360954284668

Saving best model for epoch: 164

--------------------------------------------------
[INFO]: Epoch 165 of 200
Training
[165,   100] loss: 6.610e-05
[165,   200] loss: 6.699e-05
Validation
[165,   100] loss: 8.646e-05
[165,   200] loss: 8.646e-05
Training loss: 0.000, train NMSE: -1.133e+01
Validation loss: 0.000, valid_NMSE: -9.684e+00
--------------------------------------------------
[INFO]: Epoch 166 of 200
Training
[166,   100] loss: 6.660e-05
[166,   200] loss: 6.572e-05
Training loss: 0.000, train NMSE: -1.054e+01
Validation loss: 0.000, valid_NMSE: -9.587e+00

Best validation loss: -9.5870943069458

Saving best model for epoch: 143

--------------------------------------------------
[INFO]: Epoch 144 of 200
Training
[144,   100] loss: 7.088e-05
[144,   200] loss: 7.171e-05
Validation
[144,   100] loss: 8.885e-05
[144,   200] loss: 8.885e-05
Training loss: 0.000, train NMSE: -1.062e+01
Validation loss: 0.000, valid_NMSE: -9.587e+00
--------------------------------------------------
[INFO]: Epoch 145 of 200
Training
[145,   100] loss: 7.049e-05
[145,   200] loss: 7.152e-05
Validation
[145,   100] loss: 8.884e-05
[145,   200] loss: 8.884e-05
Training loss: 0.000, train NMSE: -1.058e+01
Validation loss: 0.000, valid_NMSE: -9.603e+00

Best validation loss: -9.602957725524902

Saving best model for epoch: 145

--------------------------------------------------
[INFO]: Epoch 146 of 200
Training
[146,   100] loss: 7.018e-05
[146,   200] loss: 7.149e-05
Validation
[146,   100] loss: 8.856e-05
[146,   200] loss: 8.856e-05
Training loss: 0.000, train NMSE: -1.094e+01
Validation loss: 0.000, valid_NMSE: -9.602e+00
--------------------------------------------------
[INFO]: Epoch 147 of 200
Training
[147,   100] loss: 7.078e-05
[147,   200] loss: 7.020e-05
Validation
[147,   100] loss: 8.840e-05
[147,   200] loss: 8.840e-05
Training loss: 0.000, train NMSE: -1.117e+01
Validation loss: 0.000, valid_NMSE: -9.621e+00

Best validation loss: -9.6213960647583

Saving best model for epoch: 147

--------------------------------------------------
[INFO]: Epoch 148 of 200
Training
[148,   100] loss: 7.058e-05
[148,   200] loss: 6.976e-05
Validation
[148,   100] loss: 8.817e-05
[148,   200] loss: 8.817e-05
Training loss: 0.000, train NMSE: -1.060e+01
Validation loss: 0.000, valid_NMSE: -9.621e+00
--------------------------------------------------
[INFO]: Epoch 149 of 200
Training
[149,   100] loss: 7.021e-05
[149,   200] loss: 6.984e-05
Validation
[149,   100] loss: 8.838e-05
[149,   200] loss: 8.838e-05
Training loss: 0.000, train NMSE: -1.095e+01
Validation loss: 0.000, valid_NMSE: -9.587e+00
--------------------------------------------------
[INFO]: Epoch 150 of 200
Training
[150,   100] loss: 7.003e-05
[150,   200] loss: 6.970e-05
Validation
[150,   100] loss: 8.788e-05
[150,   200] loss: 8.788e-05
Training loss: 0.000, train NMSE: -1.102e+01
Validation loss: 0.000, valid_NMSE: -9.607e+00
--------------------------------------------------
[INFO]: Epoch 151 of 200
Training
[151,   100] loss: 6.950e-05
[151,   200] loss: 6.976e-05
Validation
[151,   100] loss: 8.798e-05
[151,   200] loss: 8.798e-05
Training loss: 0.000, train NMSE: -1.063e+01
Validation loss: 0.000, valid_NMSE: -9.605e+00
--------------------------------------------------
[INFO]: Epoch 152 of 200
Training
[152,   100] loss: 6.855e-05
[152,   200] loss: 7.021e-05
Validation
[152,   100] loss: 8.790e-05
[152,   200] loss: 8.790e-05
Training loss: 0.000, train NMSE: -1.140e+01
Validation loss: 0.000, valid_NMSE: -9.597e+00
--------------------------------------------------
[INFO]: Epoch 153 of 200
Training
[153,   100] loss: 6.881e-05
[153,   200] loss: 6.920e-05
Validation
[153,   100] loss: 8.838e-05
[153,   200] loss: 8.838e-05
Training loss: 0.000, train NMSE: -1.097e+01
Validation loss: 0.000, valid_NMSE: -9.628e+00

Best validation loss: -9.627691268920898

Saving best model for epoch: 153

--------------------------------------------------
[INFO]: Epoch 154 of 200
Training
[154,   100] loss: 6.814e-05
[154,   200] loss: 6.934e-05
Validation
[154,   100] loss: 8.721e-05
[154,   200] loss: 8.721e-05
Training loss: 0.000, train NMSE: -1.115e+01
Validation loss: 0.000, valid_NMSE: -9.623e+00
--------------------------------------------------
[INFO]: Epoch 155 of 200
Training
[155,   100] loss: 6.795e-05
[155,   200] loss: 6.949e-05
Validation
[155,   100] loss: 8.693e-05
[155,   200] loss: 8.693e-05
Training loss: 0.000, train NMSE: -1.150e+01
Validation loss: 0.000, valid_NMSE: -9.657e+00

Best validation loss: -9.656792640686035

Saving best model for epoch: 155

--------------------------------------------------
[INFO]: Epoch 156 of 200
Training
[156,   100] loss: 6.760e-05
[156,   200] loss: 6.936e-05
Validation
[156,   100] loss: 8.743e-05
[156,   200] loss: 8.743e-05
Training loss: 0.000, train NMSE: -1.126e+01
Validation loss: 0.000, valid_NMSE: -9.631e+00
--------------------------------------------------
[INFO]: Epoch 157 of 200
Training
[157,   100] loss: 6.769e-05
[157,   200] loss: 6.894e-05
Validation
[157,   100] loss: 8.766e-05
[157,   200] loss: 8.766e-05
Training loss: 0.000, train NMSE: -1.068e+01
Validation loss: 0.000, valid_NMSE: -9.597e+00
--------------------------------------------------
[INFO]: Epoch 158 of 200
Training
[158,   100] loss: 6.691e-05
[158,   200] loss: 6.877e-05
Validation
[158,   100] loss: 8.742e-05
[158,   200] loss: 8.742e-05
Training loss: 0.000, train NMSE: -1.101e+01
Validation loss: 0.000, valid_NMSE: -9.583e+00
--------------------------------------------------
[INFO]: Epoch 159 of 200
Training
[159,   100] loss: 6.778e-05
[159,   200] loss: 6.773e-05
Validation
[159,   100] loss: 8.900e-05
[159,   200] loss: 8.900e-05
Training loss: 0.000, train NMSE: -1.077e+01
Validation loss: 0.000, valid_NMSE: -9.530e+00
--------------------------------------------------
[INFO]: Epoch 160 of 200
Training
[160,   100] loss: 6.730e-05
[160,   200] loss: 6.798e-05
Validation
[160,   100] loss: 8.743e-05
[160,   200] loss: 8.743e-05
Training loss: 0.000, train NMSE: -1.148e+01
Validation loss: 0.000, valid_NMSE: -9.609e+00
--------------------------------------------------
[INFO]: Epoch 161 of 200
Training
[161,   100] loss: 6.709e-05
[161,   200] loss: 6.757e-05
Validation
[161,   100] loss: 8.755e-05
[161,   200] loss: 8.755e-05
Training loss: 0.000, train NMSE: -1.100e+01
Validation loss: 0.000, valid_NMSE: -9.615e+00
--------------------------------------------------
[INFO]: Epoch 162 of 200
Training
[162,   100] loss: 6.549e-05
[162,   200] loss: 6.864e-05
Validation
[162,   100] loss: 8.736e-05
[162,   200] loss: 8.736e-05
Training loss: 0.000, train NMSE: -1.072e+01
Validation loss: 0.000, valid_NMSE: -9.617e+00
--------------------------------------------------
[INFO]: Epoch 163 of 200
Training
[163,   100] loss: 6.654e-05
[163,   200] loss: 6.744e-05
Validation
[163,   100] loss: 8.669e-05
[163,   200] loss: 8.669e-05
Training loss: 0.000, train NMSE: -1.075e+01
Validation loss: 0.000, valid_NMSE: -9.621e+00
--------------------------------------------------
[INFO]: Epoch 164 of 200
Training
[164,   100] loss: 6.673e-05
[164,   200] loss: 6.655e-05
Validation
[164,   100] loss: 8.620e-05
[164,   200] loss: 8.620e-05
Training loss: 0.000, train NMSE: -1.109e+01
Validation loss: 0.000, valid_NMSE: -9.680e+00

Best validation loss: -9.680267333984375

Saving best model for epoch: 164

--------------------------------------------------
[INFO]: Epoch 165 of 200
Training
[165,   100] loss: 6.618e-05
[165,   200] loss: 6.702e-05
Validation
[165,   100] loss: 8.655e-05
[165,   200] loss: 8.655e-05
Training loss: 0.000, train NMSE: -1.134e+01
Validation loss: 0.000, valid_NMSE: -9.628e+00
--------------------------------------------------
[INFO]: Epoch 166 of 200
Training
[166,   100] loss: 6.668e-05
[166,   200] loss: 6.575e-05
Validation
[166,   100] loss: 8.605e-05
[166,   200] loss: 8.605e-05
Training loss: 0.000, train NMSE: -1.143e+01
Validation loss: 0.000, valid_NMSE: -9.682e+00

Best validation loss: -9.681947708129883

Saving best model for epoch: 166

--------------------------------------------------
[INFO]: Epoch 167 of 200
Training
[167,   100] loss: 6.571e-05
[167,   200] loss: 6.638e-05
Validation
[167,   100] loss: 8.662e-05
[167,   200] loss: 8.662e-05
Training loss: 0.000, train NMSE: -1.092e+01
Validation loss: 0.000, valid_NMSE: -9.609e+00
--------------------------------------------------
[INFO]: Epoch 168 of 200
Training
[168,   100] loss: 6.637e-05
[168,   200] loss: 6.545e-05
Validation
[168,   100] loss: 8.589e-05
[168,   200] loss: 8.589e-05
Training loss: 0.000, train NMSE: -1.097e+01
Validation loss: 0.000, valid_NMSE: -9.621e+00
Validation
[166,   100] loss: 8.609e-05
[166,   200] loss: 8.609e-05
Training loss: 0.000, train NMSE: -1.142e+01
Validation loss: 0.000, valid_NMSE: -9.718e+00
--------------------------------------------------
[INFO]: Epoch 167 of 200
Training
[167,   100] loss: 6.558e-05
[167,   200] loss: 6.638e-05
Validation
[167,   100] loss: 8.671e-05
[167,   200] loss: 8.671e-05
Training loss: 0.000, train NMSE: -1.093e+01
Validation loss: 0.000, valid_NMSE: -9.661e+00
--------------------------------------------------
[INFO]: Epoch 168 of 200
Training
[168,   100] loss: 6.619e-05
[168,   200] loss: 6.542e-05
Validation
[168,   100] loss: 8.571e-05
[168,   200] loss: 8.571e-05
Training loss: 0.000, train NMSE: -1.099e+01
Validation loss: 0.000, valid_NMSE: -9.697e+00
--------------------------------------------------
[INFO]: Epoch 169 of 200
Training
[169,   100] loss: 6.576e-05
[169,   200] loss: 6.585e-05
Validation
[169,   100] loss: 8.569e-05
[169,   200] loss: 8.569e-05
Training loss: 0.000, train NMSE: -1.216e+01
Validation loss: 0.000, valid_NMSE: -9.746e+00

Best validation loss: -9.745841979980469

Saving best model for epoch: 169

--------------------------------------------------
[INFO]: Epoch 170 of 200
Training
[170,   100] loss: 6.539e-05
[170,   200] loss: 6.571e-05
Validation
[170,   100] loss: 8.600e-05
[170,   200] loss: 8.600e-05
Training loss: 0.000, train NMSE: -1.122e+01
Validation loss: 0.000, valid_NMSE: -9.689e+00
--------------------------------------------------
[INFO]: Epoch 171 of 200
Training
[171,   100] loss: 6.497e-05
[171,   200] loss: 6.597e-05
Validation
[171,   100] loss: 8.601e-05
[171,   200] loss: 8.601e-05
Training loss: 0.000, train NMSE: -1.138e+01
Validation loss: 0.000, valid_NMSE: -9.722e+00
--------------------------------------------------
[INFO]: Epoch 172 of 200
Training
[172,   100] loss: 6.440e-05
[172,   200] loss: 6.581e-05
Validation
[172,   100] loss: 8.567e-05
[172,   200] loss: 8.567e-05
Training loss: 0.000, train NMSE: -1.122e+01
Validation loss: 0.000, valid_NMSE: -9.727e+00
--------------------------------------------------
[INFO]: Epoch 173 of 200
Training
[173,   100] loss: 6.533e-05
[173,   200] loss: 6.459e-05
Validation
[173,   100] loss: 8.647e-05
[173,   200] loss: 8.647e-05
Training loss: 0.000, train NMSE: -1.208e+01
Validation loss: 0.000, valid_NMSE: -9.667e+00
--------------------------------------------------
[INFO]: Epoch 174 of 200
Training
[174,   100] loss: 6.407e-05
[174,   200] loss: 6.547e-05
Validation
[174,   100] loss: 8.567e-05
[174,   200] loss: 8.567e-05
Training loss: 0.000, train NMSE: -1.096e+01
Validation loss: 0.000, valid_NMSE: -9.708e+00
--------------------------------------------------
[INFO]: Epoch 175 of 200
Training
[175,   100] loss: 6.449e-05
[175,   200] loss: 6.465e-05
Validation
[175,   100] loss: 8.521e-05
[175,   200] loss: 8.521e-05
Training loss: 0.000, train NMSE: -1.101e+01
Validation loss: 0.000, valid_NMSE: -9.739e+00
--------------------------------------------------
[INFO]: Epoch 176 of 200
Training
[176,   100] loss: 6.433e-05
[176,   200] loss: 6.467e-05
Validation
[176,   100] loss: 8.560e-05
[176,   200] loss: 8.560e-05
Training loss: 0.000, train NMSE: -1.124e+01
Validation loss: 0.000, valid_NMSE: -9.705e+00
--------------------------------------------------
[INFO]: Epoch 177 of 200
Training
[177,   100] loss: 6.369e-05
[177,   200] loss: 6.471e-05
Validation
[177,   100] loss: 8.523e-05
[177,   200] loss: 8.523e-05
Training loss: 0.000, train NMSE: -1.143e+01
Validation loss: 0.000, valid_NMSE: -9.717e+00
--------------------------------------------------
[INFO]: Epoch 178 of 200
Training
[178,   100] loss: 6.427e-05
[178,   200] loss: 6.387e-05
Validation
[178,   100] loss: 8.582e-05
[178,   200] loss: 8.582e-05
Training loss: 0.000, train NMSE: -1.099e+01
Validation loss: 0.000, valid_NMSE: -9.699e+00
--------------------------------------------------
[INFO]: Epoch 179 of 200
Training
[179,   100] loss: 6.287e-05
[179,   200] loss: 6.467e-05
Validation
[179,   100] loss: 8.551e-05
[179,   200] loss: 8.551e-05
Training loss: 0.000, train NMSE: -1.136e+01
Validation loss: 0.000, valid_NMSE: -9.722e+00
--------------------------------------------------
[INFO]: Epoch 180 of 200
Training
[180,   100] loss: 6.370e-05
[180,   200] loss: 6.346e-05
Validation
[180,   100] loss: 8.507e-05
[180,   200] loss: 8.507e-05
Training loss: 0.000, train NMSE: -1.153e+01
Validation loss: 0.000, valid_NMSE: -9.708e+00
--------------------------------------------------
[INFO]: Epoch 181 of 200
Training
[181,   100] loss: 6.276e-05
[181,   200] loss: 6.428e-05
Validation
[181,   100] loss: 8.522e-05
[181,   200] loss: 8.522e-05
Training loss: 0.000, train NMSE: -1.141e+01
Validation loss: 0.000, valid_NMSE: -9.720e+00
--------------------------------------------------
[INFO]: Epoch 182 of 200
Training
[182,   100] loss: 6.348e-05
[182,   200] loss: 6.330e-05
Validation
[182,   100] loss: 8.492e-05
[182,   200] loss: 8.492e-05
Training loss: 0.000, train NMSE: -1.132e+01
Validation loss: 0.000, valid_NMSE: -9.734e+00
--------------------------------------------------
[INFO]: Epoch 183 of 200
Training
[183,   100] loss: 6.205e-05
[183,   200] loss: 6.418e-05
Validation
[183,   100] loss: 8.461e-05
[183,   200] loss: 8.461e-05
Training loss: 0.000, train NMSE: -1.180e+01
Validation loss: 0.000, valid_NMSE: -9.749e+00

Best validation loss: -9.748941421508789

Saving best model for epoch: 183

--------------------------------------------------
[INFO]: Epoch 184 of 200
Training
[184,   100] loss: 6.230e-05
[184,   200] loss: 6.366e-05
Validation
[184,   100] loss: 8.663e-05
[184,   200] loss: 8.663e-05
Training loss: 0.000, train NMSE: -1.151e+01
Validation loss: 0.000, valid_NMSE: -9.626e+00
--------------------------------------------------
[INFO]: Epoch 185 of 200
Training
[185,   100] loss: 6.282e-05
[185,   200] loss: 6.309e-05
Validation
[185,   100] loss: 8.598e-05
[185,   200] loss: 8.598e-05
Training loss: 0.000, train NMSE: -1.126e+01
Validation loss: 0.000, valid_NMSE: -9.677e+00
--------------------------------------------------
[INFO]: Epoch 186 of 200
Training
[186,   100] loss: 6.379e-05
[186,   200] loss: 6.136e-05
Validation
[186,   100] loss: 8.425e-05
[186,   200] loss: 8.425e-05
Training loss: 0.000, train NMSE: -1.153e+01
Validation loss: 0.000, valid_NMSE: -9.775e+00

Best validation loss: -9.775040626525879

Saving best model for epoch: 186

--------------------------------------------------
[INFO]: Epoch 187 of 200
Training
[187,   100] loss: 6.250e-05
[187,   200] loss: 6.248e-05
Validation
[187,   100] loss: 8.415e-05
[187,   200] loss: 8.415e-05
Training loss: 0.000, train NMSE: -1.160e+01
Validation loss: 0.000, valid_NMSE: -9.769e+00
--------------------------------------------------
[INFO]: Epoch 188 of 200
Training
[188,   100] loss: 6.295e-05
[188,   200] loss: 6.182e-05
Validation
[188,   100] loss: 8.512e-05
[188,   200] loss: 8.512e-05
Training loss: 0.000, train NMSE: -1.160e+01
Validation loss: 0.000, valid_NMSE: -9.716e+00
--------------------------------------------------
[INFO]: Epoch 189 of 200
Training
[189,   100] loss: 6.230e-05
[189,   200] loss: 6.190e-05
Validation
[189,   100] loss: 8.477e-05
[189,   200] loss: 8.477e-05
Training loss: 0.000, train NMSE: -1.130e+01
Validation loss: 0.000, valid_NMSE: -9.741e+00
--------------------------------------------------
[INFO]: Epoch 190 of 200
Training
[190,   100] loss: 6.213e-05
[190,   200] loss: 6.192e-05
Validation
[190,   100] loss: 8.446e-05
[190,   200] loss: 8.446e-05
Training loss: 0.000, train NMSE: -1.114e+01
Validation loss: 0.000, valid_NMSE: -9.714e+00
--------------------------------------------------
[INFO]: Epoch 191 of 200
Training
[191,   100] loss: 6.179e-05
[191,   200] loss: 6.263e-05
Validation
[191,   100] loss: 8.418e-05
[191,   200] loss: 8.418e-05
Training loss: 0.000, train NMSE: -1.211e+01
Validation loss: 0.000, valid_NMSE: -9.744e+00
--------------------------------------------------
[INFO]: Epoch 192 of 200
Training
[192,   100] loss: 6.177e-05
[192,   200] loss: 6.161e-05
Validation
[192,   100] loss: 8.517e-05
[192,   200] loss: 8.517e-05
--------------------------------------------------
[INFO]: Epoch 169 of 200
Training
[169,   100] loss: 6.583e-05
[169,   200] loss: 6.588e-05
Validation
[169,   100] loss: 8.579e-05
[169,   200] loss: 8.579e-05
Training loss: 0.000, train NMSE: -1.215e+01
Validation loss: 0.000, valid_NMSE: -9.690e+00

Best validation loss: -9.689519882202148

Saving best model for epoch: 169

--------------------------------------------------
[INFO]: Epoch 170 of 200
Training
[170,   100] loss: 6.537e-05
[170,   200] loss: 6.582e-05
Validation
[170,   100] loss: 8.628e-05
[170,   200] loss: 8.628e-05
Training loss: 0.000, train NMSE: -1.122e+01
Validation loss: 0.000, valid_NMSE: -9.606e+00
--------------------------------------------------
[INFO]: Epoch 171 of 200
Training
[171,   100] loss: 6.504e-05
[171,   200] loss: 6.602e-05
Validation
[171,   100] loss: 8.607e-05
[171,   200] loss: 8.607e-05
Training loss: 0.000, train NMSE: -1.137e+01
Validation loss: 0.000, valid_NMSE: -9.651e+00
--------------------------------------------------
[INFO]: Epoch 172 of 200
Training
[172,   100] loss: 6.445e-05
[172,   200] loss: 6.588e-05
Validation
[172,   100] loss: 8.623e-05
[172,   200] loss: 8.623e-05
Training loss: 0.000, train NMSE: -1.124e+01
Validation loss: 0.000, valid_NMSE: -9.605e+00
--------------------------------------------------
[INFO]: Epoch 173 of 200
Training
[173,   100] loss: 6.542e-05
[173,   200] loss: 6.471e-05
Validation
[173,   100] loss: 8.615e-05
[173,   200] loss: 8.615e-05
Training loss: 0.000, train NMSE: -1.210e+01
Validation loss: 0.000, valid_NMSE: -9.630e+00
--------------------------------------------------
[INFO]: Epoch 174 of 200
Training
[174,   100] loss: 6.412e-05
[174,   200] loss: 6.550e-05
Validation
[174,   100] loss: 8.552e-05
[174,   200] loss: 8.552e-05
Training loss: 0.000, train NMSE: -1.096e+01
Validation loss: 0.000, valid_NMSE: -9.664e+00
--------------------------------------------------
[INFO]: Epoch 175 of 200
Training
[175,   100] loss: 6.447e-05
[175,   200] loss: 6.475e-05
Validation
[175,   100] loss: 8.530e-05
[175,   200] loss: 8.530e-05
Training loss: 0.000, train NMSE: -1.100e+01
Validation loss: 0.000, valid_NMSE: -9.665e+00
--------------------------------------------------
[INFO]: Epoch 176 of 200
Training
[176,   100] loss: 6.429e-05
[176,   200] loss: 6.474e-05
Validation
[176,   100] loss: 8.559e-05
[176,   200] loss: 8.559e-05
Training loss: 0.000, train NMSE: -1.126e+01
Validation loss: 0.000, valid_NMSE: -9.635e+00
--------------------------------------------------
[INFO]: Epoch 177 of 200
Training
[177,   100] loss: 6.384e-05
[177,   200] loss: 6.475e-05
Validation
[177,   100] loss: 8.520e-05
[177,   200] loss: 8.520e-05
Training loss: 0.000, train NMSE: -1.142e+01
Validation loss: 0.000, valid_NMSE: -9.653e+00
--------------------------------------------------
[INFO]: Epoch 178 of 200
Training
[178,   100] loss: 6.432e-05
[178,   200] loss: 6.402e-05
Validation
[178,   100] loss: 8.588e-05
[178,   200] loss: 8.588e-05
Training loss: 0.000, train NMSE: -1.095e+01
Validation loss: 0.000, valid_NMSE: -9.616e+00
--------------------------------------------------
[INFO]: Epoch 179 of 200
Training
[179,   100] loss: 6.297e-05
[179,   200] loss: 6.475e-05
Validation
[179,   100] loss: 8.570e-05
[179,   200] loss: 8.570e-05
Training loss: 0.000, train NMSE: -1.136e+01
Validation loss: 0.000, valid_NMSE: -9.644e+00
--------------------------------------------------
[INFO]: Epoch 180 of 200
Training
[180,   100] loss: 6.384e-05
[180,   200] loss: 6.358e-05
Validation
[180,   100] loss: 8.506e-05
[180,   200] loss: 8.506e-05
Training loss: 0.000, train NMSE: -1.153e+01
Validation loss: 0.000, valid_NMSE: -9.623e+00
--------------------------------------------------
[INFO]: Epoch 181 of 200
Training
[181,   100] loss: 6.302e-05
[181,   200] loss: 6.450e-05
Validation
[181,   100] loss: 8.518e-05
[181,   200] loss: 8.518e-05
Training loss: 0.000, train NMSE: -1.142e+01
Validation loss: 0.000, valid_NMSE: -9.660e+00
--------------------------------------------------
[INFO]: Epoch 182 of 200
Training
[182,   100] loss: 6.354e-05
[182,   200] loss: 6.342e-05
Validation
[182,   100] loss: 8.482e-05
[182,   200] loss: 8.482e-05
Training loss: 0.000, train NMSE: -1.129e+01
Validation loss: 0.000, valid_NMSE: -9.674e+00
--------------------------------------------------
[INFO]: Epoch 183 of 200
Training
[183,   100] loss: 6.220e-05
[183,   200] loss: 6.434e-05
Validation
[183,   100] loss: 8.473e-05
[183,   200] loss: 8.473e-05
Training loss: 0.000, train NMSE: -1.182e+01
Validation loss: 0.000, valid_NMSE: -9.651e+00
--------------------------------------------------
[INFO]: Epoch 184 of 200
Training
[184,   100] loss: 6.238e-05
[184,   200] loss: 6.380e-05
Validation
[184,   100] loss: 8.669e-05
[184,   200] loss: 8.669e-05
Training loss: 0.000, train NMSE: -1.150e+01
Validation loss: 0.000, valid_NMSE: -9.549e+00
--------------------------------------------------
[INFO]: Epoch 185 of 200
Training
[185,   100] loss: 6.289e-05
[185,   200] loss: 6.325e-05
Validation
[185,   100] loss: 8.606e-05
[185,   200] loss: 8.606e-05
Training loss: 0.000, train NMSE: -1.122e+01
Validation loss: 0.000, valid_NMSE: -9.598e+00
--------------------------------------------------
[INFO]: Epoch 186 of 200
Training
[186,   100] loss: 6.389e-05
[186,   200] loss: 6.152e-05
Validation
[186,   100] loss: 8.446e-05
[186,   200] loss: 8.446e-05
Training loss: 0.000, train NMSE: -1.152e+01
Validation loss: 0.000, valid_NMSE: -9.682e+00
--------------------------------------------------
[INFO]: Epoch 187 of 200
Training
[187,   100] loss: 6.266e-05
[187,   200] loss: 6.270e-05
Validation
[187,   100] loss: 8.422e-05
[187,   200] loss: 8.422e-05
Training loss: 0.000, train NMSE: -1.156e+01
Validation loss: 0.000, valid_NMSE: -9.692e+00

Best validation loss: -9.692020416259766

Saving best model for epoch: 187

--------------------------------------------------
[INFO]: Epoch 188 of 200
Training
[188,   100] loss: 6.296e-05
[188,   200] loss: 6.200e-05
Validation
[188,   100] loss: 8.530e-05
[188,   200] loss: 8.530e-05
Training loss: 0.000, train NMSE: -1.158e+01
Validation loss: 0.000, valid_NMSE: -9.598e+00
--------------------------------------------------
[INFO]: Epoch 189 of 200
Training
[189,   100] loss: 6.243e-05
[189,   200] loss: 6.202e-05
Validation
[189,   100] loss: 8.525e-05
[189,   200] loss: 8.525e-05
Training loss: 0.000, train NMSE: -1.130e+01
Validation loss: 0.000, valid_NMSE: -9.646e+00
--------------------------------------------------
[INFO]: Epoch 190 of 200
Training
[190,   100] loss: 6.222e-05
[190,   200] loss: 6.203e-05
Validation
[190,   100] loss: 8.463e-05
[190,   200] loss: 8.463e-05
Training loss: 0.000, train NMSE: -1.112e+01
Validation loss: 0.000, valid_NMSE: -9.652e+00
--------------------------------------------------
[INFO]: Epoch 191 of 200
Training
[191,   100] loss: 6.195e-05
[191,   200] loss: 6.293e-05
Validation
[191,   100] loss: 8.441e-05
[191,   200] loss: 8.441e-05
Training loss: 0.000, train NMSE: -1.206e+01
Validation loss: 0.000, valid_NMSE: -9.626e+00
--------------------------------------------------
[INFO]: Epoch 192 of 200
Training
[192,   100] loss: 6.195e-05
[192,   200] loss: 6.174e-05
Validation
[192,   100] loss: 8.502e-05
[192,   200] loss: 8.502e-05
Training loss: 0.000, train NMSE: -1.202e+01
Validation loss: 0.000, valid_NMSE: -9.603e+00
--------------------------------------------------
[INFO]: Epoch 193 of 200
Training
[193,   100] loss: 6.215e-05
[193,   200] loss: 6.102e-05
Validation
[193,   100] loss: 8.558e-05
[193,   200] loss: 8.558e-05
Training loss: 0.000, train NMSE: -1.225e+01
Validation loss: 0.000, valid_NMSE: -9.580e+00
--------------------------------------------------
[INFO]: Epoch 194 of 200
Training
[194,   100] loss: 6.130e-05
[194,   200] loss: 6.166e-05
Validation
[194,   100] loss: 8.482e-05
[194,   200] loss: 8.482e-05
Training loss: 0.000, train NMSE: -1.159e+01
Validation loss: 0.000, valid_NMSE: -9.642e+00
--------------------------------------------------
[INFO]: Epoch 195 of 200
Training
[195,   100] loss: 6.032e-05
[195,   200] loss: 6.226e-05/home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE
  warn(f"Failed to load image Python extension: {e}")

Training loss: 0.000, train NMSE: -1.203e+01
Validation loss: 0.000, valid_NMSE: -9.675e+00
--------------------------------------------------
[INFO]: Epoch 193 of 200
Training
[193,   100] loss: 6.210e-05
[193,   200] loss: 6.085e-05
Validation
[193,   100] loss: 8.545e-05
[193,   200] loss: 8.545e-05
Training loss: 0.000, train NMSE: -1.224e+01
Validation loss: 0.000, valid_NMSE: -9.651e+00
--------------------------------------------------
[INFO]: Epoch 194 of 200
Training
[194,   100] loss: 6.112e-05
[194,   200] loss: 6.157e-05
Validation
[194,   100] loss: 8.450e-05
[194,   200] loss: 8.450e-05
Training loss: 0.000, train NMSE: -1.157e+01
Validation loss: 0.000, valid_NMSE: -9.729e+00
--------------------------------------------------
[INFO]: Epoch 195 of 200
Training
[195,   100] loss: 6.019e-05
[195,   200] loss: 6.222e-05
Validation
[195,   100] loss: 8.497e-05
[195,   200] loss: 8.497e-05
Training loss: 0.000, train NMSE: -1.166e+01
Validation loss: 0.000, valid_NMSE: -9.698e+00
--------------------------------------------------
[INFO]: Epoch 196 of 200
Training
[196,   100] loss: 6.015e-05
[196,   200] loss: 6.185e-05
Validation
[196,   100] loss: 8.486e-05
[196,   200] loss: 8.486e-05
Training loss: 0.000, train NMSE: -1.135e+01
Validation loss: 0.000, valid_NMSE: -9.681e+00
--------------------------------------------------
[INFO]: Epoch 197 of 200
Training
[197,   100] loss: 6.048e-05
[197,   200] loss: 6.121e-05
Validation
[197,   100] loss: 8.510e-05
[197,   200] loss: 8.510e-05
Training loss: 0.000, train NMSE: -1.161e+01
Validation loss: 0.000, valid_NMSE: -9.669e+00
--------------------------------------------------
[INFO]: Epoch 198 of 200
Training
[198,   100] loss: 6.036e-05
[198,   200] loss: 6.133e-05
Validation
[198,   100] loss: 8.674e-05
[198,   200] loss: 8.674e-05
Training loss: 0.000, train NMSE: -1.154e+01
Validation loss: 0.000, valid_NMSE: -9.586e+00
--------------------------------------------------
[INFO]: Epoch 199 of 200
Training
[199,   100] loss: 5.964e-05
[199,   200] loss: 6.184e-05
Validation
[199,   100] loss: 8.424e-05
[199,   200] loss: 8.424e-05
Training loss: 0.000, train NMSE: -1.167e+01
Validation loss: 0.000, valid_NMSE: -9.702e+00
--------------------------------------------------
[INFO]: Epoch 200 of 200
Training
[200,   100] loss: 6.024e-05
[200,   200] loss: 6.056e-05
Validation
[200,   100] loss: 8.451e-05
[200,   200] loss: 8.451e-05
Training loss: 0.000, train NMSE: -1.123e+01
Validation loss: 0.000, valid_NMSE: -9.695e+00
--------------------------------------------------
Saving final model
TRAINING COMPLETE
/home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE
  warn(f"Failed to load image Python extension: {e}")

Validation
[195,   100] loss: 8.527e-05
[195,   200] loss: 8.527e-05
Training loss: 0.000, train NMSE: -1.164e+01
Validation loss: 0.000, valid_NMSE: -9.580e+00
--------------------------------------------------
[INFO]: Epoch 196 of 200
Training
[196,   100] loss: 6.034e-05
[196,   200] loss: 6.203e-05
Validation
[196,   100] loss: 8.524e-05
[196,   200] loss: 8.524e-05
Training loss: 0.000, train NMSE: -1.135e+01
Validation loss: 0.000, valid_NMSE: -9.561e+00
--------------------------------------------------
[INFO]: Epoch 197 of 200
Training
[197,   100] loss: 6.070e-05
[197,   200] loss: 6.135e-05
Validation
[197,   100] loss: 8.505e-05
[197,   200] loss: 8.505e-05
Training loss: 0.000, train NMSE: -1.163e+01
Validation loss: 0.000, valid_NMSE: -9.576e+00
--------------------------------------------------
[INFO]: Epoch 198 of 200
Training
[198,   100] loss: 6.051e-05
[198,   200] loss: 6.147e-05
Validation
[198,   100] loss: 8.684e-05
[198,   200] loss: 8.684e-05
Training loss: 0.000, train NMSE: -1.154e+01
Validation loss: 0.000, valid_NMSE: -9.459e+00
--------------------------------------------------
[INFO]: Epoch 199 of 200
Training
[199,   100] loss: 5.978e-05
[199,   200] loss: 6.200e-05
Validation
[199,   100] loss: 8.428e-05
[199,   200] loss: 8.428e-05
Training loss: 0.000, train NMSE: -1.165e+01
Validation loss: 0.000, valid_NMSE: -9.611e+00
--------------------------------------------------
[INFO]: Epoch 200 of 200
Training
[200,   100] loss: 6.044e-05
[200,   200] loss: 6.083e-05
Validation
[200,   100] loss: 8.509e-05
[200,   200] loss: 8.509e-05
Training loss: 0.000, train NMSE: -1.120e+01
Validation loss: 0.000, valid_NMSE: -9.524e+00
--------------------------------------------------
Saving final model
TRAINING COMPLETE
