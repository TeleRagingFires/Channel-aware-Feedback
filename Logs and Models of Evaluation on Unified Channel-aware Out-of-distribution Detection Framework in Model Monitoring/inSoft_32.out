1.13.1+cu117
inSoft
Dadicated Mode inSoft
Dedicated Mode inSoft
trainset len 112000 valset len 48000
New_trainset len 40000 valset len 48000
825,049 training parameters.

825,049 training parameters.

[INFO]: Epoch 1 of 200
Training
[1,   100] loss: 2.444e-04
[1,   200] loss: 1.927e-04
Validation
[1,   100] loss: 2.025e-04
[1,   200] loss: 2.018e-04
Training loss: 0.000, train NMSE: -4.011e+00
Validation loss: 0.000, valid_NMSE: -3.933e+00

Best validation loss: -3.932840347290039

Saving best model for epoch: 1

--------------------------------------------------
[INFO]: Epoch 2 of 200
Training
[2,   100] loss: 1.642e-04
[2,   200] loss: 1.512e-04
Validation
[2,   100] loss: 1.737e-04
[2,   200] loss: 1.727e-04
Training loss: 0.000, train NMSE: -4.639e+00
Validation loss: 0.000, valid_NMSE: -4.706e+00

Best validation loss: -4.706432342529297

Saving best model for epoch: 2

--------------------------------------------------
[INFO]: Epoch 3 of 200
Training
[3,   100] loss: 1.427e-04
[3,   200] loss: 1.364e-04
Validation
[3,   100] loss: 1.607e-04
[3,   200] loss: 1.595e-04
Training loss: 0.000, train NMSE: -5.168e+00
Validation loss: 0.000, valid_NMSE: -5.103e+00

Best validation loss: -5.103432655334473

Saving best model for epoch: 3

--------------------------------------------------
[INFO]: Epoch 4 of 200
Training
[4,   100] loss: 1.299e-04
[4,   200] loss: 1.285e-04
Validation
[4,   100] loss: 1.501e-04
[4,   200] loss: 1.490e-04
Training loss: 0.000, train NMSE: -5.171e+00
Validation loss: 0.000, valid_NMSE: -5.444e+00

Best validation loss: -5.443916320800781

Saving best model for epoch: 4

--------------------------------------------------
[INFO]: Epoch 5 of 200
Training
[5,   100] loss: 1.229e-04
[5,   200] loss: 1.183e-04
Validation
[5,   100] loss: 1.396e-04
[5,   200] loss: 1.384e-04
Training loss: 0.000, train NMSE: -5.740e+00
Validation loss: 0.000, valid_NMSE: -5.732e+00

Best validation loss: -5.732032775878906

Saving best model for epoch: 5

--------------------------------------------------
[INFO]: Epoch 6 of 200
Training
[6,   100] loss: 1.133e-04
[6,   200] loss: 1.125e-04
Validation
[6,   100] loss: 1.304e-04
[6,   200] loss: 1.289e-04
Training loss: 0.000, train NMSE: -6.107e+00
Validation loss: 0.000, valid_NMSE: -6.014e+00

Best validation loss: -6.014345169067383

Saving best model for epoch: 6

--------------------------------------------------
[INFO]: Epoch 7 of 200
Training
[7,   100] loss: 1.074e-04
[7,   200] loss: 1.015e-04
Validation
[7,   100] loss: 1.221e-04
[7,   200] loss: 1.206e-04
Training loss: 0.000, train NMSE: -6.591e+00
Validation loss: 0.000, valid_NMSE: -6.314e+00

Best validation loss: -6.314187049865723

Saving best model for epoch: 7

--------------------------------------------------
[INFO]: Epoch 8 of 200
Training
[8,   100] loss: 9.861e-05
[8,   200] loss: 9.392e-05
Validation
[8,   100] loss: 1.117e-04
[8,   200] loss: 1.102e-04
Training loss: 0.000, train NMSE: -7.026e+00
Validation loss: 0.000, valid_NMSE: -6.678e+00

Best validation loss: -6.677766799926758

Saving best model for epoch: 8

--------------------------------------------------
[INFO]: Epoch 9 of 200
Training
[9,   100] loss: 9.029e-05
[9,   200] loss: 8.748e-05
Validation
[9,   100] loss: 1.063e-04
[9,   200] loss: 1.048e-04
Training loss: 0.000, train NMSE: -6.575e+00
Validation loss: 0.000, valid_NMSE: -6.988e+00

Best validation loss: -6.988438606262207

Saving best model for epoch: 9

--------------------------------------------------
[INFO]: Epoch 10 of 200
Training
[10,   100] loss: 8.695e-05
[10,   200] loss: 8.139e-05
Validation
[10,   100] loss: 1.009e-04
[10,   200] loss: 9.912e-05
Training loss: 0.000, train NMSE: -7.710e+00
Validation loss: 0.000, valid_NMSE: -7.043e+00

Best validation loss: -7.042837142944336

Saving best model for epoch: 10

--------------------------------------------------
[INFO]: Epoch 11 of 200
Training
[11,   100] loss: 8.010e-05
[11,   200] loss: 7.861e-05
Validation
[11,   100] loss: 9.572e-05
[11,   200] loss: 9.400e-05
Training loss: 0.000, train NMSE: -6.783e+00
Validation loss: 0.000, valid_NMSE: -7.360e+00

Best validation loss: -7.359533309936523

Saving best model for epoch: 11

--------------------------------------------------
[INFO]: Epoch 12 of 200
Training
[12,   100] loss: 7.615e-05
[12,   200] loss: 7.829e-05
Validation
[12,   100] loss: 9.558e-05
[12,   200] loss: 9.382e-05
Training loss: 0.000, train NMSE: -7.962e+00
Validation loss: 0.000, valid_NMSE: -7.268e+00
--------------------------------------------------
[INFO]: Epoch 13 of 200
Training
[13,   100] loss: 7.653e-05
[13,   200] loss: 7.470e-05
Validation
[13,   100] loss: 9.230e-05
[13,   200] loss: 9.052e-05
Training loss: 0.000, train NMSE: -8.023e+00
Validation loss: 0.000, valid_NMSE: -7.399e+00

Best validation loss: -7.399003028869629

Saving best model for epoch: 13

--------------------------------------------------
[INFO]: Epoch 14 of 200
Training
[14,   100] loss: 7.384e-05
[14,   200] loss: 7.397e-05
Validation
[14,   100] loss: 9.058e-05
[14,   200] loss: 8.875e-05
Training loss: 0.000, train NMSE: -7.909e+00
Validation loss: 0.000, valid_NMSE: -7.501e+00

Best validation loss: -7.501077651977539

Saving best model for epoch: 14

--------------------------------------------------
[INFO]: Epoch 15 of 200
Training
[15,   100] loss: 7.187e-05
[15,   200] loss: 7.265e-05
Validation
[15,   100] loss: 9.021e-05
[15,   200] loss: 8.834e-05
Training loss: 0.000, train NMSE: -7.971e+00
Validation loss: 0.000, valid_NMSE: -7.520e+00

Best validation loss: -7.519784927368164

Saving best model for epoch: 15

--------------------------------------------------
[INFO]: Epoch 16 of 200
Training
[16,   100] loss: 7.122e-05
[16,   200] loss: 7.244e-05
Validation
[16,   100] loss: 8.845e-05
[16,   200] loss: 8.669e-05
Training loss: 0.000, train NMSE: -8.037e+00
Validation loss: 0.000, valid_NMSE: -7.647e+00

Best validation loss: -7.647428512573242

Saving best model for epoch: 16

--------------------------------------------------
[INFO]: Epoch 17 of 200
Training
[17,   100] loss: 7.035e-05
[17,   200] loss: 7.077e-05
Validation
[17,   100] loss: 8.853e-05
[17,   200] loss: 8.674e-05
Training loss: 0.000, train NMSE: -7.956e+00
Validation loss: 0.000, valid_NMSE: -7.622e+00
--------------------------------------------------
[INFO]: Epoch 18 of 200
Training
[18,   100] loss: 7.024e-05
[18,   200] loss: 7.006e-05
Validation
[18,   100] loss: 8.835e-05
[18,   200] loss: 8.654e-05
Training loss: 0.000, train NMSE: -8.718e+00
Validation loss: 0.000, valid_NMSE: -7.575e+00
--------------------------------------------------
[INFO]: Epoch 19 of 200
Training
[19,   100] loss: 6.885e-05
[19,   200] loss: 7.031e-05
Validation
[19,   100] loss: 8.579e-05
[19,   200] loss: 8.394e-05
Training loss: 0.000, train NMSE: -7.908e+00
Validation loss: 0.000, valid_NMSE: -7.828e+00

Best validation loss: -7.828070640563965

Saving best model for epoch: 19

--------------------------------------------------
[INFO]: Epoch 20 of 200
Training
[20,   100] loss: 6.899e-05
[20,   200] loss: 6.948e-05
Validation
[20,   100] loss: 8.507e-05
[20,   200] loss: 8.319e-05
Training loss: 0.000, train NMSE: -8.059e+00
Validation loss: 0.000, valid_NMSE: -7.914e+00

Best validation loss: -7.914338111877441

Saving best model for epoch: 20

--------------------------------------------------
[INFO]: Epoch 21 of 200
Training
[21,   100] loss: 6.870e-05
[21,   200] loss: 6.863e-05
Validation
[21,   100] loss: 8.485e-05
[21,   200] loss: 8.288e-05
Training loss: 0.000, train NMSE: -8.272e+00
Validation loss: 0.000, valid_NMSE: -7.936e+00

Best validation loss: -7.936164855957031

Saving best model for epoch: 21

--------------------------------------------------
[INFO]: Epoch 22 of 200
Training
[22,   100] loss: 6.871e-05
[22,   200] loss: 6.755e-05
Validation
[22,   100] loss: 8.451e-05
[22,   200] loss: 8.267e-05
Training loss: 0.000, train NMSE: -8.548e+00
Validation loss: 0.000, valid_NMSE: -7.849e+00
--------------------------------------------------
[INFO]: Epoch 23 of 200
Training
[23,   100] loss: 6.807e-05
[23,   200] loss: 6.832e-05
Validation
[23,   100] loss: 8.547e-05
[23,   200] loss: 8.361e-05
Training loss: 0.000, train NMSE: -8.402e+00
Validation loss: 0.000, valid_NMSE: -7.777e+00
--------------------------------------------------
[INFO]: Epoch 24 of 200
Training
[24,   100] loss: 6.724e-05
[24,   200] loss: 6.722e-05
Validation
[24,   100] loss: 8.512e-05
[24,   200] loss: 8.318e-05
Training loss: 0.000, train NMSE: -8.204e+00
Validation loss: 0.000, valid_NMSE: -7.745e+00
--------------------------------------------------
[INFO]: Epoch 25 of 200
Training
[25,   100] loss: 6.776e-05
[25,   200] loss: 6.680e-05
Validation
[25,   100] loss: 8.447e-05
[25,   200] loss: 8.253e-05
Training loss: 0.000, train NMSE: -8.667e+00
Validation loss: 0.000, valid_NMSE: -7.813e+00
--------------------------------------------------
[INFO]: Epoch 26 of 200
Training
[26,   100] loss: 6.691e-05
[26,   200] loss: 6.750e-05
Validation
[26,   100] loss: 8.389e-05
[26,   200] loss: 8.206e-05
Training loss: 0.000, train NMSE: -8.389e+00
Validation loss: 0.000, valid_NMSE: -7.874e+00
--------------------------------------------------
[INFO]: Epoch 27 of 200
Training
[27,   100] loss: 6.660e-05
[27,   200] loss: 6.666e-05
Validation
[27,   100] loss: 8.480e-05
[27,   200] loss: 8.289e-05
Training loss: 0.000, train NMSE: -8.717e+00
Validation loss: 0.000, valid_NMSE: -7.729e+00
--------------------------------------------------
[INFO]: Epoch 28 of 200
Training
[28,   100] loss: 6.595e-05
[28,   200] loss: 6.694e-05
Validation
[28,   100] loss: 8.193e-05
[28,   200] loss: 7.999e-05
Training loss: 0.000, train NMSE: -8.593e+00
Validation loss: 0.000, valid_NMSE: -8.068e+00

Best validation loss: -8.06759262084961

Saving best model for epoch: 28

--------------------------------------------------
[INFO]: Epoch 29 of 200
Training
[29,   100] loss: 6.540e-05
[29,   200] loss: 6.647e-05
Validation
[29,   100] loss: 8.225e-05
[29,   200] loss: 8.036e-05
Training loss: 0.000, train NMSE: -8.544e+00
Validation loss: 0.000, valid_NMSE: -8.072e+00

Best validation loss: -8.071615219116211

Saving best model for epoch: 29

--------------------------------------------------
[INFO]: Epoch 30 of 200
Training
[30,   100] loss: 6.681e-05
[30,   200] loss: 6.490e-05
Validation
[30,   100] loss: 8.124e-05
[30,   200] loss: 7.928e-05
Training loss: 0.000, train NMSE: -8.511e+00
Validation loss: 0.000, valid_NMSE: -8.130e+00

Best validation loss: -8.12950611114502

Saving best model for epoch: 30

--------------------------------------------------
[INFO]: Epoch 31 of 200
Training
[31,   100] loss: 6.581e-05
[31,   200] loss: 6.570e-05
Validation
[31,   100] loss: 8.177e-05
[31,   200] loss: 7.982e-05
Training loss: 0.000, train NMSE: -8.506e+00
Validation loss: 0.000, valid_NMSE: -8.035e+00
--------------------------------------------------
[INFO]: Epoch 32 of 200
Training
[32,   100] loss: 6.487e-05
[32,   200] loss: 6.546e-05
Validation
[32,   100] loss: 8.338e-05
[32,   200] loss: 8.159e-05
Training loss: 0.000, train NMSE: -8.497e+00
Validation loss: 0.000, valid_NMSE: -7.919e+00
--------------------------------------------------
[INFO]: Epoch 33 of 200
Training
[33,   100] loss: 6.586e-05
[33,   200] loss: 6.457e-05
Validation
[33,   100] loss: 8.273e-05
[33,   200] loss: 8.073e-05
Training loss: 0.000, train NMSE: -8.362e+00
Validation loss: 0.000, valid_NMSE: -7.946e+00
--------------------------------------------------
[INFO]: Epoch 34 of 200
Training
[34,   100] loss: 6.505e-05
[34,   200] loss: 6.496e-05
Validation
[34,   100] loss: 8.191e-05
[34,   200] loss: 7.988e-05
Training loss: 0.000, train NMSE: -8.409e+00
Validation loss: 0.000, valid_NMSE: -8.018e+00
--------------------------------------------------
[INFO]: Epoch 35 of 200
Training
[35,   100] loss: 6.404e-05
[35,   200] loss: 6.524e-05
Validation
[35,   100] loss: 8.142e-05
[35,   200] loss: 7.950e-05
Training loss: 0.000, train NMSE: -8.184e+00
Validation loss: 0.000, valid_NMSE: -8.053e+00
--------------------------------------------------
[INFO]: Epoch 36 of 200
Training
[36,   100] loss: 6.468e-05
[36,   200] loss: 6.409e-05
Validation
[36,   100] loss: 8.100e-05
[36,   200] loss: 7.907e-05
Training loss: 0.000, train NMSE: -8.264e+00
Validation loss: 0.000, valid_NMSE: -8.092e+00
--------------------------------------------------
[INFO]: Epoch 37 of 200
Training
[37,   100] loss: 6.408e-05
[37,   200] loss: 6.415e-05
Validation
[37,   100] loss: 8.427e-05
[37,   200] loss: 8.229e-05
Training loss: 0.000, train NMSE: -8.230e+00
Validation loss: 0.000, valid_NMSE: -7.814e+00
--------------------------------------------------
[INFO]: Epoch 38 of 200
Training
[38,   100] loss: 6.427e-05
[38,   200] loss: 6.393e-05
Validation
[38,   100] loss: 8.210e-05
[38,   200] loss: 8.006e-05
Training loss: 0.000, train NMSE: -7.836e+00
Validation loss: 0.000, valid_NMSE: -7.962e+00
--------------------------------------------------
[INFO]: Epoch 39 of 200
Training
[39,   100] loss: 6.453e-05
[39,   200] loss: 6.320e-05
Validation
[39,   100] loss: 8.170e-05
[39,   200] loss: 7.974e-05
Training loss: 0.000, train NMSE: -8.433e+00
Validation loss: 0.000, valid_NMSE: -8.005e+00
--------------------------------------------------
[INFO]: Epoch 40 of 200
Training
[40,   100] loss: 6.430e-05
[40,   200] loss: 6.241e-05
Validation
[40,   100] loss: 8.021e-05
[40,   200] loss: 7.820e-05
Training loss: 0.000, train NMSE: -8.244e+00
Validation loss: 0.000, valid_NMSE: -8.176e+00

Best validation loss: -8.176087379455566

Saving best model for epoch: 40

--------------------------------------------------
[INFO]: Epoch 41 of 200
Training
[41,   100] loss: 6.336e-05
[41,   200] loss: 6.365e-05
Validation
[41,   100] loss: 7.946e-05
[41,   200] loss: 7.746e-05
Training loss: 0.000, train NMSE: -8.715e+00
Validation loss: 0.000, valid_NMSE: -8.161e+00
--------------------------------------------------
[INFO]: Epoch 42 of 200
Training
[42,   100] loss: 6.293e-05
[42,   200] loss: 6.314e-05
Validation
[42,   100] loss: 7.887e-05
[42,   200] loss: 7.685e-05
Training loss: 0.000, train NMSE: -8.844e+00
Validation loss: 0.000, valid_NMSE: -8.302e+00

Best validation loss: -8.301721572875977

Saving best model for epoch: 42

--------------------------------------------------
[INFO]: Epoch 43 of 200
Training
[43,   100] loss: 6.235e-05
[43,   200] loss: 6.298e-05
Validation
[43,   100] loss: 7.991e-05
[43,   200] loss: 7.778e-05
Training loss: 0.000, train NMSE: -8.547e+00
Validation loss: 0.000, valid_NMSE: -8.149e+00
--------------------------------------------------
[INFO]: Epoch 44 of 200
Training
[44,   100] loss: 6.372e-05
[44,   200] loss: 6.280e-05
Validation
[44,   100] loss: 8.001e-05
[44,   200] loss: 7.792e-05
Training loss: 0.000, train NMSE: -8.681e+00
Validation loss: 0.000, valid_NMSE: -8.095e+00
--------------------------------------------------
[INFO]: Epoch 45 of 200
Training
[45,   100] loss: 6.198e-05
[45,   200] loss: 6.195e-05
Validation
[45,   100] loss: 7.846e-05
[45,   200] loss: 7.646e-05
Training loss: 0.000, train NMSE: -8.527e+00
Validation loss: 0.000, valid_NMSE: -8.258e+00
--------------------------------------------------
[INFO]: Epoch 46 of 200
Training
[46,   100] loss: 6.218e-05
[46,   200] loss: 6.200e-05
Validation
[46,   100] loss: 8.057e-05
[46,   200] loss: 7.856e-05
Training loss: 0.000, train NMSE: -8.548e+00
Validation loss: 0.000, valid_NMSE: -7.952e+00
--------------------------------------------------
[INFO]: Epoch 47 of 200
Training
[47,   100] loss: 6.229e-05
[47,   200] loss: 6.125e-05
Validation
[47,   100] loss: 7.860e-05
[47,   200] loss: 7.658e-05
Training loss: 0.000, train NMSE: -8.972e+00
Validation loss: 0.000, valid_NMSE: -8.135e+00
--------------------------------------------------
[INFO]: Epoch 48 of 200
Training
[48,   100] loss: 6.111e-05
[48,   200] loss: 6.114e-05
Validation
[48,   100] loss: 7.600e-05
[48,   200] loss: 7.400e-05
Training loss: 0.000, train NMSE: -9.207e+00
Validation loss: 0.000, valid_NMSE: -8.421e+00

Best validation loss: -8.421329498291016

Saving best model for epoch: 48

--------------------------------------------------
[INFO]: Epoch 49 of 200
Training
[49,   100] loss: 6.085e-05
[49,   200] loss: 6.077e-05
Validation
[49,   100] loss: 7.704e-05
[49,   200] loss: 7.508e-05
Training loss: 0.000, train NMSE: -8.275e+00
Validation loss: 0.000, valid_NMSE: -8.308e+00
--------------------------------------------------
[INFO]: Epoch 50 of 200
Training
[50,   100] loss: 6.131e-05
[50,   200] loss: 5.949e-05
Validation
[50,   100] loss: 7.641e-05
[50,   200] loss: 7.443e-05
Training loss: 0.000, train NMSE: -8.916e+00
Validation loss: 0.000, valid_NMSE: -8.302e+00
--------------------------------------------------
[INFO]: Epoch 51 of 200
Training
[51,   100] loss: 5.991e-05
[51,   200] loss: 6.129e-05
Validation
[51,   100] loss: 7.619e-05
[51,   200] loss: 7.423e-05
Training loss: 0.000, train NMSE: -8.793e+00
Validation loss: 0.000, valid_NMSE: -8.383e+00
--------------------------------------------------
[INFO]: Epoch 52 of 200
Training
[52,   100] loss: 6.023e-05
[52,   200] loss: 5.926e-05
Validation
[52,   100] loss: 7.428e-05
[52,   200] loss: 7.228e-05
Training loss: 0.000, train NMSE: -8.645e+00
Validation loss: 0.000, valid_NMSE: -8.593e+00

Best validation loss: -8.59306526184082

Saving best model for epoch: 52

--------------------------------------------------
[INFO]: Epoch 53 of 200
Training
[53,   100] loss: 6.002e-05
[53,   200] loss: 5.979e-05
Validation
[53,   100] loss: 7.543e-05
[53,   200] loss: 7.340e-05
Training loss: 0.000, train NMSE: -8.528e+00
Validation loss: 0.000, valid_NMSE: -8.470e+00
--------------------------------------------------
[INFO]: Epoch 54 of 200
Training
[54,   100] loss: 5.869e-05
[54,   200] loss: 6.026e-05
Validation
[54,   100] loss: 7.525e-05
[54,   200] loss: 7.331e-05
Training loss: 0.000, train NMSE: -8.660e+00
Validation loss: 0.000, valid_NMSE: -8.391e+00
--------------------------------------------------
[INFO]: Epoch 55 of 200
Training
[55,   100] loss: 5.878e-05
[55,   200] loss: 5.952e-05
Validation
[55,   100] loss: 7.460e-05
[55,   200] loss: 7.260e-05
Training loss: 0.000, train NMSE: -9.131e+00
Validation loss: 0.000, valid_NMSE: -8.524e+00
--------------------------------------------------
[INFO]: Epoch 56 of 200
Training
[56,   100] loss: 5.870e-05
[56,   200] loss: 5.892e-05
Validation
[56,   100] loss: 7.460e-05
[56,   200] loss: 7.274e-05
Training loss: 0.000, train NMSE: -8.757e+00
Validation loss: 0.000, valid_NMSE: -8.439e+00
--------------------------------------------------
[INFO]: Epoch 57 of 200
Training
[57,   100] loss: 5.897e-05
[57,   200] loss: 5.819e-05
Validation
[57,   100] loss: 7.235e-05
[57,   200] loss: 7.038e-05
Training loss: 0.000, train NMSE: -9.053e+00
Validation loss: 0.000, valid_NMSE: -8.704e+00

Best validation loss: -8.704320907592773

Saving best model for epoch: 57

--------------------------------------------------
[INFO]: Epoch 58 of 200
Training
[58,   100] loss: 5.874e-05
[58,   200] loss: 5.798e-05
Validation
[58,   100] loss: 7.346e-05
[58,   200] loss: 7.157e-05
Training loss: 0.000, train NMSE: -8.994e+00
Validation loss: 0.000, valid_NMSE: -8.550e+00
--------------------------------------------------
[INFO]: Epoch 59 of 200
Training
[59,   100] loss: 5.811e-05
[59,   200] loss: 5.799e-05
Validation
[59,   100] loss: 7.359e-05
[59,   200] loss: 7.169e-05
Training loss: 0.000, train NMSE: -8.853e+00
Validation loss: 0.000, valid_NMSE: -8.511e+00
--------------------------------------------------
[INFO]: Epoch 60 of 200
Training
[60,   100] loss: 5.789e-05
[60,   200] loss: 5.824e-05
Validation
[60,   100] loss: 7.436e-05
[60,   200] loss: 7.244e-05
Training loss: 0.000, train NMSE: -9.087e+00
Validation loss: 0.000, valid_NMSE: -8.413e+00
--------------------------------------------------
[INFO]: Epoch 61 of 200
Training
[61,   100] loss: 5.762e-05
[61,   200] loss: 5.821e-05
Validation
[61,   100] loss: 7.399e-05
[61,   200] loss: 7.216e-05
Training loss: 0.000, train NMSE: -8.745e+00
Validation loss: 0.000, valid_NMSE: -8.397e+00
--------------------------------------------------
[INFO]: Epoch 62 of 200
Training
[62,   100] loss: 5.656e-05
[62,   200] loss: 5.889e-05
Validation
[62,   100] loss: 7.210e-05
[62,   200] loss: 7.014e-05
Training loss: 0.000, train NMSE: -8.617e+00
Validation loss: 0.000, valid_NMSE: -8.670e+00
--------------------------------------------------
[INFO]: Epoch 63 of 200
Training
[63,   100] loss: 5.747e-05
[63,   200] loss: 5.733e-05
Validation
[63,   100] loss: 7.124e-05
[63,   200] loss: 6.932e-05
Training loss: 0.000, train NMSE: -9.132e+00
Validation loss: 0.000, valid_NMSE: -8.747e+00

Best validation loss: -8.747203826904297

Saving best model for epoch: 63

--------------------------------------------------
[INFO]: Epoch 64 of 200
Training
[64,   100] loss: 5.632e-05
[64,   200] loss: 5.863e-05
Validation
[64,   100] loss: 7.171e-05
[64,   200] loss: 6.986e-05
Training loss: 0.000, train NMSE: -8.426e+00
Validation loss: 0.000, valid_NMSE: -8.710e+00
--------------------------------------------------
[INFO]: Epoch 65 of 200
Training
[65,   100] loss: 5.761e-05
[65,   200] loss: 5.705e-05
Validation
[65,   100] loss: 7.162e-05
[65,   200] loss: 6.968e-05
Training loss: 0.000, train NMSE: -9.137e+00
Validation loss: 0.000, valid_NMSE: -8.719e+00
--------------------------------------------------
[INFO]: Epoch 66 of 200
Training
[66,   100] loss: 5.725e-05
[66,   200] loss: 5.731e-05
Validation
[66,   100] loss: 7.107e-05
[66,   200] loss: 6.919e-05
Training loss: 0.000, train NMSE: -9.379e+00
Validation loss: 0.000, valid_NMSE: -8.755e+00

Best validation loss: -8.755141258239746

Saving best model for epoch: 66

--------------------------------------------------
[INFO]: Epoch 67 of 200
Training
[67,   100] loss: 5.700e-05
[67,   200] loss: 5.715e-05
Validation
[67,   100] loss: 7.056e-05
[67,   200] loss: 6.873e-05
Training loss: 0.000, train NMSE: -8.355e+00
Validation loss: 0.000, valid_NMSE: -8.783e+00

Best validation loss: -8.783348083496094

Saving best model for epoch: 67

--------------------------------------------------
[INFO]: Epoch 68 of 200
Training
[68,   100] loss: 5.690e-05
[68,   200] loss: 5.686e-05
Validation
[68,   100] loss: 7.179e-05
[68,   200] loss: 6.999e-05
Training loss: 0.000, train NMSE: -8.327e+00
Validation loss: 0.000, valid_NMSE: -8.564e+00
--------------------------------------------------
[INFO]: Epoch 69 of 200
Training
[69,   100] loss: 5.744e-05
[69,   200] loss: 5.652e-05
Validation
[69,   100] loss: 7.120e-05
[69,   200] loss: 6.941e-05
Training loss: 0.000, train NMSE: -8.770e+00
Validation loss: 0.000, valid_NMSE: -8.697e+00
--------------------------------------------------
[INFO]: Epoch 70 of 200
Training
[70,   100] loss: 5.712e-05
[70,   200] loss: 5.655e-05
Validation
[70,   100] loss: 7.104e-05
[70,   200] loss: 6.910e-05
Training loss: 0.000, train NMSE: -9.360e+00
Validation loss: 0.000, valid_NMSE: -8.727e+00
--------------------------------------------------
[INFO]: Epoch 71 of 200
Training
[71,   100] loss: 5.602e-05
[71,   200] loss: 5.735e-05
Validation
[71,   100] loss: 7.065e-05
[71,   200] loss: 6.880e-05
Training loss: 0.000, train NMSE: -8.305e+00
Validation loss: 0.000, valid_NMSE: -8.750e+00
--------------------------------------------------
[INFO]: Epoch 72 of 200
Training
[72,   100] loss: 5.579e-05
[72,   200] loss: 5.788e-05
Validation
[72,   100] loss: 7.118e-05
[72,   200] loss: 6.933e-05
Training loss: 0.000, train NMSE: -8.983e+00
Validation loss: 0.000, valid_NMSE: -8.652e+00
--------------------------------------------------
[INFO]: Epoch 73 of 200
Training
[73,   100] loss: 5.694e-05
[73,   200] loss: 5.605e-05
Validation
[73,   100] loss: 7.094e-05
[73,   200] loss: 6.912e-05
Training loss: 0.000, train NMSE: -9.673e+00
Validation loss: 0.000, valid_NMSE: -8.671e+00
--------------------------------------------------
[INFO]: Epoch 74 of 200
Training
[74,   100] loss: 5.591e-05
[74,   200] loss: 5.708e-05
Validation
[74,   100] loss: 7.096e-05
[74,   200] loss: 6.916e-05
Training loss: 0.000, train NMSE: -8.720e+00
Validation loss: 0.000, valid_NMSE: -8.663e+00
--------------------------------------------------
[INFO]: Epoch 75 of 200
Training
[75,   100] loss: 5.704e-05
[75,   200] loss: 5.649e-05
Validation
[75,   100] loss: 6.977e-05
[75,   200] loss: 6.796e-05
Training loss: 0.000, train NMSE: -9.134e+00
Validation loss: 0.000, valid_NMSE: -8.841e+00

Best validation loss: -8.840721130371094

Saving best model for epoch: 75

--------------------------------------------------
[INFO]: Epoch 76 of 200
Training
[76,   100] loss: 5.696e-05
[76,   200] loss: 5.639e-05
Validation
[76,   100] loss: 7.052e-05
[76,   200] loss: 6.872e-05
Training loss: 0.000, train NMSE: -8.881e+00
Validation loss: 0.000, valid_NMSE: -8.650e+00
--------------------------------------------------
[INFO]: Epoch 77 of 200
Training
[77,   100] loss: 5.538e-05
[77,   200] loss: 5.685e-05
Validation
[77,   100] loss: 7.098e-05
[77,   200] loss: 6.919e-05
Training loss: 0.000, train NMSE: -9.406e+00
Validation loss: 0.000, valid_NMSE: -8.611e+00
--------------------------------------------------
[INFO]: Epoch 78 of 200
Training
[78,   100] loss: 5.568e-05
[78,   200] loss: 5.700e-05
Validation
[78,   100] loss: 6.983e-05
[78,   200] loss: 6.802e-05
Training loss: 0.000, train NMSE: -8.842e+00
Validation loss: 0.000, valid_NMSE: -8.778e+00
--------------------------------------------------
[INFO]: Epoch 79 of 200
Training
[79,   100] loss: 5.522e-05
[79,   200] loss: 5.701e-05
Validation
[79,   100] loss: 7.184e-05
[79,   200] loss: 7.009e-05
Training loss: 0.000, train NMSE: -8.792e+00
Validation loss: 0.000, valid_NMSE: -8.544e+00
--------------------------------------------------
[INFO]: Epoch 80 of 200
Training
[80,   100] loss: 5.627e-05
[80,   200] loss: 5.519e-05
Validation
[80,   100] loss: 6.928e-05
[80,   200] loss: 6.747e-05
Training loss: 0.000, train NMSE: -9.572e+00
Validation loss: 0.000, valid_NMSE: -8.883e+00

Best validation loss: -8.882831573486328

Saving best model for epoch: 80

--------------------------------------------------
[INFO]: Epoch 81 of 200
Training
[81,   100] loss: 5.654e-05
[81,   200] loss: 5.553e-05
Validation
[81,   100] loss: 6.951e-05
[81,   200] loss: 6.769e-05
Training loss: 0.000, train NMSE: -9.251e+00
Validation loss: 0.000, valid_NMSE: -8.928e+00

Best validation loss: -8.927619934082031

Saving best model for epoch: 81

--------------------------------------------------
[INFO]: Epoch 82 of 200
Training
[82,   100] loss: 5.589e-05
[82,   200] loss: 5.647e-05
Validation
[82,   100] loss: 6.978e-05
[82,   200] loss: 6.788e-05
Training loss: 0.000, train NMSE: -9.078e+00
Validation loss: 0.000, valid_NMSE: -8.793e+00
--------------------------------------------------
[INFO]: Epoch 83 of 200
Training
[83,   100] loss: 5.592e-05
[83,   200] loss: 5.608e-05
Validation
[83,   100] loss: 7.285e-05
[83,   200] loss: 7.100e-05
Training loss: 0.000, train NMSE: -9.840e+00
Validation loss: 0.000, valid_NMSE: -8.488e+00
--------------------------------------------------
[INFO]: Epoch 84 of 200
Training
[84,   100] loss: 5.560e-05
[84,   200] loss: 5.651e-05
Validation
[84,   100] loss: 7.133e-05
[84,   200] loss: 6.949e-05
Training loss: 0.000, train NMSE: -8.603e+00
Validation loss: 0.000, valid_NMSE: -8.564e+00
--------------------------------------------------
[INFO]: Epoch 85 of 200
Training
[85,   100] loss: 5.460e-05
[85,   200] loss: 5.664e-05
Validation
[85,   100] loss: 6.930e-05
[85,   200] loss: 6.740e-05
Training loss: 0.000, train NMSE: -8.989e+00
Validation loss: 0.000, valid_NMSE: -8.836e+00
--------------------------------------------------
[INFO]: Epoch 86 of 200
Training
[86,   100] loss: 5.530e-05
[86,   200] loss: 5.519e-05
Validation
[86,   100] loss: 7.079e-05
[86,   200] loss: 6.898e-05
Training loss: 0.000, train NMSE: -8.865e+00
Validation loss: 0.000, valid_NMSE: -8.589e+00
--------------------------------------------------
[INFO]: Epoch 87 of 200
Training
[87,   100] loss: 5.579e-05
[87,   200] loss: 5.526e-05
Validation
[87,   100] loss: 6.879e-05
[87,   200] loss: 6.697e-05
Training loss: 0.000, train NMSE: -9.032e+00
Validation loss: 0.000, valid_NMSE: -8.870e+00
--------------------------------------------------
[INFO]: Epoch 88 of 200
Training
[88,   100] loss: 5.522e-05
[88,   200] loss: 5.572e-05
Validation
[88,   100] loss: 6.926e-05
[88,   200] loss: 6.741e-05
Training loss: 0.000, train NMSE: -9.447e+00
Validation loss: 0.000, valid_NMSE: -8.785e+00
--------------------------------------------------
[INFO]: Epoch 89 of 200
Training
[89,   100] loss: 5.565e-05
[89,   200] loss: 5.544e-05
Validation
[89,   100] loss: 7.084e-05
[89,   200] loss: 6.900e-05
Training loss: 0.000, train NMSE: -9.685e+00
Validation loss: 0.000, valid_NMSE: -8.621e+00
--------------------------------------------------
[INFO]: Epoch 90 of 200
Training
[90,   100] loss: 5.601e-05
[90,   200] loss: 5.536e-05
Validation
[90,   100] loss: 6.922e-05
[90,   200] loss: 6.731e-05
Training loss: 0.000, train NMSE: -8.860e+00
Validation loss: 0.000, valid_NMSE: -8.873e+00
--------------------------------------------------
[INFO]: Epoch 91 of 200
Training
[91,   100] loss: 5.455e-05
[91,   200] loss: 5.625e-05
Validation
[91,   100] loss: 6.889e-05
[91,   200] loss: 6.703e-05
Training loss: 0.000, train NMSE: -8.994e+00
Validation loss: 0.000, valid_NMSE: -8.846e+00
--------------------------------------------------
[INFO]: Epoch 92 of 200
Training
[92,   100] loss: 5.420e-05
[92,   200] loss: 5.616e-05
Validation
[92,   100] loss: 7.017e-05
[92,   200] loss: 6.828e-05
Training loss: 0.000, train NMSE: -8.970e+00
Validation loss: 0.000, valid_NMSE: -8.678e+00
--------------------------------------------------
[INFO]: Epoch 93 of 200
Training
[93,   100] loss: 5.531e-05
[93,   200] loss: 5.516e-05
Validation
[93,   100] loss: 6.945e-05
[93,   200] loss: 6.758e-05
Training loss: 0.000, train NMSE: -9.476e+00
Validation loss: 0.000, valid_NMSE: -8.788e+00
--------------------------------------------------
[INFO]: Epoch 94 of 200
Training
[94,   100] loss: 5.516e-05
[94,   200] loss: 5.528e-05
Validation
[94,   100] loss: 6.957e-05
[94,   200] loss: 6.768e-05
Training loss: 0.000, train NMSE: -1.004e+01
Validation loss: 0.000, valid_NMSE: -8.736e+00
--------------------------------------------------
[INFO]: Epoch 95 of 200
Training
[95,   100] loss: 5.513e-05
[95,   200] loss: 5.549e-05
Validation
[95,   100] loss: 6.883e-05
[95,   200] loss: 6.693e-05
Training loss: 0.000, train NMSE: -9.764e+00
Validation loss: 0.000, valid_NMSE: -8.847e+00
--------------------------------------------------
[INFO]: Epoch 96 of 200
Training
[96,   100] loss: 5.480e-05
[96,   200] loss: 5.532e-05
Validation
[96,   100] loss: 6.989e-05
[96,   200] loss: 6.799e-05
Training loss: 0.000, train NMSE: -8.964e+00
Validation loss: 0.000, valid_NMSE: -8.705e+00
--------------------------------------------------
[INFO]: Epoch 97 of 200
Training
[97,   100] loss: 5.424e-05
[97,   200] loss: 5.588e-05
Validation
[97,   100] loss: 6.904e-05
[97,   200] loss: 6.722e-05
Training loss: 0.000, train NMSE: -8.939e+00
Validation loss: 0.000, valid_NMSE: -8.820e+00
--------------------------------------------------
[INFO]: Epoch 98 of 200
Training
[98,   100] loss: 5.496e-05
[98,   200] loss: 5.484e-05
Validation
[98,   100] loss: 6.912e-05
[98,   200] loss: 6.721e-05
Training loss: 0.000, train NMSE: -9.608e+00
Validation loss: 0.000, valid_NMSE: -8.843e+00
--------------------------------------------------
[INFO]: Epoch 99 of 200
Training
[99,   100] loss: 5.469e-05
[99,   200] loss: 5.528e-05
Validation
[99,   100] loss: 7.071e-05
[99,   200] loss: 6.892e-05
Training loss: 0.000, train NMSE: -9.787e+00
Validation loss: 0.000, valid_NMSE: -8.541e+00
--------------------------------------------------
[INFO]: Epoch 100 of 200
Training
[100,   100] loss: 5.359e-05
[100,   200] loss: 5.633e-05
Validation
[100,   100] loss: 6.931e-05
[100,   200] loss: 6.741e-05
Training loss: 0.000, train NMSE: -9.371e+00
Validation loss: 0.000, valid_NMSE: -8.769e+00
--------------------------------------------------
[INFO]: Epoch 101 of 200
Training
[101,   100] loss: 5.469e-05
[101,   200] loss: 5.503e-05
Validation
[101,   100] loss: 7.232e-05
[101,   200] loss: 7.056e-05
Training loss: 0.000, train NMSE: -9.330e+00
Validation loss: 0.000, valid_NMSE: -8.405e+00
--------------------------------------------------
[INFO]: Epoch 102 of 200
Training
[102,   100] loss: 5.570e-05
[102,   200] loss: 5.461e-05
Validation
[102,   100] loss: 7.105e-05
[102,   200] loss: 6.925e-05
Training loss: 0.000, train NMSE: -8.944e+00
Validation loss: 0.000, valid_NMSE: -8.494e+00
--------------------------------------------------
[INFO]: Epoch 103 of 200
Training
[103,   100] loss: 5.464e-05
[103,   200] loss: 5.482e-05
Validation
[103,   100] loss: 6.961e-05
[103,   200] loss: 6.772e-05
Training loss: 0.000, train NMSE: -8.253e+00
Validation loss: 0.000, valid_NMSE: -8.700e+00
--------------------------------------------------
[INFO]: Epoch 104 of 200
Training
[104,   100] loss: 5.576e-05
[104,   200] loss: 5.384e-05
Validation
[104,   100] loss: 6.936e-05
[104,   200] loss: 6.753e-05
Training loss: 0.000, train NMSE: -9.139e+00
Validation loss: 0.000, valid_NMSE: -8.778e+00
--------------------------------------------------
[INFO]: Epoch 105 of 200
Training
[105,   100] loss: 5.572e-05
[105,   200] loss: 5.400e-05
Validation
[105,   100] loss: 6.817e-05
[105,   200] loss: 6.636e-05
Training loss: 0.000, train NMSE: -8.731e+00
Validation loss: 0.000, valid_NMSE: -8.913e+00
--------------------------------------------------
[INFO]: Epoch 106 of 200
Training
[106,   100] loss: 5.412e-05
[106,   200] loss: 5.499e-05
Validation
[106,   100] loss: 6.941e-05
[106,   200] loss: 6.743e-05
Training loss: 0.000, train NMSE: -9.643e+00
Validation loss: 0.000, valid_NMSE: -8.789e+00
--------------------------------------------------
[INFO]: Epoch 107 of 200
Training
[107,   100] loss: 5.487e-05
[107,   200] loss: 5.494e-05
Validation
[107,   100] loss: 6.788e-05
[107,   200] loss: 6.597e-05
Training loss: 0.000, train NMSE: -9.347e+00
Validation loss: 0.000, valid_NMSE: -8.938e+00

Best validation loss: -8.937589645385742

Saving best model for epoch: 107

--------------------------------------------------
[INFO]: Epoch 108 of 200
Training
[108,   100] loss: 5.487e-05
[108,   200] loss: 5.492e-05
Validation
[108,   100] loss: 6.800e-05
[108,   200] loss: 6.614e-05
Training loss: 0.000, train NMSE: -9.454e+00
Validation loss: 0.000, valid_NMSE: -8.917e+00
--------------------------------------------------
[INFO]: Epoch 109 of 200
Training
[109,   100] loss: 5.460e-05
[109,   200] loss: 5.473e-05
Validation
[109,   100] loss: 6.878e-05
[109,   200] loss: 6.695e-05
Training loss: 0.000, train NMSE: -9.592e+00
Validation loss: 0.000, valid_NMSE: -8.796e+00
--------------------------------------------------
[INFO]: Epoch 110 of 200
Training
[110,   100] loss: 5.597e-05
[110,   200] loss: 5.364e-05
Validation
[110,   100] loss: 7.237e-05
[110,   200] loss: 7.050e-05
Training loss: 0.000, train NMSE: -9.120e+00
Validation loss: 0.000, valid_NMSE: -8.472e+00
--------------------------------------------------
[INFO]: Epoch 111 of 200
Training
[111,   100] loss: 5.469e-05
[111,   200] loss: 5.469e-05
Validation
[111,   100] loss: 6.938e-05
[111,   200] loss: 6.755e-05
Training loss: 0.000, train NMSE: -8.529e+00
Validation loss: 0.000, valid_NMSE: -8.681e+00
--------------------------------------------------
[INFO]: Epoch 112 of 200
Training
[112,   100] loss: 5.409e-05
[112,   200] loss: 5.483e-05
Validation
[112,   100] loss: 7.026e-05
[112,   200] loss: 6.841e-05
Training loss: 0.000, train NMSE: -8.928e+00
Validation loss: 0.000, valid_NMSE: -8.625e+00
--------------------------------------------------
[INFO]: Epoch 113 of 200
Training
[113,   100] loss: 5.412e-05
[113,   200] loss: 5.462e-05
Validation
[113,   100] loss: 6.940e-05
[113,   200] loss: 6.748e-05
Training loss: 0.000, train NMSE: -9.027e+00
Validation loss: 0.000, valid_NMSE: -8.715e+00
--------------------------------------------------
[INFO]: Epoch 114 of 200
Training
[114,   100] loss: 5.410e-05
[114,   200] loss: 5.465e-05
Validation
[114,   100] loss: 6.874e-05
[114,   200] loss: 6.687e-05
Training loss: 0.000, train NMSE: -8.829e+00
Validation loss: 0.000, valid_NMSE: -8.825e+00
--------------------------------------------------
[INFO]: Epoch 115 of 200
Training
[115,   100] loss: 5.399e-05
[115,   200] loss: 5.498e-05
Validation
[115,   100] loss: 6.988e-05
[115,   200] loss: 6.802e-05
Training loss: 0.000, train NMSE: -9.003e+00
Validation loss: 0.000, valid_NMSE: -8.630e+00
--------------------------------------------------
[INFO]: Epoch 116 of 200
Training
[116,   100] loss: 5.409e-05
[116,   200] loss: 5.463e-05
Validation
[116,   100] loss: 6.841e-05
[116,   200] loss: 6.656e-05
Training loss: 0.000, train NMSE: -8.991e+00
Validation loss: 0.000, valid_NMSE: -8.803e+00
--------------------------------------------------
[INFO]: Epoch 117 of 200
Training
[117,   100] loss: 5.359e-05
[117,   200] loss: 5.441e-05
Validation
[117,   100] loss: 6.914e-05
[117,   200] loss: 6.725e-05
Training loss: 0.000, train NMSE: -9.763e+00
Validation loss: 0.000, valid_NMSE: -8.709e+00
--------------------------------------------------
[INFO]: Epoch 118 of 200
Training
[118,   100] loss: 5.392e-05
[118,   200] loss: 5.460e-05
Validation
[118,   100] loss: 7.293e-05
[118,   200] loss: 7.106e-05
Training loss: 0.000, train NMSE: -9.923e+00
Validation loss: 0.000, valid_NMSE: -8.315e+00
--------------------------------------------------
[INFO]: Epoch 119 of 200
Training
[119,   100] loss: 5.458e-05
[119,   200] loss: 5.400e-05
Validation
[119,   100] loss: 6.940e-05
[119,   200] loss: 6.756e-05
Training loss: 0.000, train NMSE: -1.025e+01
Validation loss: 0.000, valid_NMSE: -8.730e+00
--------------------------------------------------
[INFO]: Epoch 120 of 200
Training
[120,   100] loss: 5.399e-05
[120,   200] loss: 5.424e-05
Validation
[120,   100] loss: 7.076e-05
[120,   200] loss: 6.886e-05
Training loss: 0.000, train NMSE: -8.765e+00
Validation loss: 0.000, valid_NMSE: -8.568e+00
--------------------------------------------------
[INFO]: Epoch 121 of 200
Training
[121,   100] loss: 5.446e-05
[121,   200] loss: 5.417e-05
Validation
[121,   100] loss: 6.790e-05
[121,   200] loss: 6.607e-05
Training loss: 0.000, train NMSE: -9.867e+00
Validation loss: 0.000, valid_NMSE: -8.948e+00

Best validation loss: -8.947980880737305

Saving best model for epoch: 121

--------------------------------------------------
[INFO]: Epoch 122 of 200
Training
[122,   100] loss: 5.313e-05
[122,   200] loss: 5.482e-05
Validation
[122,   100] loss: 6.844e-05
[122,   200] loss: 6.666e-05
Training loss: 0.000, train NMSE: -9.660e+00
Validation loss: 0.000, valid_NMSE: -8.782e+00
--------------------------------------------------
[INFO]: Epoch 123 of 200
Training
[123,   100] loss: 5.434e-05
[123,   200] loss: 5.385e-05
Validation
[123,   100] loss: 6.808e-05
[123,   200] loss: 6.622e-05
Training loss: 0.000, train NMSE: -9.367e+00
Validation loss: 0.000, valid_NMSE: -8.904e+00
--------------------------------------------------
[INFO]: Epoch 124 of 200
Training
[124,   100] loss: 5.430e-05
[124,   200] loss: 5.442e-05
Validation
[124,   100] loss: 6.950e-05
[124,   200] loss: 6.767e-05
Training loss: 0.000, train NMSE: -8.954e+00
Validation loss: 0.000, valid_NMSE: -8.698e+00
--------------------------------------------------
[INFO]: Epoch 125 of 200
Training
[125,   100] loss: 5.400e-05
[125,   200] loss: 5.355e-05
Validation
[125,   100] loss: 6.834e-05
[125,   200] loss: 6.646e-05
Training loss: 0.000, train NMSE: -9.113e+00
Validation loss: 0.000, valid_NMSE: -8.803e+00
--------------------------------------------------
[INFO]: Epoch 126 of 200
Training
[126,   100] loss: 5.426e-05
[126,   200] loss: 5.333e-05
Validation
[126,   100] loss: 6.817e-05
[126,   200] loss: 6.635e-05
Training loss: 0.000, train NMSE: -8.538e+00
Validation loss: 0.000, valid_NMSE: -8.840e+00
--------------------------------------------------
[INFO]: Epoch 127 of 200
Training
[127,   100] loss: 5.339e-05
[127,   200] loss: 5.481e-05
Validation
[127,   100] loss: 6.911e-05
[127,   200] loss: 6.724e-05
Training loss: 0.000, train NMSE: -9.273e+00
Validation loss: 0.000, valid_NMSE: -8.727e+00
--------------------------------------------------
[INFO]: Epoch 128 of 200
Training
[128,   100] loss: 5.360e-05
[128,   200] loss: 5.408e-05
Validation
[128,   100] loss: 6.833e-05
[128,   200] loss: 6.640e-05
Training loss: 0.000, train NMSE: -9.439e+00
Validation loss: 0.000, valid_NMSE: -8.843e+00
--------------------------------------------------
[INFO]: Epoch 129 of 200
Training
[129,   100] loss: 5.375e-05
[129,   200] loss: 5.380e-05
Validation
[129,   100] loss: 7.049e-05
[129,   200] loss: 6.865e-05
Training loss: 0.000, train NMSE: -9.426e+00
Validation loss: 0.000, valid_NMSE: -8.519e+00
--------------------------------------------------
[INFO]: Epoch 130 of 200
Training
[130,   100] loss: 5.366e-05
[130,   200] loss: 5.461e-05
Validation
[130,   100] loss: 7.128e-05
[130,   200] loss: 6.936e-05
Training loss: 0.000, train NMSE: -9.322e+00
Validation loss: 0.000, valid_NMSE: -8.420e+00
--------------------------------------------------
[INFO]: Epoch 131 of 200
Training
[131,   100] loss: 5.333e-05
[131,   200] loss: 5.395e-05
Validation
[131,   100] loss: 7.003e-05
[131,   200] loss: 6.821e-05
Training loss: 0.000, train NMSE: -9.321e+00
Validation loss: 0.000, valid_NMSE: -8.650e+00
--------------------------------------------------
[INFO]: Epoch 132 of 200
Training
[132,   100] loss: 5.423e-05
[132,   200] loss: 5.362e-05
Validation
[132,   100] loss: 6.875e-05
[132,   200] loss: 6.688e-05
Training loss: 0.000, train NMSE: -9.392e+00
Validation loss: 0.000, valid_NMSE: -8.731e+00
--------------------------------------------------
[INFO]: Epoch 133 of 200
Training
[133,   100] loss: 5.288e-05
[133,   200] loss: 5.431e-05
Validation
[133,   100] loss: 6.755e-05
[133,   200] loss: 6.572e-05
Training loss: 0.000, train NMSE: -9.887e+00
Validation loss: 0.000, valid_NMSE: -8.887e+00
--------------------------------------------------
[INFO]: Epoch 134 of 200
Training
[134,   100] loss: 5.312e-05
[134,   200] loss: 5.432e-05
Validation
[134,   100] loss: 6.840e-05
[134,   200] loss: 6.652e-05
Training loss: 0.000, train NMSE: -8.951e+00
Validation loss: 0.000, valid_NMSE: -8.815e+00
--------------------------------------------------
[INFO]: Epoch 135 of 200
Training
[135,   100] loss: 5.361e-05
[135,   200] loss: 5.345e-05
Validation
[135,   100] loss: 7.136e-05
[135,   200] loss: 6.947e-05
Training loss: 0.000, train NMSE: -9.939e+00
Validation loss: 0.000, valid_NMSE: -8.538e+00
--------------------------------------------------
[INFO]: Epoch 136 of 200
Training
[136,   100] loss: 5.366e-05
[136,   200] loss: 5.305e-05
Validation
[136,   100] loss: 6.908e-05
[136,   200] loss: 6.715e-05
Training loss: 0.000, train NMSE: -9.657e+00
Validation loss: 0.000, valid_NMSE: -8.720e+00
--------------------------------------------------
[INFO]: Epoch 137 of 200
Training
[137,   100] loss: 5.374e-05
[137,   200] loss: 5.327e-05
Validation
[137,   100] loss: 6.929e-05
[137,   200] loss: 6.748e-05
Training loss: 0.000, train NMSE: -9.929e+00
Validation loss: 0.000, valid_NMSE: -8.675e+00
--------------------------------------------------
[INFO]: Epoch 138 of 200
Training
[138,   100] loss: 5.344e-05
[138,   200] loss: 5.360e-05
Validation
[138,   100] loss: 6.800e-05
[138,   200] loss: 6.604e-05
Training loss: 0.000, train NMSE: -1.004e+01
Validation loss: 0.000, valid_NMSE: -8.919e+00
--------------------------------------------------
[INFO]: Epoch 139 of 200
Training
[139,   100] loss: 5.369e-05
[139,   200] loss: 5.341e-05
Validation
[139,   100] loss: 6.866e-05
[139,   200] loss: 6.683e-05
Training loss: 0.000, train NMSE: -9.135e+00
Validation loss: 0.000, valid_NMSE: -8.761e+00
--------------------------------------------------
[INFO]: Epoch 140 of 200
Training
[140,   100] loss: 5.309e-05
[140,   200] loss: 5.399e-05
Validation
[140,   100] loss: 6.802e-05
[140,   200] loss: 6.617e-05
Training loss: 0.000, train NMSE: -9.324e+00
Validation loss: 0.000, valid_NMSE: -8.891e+00
--------------------------------------------------
[INFO]: Epoch 141 of 200
Training
[141,   100] loss: 5.393e-05
[141,   200] loss: 5.269e-05
Validation
[141,   100] loss: 6.818e-05
[141,   200] loss: 6.627e-05
Training loss: 0.000, train NMSE: -9.254e+00
Validation loss: 0.000, valid_NMSE: -8.880e+00
--------------------------------------------------
[INFO]: Epoch 142 of 200
Training
[142,   100] loss: 5.273e-05
[142,   200] loss: 5.393e-05
Validation
[142,   100] loss: 6.802e-05
[142,   200] loss: 6.619e-05
Training loss: 0.000, train NMSE: -9.368e+00
Validation loss: 0.000, valid_NMSE: -8.823e+00
--------------------------------------------------
[INFO]: Epoch 143 of 200
Training
[143,   100] loss: 5.340e-05
[143,   200] loss: 5.301e-05
Validation
[143,   100] loss: 6.830e-05
[143,   200] loss: 6.639e-05
Training loss: 0.000, train NMSE: -9.043e+00
Validation loss: 0.000, valid_NMSE: -8.821e+00
--------------------------------------------------
[INFO]: Epoch 144 of 200
Training
[144,   100] loss: 5.394e-05
[144,   200] loss: 5.324e-05
Validation
[144,   100] loss: 6.752e-05
[144,   200] loss: 6.570e-05
Training loss: 0.000, train NMSE: -9.255e+00
Validation loss: 0.000, valid_NMSE: -8.896e+00
--------------------------------------------------
[INFO]: Epoch 145 of 200
Training
[145,   100] loss: 5.354e-05
[145,   200] loss: 5.336e-05
Validation
[145,   100] loss: 6.854e-05
[145,   200] loss: 6.668e-05
Training loss: 0.000, train NMSE: -8.791e+00
Validation loss: 0.000, valid_NMSE: -8.735e+00
--------------------------------------------------
[INFO]: Epoch 146 of 200
Training
[146,   100] loss: 5.246e-05
[146,   200] loss: 5.418e-05
Validation
[146,   100] loss: 6.787e-05
[146,   200] loss: 6.601e-05
Training loss: 0.000, train NMSE: -8.976e+00
Validation loss: 0.000, valid_NMSE: -8.868e+00
--------------------------------------------------
[INFO]: Epoch 147 of 200
Training
[147,   100] loss: 5.284e-05
[147,   200] loss: 5.292e-05
Validation
[147,   100] loss: 6.816e-05
[147,   200] loss: 6.636e-05
Training loss: 0.000, train NMSE: -9.157e+00
Validation loss: 0.000, valid_NMSE: -8.748e+00
--------------------------------------------------
[INFO]: Epoch 148 of 200
Training
[148,   100] loss: 5.277e-05
[148,   200] loss: 5.384e-05
Validation
[148,   100] loss: 6.800e-05
[148,   200] loss: 6.612e-05
Training loss: 0.000, train NMSE: -8.482e+00
Validation loss: 0.000, valid_NMSE: -8.838e+00
--------------------------------------------------
[INFO]: Epoch 149 of 200
Training
[149,   100] loss: 5.296e-05
[149,   200] loss: 5.296e-05
Validation
[149,   100] loss: 6.718e-05
[149,   200] loss: 6.536e-05
Training loss: 0.000, train NMSE: -8.263e+00
Validation loss: 0.000, valid_NMSE: -8.928e+00
--------------------------------------------------
[INFO]: Epoch 150 of 200
Training
[150,   100] loss: 5.366e-05
[150,   200] loss: 5.246e-05
Validation
[150,   100] loss: 6.709e-05
[150,   200] loss: 6.524e-05
Training loss: 0.000, train NMSE: -9.276e+00
Validation loss: 0.000, valid_NMSE: -8.897e+00
--------------------------------------------------
[INFO]: Epoch 151 of 200
Training
[151,   100] loss: 5.348e-05
[151,   200] loss: 5.261e-05
Validation
[151,   100] loss: 6.929e-05
[151,   200] loss: 6.741e-05
Training loss: 0.000, train NMSE: -9.516e+00
Validation loss: 0.000, valid_NMSE: -8.629e+00
--------------------------------------------------
[INFO]: Epoch 152 of 200
Training
[152,   100] loss: 5.323e-05
[152,   200] loss: 5.272e-05
Validation
[152,   100] loss: 6.724e-05
[152,   200] loss: 6.536e-05
Training loss: 0.000, train NMSE: -9.671e+00
Validation loss: 0.000, valid_NMSE: -8.968e+00

Best validation loss: -8.968311309814453

Saving best model for epoch: 152

--------------------------------------------------
[INFO]: Epoch 153 of 200
Training
[153,   100] loss: 5.259e-05
[153,   200] loss: 5.341e-05
Validation
[153,   100] loss: 6.789e-05
[153,   200] loss: 6.608e-05
Training loss: 0.000, train NMSE: -9.397e+00
Validation loss: 0.000, valid_NMSE: -8.855e+00
--------------------------------------------------
[INFO]: Epoch 154 of 200
Training
[154,   100] loss: 5.285e-05
[154,   200] loss: 5.280e-05
Validation
[154,   100] loss: 6.691e-05
[154,   200] loss: 6.512e-05
Training loss: 0.000, train NMSE: -9.646e+00
Validation loss: 0.000, valid_NMSE: -9.002e+00

Best validation loss: -9.002161979675293

Saving best model for epoch: 154

--------------------------------------------------
[INFO]: Epoch 155 of 200
Training
[155,   100] loss: 5.203e-05
[155,   200] loss: 5.417e-05
Validation
[155,   100] loss: 6.809e-05
[155,   200] loss: 6.626e-05
Training loss: 0.000, train NMSE: -9.029e+00
Validation loss: 0.000, valid_NMSE: -8.829e+00
--------------------------------------------------
[INFO]: Epoch 156 of 200
Training
[156,   100] loss: 5.230e-05
[156,   200] loss: 5.323e-05
Validation
[156,   100] loss: 6.988e-05
[156,   200] loss: 6.797e-05
Training loss: 0.000, train NMSE: -9.468e+00
Validation loss: 0.000, valid_NMSE: -8.590e+00
--------------------------------------------------
[INFO]: Epoch 157 of 200
Training
[157,   100] loss: 5.307e-05
[157,   200] loss: 5.220e-05
Validation
[157,   100] loss: 6.693e-05
[157,   200] loss: 6.501e-05
Training loss: 0.000, train NMSE: -9.060e+00
Validation loss: 0.000, valid_NMSE: -9.008e+00

Best validation loss: -9.007976531982422

Saving best model for epoch: 157

--------------------------------------------------
[INFO]: Epoch 158 of 200
Training
[158,   100] loss: 5.187e-05
[158,   200] loss: 5.317e-05
Validation
[158,   100] loss: 6.700e-05
[158,   200] loss: 6.514e-05
Training loss: 0.000, train NMSE: -9.000e+00
Validation loss: 0.000, valid_NMSE: -8.940e+00
--------------------------------------------------
[INFO]: Epoch 159 of 200
Training
[159,   100] loss: 5.265e-05
[159,   200] loss: 5.290e-05
Validation
[159,   100] loss: 6.709e-05
[159,   200] loss: 6.526e-05
Training loss: 0.000, train NMSE: -1.012e+01
Validation loss: 0.000, valid_NMSE: -8.939e+00
--------------------------------------------------
[INFO]: Epoch 160 of 200
Training
[160,   100] loss: 5.318e-05
[160,   200] loss: 5.232e-05
Validation
[160,   100] loss: 6.667e-05
[160,   200] loss: 6.485e-05
Training loss: 0.000, train NMSE: -9.354e+00
Validation loss: 0.000, valid_NMSE: -9.014e+00

Best validation loss: -9.013528823852539

Saving best model for epoch: 160

--------------------------------------------------
[INFO]: Epoch 161 of 200
Training
[161,   100] loss: 5.268e-05
[161,   200] loss: 5.247e-05
Validation
[161,   100] loss: 6.771e-05
[161,   200] loss: 6.583e-05
Training loss: 0.000, train NMSE: -9.621e+00
Validation loss: 0.000, valid_NMSE: -8.815e+00
--------------------------------------------------
[INFO]: Epoch 162 of 200
Training
[162,   100] loss: 5.290e-05
[162,   200] loss: 5.222e-05
Validation
[162,   100] loss: 6.844e-05
[162,   200] loss: 6.655e-05
Training loss: 0.000, train NMSE: -9.491e+00
Validation loss: 0.000, valid_NMSE: -8.702e+00
--------------------------------------------------
[INFO]: Epoch 163 of 200
Training
[163,   100] loss: 5.218e-05
[163,   200] loss: 5.273e-05
Validation
[163,   100] loss: 6.893e-05
[163,   200] loss: 6.705e-05
Training loss: 0.000, train NMSE: -8.847e+00
Validation loss: 0.000, valid_NMSE: -8.708e+00
--------------------------------------------------
[INFO]: Epoch 164 of 200
Training
[164,   100] loss: 5.250e-05
[164,   200] loss: 5.200e-05
Validation
[164,   100] loss: 6.805e-05
[164,   200] loss: 6.612e-05
Training loss: 0.000, train NMSE: -9.990e+00
Validation loss: 0.000, valid_NMSE: -8.825e+00
--------------------------------------------------
[INFO]: Epoch 165 of 200
Training
[165,   100] loss: 5.219e-05
[165,   200] loss: 5.215e-05
Validation
[165,   100] loss: 6.725e-05
[165,   200] loss: 6.540e-05
Training loss: 0.000, train NMSE: -8.915e+00
Validation loss: 0.000, valid_NMSE: -8.852e+00
--------------------------------------------------
[INFO]: Epoch 166 of 200
Training
[166,   100] loss: 5.306e-05
[166,   200] loss: 5.193e-05
Validation
[166,   100] loss: 6.715e-05
[166,   200] loss: 6.534e-05
Training loss: 0.000, train NMSE: -9.088e+00
Validation loss: 0.000, valid_NMSE: -8.881e+00
--------------------------------------------------
[INFO]: Epoch 167 of 200
Training
[167,   100] loss: 5.265e-05
[167,   200] loss: 5.279e-05
Validation
[167,   100] loss: 6.783e-05
[167,   200] loss: 6.592e-05
Training loss: 0.000, train NMSE: -1.002e+01
Validation loss: 0.000, valid_NMSE: -8.914e+00
--------------------------------------------------
[INFO]: Epoch 168 of 200
Training
[168,   100] loss: 5.173e-05
[168,   200] loss: 5.268e-05
Validation
[168,   100] loss: 6.893e-05
[168,   200] loss: 6.707e-05
Training loss: 0.000, train NMSE: -9.121e+00
Validation loss: 0.000, valid_NMSE: -8.645e+00
--------------------------------------------------
[INFO]: Epoch 169 of 200
Training
[169,   100] loss: 5.313e-05
[169,   200] loss: 5.151e-05
Validation
[169,   100] loss: 6.782e-05
[169,   200] loss: 6.587e-05
Training loss: 0.000, train NMSE: -1.024e+01
Validation loss: 0.000, valid_NMSE: -8.781e+00
--------------------------------------------------
[INFO]: Epoch 170 of 200
Training
[170,   100] loss: 5.116e-05
[170,   200] loss: 5.309e-05
Validation
[170,   100] loss: 6.795e-05
[170,   200] loss: 6.612e-05
Training loss: 0.000, train NMSE: -9.814e+00
Validation loss: 0.000, valid_NMSE: -8.763e+00
--------------------------------------------------
[INFO]: Epoch 171 of 200
Training
[171,   100] loss: 5.146e-05
[171,   200] loss: 5.203e-05
Validation
[171,   100] loss: 6.657e-05
[171,   200] loss: 6.476e-05
Training loss: 0.000, train NMSE: -9.594e+00
Validation loss: 0.000, valid_NMSE: -9.035e+00

Best validation loss: -9.03480339050293

Saving best model for epoch: 171

--------------------------------------------------
[INFO]: Epoch 172 of 200
Training
[172,   100] loss: 5.205e-05
[172,   200] loss: 5.252e-05
Validation
[172,   100] loss: 6.935e-05
[172,   200] loss: 6.744e-05
Training loss: 0.000, train NMSE: -9.215e+00
Validation loss: 0.000, valid_NMSE: -8.628e+00
--------------------------------------------------
[INFO]: Epoch 173 of 200
Training
[173,   100] loss: 5.227e-05
[173,   200] loss: 5.198e-05
Validation
[173,   100] loss: 6.800e-05
[173,   200] loss: 6.618e-05
Training loss: 0.000, train NMSE: -1.010e+01
Validation loss: 0.000, valid_NMSE: -8.791e+00
--------------------------------------------------
[INFO]: Epoch 174 of 200
Training
[174,   100] loss: 5.190e-05
[174,   200] loss: 5.195e-05
Validation
[174,   100] loss: 6.780e-05
[174,   200] loss: 6.594e-05
Training loss: 0.000, train NMSE: -9.678e+00
Validation loss: 0.000, valid_NMSE: -8.859e+00
--------------------------------------------------
[INFO]: Epoch 175 of 200
Training
[175,   100] loss: 5.149e-05
[175,   200] loss: 5.226e-05
Validation
[175,   100] loss: 6.896e-05
[175,   200] loss: 6.714e-05
Training loss: 0.000, train NMSE: -1.019e+01
Validation loss: 0.000, valid_NMSE: -8.582e+00
--------------------------------------------------
[INFO]: Epoch 176 of 200
Training
[176,   100] loss: 5.218e-05
[176,   200] loss: 5.225e-05
Validation
[176,   100] loss: 6.668e-05
[176,   200] loss: 6.486e-05
Training loss: 0.000, train NMSE: -9.654e+00
Validation loss: 0.000, valid_NMSE: -8.979e+00
--------------------------------------------------
[INFO]: Epoch 177 of 200
Training
[177,   100] loss: 5.227e-05
[177,   200] loss: 5.127e-05
Validation
[177,   100] loss: 6.697e-05
[177,   200] loss: 6.510e-05
Training loss: 0.000, train NMSE: -9.592e+00
Validation loss: 0.000, valid_NMSE: -8.900e+00
--------------------------------------------------
[INFO]: Epoch 178 of 200
Training
[178,   100] loss: 5.193e-05
[178,   200] loss: 5.208e-05
Validation
[178,   100] loss: 6.834e-05
[178,   200] loss: 6.648e-05
Training loss: 0.000, train NMSE: -9.393e+00
Validation loss: 0.000, valid_NMSE: -8.732e+00
--------------------------------------------------
[INFO]: Epoch 179 of 200
Training
[179,   100] loss: 5.207e-05
[179,   200] loss: 5.137e-05
Validation
[179,   100] loss: 6.769e-05
[179,   200] loss: 6.578e-05
Training loss: 0.000, train NMSE: -9.482e+00
Validation loss: 0.000, valid_NMSE: -8.893e+00
--------------------------------------------------
[INFO]: Epoch 180 of 200
Training
[180,   100] loss: 5.124e-05
[180,   200] loss: 5.322e-05
Validation
[180,   100] loss: 6.788e-05
[180,   200] loss: 6.603e-05
Training loss: 0.000, train NMSE: -9.225e+00
Validation loss: 0.000, valid_NMSE: -8.851e+00
--------------------------------------------------
[INFO]: Epoch 181 of 200
Training
[181,   100] loss: 5.112e-05/home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE
  warn(f"Failed to load image Python extension: {e}")

[181,   200] loss: 5.275e-05
Validation
[181,   100] loss: 6.858e-05
[181,   200] loss: 6.672e-05
Training loss: 0.000, train NMSE: -9.030e+00
Validation loss: 0.000, valid_NMSE: -8.673e+00
--------------------------------------------------
[INFO]: Epoch 182 of 200
Training
[182,   100] loss: 5.215e-05
[182,   200] loss: 5.153e-05
Validation
[182,   100] loss: 6.745e-05
[182,   200] loss: 6.561e-05
Training loss: 0.000, train NMSE: -9.628e+00
Validation loss: 0.000, valid_NMSE: -8.865e+00
--------------------------------------------------
[INFO]: Epoch 183 of 200
Training
[183,   100] loss: 5.136e-05
[183,   200] loss: 5.173e-05
Validation
[183,   100] loss: 6.682e-05
[183,   200] loss: 6.500e-05
Training loss: 0.000, train NMSE: -9.992e+00
Validation loss: 0.000, valid_NMSE: -8.956e+00
--------------------------------------------------
[INFO]: Epoch 184 of 200
Training
[184,   100] loss: 5.132e-05
[184,   200] loss: 5.163e-05
Validation
[184,   100] loss: 6.748e-05
[184,   200] loss: 6.556e-05
Training loss: 0.000, train NMSE: -9.415e+00
Validation loss: 0.000, valid_NMSE: -8.880e+00
--------------------------------------------------
[INFO]: Epoch 185 of 200
Training
[185,   100] loss: 5.229e-05
[185,   200] loss: 5.080e-05
Validation
[185,   100] loss: 6.752e-05
[185,   200] loss: 6.563e-05
Training loss: 0.000, train NMSE: -9.238e+00
Validation loss: 0.000, valid_NMSE: -8.805e+00
--------------------------------------------------
[INFO]: Epoch 186 of 200
Training
[186,   100] loss: 5.148e-05
[186,   200] loss: 5.209e-05
Validation
[186,   100] loss: 6.678e-05
[186,   200] loss: 6.497e-05
Training loss: 0.000, train NMSE: -9.851e+00
Validation loss: 0.000, valid_NMSE: -8.896e+00
--------------------------------------------------
[INFO]: Epoch 187 of 200
Training
[187,   100] loss: 5.126e-05
[187,   200] loss: 5.258e-05
Validation
[187,   100] loss: 6.797e-05
[187,   200] loss: 6.617e-05
Training loss: 0.000, train NMSE: -9.321e+00
Validation loss: 0.000, valid_NMSE: -8.817e+00
--------------------------------------------------
[INFO]: Epoch 188 of 200
Training
[188,   100] loss: 5.213e-05
[188,   200] loss: 5.149e-05
Validation
[188,   100] loss: 6.768e-05
[188,   200] loss: 6.587e-05
Training loss: 0.000, train NMSE: -9.194e+00
Validation loss: 0.000, valid_NMSE: -8.761e+00
--------------------------------------------------
[INFO]: Epoch 189 of 200
Training
[189,   100] loss: 5.092e-05
[189,   200] loss: 5.162e-05
Validation
[189,   100] loss: 6.767e-05
[189,   200] loss: 6.587e-05
Training loss: 0.000, train NMSE: -9.333e+00
Validation loss: 0.000, valid_NMSE: -8.786e+00
--------------------------------------------------
[INFO]: Epoch 190 of 200
Training
[190,   100] loss: 5.058e-05
[190,   200] loss: 5.159e-05
Validation
[190,   100] loss: 6.658e-05
[190,   200] loss: 6.475e-05
Training loss: 0.000, train NMSE: -9.940e+00
Validation loss: 0.000, valid_NMSE: -8.928e+00
--------------------------------------------------
[INFO]: Epoch 191 of 200
Training
[191,   100] loss: 5.118e-05
[191,   200] loss: 5.122e-05
Validation
[191,   100] loss: 6.700e-05
[191,   200] loss: 6.516e-05
Training loss: 0.000, train NMSE: -9.348e+00
Validation loss: 0.000, valid_NMSE: -8.878e+00
--------------------------------------------------
[INFO]: Epoch 192 of 200
Training
[192,   100] loss: 5.179e-05
[192,   200] loss: 5.114e-05
Validation
[192,   100] loss: 6.657e-05
[192,   200] loss: 6.472e-05
Training loss: 0.000, train NMSE: -9.798e+00
Validation loss: 0.000, valid_NMSE: -8.975e+00
--------------------------------------------------
[INFO]: Epoch 193 of 200
Training
[193,   100] loss: 5.238e-05
[193,   200] loss: 5.012e-05
Validation
[193,   100] loss: 6.670e-05
[193,   200] loss: 6.489e-05
Training loss: 0.000, train NMSE: -9.482e+00
Validation loss: 0.000, valid_NMSE: -8.962e+00
--------------------------------------------------
[INFO]: Epoch 194 of 200
Training
[194,   100] loss: 5.157e-05
[194,   200] loss: 5.025e-05
Validation
[194,   100] loss: 6.674e-05
[194,   200] loss: 6.495e-05
Training loss: 0.000, train NMSE: -9.144e+00
Validation loss: 0.000, valid_NMSE: -8.889e+00
--------------------------------------------------
[INFO]: Epoch 195 of 200
Training
[195,   100] loss: 5.107e-05
[195,   200] loss: 5.147e-05
Validation
[195,   100] loss: 6.721e-05
[195,   200] loss: 6.535e-05
Training loss: 0.000, train NMSE: -9.624e+00
Validation loss: 0.000, valid_NMSE: -8.841e+00
--------------------------------------------------
[INFO]: Epoch 196 of 200
Training
[196,   100] loss: 5.189e-05
[196,   200] loss: 5.013e-05
Validation
[196,   100] loss: 6.760e-05
[196,   200] loss: 6.571e-05
Training loss: 0.000, train NMSE: -9.049e+00
Validation loss: 0.000, valid_NMSE: -8.781e+00
--------------------------------------------------
[INFO]: Epoch 197 of 200
Training
[197,   100] loss: 5.187e-05
[197,   200] loss: 5.080e-05
Validation
[197,   100] loss: 6.676e-05
[197,   200] loss: 6.492e-05
Training loss: 0.000, train NMSE: -9.781e+00
Validation loss: 0.000, valid_NMSE: -8.908e+00
--------------------------------------------------
[INFO]: Epoch 198 of 200
Training
[198,   100] loss: 5.136e-05
[198,   200] loss: 5.004e-05
Validation
[198,   100] loss: 6.695e-05
[198,   200] loss: 6.513e-05
Training loss: 0.000, train NMSE: -9.470e+00
Validation loss: 0.000, valid_NMSE: -8.862e+00
--------------------------------------------------
[INFO]: Epoch 199 of 200
Training
[199,   100] loss: 5.106e-05
[199,   200] loss: 5.135e-05
Validation
[199,   100] loss: 6.721e-05
[199,   200] loss: 6.529e-05
Training loss: 0.000, train NMSE: -9.696e+00
Validation loss: 0.000, valid_NMSE: -8.866e+00
--------------------------------------------------
[INFO]: Epoch 200 of 200
Training
[200,   100] loss: 5.079e-05
[200,   200] loss: 5.108e-05
Validation
[200,   100] loss: 6.735e-05
[200,   200] loss: 6.550e-05
Training loss: 0.000, train NMSE: -9.889e+00
Validation loss: 0.000, valid_NMSE: -8.832e+00
--------------------------------------------------
Saving final model
TRAINING COMPLETE
