1.13.1+cu117
outEnergyID
Dadicated Mode outEnergyID
Dedicated Mode outEnergyID
trainset len 112000 valset len 48000
New_trainset len 40000 valset len 48000
1,611,673 training parameters.

1,611,673 training parameters.

[INFO]: Epoch 1 of 200
Training
[1,   100] loss: 8.745e-04
[1,   200] loss: 7.462e-04
Validation
[1,   100] loss: 6.174e-04
[1,   200] loss: 6.174e-04
Training loss: 0.001, train NMSE: -1.259e+00
Validation loss: 0.001, valid_NMSE: -1.282e+00

Best validation loss: -1.281836748123169

Saving best model for epoch: 1

--------------------------------------------------
[INFO]: Epoch 2 of 200
Training
[2,   100] loss: 6.438e-04
[2,   200] loss: 6.078e-04
Validation
[2,   100] loss: 5.413e-04
[2,   200] loss: 5.413e-04
Training loss: 0.001, train NMSE: -1.859e+00
Validation loss: 0.001, valid_NMSE: -1.905e+00

Best validation loss: -1.9046473503112793

Saving best model for epoch: 2

--------------------------------------------------
[INFO]: Epoch 3 of 200
Training
[3,   100] loss: 5.832e-04
[3,   200] loss: 5.672e-04
Validation
[3,   100] loss: 5.120e-04
[3,   200] loss: 5.120e-04
Training loss: 0.001, train NMSE: -2.182e+00
Validation loss: 0.001, valid_NMSE: -2.178e+00

Best validation loss: -2.1775529384613037

Saving best model for epoch: 3

--------------------------------------------------
[INFO]: Epoch 4 of 200
Training
[4,   100] loss: 5.494e-04
[4,   200] loss: 5.456e-04
Validation
[4,   100] loss: 4.912e-04
[4,   200] loss: 4.912e-04
Training loss: 0.001, train NMSE: -2.164e+00
Validation loss: 0.000, valid_NMSE: -2.383e+00

Best validation loss: -2.3827245235443115

Saving best model for epoch: 4

--------------------------------------------------
[INFO]: Epoch 5 of 200
Training
[5,   100] loss: 5.294e-04
[5,   200] loss: 5.241e-04
Validation
[5,   100] loss: 4.754e-04
[5,   200] loss: 4.754e-04
Training loss: 0.001, train NMSE: -2.499e+00
Validation loss: 0.000, valid_NMSE: -2.554e+00

Best validation loss: -2.553640604019165

Saving best model for epoch: 5

--------------------------------------------------
[INFO]: Epoch 6 of 200
Training
[6,   100] loss: 5.126e-04
[6,   200] loss: 5.070e-04
Validation
[6,   100] loss: 4.606e-04
[6,   200] loss: 4.606e-04
Training loss: 0.001, train NMSE: -2.589e+00
Validation loss: 0.000, valid_NMSE: -2.713e+00

Best validation loss: -2.712658405303955

Saving best model for epoch: 6

--------------------------------------------------
[INFO]: Epoch 7 of 200
Training
[7,   100] loss: 4.994e-04
[7,   200] loss: 4.912e-04
Validation
[7,   100] loss: 4.487e-04
[7,   200] loss: 4.487e-04
Training loss: 0.000, train NMSE: -2.485e+00
Validation loss: 0.000, valid_NMSE: -2.859e+00

Best validation loss: -2.8589823246002197

Saving best model for epoch: 7

--------------------------------------------------
[INFO]: Epoch 8 of 200
Training
[8,   100] loss: 4.866e-04
[8,   200] loss: 4.782e-04
Validation
[8,   100] loss: 4.379e-04
[8,   200] loss: 4.379e-04
Training loss: 0.000, train NMSE: -2.790e+00
Validation loss: 0.000, valid_NMSE: -2.977e+00

Best validation loss: -2.9767916202545166

Saving best model for epoch: 8

--------------------------------------------------
[INFO]: Epoch 9 of 200
Training
[9,   100] loss: 4.744e-04
[9,   200] loss: 4.669e-04
Validation
[9,   100] loss: 4.271e-04
[9,   200] loss: 4.271e-04
Training loss: 0.000, train NMSE: -3.088e+00
Validation loss: 0.000, valid_NMSE: -3.112e+00

Best validation loss: -3.1118128299713135

Saving best model for epoch: 9

--------------------------------------------------
[INFO]: Epoch 10 of 200
Training
[10,   100] loss: 4.610e-04
[10,   200] loss: 4.562e-04
Validation
[10,   100] loss: 4.185e-04
[10,   200] loss: 4.185e-04
Training loss: 0.000, train NMSE: -3.069e+00
Validation loss: 0.000, valid_NMSE: -3.222e+00

Best validation loss: -3.222074031829834

Saving best model for epoch: 10

--------------------------------------------------
[INFO]: Epoch 11 of 200
Training
[11,   100] loss: 4.508e-04
[11,   200] loss: 4.429e-04
Validation
[11,   100] loss: 4.064e-04
[11,   200] loss: 4.064e-04
Training loss: 0.000, train NMSE: -3.330e+00
Validation loss: 0.000, valid_NMSE: -3.375e+00

Best validation loss: -3.3750178813934326

Saving best model for epoch: 11

--------------------------------------------------
[INFO]: Epoch 12 of 200
Training
[12,   100] loss: 4.378e-04
[12,   200] loss: 4.311e-04
Validation
[12,   100] loss: 3.965e-04
[12,   200] loss: 3.965e-04
Training loss: 0.000, train NMSE: -3.411e+00
Validation loss: 0.000, valid_NMSE: -3.499e+00

Best validation loss: -3.498591423034668

Saving best model for epoch: 12

--------------------------------------------------
[INFO]: Epoch 13 of 200
Training
[13,   100] loss: 4.241e-04
[13,   200] loss: 4.195e-04
Validation
[13,   100] loss: 3.839e-04
[13,   200] loss: 3.839e-04
Training loss: 0.000, train NMSE: -3.511e+00
Validation loss: 0.000, valid_NMSE: -3.674e+00

Best validation loss: -3.6739206314086914

Saving best model for epoch: 13

--------------------------------------------------
[INFO]: Epoch 14 of 200
Training
[14,   100] loss: 4.088e-04
[14,   200] loss: 4.103e-04
Validation
[14,   100] loss: 3.735e-04
[14,   200] loss: 3.735e-04
Training loss: 0.000, train NMSE: -3.719e+00
Validation loss: 0.000, valid_NMSE: -3.799e+00

Best validation loss: -3.7990667819976807

Saving best model for epoch: 14

--------------------------------------------------
[INFO]: Epoch 15 of 200
Training
[15,   100] loss: 3.993e-04
[15,   200] loss: 3.965e-04
Validation
[15,   100] loss: 3.634e-04
[15,   200] loss: 3.634e-04
Training loss: 0.000, train NMSE: -3.522e+00
Validation loss: 0.000, valid_NMSE: -3.937e+00

Best validation loss: -3.936943531036377

Saving best model for epoch: 15

--------------------------------------------------
[INFO]: Epoch 16 of 200
Training
[16,   100] loss: 3.867e-04
[16,   200] loss: 3.874e-04
Validation
[16,   100] loss: 3.541e-04
[16,   200] loss: 3.541e-04
Training loss: 0.000, train NMSE: -4.056e+00
Validation loss: 0.000, valid_NMSE: -4.042e+00

Best validation loss: -4.041590690612793

Saving best model for epoch: 16

--------------------------------------------------
[INFO]: Epoch 17 of 200
Training
[17,   100] loss: 3.768e-04
[17,   200] loss: 3.756e-04
Validation
[17,   100] loss: 3.445e-04
[17,   200] loss: 3.445e-04
Training loss: 0.000, train NMSE: -4.137e+00
Validation loss: 0.000, valid_NMSE: -4.191e+00

Best validation loss: -4.190732955932617

Saving best model for epoch: 17

--------------------------------------------------
[INFO]: Epoch 18 of 200
Training
[18,   100] loss: 3.670e-04
[18,   200] loss: 3.653e-04
Validation
[18,   100] loss: 3.356e-04
[18,   200] loss: 3.356e-04
Training loss: 0.000, train NMSE: -3.713e+00
Validation loss: 0.000, valid_NMSE: -4.324e+00

Best validation loss: -4.324199676513672

Saving best model for epoch: 18

--------------------------------------------------
[INFO]: Epoch 19 of 200
Training
[19,   100] loss: 3.595e-04
[19,   200] loss: 3.545e-04
Validation
[19,   100] loss: 3.285e-04
[19,   200] loss: 3.285e-04
Training loss: 0.000, train NMSE: -3.517e+00
Validation loss: 0.000, valid_NMSE: -4.409e+00

Best validation loss: -4.408714294433594

Saving best model for epoch: 19

--------------------------------------------------
[INFO]: Epoch 20 of 200
Training
[20,   100] loss: 3.511e-04
[20,   200] loss: 3.438e-04
Validation
[20,   100] loss: 3.198e-04
[20,   200] loss: 3.198e-04
Training loss: 0.000, train NMSE: -4.341e+00
Validation loss: 0.000, valid_NMSE: -4.533e+00

Best validation loss: -4.533496379852295

Saving best model for epoch: 20

--------------------------------------------------
[INFO]: Epoch 21 of 200
Training
[21,   100] loss: 3.431e-04
[21,   200] loss: 3.351e-04
Validation
[21,   100] loss: 3.139e-04
[21,   200] loss: 3.139e-04
Training loss: 0.000, train NMSE: -4.567e+00
Validation loss: 0.000, valid_NMSE: -4.602e+00

Best validation loss: -4.60194206237793

Saving best model for epoch: 21

--------------------------------------------------
[INFO]: Epoch 22 of 200
Training
[22,   100] loss: 3.304e-04
[22,   200] loss: 3.327e-04
Validation
[22,   100] loss: 3.074e-04
[22,   200] loss: 3.074e-04
Training loss: 0.000, train NMSE: -4.483e+00
Validation loss: 0.000, valid_NMSE: -4.698e+00

Best validation loss: -4.697610855102539

Saving best model for epoch: 22

--------------------------------------------------
[INFO]: Epoch 23 of 200
Training
[23,   100] loss: 3.247e-04
[23,   200] loss: 3.235e-04
Validation
[23,   100] loss: 3.008e-04
[23,   200] loss: 3.008e-04
Training loss: 0.000, train NMSE: -4.726e+00
Validation loss: 0.000, valid_NMSE: -4.810e+00

Best validation loss: -4.809935092926025

Saving best model for epoch: 23

--------------------------------------------------
[INFO]: Epoch 24 of 200
Training
[24,   100] loss: 3.181e-04
[24,   200] loss: 3.174e-04
Validation
[24,   100] loss: 2.963e-04
[24,   200] loss: 2.963e-04
Training loss: 0.000, train NMSE: -4.824e+00
Validation loss: 0.000, valid_NMSE: -4.862e+00

Best validation loss: -4.862002849578857

Saving best model for epoch: 24

--------------------------------------------------
[INFO]: Epoch 25 of 200
Training
[25,   100] loss: 3.155e-04
[25,   200] loss: 3.087e-04
Validation
[25,   100] loss: 2.901e-04
[25,   200] loss: 2.901e-04
Training loss: 0.000, train NMSE: -4.951e+00
Validation loss: 0.000, valid_NMSE: -4.964e+00

Best validation loss: -4.963589668273926

Saving best model for epoch: 25

--------------------------------------------------
[INFO]: Epoch 26 of 200
Training
[26,   100] loss: 3.035e-04
[26,   200] loss: 3.097e-04
Validation
[26,   100] loss: 2.863e-04
[26,   200] loss: 2.863e-04
Training loss: 0.000, train NMSE: -5.003e+00
Validation loss: 0.000, valid_NMSE: -5.019e+00

Best validation loss: -5.018880367279053

Saving best model for epoch: 26

--------------------------------------------------
[INFO]: Epoch 27 of 200
Training
[27,   100] loss: 3.044e-04
[27,   200] loss: 2.987e-04
Validation
[27,   100] loss: 2.840e-04
[27,   200] loss: 2.840e-04
Training loss: 0.000, train NMSE: -5.041e+00
Validation loss: 0.000, valid_NMSE: -5.036e+00

Best validation loss: -5.036301136016846

Saving best model for epoch: 27

--------------------------------------------------
[INFO]: Epoch 28 of 200
Training
[28,   100] loss: 2.979e-04
[28,   200] loss: 2.962e-04
Validation
[28,   100] loss: 2.791e-04
[28,   200] loss: 2.791e-04
Training loss: 0.000, train NMSE: -4.710e+00
Validation loss: 0.000, valid_NMSE: -5.150e+00

Best validation loss: -5.150297164916992

Saving best model for epoch: 28

--------------------------------------------------
[INFO]: Epoch 29 of 200
Training
[29,   100] loss: 2.933e-04
[29,   200] loss: 2.923e-04
Validation
[29,   100] loss: 2.756e-04
[29,   200] loss: 2.756e-04
Training loss: 0.000, train NMSE: -5.347e+00
Validation loss: 0.000, valid_NMSE: -5.194e+00

Best validation loss: -5.1938886642456055

Saving best model for epoch: 29

--------------------------------------------------
[INFO]: Epoch 30 of 200
Training
[30,   100] loss: 2.879e-04
[30,   200] loss: 2.897e-04
Validation
[30,   100] loss: 2.722e-04
[30,   200] loss: 2.722e-04
Training loss: 0.000, train NMSE: -5.266e+00
Validation loss: 0.000, valid_NMSE: -5.256e+00

Best validation loss: -5.256066799163818

Saving best model for epoch: 30

--------------------------------------------------
[INFO]: Epoch 31 of 200
Training
[31,   100] loss: 2.859e-04
[31,   200] loss: 2.847e-04
Validation
[31,   100] loss: 2.701e-04
[31,   200] loss: 2.701e-04
Training loss: 0.000, train NMSE: -5.294e+00
Validation loss: 0.000, valid_NMSE: -5.278e+00

Best validation loss: -5.2777910232543945

Saving best model for epoch: 31

--------------------------------------------------
[INFO]: Epoch 32 of 200
Training
[32,   100] loss: 2.812e-04
[32,   200] loss: 2.814e-04
Validation
[32,   100] loss: 2.652e-04
[32,   200] loss: 2.652e-04
Training loss: 0.000, train NMSE: -5.018e+00
Validation loss: 0.000, valid_NMSE: -5.392e+00

Best validation loss: -5.391813278198242

Saving best model for epoch: 32

--------------------------------------------------
[INFO]: Epoch 33 of 200
Training
[33,   100] loss: 2.782e-04
[33,   200] loss: 2.773e-04
Validation
[33,   100] loss: 2.646e-04
[33,   200] loss: 2.646e-04
Training loss: 0.000, train NMSE: -5.587e+00
Validation loss: 0.000, valid_NMSE: -5.354e+00
--------------------------------------------------
[INFO]: Epoch 34 of 200
Training
[34,   100] loss: 2.752e-04
[34,   200] loss: 2.742e-04
Validation
[34,   100] loss: 2.607e-04
[34,   200] loss: 2.607e-04
Training loss: 0.000, train NMSE: -5.176e+00
Validation loss: 0.000, valid_NMSE: -5.443e+00

Best validation loss: -5.443339824676514

Saving best model for epoch: 34

--------------------------------------------------
[INFO]: Epoch 35 of 200
Training
[35,   100] loss: 2.738e-04
[35,   200] loss: 2.698e-04
Validation
[35,   100] loss: 2.604e-04
[35,   200] loss: 2.604e-04
Training loss: 0.000, train NMSE: -5.434e+00
Validation loss: 0.000, valid_NMSE: -5.440e+00
--------------------------------------------------
[INFO]: Epoch 36 of 200
Training
[36,   100] loss: 2.693e-04
[36,   200] loss: 2.685e-04
Validation
[36,   100] loss: 2.553e-04
[36,   200] loss: 2.553e-04
Training loss: 0.000, train NMSE: -5.511e+00
Validation loss: 0.000, valid_NMSE: -5.539e+00

Best validation loss: -5.5388593673706055

Saving best model for epoch: 36

--------------------------------------------------
[INFO]: Epoch 37 of 200
Training
[37,   100] loss: 2.662e-04
[37,   200] loss: 2.656e-04
Validation
[37,   100] loss: 2.529e-04
[37,   200] loss: 2.529e-04
Training loss: 0.000, train NMSE: -5.280e+00
Validation loss: 0.000, valid_NMSE: -5.578e+00

Best validation loss: -5.578478813171387

Saving best model for epoch: 37

--------------------------------------------------
[INFO]: Epoch 38 of 200
Training
[38,   100] loss: 2.620e-04
[38,   200] loss: 2.640e-04
Validation
[38,   100] loss: 2.516e-04
[38,   200] loss: 2.516e-04
Training loss: 0.000, train NMSE: -5.687e+00
Validation loss: 0.000, valid_NMSE: -5.609e+00

Best validation loss: -5.609096527099609

Saving best model for epoch: 38

--------------------------------------------------
[INFO]: Epoch 39 of 200
Training
[39,   100] loss: 2.580e-04
[39,   200] loss: 2.638e-04
Validation
[39,   100] loss: 2.488e-04
[39,   200] loss: 2.488e-04
Training loss: 0.000, train NMSE: -5.395e+00
Validation loss: 0.000, valid_NMSE: -5.664e+00

Best validation loss: -5.6642937660217285

Saving best model for epoch: 39

--------------------------------------------------
[INFO]: Epoch 40 of 200
Training
[40,   100] loss: 2.591e-04
[40,   200] loss: 2.574e-04
Validation
[40,   100] loss: 2.467e-04
[40,   200] loss: 2.467e-04
Training loss: 0.000, train NMSE: -5.913e+00
Validation loss: 0.000, valid_NMSE: -5.699e+00

Best validation loss: -5.699445724487305

Saving best model for epoch: 40

--------------------------------------------------
[INFO]: Epoch 41 of 200
Training
[41,   100] loss: 2.562e-04
[41,   200] loss: 2.558e-04
Validation
[41,   100] loss: 2.472e-04
[41,   200] loss: 2.472e-04
Training loss: 0.000, train NMSE: -5.808e+00
Validation loss: 0.000, valid_NMSE: -5.640e+00
--------------------------------------------------
[INFO]: Epoch 42 of 200
Training
[42,   100] loss: 2.546e-04
[42,   200] loss: 2.528e-04
Validation
[42,   100] loss: 2.443e-04
[42,   200] loss: 2.443e-04
Training loss: 0.000, train NMSE: -6.086e+00
Validation loss: 0.000, valid_NMSE: -5.729e+00

Best validation loss: -5.7291035652160645

Saving best model for epoch: 42

--------------------------------------------------
[INFO]: Epoch 43 of 200
Training
[43,   100] loss: 2.531e-04
[43,   200] loss: 2.504e-04
Validation
[43,   100] loss: 2.422e-04
[43,   200] loss: 2.422e-04
Training loss: 0.000, train NMSE: -5.550e+00
Validation loss: 0.000, valid_NMSE: -5.749e+00

Best validation loss: -5.749403953552246

Saving best model for epoch: 43

--------------------------------------------------
[INFO]: Epoch 44 of 200
Training
[44,   100] loss: 2.507e-04
[44,   200] loss: 2.485e-04
Validation
[44,   100] loss: 2.433e-04
[44,   200] loss: 2.433e-04
Training loss: 0.000, train NMSE: -5.561e+00
Validation loss: 0.000, valid_NMSE: -5.666e+00
--------------------------------------------------
[INFO]: Epoch 45 of 200
Training
[45,   100] loss: 2.455e-04
[45,   200] loss: 2.500e-04
Validation
[45,   100] loss: 2.392e-04
[45,   200] loss: 2.392e-04
Training loss: 0.000, train NMSE: -5.810e+00
Validation loss: 0.000, valid_NMSE: -5.791e+00

Best validation loss: -5.791079521179199

Saving best model for epoch: 45

--------------------------------------------------
[INFO]: Epoch 46 of 200
Training
[46,   100] loss: 2.469e-04
[46,   200] loss: 2.453e-04
Validation
[46,   100] loss: 2.378e-04
[46,   200] loss: 2.378e-04
Training loss: 0.000, train NMSE: -5.671e+00
Validation loss: 0.000, valid_NMSE: -5.807e+00

Best validation loss: -5.807190418243408

Saving best model for epoch: 46

--------------------------------------------------
[INFO]: Epoch 47 of 200
Training
[47,   100] loss: 2.436e-04
[47,   200] loss: 2.446e-04
Validation
[47,   100] loss: 2.359e-04
[47,   200] loss: 2.359e-04
Training loss: 0.000, train NMSE: -6.489e+00
Validation loss: 0.000, valid_NMSE: -5.861e+00

Best validation loss: -5.8611345291137695

Saving best model for epoch: 47

--------------------------------------------------
[INFO]: Epoch 48 of 200
Training
[48,   100] loss: 2.404e-04
[48,   200] loss: 2.450e-04
Validation
[48,   100] loss: 2.364e-04
[48,   200] loss: 2.364e-04
Training loss: 0.000, train NMSE: -5.935e+00
Validation loss: 0.000, valid_NMSE: -5.808e+00
--------------------------------------------------
[INFO]: Epoch 49 of 200
Training
[49,   100] loss: 2.400e-04
[49,   200] loss: 2.417e-04
Validation
[49,   100] loss: 2.343e-04
[49,   200] loss: 2.343e-04
Training loss: 0.000, train NMSE: -5.802e+00
Validation loss: 0.000, valid_NMSE: -5.875e+00

Best validation loss: -5.8751020431518555

Saving best model for epoch: 49

--------------------------------------------------
[INFO]: Epoch 50 of 200
Training
[50,   100] loss: 2.374e-04
[50,   200] loss: 2.407e-04
Validation
[50,   100] loss: 2.346e-04
[50,   200] loss: 2.346e-04
Training loss: 0.000, train NMSE: -5.926e+00
Validation loss: 0.000, valid_NMSE: -5.828e+00
--------------------------------------------------
[INFO]: Epoch 51 of 200
Training
[51,   100] loss: 2.386e-04
[51,   200] loss: 2.367e-04
Validation
[51,   100] loss: 2.312e-04
[51,   200] loss: 2.312e-04
Training loss: 0.000, train NMSE: -6.172e+00
Validation loss: 0.000, valid_NMSE: -5.911e+00

Best validation loss: -5.911274433135986

Saving best model for epoch: 51

--------------------------------------------------
[INFO]: Epoch 52 of 200
Training
[52,   100] loss: 2.384e-04
[52,   200] loss: 2.341e-04
Validation
[52,   100] loss: 2.309e-04
[52,   200] loss: 2.309e-04
Training loss: 0.000, train NMSE: -6.162e+00
Validation loss: 0.000, valid_NMSE: -5.916e+00

Best validation loss: -5.91574764251709

Saving best model for epoch: 52

--------------------------------------------------
[INFO]: Epoch 53 of 200
Training
[53,   100] loss: 2.346e-04
[53,   200] loss: 2.360e-04
Validation
[53,   100] loss: 2.284e-04
[53,   200] loss: 2.284e-04
Training loss: 0.000, train NMSE: -5.771e+00
Validation loss: 0.000, valid_NMSE: -5.979e+00

Best validation loss: -5.978588581085205

Saving best model for epoch: 53

--------------------------------------------------
[INFO]: Epoch 54 of 200
Training
[54,   100] loss: 2.335e-04
[54,   200] loss: 2.332e-04
Validation
[54,   100] loss: 2.276e-04
[54,   200] loss: 2.276e-04
Training loss: 0.000, train NMSE: -5.802e+00
Validation loss: 0.000, valid_NMSE: -6.000e+00

Best validation loss: -5.999669551849365

Saving best model for epoch: 54

--------------------------------------------------
[INFO]: Epoch 55 of 200
Training
[55,   100] loss: 2.312e-04
[55,   200] loss: 2.333e-04
Validation
[55,   100] loss: 2.283e-04
[55,   200] loss: 2.283e-04
Training loss: 0.000, train NMSE: -6.304e+00
Validation loss: 0.000, valid_NMSE: -5.952e+00
--------------------------------------------------
[INFO]: Epoch 56 of 200
Training
[56,   100] loss: 2.318e-04
[56,   200] loss: 2.303e-04
Validation
[56,   100] loss: 2.258e-04
[56,   200] loss: 2.258e-04
Training loss: 0.000, train NMSE: -6.498e+00
Validation loss: 0.000, valid_NMSE: -6.018e+00

Best validation loss: -6.01785135269165

Saving best model for epoch: 56

--------------------------------------------------
[INFO]: Epoch 57 of 200
Training
[57,   100] loss: 2.287e-04
[57,   200] loss: 2.310e-04
Validation
[57,   100] loss: 2.281e-04
[57,   200] loss: 2.281e-04
Training loss: 0.000, train NMSE: -6.394e+00
Validation loss: 0.000, valid_NMSE: -5.895e+00
--------------------------------------------------
[INFO]: Epoch 58 of 200
Training
[58,   100] loss: 2.279e-04
[58,   200] loss: 2.289e-04
Validation
[58,   100] loss: 2.245e-04
[58,   200] loss: 2.245e-04
Training loss: 0.000, train NMSE: -6.047e+00
Validation loss: 0.000, valid_NMSE: -6.048e+00

Best validation loss: -6.048189163208008

Saving best model for epoch: 58

--------------------------------------------------
[INFO]: Epoch 59 of 200
Training
[59,   100] loss: 2.279e-04
[59,   200] loss: 2.267e-04
Validation
[59,   100] loss: 2.243e-04
[59,   200] loss: 2.243e-04
Training loss: 0.000, train NMSE: -5.898e+00
Validation loss: 0.000, valid_NMSE: -6.021e+00
--------------------------------------------------
[INFO]: Epoch 60 of 200
Training
[60,   100] loss: 2.279e-04
[60,   200] loss: 2.245e-04
Validation
[60,   100] loss: 2.223e-04
[60,   200] loss: 2.223e-04
Training loss: 0.000, train NMSE: -6.175e+00
Validation loss: 0.000, valid_NMSE: -6.050e+00

Best validation loss: -6.049929618835449

Saving best model for epoch: 60

--------------------------------------------------
[INFO]: Epoch 61 of 200
Training
[61,   100] loss: 2.244e-04
[61,   200] loss: 2.254e-04
Validation
[61,   100] loss: 2.210e-04
[61,   200] loss: 2.210e-04
Training loss: 0.000, train NMSE: -6.177e+00
Validation loss: 0.000, valid_NMSE: -6.113e+00

Best validation loss: -6.1127214431762695

Saving best model for epoch: 61

--------------------------------------------------
[INFO]: Epoch 62 of 200
Training
[62,   100] loss: 2.257e-04
[62,   200] loss: 2.221e-04
Validation
[62,   100] loss: 2.209e-04
[62,   200] loss: 2.209e-04
Training loss: 0.000, train NMSE: -6.293e+00
Validation loss: 0.000, valid_NMSE: -6.080e+00
--------------------------------------------------
[INFO]: Epoch 63 of 200
Training
[63,   100] loss: 2.215e-04
[63,   200] loss: 2.240e-04
Validation
[63,   100] loss: 2.193e-04
[63,   200] loss: 2.193e-04
Training loss: 0.000, train NMSE: -6.143e+00
Validation loss: 0.000, valid_NMSE: -6.171e+00

Best validation loss: -6.170901298522949

Saving best model for epoch: 63

--------------------------------------------------
[INFO]: Epoch 64 of 200
Training
[64,   100] loss: 2.215e-04
[64,   200] loss: 2.220e-04
Validation
[64,   100] loss: 2.198e-04
[64,   200] loss: 2.198e-04
Training loss: 0.000, train NMSE: -6.574e+00
Validation loss: 0.000, valid_NMSE: -6.112e+00
--------------------------------------------------
[INFO]: Epoch 65 of 200
Training
[65,   100] loss: 2.190e-04
[65,   200] loss: 2.228e-04
Validation
[65,   100] loss: 2.213e-04
[65,   200] loss: 2.213e-04
Training loss: 0.000, train NMSE: -5.830e+00
Validation loss: 0.000, valid_NMSE: -5.996e+00
--------------------------------------------------
[INFO]: Epoch 66 of 200
Training
[66,   100] loss: 2.178e-04
[66,   200] loss: 2.215e-04
Validation
[66,   100] loss: 2.179e-04
[66,   200] loss: 2.179e-04
Training loss: 0.000, train NMSE: -6.595e+00
Validation loss: 0.000, valid_NMSE: -6.139e+00
--------------------------------------------------
[INFO]: Epoch 67 of 200
Training
[67,   100] loss: 2.208e-04
[67,   200] loss: 2.174e-04
Validation
[67,   100] loss: 2.183e-04
[67,   200] loss: 2.183e-04
Training loss: 0.000, train NMSE: -5.995e+00
Validation loss: 0.000, valid_NMSE: -6.093e+00
--------------------------------------------------
[INFO]: Epoch 68 of 200
Training
[68,   100] loss: 2.176e-04
[68,   200] loss: 2.184e-04
Validation
[68,   100] loss: 2.172e-04
[68,   200] loss: 2.172e-04
Training loss: 0.000, train NMSE: -6.929e+00
Validation loss: 0.000, valid_NMSE: -6.163e+00
--------------------------------------------------
[INFO]: Epoch 69 of 200
Training
[69,   100] loss: 2.193e-04
[69,   200] loss: 2.156e-04
Validation
[69,   100] loss: 2.179e-04
[69,   200] loss: 2.179e-04
Training loss: 0.000, train NMSE: -6.171e+00
Validation loss: 0.000, valid_NMSE: -6.113e+00
--------------------------------------------------
[INFO]: Epoch 70 of 200
Training
[70,   100] loss: 2.158e-04
[70,   200] loss: 2.173e-04
Validation
[70,   100] loss: 2.151e-04
[70,   200] loss: 2.151e-04
Training loss: 0.000, train NMSE: -6.182e+00
Validation loss: 0.000, valid_NMSE: -6.185e+00

Best validation loss: -6.185334205627441

Saving best model for epoch: 70

--------------------------------------------------
[INFO]: Epoch 71 of 200
Training
[71,   100] loss: 2.169e-04
[71,   200] loss: 2.142e-04
Validation
[71,   100] loss: 2.155e-04
[71,   200] loss: 2.155e-04
Training loss: 0.000, train NMSE: -6.627e+00
Validation loss: 0.000, valid_NMSE: -6.150e+00
--------------------------------------------------
[INFO]: Epoch 72 of 200
Training
[72,   100] loss: 2.137e-04
[72,   200] loss: 2.159e-04
Validation
[72,   100] loss: 2.143e-04
[72,   200] loss: 2.143e-04
Training loss: 0.000, train NMSE: -6.741e+00
Validation loss: 0.000, valid_NMSE: -6.181e+00
--------------------------------------------------
[INFO]: Epoch 73 of 200
Training
[73,   100] loss: 2.135e-04
[73,   200] loss: 2.141e-04
Validation
[73,   100] loss: 2.138e-04
[73,   200] loss: 2.138e-04
Training loss: 0.000, train NMSE: -6.386e+00
Validation loss: 0.000, valid_NMSE: -6.183e+00
--------------------------------------------------
[INFO]: Epoch 74 of 200
Training
[74,   100] loss: 2.125e-04
[74,   200] loss: 2.130e-04
Validation
[74,   100] loss: 2.129e-04
[74,   200] loss: 2.129e-04
Training loss: 0.000, train NMSE: -6.851e+00
Validation loss: 0.000, valid_NMSE: -6.204e+00

Best validation loss: -6.2039899826049805

Saving best model for epoch: 74

--------------------------------------------------
[INFO]: Epoch 75 of 200
Training
[75,   100] loss: 2.128e-04
[75,   200] loss: 2.115e-04
Validation
[75,   100] loss: 2.128e-04
[75,   200] loss: 2.128e-04
Training loss: 0.000, train NMSE: -6.726e+00
Validation loss: 0.000, valid_NMSE: -6.224e+00

Best validation loss: -6.224405765533447

Saving best model for epoch: 75

--------------------------------------------------
[INFO]: Epoch 76 of 200
Training
[76,   100] loss: 2.099e-04
[76,   200] loss: 2.131e-04
Validation
[76,   100] loss: 2.114e-04
[76,   200] loss: 2.114e-04
Training loss: 0.000, train NMSE: -6.599e+00
Validation loss: 0.000, valid_NMSE: -6.253e+00

Best validation loss: -6.252742290496826

Saving best model for epoch: 76

--------------------------------------------------
[INFO]: Epoch 77 of 200
Training
[77,   100] loss: 2.089e-04
[77,   200] loss: 2.124e-04
Validation
[77,   100] loss: 2.107e-04
[77,   200] loss: 2.107e-04
Training loss: 0.000, train NMSE: -6.051e+00
Validation loss: 0.000, valid_NMSE: -6.294e+00

Best validation loss: -6.2944183349609375

Saving best model for epoch: 77

--------------------------------------------------
[INFO]: Epoch 78 of 200
Training
[78,   100] loss: 2.102e-04
[78,   200] loss: 2.097e-04
Validation
[78,   100] loss: 2.121e-04
[78,   200] loss: 2.121e-04
Training loss: 0.000, train NMSE: -6.676e+00
Validation loss: 0.000, valid_NMSE: -6.168e+00
--------------------------------------------------
[INFO]: Epoch 79 of 200
Training
[79,   100] loss: 2.088e-04
[79,   200] loss: 2.092e-04
Validation
[79,   100] loss: 2.109e-04
[79,   200] loss: 2.109e-04
Training loss: 0.000, train NMSE: -6.521e+00
Validation loss: 0.000, valid_NMSE: -6.269e+00
--------------------------------------------------
[INFO]: Epoch 80 of 200
Training
[80,   100] loss: 2.069e-04
[80,   200] loss: 2.099e-04
Validation
[80,   100] loss: 2.105e-04
[80,   200] loss: 2.105e-04
Training loss: 0.000, train NMSE: -7.120e+00
Validation loss: 0.000, valid_NMSE: -6.243e+00
--------------------------------------------------
[INFO]: Epoch 81 of 200
Training
[81,   100] loss: 2.067e-04
[81,   200] loss: 2.087e-04
Validation
[81,   100] loss: 2.100e-04
[81,   200] loss: 2.100e-04
Training loss: 0.000, train NMSE: -6.598e+00
Validation loss: 0.000, valid_NMSE: -6.237e+00
--------------------------------------------------
[INFO]: Epoch 82 of 200
Training
[82,   100] loss: 2.067e-04
[82,   200] loss: 2.067e-04
Validation
[82,   100] loss: 2.096e-04
[82,   200] loss: 2.096e-04
Training loss: 0.000, train NMSE: -6.447e+00
Validation loss: 0.000, valid_NMSE: -6.232e+00
--------------------------------------------------
[INFO]: Epoch 83 of 200
Training
[83,   100] loss: 2.065e-04
[83,   200] loss: 2.063e-04
Validation
[83,   100] loss: 2.099e-04
[83,   200] loss: 2.099e-04
Training loss: 0.000, train NMSE: -6.661e+00
Validation loss: 0.000, valid_NMSE: -6.234e+00
--------------------------------------------------
[INFO]: Epoch 84 of 200
Training
[84,   100] loss: 2.058e-04
[84,   200] loss: 2.053e-04
Validation
[84,   100] loss: 2.077e-04
[84,   200] loss: 2.077e-04
Training loss: 0.000, train NMSE: -6.978e+00
Validation loss: 0.000, valid_NMSE: -6.305e+00

Best validation loss: -6.305475234985352

Saving best model for epoch: 84

--------------------------------------------------
[INFO]: Epoch 85 of 200
Training
[85,   100] loss: 2.051e-04
[85,   200] loss: 2.054e-04
Validation
[85,   100] loss: 2.083e-04
[85,   200] loss: 2.083e-04
Training loss: 0.000, train NMSE: -7.115e+00
Validation loss: 0.000, valid_NMSE: -6.249e+00
--------------------------------------------------
[INFO]: Epoch 86 of 200
Training
[86,   100] loss: 2.031e-04
[86,   200] loss: 2.058e-04
Validation
[86,   100] loss: 2.065e-04
[86,   200] loss: 2.065e-04
Training loss: 0.000, train NMSE: -6.781e+00
Validation loss: 0.000, valid_NMSE: -6.346e+00

Best validation loss: -6.346301078796387

Saving best model for epoch: 86

--------------------------------------------------
[INFO]: Epoch 87 of 200
Training
[87,   100] loss: 2.048e-04
[87,   200] loss: 2.027e-04
Validation
[87,   100] loss: 2.072e-04
[87,   200] loss: 2.072e-04
Training loss: 0.000, train NMSE: -6.152e+00
Validation loss: 0.000, valid_NMSE: -6.280e+00
--------------------------------------------------
[INFO]: Epoch 88 of 200
Training
[88,   100] loss: 2.020e-04
[88,   200] loss: 2.051e-04
Validation
[88,   100] loss: 2.076e-04
[88,   200] loss: 2.076e-04
Training loss: 0.000, train NMSE: -5.830e+00
Validation loss: 0.000, valid_NMSE: -6.265e+00
--------------------------------------------------
[INFO]: Epoch 89 of 200
Training
[89,   100] loss: 2.006e-04
[89,   200] loss: 2.039e-04
Validation
[89,   100] loss: 2.064e-04
[89,   200] loss: 2.064e-04
Training loss: 0.000, train NMSE: -6.772e+00
Validation loss: 0.000, valid_NMSE: -6.295e+00
--------------------------------------------------
[INFO]: Epoch 90 of 200
Training
[90,   100] loss: 2.030e-04
[90,   200] loss: 2.015e-04
Validation
[90,   100] loss: 2.058e-04
[90,   200] loss: 2.058e-04
Training loss: 0.000, train NMSE: -6.544e+00
Validation loss: 0.000, valid_NMSE: -6.315e+00
--------------------------------------------------
[INFO]: Epoch 91 of 200
Training
[91,   100] loss: 2.003e-04
[91,   200] loss: 2.026e-04
Validation
[91,   100] loss: 2.058e-04
[91,   200] loss: 2.058e-04
Training loss: 0.000, train NMSE: -6.054e+00
Validation loss: 0.000, valid_NMSE: -6.340e+00
--------------------------------------------------
[INFO]: Epoch 92 of 200
Training
[92,   100] loss: 2.000e-04
[92,   200] loss: 2.014e-04
Validation
[92,   100] loss: 2.046e-04
[92,   200] loss: 2.046e-04
Training loss: 0.000, train NMSE: -7.711e+00
Validation loss: 0.000, valid_NMSE: -6.335e+00
--------------------------------------------------
[INFO]: Epoch 93 of 200
Training
[93,   100] loss: 1.970e-04
[93,   200] loss: 2.034e-04
Validation
[93,   100] loss: 2.047e-04
[93,   200] loss: 2.047e-04
Training loss: 0.000, train NMSE: -6.916e+00
Validation loss: 0.000, valid_NMSE: -6.322e+00
--------------------------------------------------
[INFO]: Epoch 94 of 200
Training
[94,   100] loss: 2.000e-04
[94,   200] loss: 1.996e-04
Validation
[94,   100] loss: 2.043e-04
[94,   200] loss: 2.043e-04
Training loss: 0.000, train NMSE: -6.913e+00
Validation loss: 0.000, valid_NMSE: -6.343e+00
--------------------------------------------------
[INFO]: Epoch 95 of 200
Training
[95,   100] loss: 1.990e-04
[95,   200] loss: 1.996e-04
Validation
[95,   100] loss: 2.034e-04
[95,   200] loss: 2.034e-04
Training loss: 0.000, train NMSE: -7.186e+00
Validation loss: 0.000, valid_NMSE: -6.370e+00

Best validation loss: -6.369831562042236

Saving best model for epoch: 95

--------------------------------------------------
[INFO]: Epoch 96 of 200
Training
[96,   100] loss: 2.004e-04
[96,   200] loss: 1.966e-04
Validation
[96,   100] loss: 2.045e-04
[96,   200] loss: 2.045e-04
Training loss: 0.000, train NMSE: -6.634e+00
Validation loss: 0.000, valid_NMSE: -6.295e+00
--------------------------------------------------
[INFO]: Epoch 97 of 200
Training
[97,   100] loss: 1.978e-04
[97,   200] loss: 1.979e-04
Validation
[97,   100] loss: 2.046e-04
[97,   200] loss: 2.046e-04
Training loss: 0.000, train NMSE: -6.560e+00
Validation loss: 0.000, valid_NMSE: -6.287e+00
--------------------------------------------------
[INFO]: Epoch 98 of 200
Training
[98,   100] loss: 1.973e-04
[98,   200] loss: 1.974e-04
Validation
[98,   100] loss: 2.037e-04
[98,   200] loss: 2.037e-04
Training loss: 0.000, train NMSE: -6.436e+00
Validation loss: 0.000, valid_NMSE: -6.360e+00
--------------------------------------------------
[INFO]: Epoch 99 of 200
Training
[99,   100] loss: 1.993e-04
[99,   200] loss: 1.953e-04
Validation
[99,   100] loss: 2.031e-04
[99,   200] loss: 2.031e-04
Training loss: 0.000, train NMSE: -6.657e+00
Validation loss: 0.000, valid_NMSE: -6.347e+00
--------------------------------------------------
[INFO]: Epoch 100 of 200
Training
[100,   100] loss: 1.944e-04
[100,   200] loss: 1.979e-04
Validation
[100,   100] loss: 2.013e-04
[100,   200] loss: 2.013e-04
Training loss: 0.000, train NMSE: -6.868e+00
Validation loss: 0.000, valid_NMSE: -6.412e+00

Best validation loss: -6.412321090698242

Saving best model for epoch: 100

--------------------------------------------------
[INFO]: Epoch 101 of 200
Training
[101,   100] loss: 1.954e-04
[101,   200] loss: 1.960e-04
Validation
[101,   100] loss: 2.021e-04
[101,   200] loss: 2.021e-04
Training loss: 0.000, train NMSE: -7.344e+00
Validation loss: 0.000, valid_NMSE: -6.341e+00
--------------------------------------------------
[INFO]: Epoch 102 of 200
Training
[102,   100] loss: 1.963e-04
[102,   200] loss: 1.943e-04
Validation
[102,   100] loss: 2.008e-04
[102,   200] loss: 2.008e-04
Training loss: 0.000, train NMSE: -6.732e+00
Validation loss: 0.000, valid_NMSE: -6.414e+00

Best validation loss: -6.414090156555176

Saving best model for epoch: 102

--------------------------------------------------
[INFO]: Epoch 103 of 200
Training
[103,   100] loss: 1.949e-04
[103,   200] loss: 1.953e-04
Validation
[103,   100] loss: 2.019e-04
[103,   200] loss: 2.019e-04
Training loss: 0.000, train NMSE: -7.200e+00
Validation loss: 0.000, valid_NMSE: -6.363e+00
--------------------------------------------------
[INFO]: Epoch 104 of 200
Training
[104,   100] loss: 1.926e-04
[104,   200] loss: 1.964e-04
Validation
[104,   100] loss: 2.022e-04
[104,   200] loss: 2.022e-04
Training loss: 0.000, train NMSE: -6.404e+00
Validation loss: 0.000, valid_NMSE: -6.337e+00
--------------------------------------------------
[INFO]: Epoch 105 of 200
Training
[105,   100] loss: 1.941e-04
[105,   200] loss: 1.936e-04
Validation
[105,   100] loss: 2.012e-04
[105,   200] loss: 2.012e-04
Training loss: 0.000, train NMSE: -6.513e+00
Validation loss: 0.000, valid_NMSE: -6.347e+00
--------------------------------------------------
[INFO]: Epoch 106 of 200
Training
[106,   100] loss: 1.953e-04
[106,   200] loss: 1.915e-04
Validation
[106,   100] loss: 2.003e-04
[106,   200] loss: 2.003e-04
Training loss: 0.000, train NMSE: -7.103e+00
Validation loss: 0.000, valid_NMSE: -6.411e+00
--------------------------------------------------
[INFO]: Epoch 107 of 200
Training
[107,   100] loss: 1.906e-04
[107,   200] loss: 1.951e-04
Validation
[107,   100] loss: 2.005e-04
[107,   200] loss: 2.005e-04
Training loss: 0.000, train NMSE: -7.036e+00
Validation loss: 0.000, valid_NMSE: -6.393e+00
--------------------------------------------------
[INFO]: Epoch 108 of 200
Training
[108,   100] loss: 1.932e-04
[108,   200] loss: 1.915e-04
Validation
[108,   100] loss: 2.003e-04
[108,   200] loss: 2.003e-04
Training loss: 0.000, train NMSE: -6.861e+00
Validation loss: 0.000, valid_NMSE: -6.344e+00
--------------------------------------------------
[INFO]: Epoch 109 of 200
Training
[109,   100] loss: 1.917e-04
[109,   200] loss: 1.927e-04
Validation
[109,   100] loss: 1.996e-04
[109,   200] loss: 1.996e-04
Training loss: 0.000, train NMSE: -6.219e+00
Validation loss: 0.000, valid_NMSE: -6.365e+00
--------------------------------------------------
[INFO]: Epoch 110 of 200
Training
[110,   100] loss: 1.911e-04
[110,   200] loss: 1.924e-04
Validation
[110,   100] loss: 1.995e-04
[110,   200] loss: 1.995e-04
Training loss: 0.000, train NMSE: -7.014e+00
Validation loss: 0.000, valid_NMSE: -6.420e+00

Best validation loss: -6.420126914978027

Saving best model for epoch: 110

--------------------------------------------------
[INFO]: Epoch 111 of 200
Training
[111,   100] loss: 1.900e-04
[111,   200] loss: 1.921e-04
Validation
[111,   100] loss: 1.993e-04
[111,   200] loss: 1.993e-04
Training loss: 0.000, train NMSE: -7.235e+00
Validation loss: 0.000, valid_NMSE: -6.404e+00
--------------------------------------------------
[INFO]: Epoch 112 of 200
Training
[112,   100] loss: 1.903e-04
[112,   200] loss: 1.915e-04
Validation
[112,   100] loss: 2.003e-04
[112,   200] loss: 2.003e-04
Training loss: 0.000, train NMSE: -6.617e+00
Validation loss: 0.000, valid_NMSE: -6.309e+00
--------------------------------------------------
[INFO]: Epoch 113 of 200
Training
[113,   100] loss: 1.891e-04
[113,   200] loss: 1.924e-04
Validation
[113,   100] loss: 1.981e-04
[113,   200] loss: 1.981e-04
Training loss: 0.000, train NMSE: -6.968e+00
Validation loss: 0.000, valid_NMSE: -6.426e+00

Best validation loss: -6.426266670227051

Saving best model for epoch: 113

--------------------------------------------------
[INFO]: Epoch 114 of 200
Training
[114,   100] loss: 1.912e-04
[114,   200] loss: 1.885e-04
Validation
[114,   100] loss: 1.984e-04
[114,   200] loss: 1.984e-04
Training loss: 0.000, train NMSE: -7.378e+00
Validation loss: 0.000, valid_NMSE: -6.382e+00
--------------------------------------------------
[INFO]: Epoch 115 of 200
Training
[115,   100] loss: 1.893e-04
[115,   200] loss: 1.894e-04
Validation
[115,   100] loss: 1.981e-04
[115,   200] loss: 1.981e-04
Training loss: 0.000, train NMSE: -7.411e+00
Validation loss: 0.000, valid_NMSE: -6.393e+00
--------------------------------------------------
[INFO]: Epoch 116 of 200
Training
[116,   100] loss: 1.889e-04
[116,   200] loss: 1.892e-04
Validation
[116,   100] loss: 1.978e-04
[116,   200] loss: 1.978e-04
Training loss: 0.000, train NMSE: -6.994e+00
Validation loss: 0.000, valid_NMSE: -6.426e+00

Best validation loss: -6.426342964172363

Saving best model for epoch: 116

--------------------------------------------------
[INFO]: Epoch 117 of 200
Training
[117,   100] loss: 1.874e-04
[117,   200] loss: 1.903e-04
Validation
[117,   100] loss: 1.979e-04
[117,   200] loss: 1.979e-04
Training loss: 0.000, train NMSE: -6.948e+00
Validation loss: 0.000, valid_NMSE: -6.415e+00
--------------------------------------------------
[INFO]: Epoch 118 of 200
Training
[118,   100] loss: 1.879e-04
[118,   200] loss: 1.887e-04
Validation
[118,   100] loss: 1.982e-04
[118,   200] loss: 1.982e-04
Training loss: 0.000, train NMSE: -6.996e+00
Validation loss: 0.000, valid_NMSE: -6.371e+00
--------------------------------------------------
[INFO]: Epoch 119 of 200
Training
[119,   100] loss: 1.879e-04
[119,   200] loss: 1.873e-04
Validation
[119,   100] loss: 1.966e-04
[119,   200] loss: 1.966e-04
Training loss: 0.000, train NMSE: -7.252e+00
Validation loss: 0.000, valid_NMSE: -6.471e+00

Best validation loss: -6.471017837524414

Saving best model for epoch: 119

--------------------------------------------------
[INFO]: Epoch 120 of 200
Training
[120,   100] loss: 1.865e-04
[120,   200] loss: 1.884e-04
Validation
[120,   100] loss: 1.967e-04
[120,   200] loss: 1.967e-04
Training loss: 0.000, train NMSE: -7.077e+00
Validation loss: 0.000, valid_NMSE: -6.466e+00
--------------------------------------------------
[INFO]: Epoch 121 of 200
Training
[121,   100] loss: 1.867e-04
[121,   200] loss: 1.876e-04
Validation
[121,   100] loss: 1.972e-04
[121,   200] loss: 1.972e-04
Training loss: 0.000, train NMSE: -6.896e+00
Validation loss: 0.000, valid_NMSE: -6.440e+00
--------------------------------------------------
[INFO]: Epoch 122 of 200
Training
[122,   100] loss: 1.854e-04
[122,   200] loss: 1.882e-04
Validation
[122,   100] loss: 1.964e-04
[122,   200] loss: 1.964e-04
Training loss: 0.000, train NMSE: -6.938e+00
Validation loss: 0.000, valid_NMSE: -6.432e+00
--------------------------------------------------
[INFO]: Epoch 123 of 200
Training
[123,   100] loss: 1.851e-04
[123,   200] loss: 1.874e-04
Validation
[123,   100] loss: 1.953e-04
[123,   200] loss: 1.953e-04
Training loss: 0.000, train NMSE: -7.103e+00
Validation loss: 0.000, valid_NMSE: -6.474e+00

Best validation loss: -6.474328517913818

Saving best model for epoch: 123

--------------------------------------------------
[INFO]: Epoch 124 of 200
Training
[124,   100] loss: 1.866e-04
[124,   200] loss: 1.858e-04
Validation
[124,   100] loss: 1.977e-04
[124,   200] loss: 1.977e-04
Training loss: 0.000, train NMSE: -7.132e+00
Validation loss: 0.000, valid_NMSE: -6.349e+00
--------------------------------------------------
[INFO]: Epoch 125 of 200
Training
[125,   100] loss: 1.846e-04
[125,   200] loss: 1.863e-04
Validation
[125,   100] loss: 1.954e-04
[125,   200] loss: 1.954e-04
Training loss: 0.000, train NMSE: -7.152e+00
Validation loss: 0.000, valid_NMSE: -6.426e+00
--------------------------------------------------
[INFO]: Epoch 126 of 200
Training
[126,   100] loss: 1.849e-04
[126,   200] loss: 1.852e-04
Validation
[126,   100] loss: 1.944e-04
[126,   200] loss: 1.944e-04
Training loss: 0.000, train NMSE: -7.082e+00
Validation loss: 0.000, valid_NMSE: -6.503e+00

Best validation loss: -6.502780437469482

Saving best model for epoch: 126

--------------------------------------------------
[INFO]: Epoch 127 of 200
Training
[127,   100] loss: 1.861e-04
[127,   200] loss: 1.837e-04
Validation
[127,   100] loss: 1.945e-04
[127,   200] loss: 1.945e-04
Training loss: 0.000, train NMSE: -7.663e+00
Validation loss: 0.000, valid_NMSE: -6.474e+00
--------------------------------------------------
[INFO]: Epoch 128 of 200
Training
[128,   100] loss: 1.850e-04
[128,   200] loss: 1.843e-04
Validation
[128,   100] loss: 1.957e-04
[128,   200] loss: 1.957e-04
Training loss: 0.000, train NMSE: -6.568e+00
Validation loss: 0.000, valid_NMSE: -6.449e+00
--------------------------------------------------
[INFO]: Epoch 129 of 200
Training
[129,   100] loss: 1.832e-04
[129,   200] loss: 1.849e-04
Validation
[129,   100] loss: 1.959e-04
[129,   200] loss: 1.959e-04
Training loss: 0.000, train NMSE: -6.731e+00
Validation loss: 0.000, valid_NMSE: -6.397e+00
--------------------------------------------------
[INFO]: Epoch 130 of 200
Training
[130,   100] loss: 1.849e-04
[130,   200] loss: 1.831e-04
Validation
[130,   100] loss: 1.942e-04
[130,   200] loss: 1.942e-04
Training loss: 0.000, train NMSE: -7.276e+00
Validation loss: 0.000, valid_NMSE: -6.480e+00
--------------------------------------------------
[INFO]: Epoch 131 of 200
Training
[131,   100] loss: 1.830e-04
[131,   200] loss: 1.836e-04
Validation
[131,   100] loss: 1.956e-04
[131,   200] loss: 1.956e-04
Training loss: 0.000, train NMSE: -6.770e+00
Validation loss: 0.000, valid_NMSE: -6.416e+00
--------------------------------------------------
[INFO]: Epoch 132 of 200
Training
[132,   100] loss: 1.822e-04
[132,   200] loss: 1.846e-04
Validation
[132,   100] loss: 1.950e-04
[132,   200] loss: 1.950e-04
Training loss: 0.000, train NMSE: -7.067e+00
Validation loss: 0.000, valid_NMSE: -6.466e+00
--------------------------------------------------
[INFO]: Epoch 133 of 200
Training
[133,   100] loss: 1.821e-04
[133,   200] loss: 1.830e-04
Validation
[133,   100] loss: 1.943e-04
[133,   200] loss: 1.943e-04
Training loss: 0.000, train NMSE: -7.344e+00
Validation loss: 0.000, valid_NMSE: -6.486e+00
--------------------------------------------------
[INFO]: Epoch 134 of 200
Training
[134,   100] loss: 1.824e-04
[134,   200] loss: 1.825e-04
Validation
[134,   100] loss: 1.951e-04
[134,   200] loss: 1.951e-04
Training loss: 0.000, train NMSE: -6.932e+00
Validation loss: 0.000, valid_NMSE: -6.443e+00
--------------------------------------------------
[INFO]: Epoch 135 of 200
Training
[135,   100] loss: 1.801e-04
[135,   200] loss: 1.837e-04
Validation
[135,   100] loss: 1.930e-04
[135,   200] loss: 1.930e-04
Training loss: 0.000, train NMSE: -7.004e+00
Validation loss: 0.000, valid_NMSE: -6.477e+00
--------------------------------------------------
[INFO]: Epoch 136 of 200
Training
[136,   100] loss: 1.819e-04
[136,   200] loss: 1.821e-04
Validation
[136,   100] loss: 1.925e-04
[136,   200] loss: 1.925e-04
Training loss: 0.000, train NMSE: -7.134e+00
Validation loss: 0.000, valid_NMSE: -6.521e+00

Best validation loss: -6.521372318267822

Saving best model for epoch: 136

--------------------------------------------------
[INFO]: Epoch 137 of 200
Training
[137,   100] loss: 1.801e-04
[137,   200] loss: 1.826e-04
Validation
[137,   100] loss: 1.928e-04
[137,   200] loss: 1.928e-04
Training loss: 0.000, train NMSE: -7.439e+00
Validation loss: 0.000, valid_NMSE: -6.530e+00

Best validation loss: -6.529819488525391

Saving best model for epoch: 137

--------------------------------------------------
[INFO]: Epoch 138 of 200
Training
[138,   100] loss: 1.811e-04
[138,   200] loss: 1.809e-04
Validation
[138,   100] loss: 1.928e-04
[138,   200] loss: 1.928e-04
Training loss: 0.000, train NMSE: -6.831e+00
Validation loss: 0.000, valid_NMSE: -6.536e+00

Best validation loss: -6.536104202270508

Saving best model for epoch: 138

--------------------------------------------------
[INFO]: Epoch 139 of 200
Training
[139,   100] loss: 1.810e-04
[139,   200] loss: 1.807e-04
Validation
[139,   100] loss: 1.952e-04
[139,   200] loss: 1.952e-04
Training loss: 0.000, train NMSE: -6.840e+00
Validation loss: 0.000, valid_NMSE: -6.414e+00
--------------------------------------------------
[INFO]: Epoch 140 of 200
Training
[140,   100] loss: 1.813e-04
[140,   200] loss: 1.794e-04
Validation
[140,   100] loss: 1.919e-04
[140,   200] loss: 1.919e-04
Training loss: 0.000, train NMSE: -7.270e+00
Validation loss: 0.000, valid_NMSE: -6.504e+00
--------------------------------------------------
[INFO]: Epoch 141 of 200
Training
[141,   100] loss: 1.796e-04
[141,   200] loss: 1.804e-04
Validation
[141,   100] loss: 1.926e-04
[141,   200] loss: 1.926e-04
Training loss: 0.000, train NMSE: -6.856e+00
Validation loss: 0.000, valid_NMSE: -6.496e+00
--------------------------------------------------
[INFO]: Epoch 142 of 200
Training
[142,   100] loss: 1.787e-04
[142,   200] loss: 1.807e-04
Validation
[142,   100] loss: 1.929e-04
[142,   200] loss: 1.929e-04
Training loss: 0.000, train NMSE: -7.106e+00
Validation loss: 0.000, valid_NMSE: -6.531e+00
--------------------------------------------------
[INFO]: Epoch 143 of 200
Training
[143,   100] loss: 1.793e-04
[143,   200] loss: 1.797e-04
Validation
[143,   100] loss: 1.923e-04
[143,   200] loss: 1.923e-04
Training loss: 0.000, train NMSE: -7.248e+00
Validation loss: 0.000, valid_NMSE: -6.501e+00
--------------------------------------------------
[INFO]: Epoch 144 of 200
Training
[144,   100] loss: 1.768e-04
[144,   200] loss: 1.816e-04
Validation
[144,   100] loss: 1.916e-04
[144,   200] loss: 1.916e-04
Training loss: 0.000, train NMSE: -7.392e+00
Validation loss: 0.000, valid_NMSE: -6.520e+00
--------------------------------------------------
[INFO]: Epoch 145 of 200
Training
[145,   100] loss: 1.784e-04
[145,   200] loss: 1.794e-04
Validation
[145,   100] loss: 1.932e-04
[145,   200] loss: 1.932e-04
Training loss: 0.000, train NMSE: -7.184e+00
Validation loss: 0.000, valid_NMSE: -6.485e+00
--------------------------------------------------
[INFO]: Epoch 146 of 200
Training
[146,   100] loss: 1.794e-04
[146,   200] loss: 1.775e-04
Validation
[146,   100] loss: 1.934e-04
[146,   200] loss: 1.934e-04
Training loss: 0.000, train NMSE: -6.737e+00
Validation loss: 0.000, valid_NMSE: -6.475e+00
--------------------------------------------------
[INFO]: Epoch 147 of 200
Training
[147,   100] loss: 1.767e-04
[147,   200] loss: 1.795e-04
Validation
[147,   100] loss: 1.924e-04
[147,   200] loss: 1.924e-04
Training loss: 0.000, train NMSE: -7.057e+00
Validation loss: 0.000, valid_NMSE: -6.477e+00
--------------------------------------------------
[INFO]: Epoch 148 of 200
Training
[148,   100] loss: 1.766e-04
[148,   200] loss: 1.790e-04
Validation
[148,   100] loss: 1.909e-04
[148,   200] loss: 1.909e-04
Training loss: 0.000, train NMSE: -6.764e+00
Validation loss: 0.000, valid_NMSE: -6.528e+00
--------------------------------------------------
[INFO]: Epoch 149 of 200
Training
[149,   100] loss: 1.782e-04
[149,   200] loss: 1.773e-04
Validation
[149,   100] loss: 1.925e-04
[149,   200] loss: 1.925e-04
Training loss: 0.000, train NMSE: -6.891e+00
Validation loss: 0.000, valid_NMSE: -6.442e+00
--------------------------------------------------
[INFO]: Epoch 150 of 200
Training
[150,   100] loss: 1.774e-04
[150,   200] loss: 1.774e-04
Validation
[150,   100] loss: 1.943e-04
[150,   200] loss: 1.943e-04
Training loss: 0.000, train NMSE: -7.275e+00
Validation loss: 0.000, valid_NMSE: -6.477e+00
--------------------------------------------------
[INFO]: Epoch 151 of 200
Training
[151,   100] loss: 1.766e-04
[151,   200] loss: 1.773e-04
Validation
[151,   100] loss: 1.914e-04
[151,   200] loss: 1.914e-04
Training loss: 0.000, train NMSE: -7.309e+00
Validation loss: 0.000, valid_NMSE: -6.493e+00
--------------------------------------------------
[INFO]: Epoch 152 of 200
Training
[152,   100] loss: 1.766e-04
[152,   200] loss: 1.773e-04
Validation
[152,   100] loss: 1.931e-04
[152,   200] loss: 1.931e-04
Training loss: 0.000, train NMSE: -7.026e+00
Validation loss: 0.000, valid_NMSE: -6.423e+00
--------------------------------------------------
[INFO]: Epoch 153 of 200
Training
[153,   100] loss: 1.743e-04
[153,   200] loss: 1.787e-04
Validation
[153,   100] loss: 1.922e-04
[153,   200] loss: 1.922e-04
Training loss: 0.000, train NMSE: -7.436e+00
Validation loss: 0.000, valid_NMSE: -6.551e+00

Best validation loss: -6.550776958465576

Saving best model for epoch: 153

--------------------------------------------------
[INFO]: Epoch 154 of 200
Training
[154,   100] loss: 1.755e-04
[154,   200] loss: 1.771e-04
Validation
[154,   100] loss: 1.905e-04
[154,   200] loss: 1.905e-04
Training loss: 0.000, train NMSE: -7.400e+00
Validation loss: 0.000, valid_NMSE: -6.499e+00
--------------------------------------------------
[INFO]: Epoch 155 of 200
Training
[155,   100] loss: 1.762e-04
[155,   200] loss: 1.751e-04
Validation
[155,   100] loss: 1.902e-04
[155,   200] loss: 1.902e-04
Training loss: 0.000, train NMSE: -7.328e+00
Validation loss: 0.000, valid_NMSE: -6.538e+00
--------------------------------------------------
[INFO]: Epoch 156 of 200
Training
[156,   100] loss: 1.740e-04
[156,   200] loss: 1.768e-04
Validation
[156,   100] loss: 1.896e-04
[156,   200] loss: 1.896e-04
Training loss: 0.000, train NMSE: -7.335e+00
Validation loss: 0.000, valid_NMSE: -6.538e+00
--------------------------------------------------
[INFO]: Epoch 157 of 200
Training
[157,   100] loss: 1.750e-04
[157,   200] loss: 1.759e-04
Validation
[157,   100] loss: 1.901e-04
[157,   200] loss: 1.901e-04
Training loss: 0.000, train NMSE: -7.195e+00
Validation loss: 0.000, valid_NMSE: -6.549e+00
--------------------------------------------------
[INFO]: Epoch 158 of 200
Training
[158,   100] loss: 1.737e-04
[158,   200] loss: 1.764e-04
Validation
[158,   100] loss: 1.901e-04
[158,   200] loss: 1.901e-04
Training loss: 0.000, train NMSE: -7.442e+00
Validation loss: 0.000, valid_NMSE: -6.520e+00
--------------------------------------------------
[INFO]: Epoch 159 of 200
Training
[159,   100] loss: 1.733e-04
[159,   200] loss: 1.760e-04
Validation
[159,   100] loss: 1.906e-04
[159,   200] loss: 1.906e-04
Training loss: 0.000, train NMSE: -7.814e+00
Validation loss: 0.000, valid_NMSE: -6.505e+00
--------------------------------------------------
[INFO]: Epoch 160 of 200
Training
[160,   100] loss: 1.739e-04
[160,   200] loss: 1.755e-04
Validation
[160,   100] loss: 1.887e-04
[160,   200] loss: 1.887e-04
Training loss: 0.000, train NMSE: -7.235e+00
Validation loss: 0.000, valid_NMSE: -6.579e+00

Best validation loss: -6.579070568084717

Saving best model for epoch: 160

--------------------------------------------------
[INFO]: Epoch 161 of 200
Training
[161,   100] loss: 1.745e-04
[161,   200] loss: 1.738e-04
Validation
[161,   100] loss: 1.905e-04
[161,   200] loss: 1.905e-04
Training loss: 0.000, train NMSE: -7.379e+00
Validation loss: 0.000, valid_NMSE: -6.511e+00
--------------------------------------------------
[INFO]: Epoch 162 of 200
Training
[162,   100] loss: 1.739e-04
[162,   200] loss: 1.741e-04
Validation
[162,   100] loss: 1.897e-04
[162,   200] loss: 1.897e-04
Training loss: 0.000, train NMSE: -8.037e+00
Validation loss: 0.000, valid_NMSE: -6.526e+00
--------------------------------------------------
[INFO]: Epoch 163 of 200
Training
[163,   100] loss: 1.751e-04
[163,   200] loss: 1.723e-04
Validation
[163,   100] loss: 1.886e-04
[163,   200] loss: 1.886e-04
Training loss: 0.000, train NMSE: -7.128e+00
Validation loss: 0.000, valid_NMSE: -6.593e+00

Best validation loss: -6.592650413513184

Saving best model for epoch: 163

--------------------------------------------------
[INFO]: Epoch 164 of 200
Training
[164,   100] loss: 1.726e-04
[164,   200] loss: 1.740e-04
Validation
[164,   100] loss: 1.891e-04
[164,   200] loss: 1.891e-04
Training loss: 0.000, train NMSE: -7.680e+00
Validation loss: 0.000, valid_NMSE: -6.568e+00
--------------------------------------------------
[INFO]: Epoch 165 of 200
Training
[165,   100] loss: 1.749e-04
[165,   200] loss: 1.714e-04
Validation
[165,   100] loss: 1.881e-04
[165,   200] loss: 1.881e-04
Training loss: 0.000, train NMSE: -6.799e+00
Validation loss: 0.000, valid_NMSE: -6.598e+00

Best validation loss: -6.598381996154785

Saving best model for epoch: 165

--------------------------------------------------
[INFO]: Epoch 166 of 200
Training
[166,   100] loss: 1.734e-04
[166,   200] loss: 1.728e-04
Validation
[166,   100] loss: 1.898e-04
[166,   200] loss: 1.898e-04
Training loss: 0.000, train NMSE: -6.690e+00
Validation loss: 0.000, valid_NMSE: -6.534e+00
--------------------------------------------------
[INFO]: Epoch 167 of 200
Training
[167,   100] loss: 1.715e-04
[167,   200] loss: 1.740e-04
Validation
[167,   100] loss: 1.886e-04
[167,   200] loss: 1.886e-04
Training loss: 0.000, train NMSE: -7.029e+00
Validation loss: 0.000, valid_NMSE: -6.579e+00
--------------------------------------------------
[INFO]: Epoch 168 of 200
Training
[168,   100] loss: 1.708e-04
[168,   200] loss: 1.740e-04
Validation
[168,   100] loss: 1.879e-04
[168,   200] loss: 1.879e-04
Training loss: 0.000, train NMSE: -7.551e+00
Validation loss: 0.000, valid_NMSE: -6.623e+00

Best validation loss: -6.622857093811035

Saving best model for epoch: 168

--------------------------------------------------
[INFO]: Epoch 169 of 200
Training
[169,   100] loss: 1.711e-04
[169,   200] loss: 1.731e-04
Validation
[169,   100] loss: 1.874e-04
[169,   200] loss: 1.874e-04
Training loss: 0.000, train NMSE: -8.060e+00
Validation loss: 0.000, valid_NMSE: -6.613e+00
--------------------------------------------------
[INFO]: Epoch 170 of 200
Training
[170,   100] loss: 1.737e-04
[170,   200] loss: 1.698e-04
Validation
[170,   100] loss: 1.880e-04
[170,   200] loss: 1.880e-04
Training loss: 0.000, train NMSE: -6.881e+00
Validation loss: 0.000, valid_NMSE: -6.621e+00
--------------------------------------------------
[INFO]: Epoch 171 of 200
Training
[171,   100] loss: 1.717e-04
[171,   200] loss: 1.715e-04
Validation
[171,   100] loss: 1.872e-04
[171,   200] loss: 1.872e-04
Training loss: 0.000, train NMSE: -7.489e+00
Validation loss: 0.000, valid_NMSE: -6.605e+00
--------------------------------------------------
[INFO]: Epoch 172 of 200
Training
[172,   100] loss: 1.704e-04
[172,   200] loss: 1.719e-04
Validation
[172,   100] loss: 1.883e-04
[172,   200] loss: 1.883e-04
Training loss: 0.000, train NMSE: -7.622e+00
Validation loss: 0.000, valid_NMSE: -6.580e+00
--------------------------------------------------
[INFO]: Epoch 173 of 200
Training
[173,   100] loss: 1.727e-04
[173,   200] loss: 1.690e-04
Validation
[173,   100] loss: 1.873e-04
[173,   200] loss: 1.873e-04
Training loss: 0.000, train NMSE: -7.839e+00
Validation loss: 0.000, valid_NMSE: -6.634e+00

Best validation loss: -6.633716106414795

Saving best model for epoch: 173

--------------------------------------------------
[INFO]: Epoch 174 of 200
Training
[174,   100] loss: 1.691e-04
[174,   200] loss: 1.728e-04
Validation
[174,   100] loss: 1.902e-04
[174,   200] loss: 1.902e-04
Training loss: 0.000, train NMSE: -7.093e+00
Validation loss: 0.000, valid_NMSE: -6.532e+00
--------------------------------------------------
[INFO]: Epoch 175 of 200
Training
[175,   100] loss: 1.709e-04
[175,   200] loss: 1.703e-04
Validation
[175,   100] loss: 1.897e-04
[175,   200] loss: 1.897e-04
Training loss: 0.000, train NMSE: -7.532e+00
Validation loss: 0.000, valid_NMSE: -6.476e+00
--------------------------------------------------
[INFO]: Epoch 176 of 200
Training
[176,   100] loss: 1.695e-04
[176,   200] loss: 1.713e-04
Validation
[176,   100] loss: 1.866e-04
[176,   200] loss: 1.866e-04
Training loss: 0.000, train NMSE: -7.509e+00
Validation loss: 0.000, valid_NMSE: -6.641e+00

Best validation loss: -6.641231060028076

Saving best model for epoch: 176

--------------------------------------------------
[INFO]: Epoch 177 of 200
Training
[177,   100] loss: 1.702e-04
[177,   200] loss: 1.697e-04
Validation
[177,   100] loss: 1.876e-04
[177,   200] loss: 1.876e-04
Training loss: 0.000, train NMSE: -7.371e+00
Validation loss: 0.000, valid_NMSE: -6.608e+00
--------------------------------------------------
[INFO]: Epoch 178 of 200
Training
[178,   100] loss: 1.683e-04
[178,   200] loss: 1.714e-04
Validation
[178,   100] loss: 1.885e-04
[178,   200] loss: 1.885e-04
Training loss: 0.000, train NMSE: -7.236e+00
Validation loss: 0.000, valid_NMSE: -6.557e+00
--------------------------------------------------
[INFO]: Epoch 179 of 200
Training
[179,   100] loss: 1.668e-04
[179,   200] loss: 1.725e-04
Validation
[179,   100] loss: 1.870e-04
[179,   200] loss: 1.870e-04
Training loss: 0.000, train NMSE: -7.726e+00
Validation loss: 0.000, valid_NMSE: -6.630e+00
--------------------------------------------------
[INFO]: Epoch 180 of 200
Training
[180,   100] loss: 1.684e-04
[180,   200] loss: 1.705e-04
Validation
[180,   100] loss: 1.889e-04
[180,   200] loss: 1.889e-04
Training loss: 0.000, train NMSE: -7.615e+00
Validation loss: 0.000, valid_NMSE: -6.506e+00
--------------------------------------------------
[INFO]: Epoch 181 of 200
Training
[181,   100] loss: 1.684e-04
[181,   200] loss: 1.700e-04
Validation
[181,   100] loss: 1.877e-04
[181,   200] loss: 1.877e-04
Training loss: 0.000, train NMSE: -7.724e+00
Validation loss: 0.000, valid_NMSE: -6.569e+00
--------------------------------------------------
[INFO]: Epoch 182 of 200
Training
[182,   100] loss: 1.662e-04
[182,   200] loss: 1.712e-04
Validation
[182,   100] loss: 1.881e-04
[182,   200] loss: 1.881e-04
Training loss: 0.000, train NMSE: -7.836e+00
Validation loss: 0.000, valid_NMSE: -6.550e+00
--------------------------------------------------
[INFO]: Epoch 183 of 200
Training
[183,   100] loss: 1.688e-04
[183,   200] loss: 1.686e-04
Validation
[183,   100] loss: 1.891e-04
[183,   200] loss: 1.891e-04
Training loss: 0.000, train NMSE: -7.564e+00
Validation loss: 0.000, valid_NMSE: -6.454e+00
--------------------------------------------------
[INFO]: Epoch 184 of 200
Training
[184,   100] loss: 1.697e-04
[184,   200] loss: 1.671e-04
Validation
[184,   100] loss: 1.871e-04
[184,   200] loss: 1.871e-04
Training loss: 0.000, train NMSE: -7.425e+00
Validation loss: 0.000, valid_NMSE: -6.539e+00
--------------------------------------------------
[INFO]: Epoch 185 of 200
Training
[185,   100] loss: 1.673e-04
[185,   200] loss: 1.694e-04
Validation
[185,   100] loss: 1.880e-04
[185,   200] loss: 1.880e-04
Training loss: 0.000, train NMSE: -7.231e+00
Validation loss: 0.000, valid_NMSE: -6.541e+00
--------------------------------------------------
[INFO]: Epoch 186 of 200
Training
[186,   100] loss: 1.681e-04
[186,   200] loss: 1.678e-04
Validation
[186,   100] loss: 1.861e-04
[186,   200] loss: 1.861e-04
Training loss: 0.000, train NMSE: -6.921e+00
Validation loss: 0.000, valid_NMSE: -6.601e+00
--------------------------------------------------
[INFO]: Epoch 187 of 200
Training
[187,   100] loss: 1.696e-04
[187,   200] loss: 1.659e-04
Validation
[187,   100] loss: 1.859e-04
[187,   200] loss: 1.859e-04
Training loss: 0.000, train NMSE: -7.321e+00
Validation loss: 0.000, valid_NMSE: -6.632e+00
--------------------------------------------------
[INFO]: Epoch 188 of 200
Training
[188,   100] loss: 1.671e-04
[188,   200] loss: 1.679e-04
Validation
[188,   100] loss: 1.860e-04
[188,   200] loss: 1.860e-04
Training loss: 0.000, train NMSE: -7.386e+00
Validation loss: 0.000, valid_NMSE: -6.595e+00
--------------------------------------------------
[INFO]: Epoch 189 of 200
Training
[189,   100] loss: 1.670e-04
[189,   200] loss: 1.672e-04
Validation
[189,   100] loss: 1.874e-04
[189,   200] loss: 1.874e-04
Training loss: 0.000, train NMSE: -7.272e+00
Validation loss: 0.000, valid_NMSE: -6.588e+00
--------------------------------------------------
[INFO]: Epoch 190 of 200
Training
[190,   100] loss: 1.660e-04
[190,   200] loss: 1.678e-04
Validation
[190,   100] loss: 1.878e-04
[190,   200] loss: 1.878e-04
Training loss: 0.000, train NMSE: -7.435e+00
Validation loss: 0.000, valid_NMSE: -6.544e+00
--------------------------------------------------
[INFO]: Epoch 191 of 200
Training
[191,   100] loss: 1.632e-04
[191,   200] loss: 1.697e-04
Validation
[191,   100] loss: 1.858e-04
[191,   200] loss: 1.858e-04
Training loss: 0.000, train NMSE: -7.540e+00
Validation loss: 0.000, valid_NMSE: -6.607e+00
--------------------------------------------------
[INFO]: Epoch 192 of 200
Training
[192,   100] loss: 1.651e-04
[192,   200] loss: 1.683e-04
Validation
[192,   100] loss: 1.865e-04
[192,   200] loss: 1.865e-04
Training loss: 0.000, train NMSE: -7.468e+00
Validation loss: 0.000, valid_NMSE: -6.602e+00
--------------------------------------------------
[INFO]: Epoch 193 of 200
Training
[193,   100] loss: 1.666e-04
[193,   200] loss: 1.664e-04
Validation
[193,   100] loss: 1.868e-04
[193,   200] loss: 1.868e-04
Training loss: 0.000, train NMSE: -7.696e+00
Validation loss: 0.000, valid_NMSE: -6.639e+00
--------------------------------------------------
[INFO]: Epoch 194 of 200
Training
[194,   100] loss: 1.652e-04
[194,   200] loss: 1.674e-04
Validation
[194,   100] loss: 1.857e-04
[194,   200] loss: 1.857e-04
Training loss: 0.000, train NMSE: -7.103e+00
Validation loss: 0.000, valid_NMSE: -6.641e+00

Best validation loss: -6.641265869140625

Saving best model for epoch: 194

--------------------------------------------------
[INFO]: Epoch 195 of 200
Training
[195,   100] loss: 1.646e-04
[195,   200] loss: 1.671e-04
Validation
[195,   100] loss: 1.872e-04
[195,   200] loss: 1.872e-04
Training loss: 0.000, train NMSE: -7.313e+00
Validation loss: 0.000, valid_NMSE: -6.536e+00
--------------------------------------------------
[INFO]: Epoch 196 of 200
Training
[196,   100] loss: 1.653e-04
[196,   200] loss: 1.658e-04
Validation
[196,   100] loss: 1.859e-04
[196,   200] loss: 1.859e-04
Training loss: 0.000, train NMSE: -7.888e+00
Validation loss: 0.000, valid_NMSE: -6.630e+00
--------------------------------------------------
[INFO]: Epoch 197 of 200
Training
[197,   100] loss: 1.651e-04
[197,   200] loss: 1.654e-04
Validation
[197,   100] loss: 1.846e-04
[197,   200] loss: 1.846e-04
Training loss: 0.000, train NMSE: -7.066e+00
Validation loss: 0.000, valid_NMSE: -6.638e+00/home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE
  warn(f"Failed to load image Python extension: {e}")

--------------------------------------------------
[INFO]: Epoch 198 of 200
Training
[198,   100] loss: 1.647e-04
[198,   200] loss: 1.663e-04
Validation
[198,   100] loss: 1.840e-04
[198,   200] loss: 1.840e-04
Training loss: 0.000, train NMSE: -6.810e+00
Validation loss: 0.000, valid_NMSE: -6.708e+00

Best validation loss: -6.708333969116211

Saving best model for epoch: 198

--------------------------------------------------
[INFO]: Epoch 199 of 200
Training
[199,   100] loss: 1.625e-04
[199,   200] loss: 1.674e-04
Validation
[199,   100] loss: 1.845e-04
[199,   200] loss: 1.845e-04
Training loss: 0.000, train NMSE: -7.440e+00
Validation loss: 0.000, valid_NMSE: -6.644e+00
--------------------------------------------------
[INFO]: Epoch 200 of 200
Training
[200,   100] loss: 1.653e-04
[200,   200] loss: 1.652e-04
Validation
[200,   100] loss: 1.853e-04
[200,   200] loss: 1.853e-04
Training loss: 0.000, train NMSE: -8.064e+00
Validation loss: 0.000, valid_NMSE: -6.646e+00
--------------------------------------------------
Saving final model
TRAINING COMPLETE
