1.13.1+cu117
outEnergyID
Dadicated Mode outEnergyID
Dedicated Mode outEnergyID
trainset len 112000 valset len 48000
New_trainset len 40000 valset len 48000
825,049 training parameters.

825,049 training parameters.

[INFO]: Epoch 1 of 200
Training
[1,   100] loss: 9.352e-04
[1,   200] loss: 9.014e-04
Validation
[1,   100] loss: 7.560e-04
[1,   200] loss: 7.560e-04
Training loss: 0.001, train NMSE: -2.272e-01
Validation loss: 0.001, valid_NMSE: -3.050e-01

Best validation loss: -0.3049800395965576

Saving best model for epoch: 1

--------------------------------------------------
[INFO]: Epoch 2 of 200
Training
[2,   100] loss: 8.529e-04
[2,   200] loss: 8.392e-04
Validation
[2,   100] loss: 7.236e-04
[2,   200] loss: 7.236e-04
Training loss: 0.001, train NMSE: -4.049e-01
Validation loss: 0.001, valid_NMSE: -5.050e-01

Best validation loss: -0.5050434470176697

Saving best model for epoch: 2

--------------------------------------------------
[INFO]: Epoch 3 of 200
Training
[3,   100] loss: 8.253e-04
[3,   200] loss: 8.236e-04
Validation
[3,   100] loss: 7.144e-04
[3,   200] loss: 7.144e-04
Training loss: 0.001, train NMSE: -7.105e-01
Validation loss: 0.001, valid_NMSE: -5.714e-01

Best validation loss: -0.5713571310043335

Saving best model for epoch: 3

--------------------------------------------------
[INFO]: Epoch 4 of 200
Training
[4,   100] loss: 8.124e-04
[4,   200] loss: 8.170e-04
Validation
[4,   100] loss: 7.073e-04
[4,   200] loss: 7.073e-04
Training loss: 0.001, train NMSE: -5.699e-01
Validation loss: 0.001, valid_NMSE: -6.175e-01

Best validation loss: -0.6175313591957092

Saving best model for epoch: 4

--------------------------------------------------
[INFO]: Epoch 5 of 200
Training
[5,   100] loss: 8.069e-04
[5,   200] loss: 8.063e-04
Validation
[5,   100] loss: 7.014e-04
[5,   200] loss: 7.014e-04
Training loss: 0.001, train NMSE: -6.525e-01
Validation loss: 0.001, valid_NMSE: -6.622e-01

Best validation loss: -0.6622295379638672

Saving best model for epoch: 5

--------------------------------------------------
[INFO]: Epoch 6 of 200
Training
[6,   100] loss: 8.008e-04
[6,   200] loss: 7.958e-04
Validation
[6,   100] loss: 6.942e-04
[6,   200] loss: 6.942e-04
Training loss: 0.001, train NMSE: -6.750e-01
Validation loss: 0.001, valid_NMSE: -7.122e-01

Best validation loss: -0.7122464179992676

Saving best model for epoch: 6

--------------------------------------------------
[INFO]: Epoch 7 of 200
Training
[7,   100] loss: 7.917e-04
[7,   200] loss: 7.855e-04
Validation
[7,   100] loss: 6.858e-04
[7,   200] loss: 6.858e-04
Training loss: 0.001, train NMSE: -8.818e-01
Validation loss: 0.001, valid_NMSE: -7.668e-01

Best validation loss: -0.7668030858039856

Saving best model for epoch: 7

--------------------------------------------------
[INFO]: Epoch 8 of 200
Training
[8,   100] loss: 7.790e-04
[8,   200] loss: 7.764e-04
Validation
[8,   100] loss: 6.768e-04
[8,   200] loss: 6.768e-04
Training loss: 0.001, train NMSE: -8.418e-01
Validation loss: 0.001, valid_NMSE: -8.193e-01

Best validation loss: -0.8193349242210388

Saving best model for epoch: 8

--------------------------------------------------
[INFO]: Epoch 9 of 200
Training
[9,   100] loss: 7.713e-04
[9,   200] loss: 7.613e-04
Validation
[9,   100] loss: 6.679e-04
[9,   200] loss: 6.679e-04
Training loss: 0.001, train NMSE: -8.546e-01
Validation loss: 0.001, valid_NMSE: -8.777e-01

Best validation loss: -0.8776620626449585

Saving best model for epoch: 9

--------------------------------------------------
[INFO]: Epoch 10 of 200
Training
[10,   100] loss: 7.587e-04
[10,   200] loss: 7.522e-04
Validation
[10,   100] loss: 6.593e-04
[10,   200] loss: 6.593e-04
Training loss: 0.001, train NMSE: -9.165e-01
Validation loss: 0.001, valid_NMSE: -9.286e-01

Best validation loss: -0.9286186099052429

Saving best model for epoch: 10

--------------------------------------------------
[INFO]: Epoch 11 of 200
Training
[11,   100] loss: 7.456e-04
[11,   200] loss: 7.453e-04
Validation
[11,   100] loss: 6.514e-04
[11,   200] loss: 6.514e-04
Training loss: 0.001, train NMSE: -9.643e-01
Validation loss: 0.001, valid_NMSE: -9.759e-01

Best validation loss: -0.9759435653686523

Saving best model for epoch: 11

--------------------------------------------------
[INFO]: Epoch 12 of 200
Training
[12,   100] loss: 7.363e-04
[12,   200] loss: 7.380e-04
Validation
[12,   100] loss: 6.450e-04
[12,   200] loss: 6.450e-04
Training loss: 0.001, train NMSE: -9.857e-01
Validation loss: 0.001, valid_NMSE: -1.023e+00

Best validation loss: -1.023134708404541

Saving best model for epoch: 12

--------------------------------------------------
[INFO]: Epoch 13 of 200
Training
[13,   100] loss: 7.305e-04
[13,   200] loss: 7.272e-04
Validation
[13,   100] loss: 6.398e-04
[13,   200] loss: 6.398e-04
Training loss: 0.001, train NMSE: -1.070e+00
Validation loss: 0.001, valid_NMSE: -1.051e+00

Best validation loss: -1.0511376857757568

Saving best model for epoch: 13

--------------------------------------------------
[INFO]: Epoch 14 of 200
Training
[14,   100] loss: 7.196e-04
[14,   200] loss: 7.243e-04
Validation
[14,   100] loss: 6.335e-04
[14,   200] loss: 6.335e-04
Training loss: 0.001, train NMSE: -1.105e+00
Validation loss: 0.001, valid_NMSE: -1.105e+00

Best validation loss: -1.1053577661514282

Saving best model for epoch: 14

--------------------------------------------------
[INFO]: Epoch 15 of 200
Training
[15,   100] loss: 7.174e-04
[15,   200] loss: 7.128e-04
Validation
[15,   100] loss: 6.290e-04
[15,   200] loss: 6.290e-04
Training loss: 0.001, train NMSE: -1.228e+00
Validation loss: 0.001, valid_NMSE: -1.141e+00

Best validation loss: -1.1407076120376587

Saving best model for epoch: 15

--------------------------------------------------
[INFO]: Epoch 16 of 200
Training
[16,   100] loss: 7.059e-04
[16,   200] loss: 7.116e-04
Validation
[16,   100] loss: 6.239e-04
[16,   200] loss: 6.239e-04
Training loss: 0.001, train NMSE: -1.386e+00
Validation loss: 0.001, valid_NMSE: -1.186e+00

Best validation loss: -1.1860369443893433

Saving best model for epoch: 16

--------------------------------------------------
[INFO]: Epoch 17 of 200
Training
[17,   100] loss: 7.041e-04
[17,   200] loss: 7.020e-04
Validation
[17,   100] loss: 6.202e-04
[17,   200] loss: 6.202e-04
Training loss: 0.001, train NMSE: -1.419e+00
Validation loss: 0.001, valid_NMSE: -1.222e+00

Best validation loss: -1.2217845916748047

Saving best model for epoch: 17

--------------------------------------------------
[INFO]: Epoch 18 of 200
Training
[18,   100] loss: 6.962e-04
[18,   200] loss: 6.988e-04
Validation
[18,   100] loss: 6.161e-04
[18,   200] loss: 6.161e-04
Training loss: 0.001, train NMSE: -1.405e+00
Validation loss: 0.001, valid_NMSE: -1.262e+00

Best validation loss: -1.262017011642456

Saving best model for epoch: 18

--------------------------------------------------
[INFO]: Epoch 19 of 200
Training
[19,   100] loss: 6.961e-04
[19,   200] loss: 6.882e-04
Validation
[19,   100] loss: 6.120e-04
[19,   200] loss: 6.120e-04
Training loss: 0.001, train NMSE: -1.313e+00
Validation loss: 0.001, valid_NMSE: -1.290e+00

Best validation loss: -1.2899280786514282

Saving best model for epoch: 19

--------------------------------------------------
[INFO]: Epoch 20 of 200
Training
[20,   100] loss: 6.861e-04
[20,   200] loss: 6.878e-04
Validation
[20,   100] loss: 6.081e-04
[20,   200] loss: 6.081e-04
Training loss: 0.001, train NMSE: -1.413e+00
Validation loss: 0.001, valid_NMSE: -1.339e+00

Best validation loss: -1.338854432106018

Saving best model for epoch: 20

--------------------------------------------------
[INFO]: Epoch 21 of 200
Training
[21,   100] loss: 6.838e-04
[21,   200] loss: 6.808e-04
Validation
[21,   100] loss: 6.035e-04
[21,   200] loss: 6.035e-04
Training loss: 0.001, train NMSE: -1.587e+00
Validation loss: 0.001, valid_NMSE: -1.373e+00

Best validation loss: -1.3726816177368164

Saving best model for epoch: 21

--------------------------------------------------
[INFO]: Epoch 22 of 200
Training
[22,   100] loss: 6.763e-04
[22,   200] loss: 6.793e-04
Validation
[22,   100] loss: 6.002e-04
[22,   200] loss: 6.002e-04
Training loss: 0.001, train NMSE: -1.430e+00
Validation loss: 0.001, valid_NMSE: -1.397e+00

Best validation loss: -1.3971247673034668

Saving best model for epoch: 22

--------------------------------------------------
[INFO]: Epoch 23 of 200
Training
[23,   100] loss: 6.750e-04
[23,   200] loss: 6.705e-04
Validation
[23,   100] loss: 5.974e-04
[23,   200] loss: 5.974e-04
Training loss: 0.001, train NMSE: -1.495e+00
Validation loss: 0.001, valid_NMSE: -1.430e+00

Best validation loss: -1.429638147354126

Saving best model for epoch: 23

--------------------------------------------------
[INFO]: Epoch 24 of 200
Training
[24,   100] loss: 6.697e-04
[24,   200] loss: 6.666e-04
Validation
[24,   100] loss: 5.935e-04
[24,   200] loss: 5.935e-04
Training loss: 0.001, train NMSE: -1.600e+00
Validation loss: 0.001, valid_NMSE: -1.457e+00

Best validation loss: -1.4572877883911133

Saving best model for epoch: 24

--------------------------------------------------
[INFO]: Epoch 25 of 200
Training
[25,   100] loss: 6.695e-04
[25,   200] loss: 6.596e-04
Validation
[25,   100] loss: 5.893e-04
[25,   200] loss: 5.893e-04
Training loss: 0.001, train NMSE: -1.685e+00
Validation loss: 0.001, valid_NMSE: -1.495e+00

Best validation loss: -1.4952157735824585

Saving best model for epoch: 25

--------------------------------------------------
[INFO]: Epoch 26 of 200
Training
[26,   100] loss: 6.591e-04
[26,   200] loss: 6.608e-04
Validation
[26,   100] loss: 5.864e-04
[26,   200] loss: 5.864e-04
Training loss: 0.001, train NMSE: -1.596e+00
Validation loss: 0.001, valid_NMSE: -1.505e+00

Best validation loss: -1.5049710273742676

Saving best model for epoch: 26

--------------------------------------------------
[INFO]: Epoch 27 of 200
Training
[27,   100] loss: 6.594e-04
[27,   200] loss: 6.529e-04
Validation
[27,   100] loss: 5.863e-04
[27,   200] loss: 5.863e-04
Training loss: 0.001, train NMSE: -1.546e+00
Validation loss: 0.001, valid_NMSE: -1.511e+00

Best validation loss: -1.5108031034469604

Saving best model for epoch: 27

--------------------------------------------------
[INFO]: Epoch 28 of 200
Training
[28,   100] loss: 6.514e-04
[28,   200] loss: 6.524e-04
Validation
[28,   100] loss: 5.801e-04
[28,   200] loss: 5.801e-04
Training loss: 0.001, train NMSE: -1.577e+00
Validation loss: 0.001, valid_NMSE: -1.566e+00

Best validation loss: -1.5660748481750488

Saving best model for epoch: 28

--------------------------------------------------
[INFO]: Epoch 29 of 200
Training
[29,   100] loss: 6.453e-04
[29,   200] loss: 6.518e-04
Validation
[29,   100] loss: 5.767e-04
[29,   200] loss: 5.767e-04
Training loss: 0.001, train NMSE: -1.846e+00
Validation loss: 0.001, valid_NMSE: -1.599e+00

Best validation loss: -1.5991644859313965

Saving best model for epoch: 29

--------------------------------------------------
[INFO]: Epoch 30 of 200
Training
[30,   100] loss: 6.406e-04
[30,   200] loss: 6.492e-04
Validation
[30,   100] loss: 5.741e-04
[30,   200] loss: 5.741e-04
Training loss: 0.001, train NMSE: -1.593e+00
Validation loss: 0.001, valid_NMSE: -1.614e+00

Best validation loss: -1.6138484477996826

Saving best model for epoch: 30

--------------------------------------------------
[INFO]: Epoch 31 of 200
Training
[31,   100] loss: 6.416e-04
[31,   200] loss: 6.404e-04
Validation
[31,   100] loss: 5.723e-04
[31,   200] loss: 5.723e-04
Training loss: 0.001, train NMSE: -1.819e+00
Validation loss: 0.001, valid_NMSE: -1.638e+00

Best validation loss: -1.6382558345794678

Saving best model for epoch: 31

--------------------------------------------------
[INFO]: Epoch 32 of 200
Training
[32,   100] loss: 6.362e-04
[32,   200] loss: 6.388e-04
Validation
[32,   100] loss: 5.686e-04
[32,   200] loss: 5.686e-04
Training loss: 0.001, train NMSE: -1.662e+00
Validation loss: 0.001, valid_NMSE: -1.655e+00

Best validation loss: -1.6553266048431396

Saving best model for epoch: 32

--------------------------------------------------
[INFO]: Epoch 33 of 200
Training
[33,   100] loss: 6.358e-04
[33,   200] loss: 6.323e-04
Validation
[33,   100] loss: 5.655e-04
[33,   200] loss: 5.655e-04
Training loss: 0.001, train NMSE: -1.902e+00
Validation loss: 0.001, valid_NMSE: -1.695e+00

Best validation loss: -1.6950219869613647

Saving best model for epoch: 33

--------------------------------------------------
[INFO]: Epoch 34 of 200
Training
[34,   100] loss: 6.295e-04
[34,   200] loss: 6.316e-04
Validation
[34,   100] loss: 5.636e-04
[34,   200] loss: 5.636e-04
Training loss: 0.001, train NMSE: -1.846e+00
Validation loss: 0.001, valid_NMSE: -1.701e+00

Best validation loss: -1.7008394002914429

Saving best model for epoch: 34

--------------------------------------------------
[INFO]: Epoch 35 of 200
Training
[35,   100] loss: 6.263e-04
[35,   200] loss: 6.285e-04
Validation
[35,   100] loss: 5.620e-04
[35,   200] loss: 5.620e-04
Training loss: 0.001, train NMSE: -1.963e+00
Validation loss: 0.001, valid_NMSE: -1.713e+00

Best validation loss: -1.7127388715744019

Saving best model for epoch: 35

--------------------------------------------------
[INFO]: Epoch 36 of 200
Training
[36,   100] loss: 6.234e-04
[36,   200] loss: 6.259e-04
Validation
[36,   100] loss: 5.598e-04
[36,   200] loss: 5.598e-04
Training loss: 0.001, train NMSE: -1.963e+00
Validation loss: 0.001, valid_NMSE: -1.741e+00

Best validation loss: -1.7407944202423096

Saving best model for epoch: 36

--------------------------------------------------
[INFO]: Epoch 37 of 200
Training
[37,   100] loss: 6.198e-04
[37,   200] loss: 6.224e-04
Validation
[37,   100] loss: 5.552e-04
[37,   200] loss: 5.552e-04
Training loss: 0.001, train NMSE: -1.968e+00
Validation loss: 0.001, valid_NMSE: -1.779e+00

Best validation loss: -1.7793089151382446

Saving best model for epoch: 37

--------------------------------------------------
[INFO]: Epoch 38 of 200
Training
[38,   100] loss: 6.202e-04
[38,   200] loss: 6.167e-04
Validation
[38,   100] loss: 5.543e-04
[38,   200] loss: 5.543e-04
Training loss: 0.001, train NMSE: -1.990e+00
Validation loss: 0.001, valid_NMSE: -1.776e+00
--------------------------------------------------
[INFO]: Epoch 39 of 200
Training
[39,   100] loss: 6.165e-04
[39,   200] loss: 6.141e-04
Validation
[39,   100] loss: 5.520e-04
[39,   200] loss: 5.520e-04
Training loss: 0.001, train NMSE: -1.829e+00
Validation loss: 0.001, valid_NMSE: -1.800e+00

Best validation loss: -1.8003071546554565

Saving best model for epoch: 39

--------------------------------------------------
[INFO]: Epoch 40 of 200
Training
[40,   100] loss: 6.101e-04
[40,   200] loss: 6.155e-04
Validation
[40,   100] loss: 5.494e-04
[40,   200] loss: 5.494e-04
Training loss: 0.001, train NMSE: -1.870e+00
Validation loss: 0.001, valid_NMSE: -1.828e+00

Best validation loss: -1.8281311988830566

Saving best model for epoch: 40

--------------------------------------------------
[INFO]: Epoch 41 of 200
Training
[41,   100] loss: 6.128e-04
[41,   200] loss: 6.067e-04
Validation
[41,   100] loss: 5.463e-04
[41,   200] loss: 5.463e-04
Training loss: 0.001, train NMSE: -2.011e+00
Validation loss: 0.001, valid_NMSE: -1.857e+00

Best validation loss: -1.8567357063293457

Saving best model for epoch: 41

--------------------------------------------------
[INFO]: Epoch 42 of 200
Training
[42,   100] loss: 6.054e-04
[42,   200] loss: 6.078e-04
Validation
[42,   100] loss: 5.462e-04
[42,   200] loss: 5.462e-04
Training loss: 0.001, train NMSE: -2.037e+00
Validation loss: 0.001, valid_NMSE: -1.855e+00
--------------------------------------------------
[INFO]: Epoch 43 of 200
Training
[43,   100] loss: 6.075e-04
[43,   200] loss: 6.011e-04
Validation
[43,   100] loss: 5.429e-04
[43,   200] loss: 5.429e-04
Training loss: 0.001, train NMSE: -1.952e+00
Validation loss: 0.001, valid_NMSE: -1.887e+00

Best validation loss: -1.886888027191162

Saving best model for epoch: 43

--------------------------------------------------
[INFO]: Epoch 44 of 200
Training
[44,   100] loss: 6.034e-04
[44,   200] loss: 5.998e-04
Validation
[44,   100] loss: 5.418e-04
[44,   200] loss: 5.418e-04
Training loss: 0.001, train NMSE: -2.163e+00
Validation loss: 0.001, valid_NMSE: -1.897e+00

Best validation loss: -1.8966894149780273

Saving best model for epoch: 44

--------------------------------------------------
[INFO]: Epoch 45 of 200
Training
[45,   100] loss: 5.980e-04
[45,   200] loss: 6.000e-04
Validation
[45,   100] loss: 5.399e-04
[45,   200] loss: 5.399e-04
Training loss: 0.001, train NMSE: -1.973e+00
Validation loss: 0.001, valid_NMSE: -1.900e+00

Best validation loss: -1.9001269340515137

Saving best model for epoch: 45

--------------------------------------------------
[INFO]: Epoch 46 of 200
Training
[46,   100] loss: 5.973e-04
[46,   200] loss: 5.961e-04
Validation
[46,   100] loss: 5.375e-04
[46,   200] loss: 5.375e-04
Training loss: 0.001, train NMSE: -2.101e+00
Validation loss: 0.001, valid_NMSE: -1.920e+00

Best validation loss: -1.9202044010162354

Saving best model for epoch: 46

--------------------------------------------------
[INFO]: Epoch 47 of 200
Training
[47,   100] loss: 5.912e-04
[47,   200] loss: 5.974e-04
Validation
[47,   100] loss: 5.363e-04
[47,   200] loss: 5.363e-04
Training loss: 0.001, train NMSE: -1.999e+00
Validation loss: 0.001, valid_NMSE: -1.948e+00

Best validation loss: -1.9477663040161133

Saving best model for epoch: 47

--------------------------------------------------
[INFO]: Epoch 48 of 200
Training
[48,   100] loss: 5.964e-04
[48,   200] loss: 5.868e-04
Validation
[48,   100] loss: 5.346e-04
[48,   200] loss: 5.346e-04
Training loss: 0.001, train NMSE: -2.052e+00
Validation loss: 0.001, valid_NMSE: -1.951e+00

Best validation loss: -1.9510811567306519

Saving best model for epoch: 48

--------------------------------------------------
[INFO]: Epoch 49 of 200
Training
[49,   100] loss: 5.874e-04
[49,   200] loss: 5.915e-04
Validation
[49,   100] loss: 5.330e-04
[49,   200] loss: 5.330e-04
Training loss: 0.001, train NMSE: -2.080e+00
Validation loss: 0.001, valid_NMSE: -1.964e+00

Best validation loss: -1.9641035795211792

Saving best model for epoch: 49

--------------------------------------------------
[INFO]: Epoch 50 of 200
Training
[50,   100] loss: 5.899e-04
[50,   200] loss: 5.856e-04
Validation
[50,   100] loss: 5.317e-04
[50,   200] loss: 5.317e-04
Training loss: 0.001, train NMSE: -2.014e+00
Validation loss: 0.001, valid_NMSE: -1.979e+00

Best validation loss: -1.9789432287216187

Saving best model for epoch: 50

--------------------------------------------------
[INFO]: Epoch 51 of 200
Training
[51,   100] loss: 5.828e-04
[51,   200] loss: 5.878e-04
Validation
[51,   100] loss: 5.290e-04
[51,   200] loss: 5.290e-04
Training loss: 0.001, train NMSE: -2.327e+00
Validation loss: 0.001, valid_NMSE: -2.022e+00

Best validation loss: -2.021670341491699

Saving best model for epoch: 51

--------------------------------------------------
[INFO]: Epoch 52 of 200
Training
[52,   100] loss: 5.829e-04
[52,   200] loss: 5.841e-04
Validation
[52,   100] loss: 5.294e-04
[52,   200] loss: 5.294e-04
Training loss: 0.001, train NMSE: -2.224e+00
Validation loss: 0.001, valid_NMSE: -1.999e+00
--------------------------------------------------
[INFO]: Epoch 53 of 200
Training
[53,   100] loss: 5.868e-04
[53,   200] loss: 5.752e-04
Validation
[53,   100] loss: 5.255e-04
[53,   200] loss: 5.255e-04
Training loss: 0.001, train NMSE: -2.241e+00
Validation loss: 0.001, valid_NMSE: -2.057e+00

Best validation loss: -2.0572643280029297

Saving best model for epoch: 53

--------------------------------------------------
[INFO]: Epoch 54 of 200
Training
[54,   100] loss: 5.799e-04
[54,   200] loss: 5.780e-04
Validation
[54,   100] loss: 5.249e-04
[54,   200] loss: 5.249e-04
Training loss: 0.001, train NMSE: -1.889e+00
Validation loss: 0.001, valid_NMSE: -2.051e+00
--------------------------------------------------
[INFO]: Epoch 55 of 200
Training
[55,   100] loss: 5.786e-04
[55,   200] loss: 5.750e-04
Validation
[55,   100] loss: 5.241e-04
[55,   200] loss: 5.241e-04
Training loss: 0.001, train NMSE: -2.217e+00
Validation loss: 0.001, valid_NMSE: -2.062e+00

Best validation loss: -2.061750888824463

Saving best model for epoch: 55

--------------------------------------------------
[INFO]: Epoch 56 of 200
Training
[56,   100] loss: 5.759e-04
[56,   200] loss: 5.743e-04
Validation
[56,   100] loss: 5.212e-04
[56,   200] loss: 5.212e-04
Training loss: 0.001, train NMSE: -2.329e+00
Validation loss: 0.001, valid_NMSE: -2.100e+00

Best validation loss: -2.100497245788574

Saving best model for epoch: 56

--------------------------------------------------
[INFO]: Epoch 57 of 200
Training
[57,   100] loss: 5.687e-04
[57,   200] loss: 5.783e-04
Validation
[57,   100] loss: 5.217e-04
[57,   200] loss: 5.217e-04
Training loss: 0.001, train NMSE: -2.220e+00
Validation loss: 0.001, valid_NMSE: -2.101e+00

Best validation loss: -2.1005594730377197

Saving best model for epoch: 57

--------------------------------------------------
[INFO]: Epoch 58 of 200
Training
[58,   100] loss: 5.722e-04
[58,   200] loss: 5.707e-04
Validation
[58,   100] loss: 5.201e-04
[58,   200] loss: 5.201e-04
Training loss: 0.001, train NMSE: -2.291e+00
Validation loss: 0.001, valid_NMSE: -2.108e+00

Best validation loss: -2.1075210571289062

Saving best model for epoch: 58

--------------------------------------------------
[INFO]: Epoch 59 of 200
Training
[59,   100] loss: 5.693e-04
[59,   200] loss: 5.688e-04
Validation
[59,   100] loss: 5.196e-04
[59,   200] loss: 5.196e-04
Training loss: 0.001, train NMSE: -2.124e+00
Validation loss: 0.001, valid_NMSE: -2.129e+00

Best validation loss: -2.1291801929473877

Saving best model for epoch: 59

--------------------------------------------------
[INFO]: Epoch 60 of 200
Training
[60,   100] loss: 5.676e-04
[60,   200] loss: 5.685e-04
Validation
[60,   100] loss: 5.164e-04
[60,   200] loss: 5.164e-04
Training loss: 0.001, train NMSE: -2.541e+00
Validation loss: 0.001, valid_NMSE: -2.170e+00

Best validation loss: -2.1702005863189697

Saving best model for epoch: 60

--------------------------------------------------
[INFO]: Epoch 61 of 200
Training
[61,   100] loss: 5.633e-04
[61,   200] loss: 5.681e-04
Validation
[61,   100] loss: 5.176e-04
[61,   200] loss: 5.176e-04
Training loss: 0.001, train NMSE: -2.104e+00
Validation loss: 0.001, valid_NMSE: -2.144e+00
--------------------------------------------------
[INFO]: Epoch 62 of 200
Training
[62,   100] loss: 5.629e-04
[62,   200] loss: 5.655e-04
Validation
[62,   100] loss: 5.153e-04
[62,   200] loss: 5.153e-04
Training loss: 0.001, train NMSE: -2.520e+00
Validation loss: 0.001, valid_NMSE: -2.168e+00
--------------------------------------------------
[INFO]: Epoch 63 of 200
Training
[63,   100] loss: 5.647e-04
[63,   200] loss: 5.606e-04
Validation
[63,   100] loss: 5.155e-04
[63,   200] loss: 5.155e-04
Training loss: 0.001, train NMSE: -2.085e+00
Validation loss: 0.001, valid_NMSE: -2.159e+00
--------------------------------------------------
[INFO]: Epoch 64 of 200
Training
[64,   100] loss: 5.657e-04
[64,   200] loss: 5.563e-04
Validation
[64,   100] loss: 5.139e-04
[64,   200] loss: 5.139e-04
Training loss: 0.001, train NMSE: -2.337e+00
Validation loss: 0.001, valid_NMSE: -2.182e+00

Best validation loss: -2.1824254989624023

Saving best model for epoch: 64

--------------------------------------------------
[INFO]: Epoch 65 of 200
Training
[65,   100] loss: 5.624e-04
[65,   200] loss: 5.564e-04
Validation
[65,   100] loss: 5.137e-04
[65,   200] loss: 5.137e-04
Training loss: 0.001, train NMSE: -2.423e+00
Validation loss: 0.001, valid_NMSE: -2.181e+00
--------------------------------------------------
[INFO]: Epoch 66 of 200
Training
[66,   100] loss: 5.597e-04
[66,   200] loss: 5.560e-04
Validation
[66,   100] loss: 5.130e-04
[66,   200] loss: 5.130e-04
Training loss: 0.001, train NMSE: -2.355e+00
Validation loss: 0.001, valid_NMSE: -2.195e+00

Best validation loss: -2.1948049068450928

Saving best model for epoch: 66

--------------------------------------------------
[INFO]: Epoch 67 of 200
Training
[67,   100] loss: 5.560e-04
[67,   200] loss: 5.565e-04
Validation
[67,   100] loss: 5.135e-04
[67,   200] loss: 5.135e-04
Training loss: 0.001, train NMSE: -2.449e+00
Validation loss: 0.001, valid_NMSE: -2.197e+00

Best validation loss: -2.1974964141845703

Saving best model for epoch: 67

--------------------------------------------------
[INFO]: Epoch 68 of 200
Training
[68,   100] loss: 5.563e-04
[68,   200] loss: 5.530e-04
Validation
[68,   100] loss: 5.113e-04
[68,   200] loss: 5.113e-04
Training loss: 0.001, train NMSE: -2.396e+00
Validation loss: 0.001, valid_NMSE: -2.231e+00

Best validation loss: -2.230684518814087

Saving best model for epoch: 68

--------------------------------------------------
[INFO]: Epoch 69 of 200
Training
[69,   100] loss: 5.552e-04
[69,   200] loss: 5.512e-04
Validation
[69,   100] loss: 5.076e-04
[69,   200] loss: 5.076e-04
Training loss: 0.001, train NMSE: -2.280e+00
Validation loss: 0.001, valid_NMSE: -2.255e+00

Best validation loss: -2.2554590702056885

Saving best model for epoch: 69

--------------------------------------------------
[INFO]: Epoch 70 of 200
Training
[70,   100] loss: 5.487e-04
[70,   200] loss: 5.547e-04
Validation
[70,   100] loss: 5.075e-04
[70,   200] loss: 5.075e-04
Training loss: 0.001, train NMSE: -2.353e+00
Validation loss: 0.001, valid_NMSE: -2.257e+00

Best validation loss: -2.2568421363830566

Saving best model for epoch: 70

--------------------------------------------------
[INFO]: Epoch 71 of 200
Training
[71,   100] loss: 5.482e-04
[71,   200] loss: 5.535e-04
Validation
[71,   100] loss: 5.063e-04
[71,   200] loss: 5.063e-04
Training loss: 0.001, train NMSE: -2.616e+00
Validation loss: 0.001, valid_NMSE: -2.271e+00

Best validation loss: -2.2708914279937744

Saving best model for epoch: 71

--------------------------------------------------
[INFO]: Epoch 72 of 200
Training
[72,   100] loss: 5.484e-04
[72,   200] loss: 5.500e-04
Validation
[72,   100] loss: 5.047e-04
[72,   200] loss: 5.047e-04
Training loss: 0.001, train NMSE: -2.537e+00
Validation loss: 0.001, valid_NMSE: -2.307e+00

Best validation loss: -2.306924819946289

Saving best model for epoch: 72

--------------------------------------------------
[INFO]: Epoch 73 of 200
Training
[73,   100] loss: 5.478e-04
[73,   200] loss: 5.472e-04
Validation
[73,   100] loss: 5.040e-04
[73,   200] loss: 5.040e-04
Training loss: 0.001, train NMSE: -2.492e+00
Validation loss: 0.001, valid_NMSE: -2.314e+00

Best validation loss: -2.3136987686157227

Saving best model for epoch: 73

--------------------------------------------------
[INFO]: Epoch 74 of 200
Training
[74,   100] loss: 5.486e-04
[74,   200] loss: 5.436e-04
Validation
[74,   100] loss: 5.042e-04
[74,   200] loss: 5.042e-04
Training loss: 0.001, train NMSE: -2.535e+00
Validation loss: 0.001, valid_NMSE: -2.299e+00
--------------------------------------------------
[INFO]: Epoch 75 of 200
Training
[75,   100] loss: 5.435e-04
[75,   200] loss: 5.473e-04
Validation
[75,   100] loss: 5.042e-04
[75,   200] loss: 5.042e-04
Training loss: 0.001, train NMSE: -2.515e+00
Validation loss: 0.001, valid_NMSE: -2.295e+00
--------------------------------------------------
[INFO]: Epoch 76 of 200
Training
[76,   100] loss: 5.429e-04
[76,   200] loss: 5.441e-04
Validation
[76,   100] loss: 5.009e-04
[76,   200] loss: 5.009e-04
Training loss: 0.001, train NMSE: -2.361e+00
Validation loss: 0.001, valid_NMSE: -2.342e+00

Best validation loss: -2.3415844440460205

Saving best model for epoch: 76

--------------------------------------------------
[INFO]: Epoch 77 of 200
Training
[77,   100] loss: 5.442e-04
[77,   200] loss: 5.402e-04
Validation
[77,   100] loss: 5.037e-04
[77,   200] loss: 5.037e-04
Training loss: 0.001, train NMSE: -2.620e+00
Validation loss: 0.001, valid_NMSE: -2.308e+00
--------------------------------------------------
[INFO]: Epoch 78 of 200
Training
[78,   100] loss: 5.422e-04
[78,   200] loss: 5.401e-04
Validation
[78,   100] loss: 5.003e-04
[78,   200] loss: 5.003e-04
Training loss: 0.001, train NMSE: -2.404e+00
Validation loss: 0.001, valid_NMSE: -2.336e+00
--------------------------------------------------
[INFO]: Epoch 79 of 200
Training
[79,   100] loss: 5.380e-04
[79,   200] loss: 5.420e-04
Validation
[79,   100] loss: 5.005e-04
[79,   200] loss: 5.005e-04
Training loss: 0.001, train NMSE: -2.355e+00
Validation loss: 0.001, valid_NMSE: -2.356e+00

Best validation loss: -2.355510950088501

Saving best model for epoch: 79

--------------------------------------------------
[INFO]: Epoch 80 of 200
Training
[80,   100] loss: 5.383e-04
[80,   200] loss: 5.396e-04
Validation
[80,   100] loss: 5.005e-04
[80,   200] loss: 5.005e-04
Training loss: 0.001, train NMSE: -2.285e+00
Validation loss: 0.001, valid_NMSE: -2.347e+00
--------------------------------------------------
[INFO]: Epoch 81 of 200
Training
[81,   100] loss: 5.391e-04
[81,   200] loss: 5.368e-04
Validation
[81,   100] loss: 4.977e-04
[81,   200] loss: 4.977e-04
Training loss: 0.001, train NMSE: -2.369e+00
Validation loss: 0.000, valid_NMSE: -2.375e+00

Best validation loss: -2.374833106994629

Saving best model for epoch: 81

--------------------------------------------------
[INFO]: Epoch 82 of 200
Training
[82,   100] loss: 5.333e-04
[82,   200] loss: 5.388e-04
Validation
[82,   100] loss: 4.999e-04
[82,   200] loss: 4.999e-04
Training loss: 0.001, train NMSE: -2.367e+00
Validation loss: 0.000, valid_NMSE: -2.343e+00
--------------------------------------------------
[INFO]: Epoch 83 of 200
Training
[83,   100] loss: 5.311e-04
[83,   200] loss: 5.395e-04
Validation
[83,   100] loss: 4.976e-04
[83,   200] loss: 4.976e-04
Training loss: 0.001, train NMSE: -2.365e+00
Validation loss: 0.000, valid_NMSE: -2.401e+00

Best validation loss: -2.401336193084717

Saving best model for epoch: 83

--------------------------------------------------
[INFO]: Epoch 84 of 200
Training
[84,   100] loss: 5.322e-04
[84,   200] loss: 5.356e-04
Validation
[84,   100] loss: 4.968e-04
[84,   200] loss: 4.968e-04
Training loss: 0.001, train NMSE: -2.543e+00
Validation loss: 0.000, valid_NMSE: -2.399e+00
--------------------------------------------------
[INFO]: Epoch 85 of 200
Training
[85,   100] loss: 5.300e-04
[85,   200] loss: 5.374e-04
Validation
[85,   100] loss: 4.943e-04
[85,   200] loss: 4.943e-04
Training loss: 0.001, train NMSE: -2.441e+00
Validation loss: 0.000, valid_NMSE: -2.414e+00

Best validation loss: -2.4144704341888428

Saving best model for epoch: 85

--------------------------------------------------
[INFO]: Epoch 86 of 200
Training
[86,   100] loss: 5.290e-04
[86,   200] loss: 5.341e-04
Validation
[86,   100] loss: 4.972e-04
[86,   200] loss: 4.972e-04
Training loss: 0.001, train NMSE: -2.419e+00
Validation loss: 0.000, valid_NMSE: -2.386e+00
--------------------------------------------------
[INFO]: Epoch 87 of 200
Training
[87,   100] loss: 5.288e-04
[87,   200] loss: 5.330e-04
Validation
[87,   100] loss: 4.935e-04
[87,   200] loss: 4.935e-04
Training loss: 0.001, train NMSE: -2.357e+00
Validation loss: 0.000, valid_NMSE: -2.419e+00

Best validation loss: -2.4192638397216797

Saving best model for epoch: 87

--------------------------------------------------
[INFO]: Epoch 88 of 200
Training
[88,   100] loss: 5.294e-04
[88,   200] loss: 5.299e-04
Validation
[88,   100] loss: 4.955e-04
[88,   200] loss: 4.955e-04
Training loss: 0.001, train NMSE: -2.499e+00
Validation loss: 0.000, valid_NMSE: -2.396e+00
--------------------------------------------------
[INFO]: Epoch 89 of 200
Training
[89,   100] loss: 5.288e-04
[89,   200] loss: 5.293e-04
Validation
[89,   100] loss: 4.926e-04
[89,   200] loss: 4.926e-04
Training loss: 0.001, train NMSE: -2.638e+00
Validation loss: 0.000, valid_NMSE: -2.429e+00

Best validation loss: -2.4294843673706055

Saving best model for epoch: 89

--------------------------------------------------
[INFO]: Epoch 90 of 200
Training
[90,   100] loss: 5.238e-04
[90,   200] loss: 5.318e-04
Validation
[90,   100] loss: 4.922e-04
[90,   200] loss: 4.922e-04
Training loss: 0.001, train NMSE: -2.559e+00
Validation loss: 0.000, valid_NMSE: -2.413e+00
--------------------------------------------------
[INFO]: Epoch 91 of 200
Training
[91,   100] loss: 5.245e-04
[91,   200] loss: 5.300e-04
Validation
[91,   100] loss: 4.928e-04
[91,   200] loss: 4.928e-04
Training loss: 0.001, train NMSE: -2.597e+00
Validation loss: 0.000, valid_NMSE: -2.447e+00

Best validation loss: -2.446584939956665

Saving best model for epoch: 91

--------------------------------------------------
[INFO]: Epoch 92 of 200
Training
[92,   100] loss: 5.252e-04
[92,   200] loss: 5.265e-04
Validation
[92,   100] loss: 4.937e-04
[92,   200] loss: 4.937e-04
Training loss: 0.001, train NMSE: -2.599e+00
Validation loss: 0.000, valid_NMSE: -2.415e+00
--------------------------------------------------
[INFO]: Epoch 93 of 200
Training
[93,   100] loss: 5.200e-04
[93,   200] loss: 5.290e-04
Validation
[93,   100] loss: 4.925e-04
[93,   200] loss: 4.925e-04
Training loss: 0.001, train NMSE: -2.668e+00
Validation loss: 0.000, valid_NMSE: -2.422e+00
--------------------------------------------------
[INFO]: Epoch 94 of 200
Training
[94,   100] loss: 5.225e-04
[94,   200] loss: 5.246e-04
Validation
[94,   100] loss: 4.926e-04
[94,   200] loss: 4.926e-04
Training loss: 0.001, train NMSE: -2.664e+00
Validation loss: 0.000, valid_NMSE: -2.427e+00
--------------------------------------------------
[INFO]: Epoch 95 of 200
Training
[95,   100] loss: 5.250e-04
[95,   200] loss: 5.207e-04
Validation
[95,   100] loss: 4.909e-04
[95,   200] loss: 4.909e-04
Training loss: 0.001, train NMSE: -2.577e+00
Validation loss: 0.000, valid_NMSE: -2.450e+00

Best validation loss: -2.4497506618499756

Saving best model for epoch: 95

--------------------------------------------------
[INFO]: Epoch 96 of 200
Training
[96,   100] loss: 5.244e-04
[96,   200] loss: 5.189e-04
Validation
[96,   100] loss: 4.889e-04
[96,   200] loss: 4.889e-04
Training loss: 0.001, train NMSE: -2.534e+00
Validation loss: 0.000, valid_NMSE: -2.453e+00

Best validation loss: -2.4530651569366455

Saving best model for epoch: 96

--------------------------------------------------
[INFO]: Epoch 97 of 200
Training
[97,   100] loss: 5.212e-04
[97,   200] loss: 5.211e-04
Validation
[97,   100] loss: 4.888e-04
[97,   200] loss: 4.888e-04
Training loss: 0.001, train NMSE: -2.682e+00
Validation loss: 0.000, valid_NMSE: -2.478e+00

Best validation loss: -2.4776759147644043

Saving best model for epoch: 97

--------------------------------------------------
[INFO]: Epoch 98 of 200
Training
[98,   100] loss: 5.218e-04
[98,   200] loss: 5.174e-04
Validation
[98,   100] loss: 4.891e-04
[98,   200] loss: 4.891e-04
Training loss: 0.001, train NMSE: -2.450e+00
Validation loss: 0.000, valid_NMSE: -2.445e+00
--------------------------------------------------
[INFO]: Epoch 99 of 200
Training
[99,   100] loss: 5.175e-04
[99,   200] loss: 5.204e-04
Validation
[99,   100] loss: 4.920e-04
[99,   200] loss: 4.920e-04
Training loss: 0.001, train NMSE: -2.726e+00
Validation loss: 0.000, valid_NMSE: -2.426e+00
--------------------------------------------------
[INFO]: Epoch 100 of 200
Training
[100,   100] loss: 5.182e-04
[100,   200] loss: 5.178e-04
Validation
[100,   100] loss: 4.892e-04
[100,   200] loss: 4.892e-04
Training loss: 0.001, train NMSE: -2.689e+00
Validation loss: 0.000, valid_NMSE: -2.446e+00
--------------------------------------------------
[INFO]: Epoch 101 of 200
Training
[101,   100] loss: 5.142e-04
[101,   200] loss: 5.209e-04
Validation
[101,   100] loss: 4.866e-04
[101,   200] loss: 4.866e-04
Training loss: 0.001, train NMSE: -2.550e+00
Validation loss: 0.000, valid_NMSE: -2.478e+00

Best validation loss: -2.4782040119171143

Saving best model for epoch: 101

--------------------------------------------------
[INFO]: Epoch 102 of 200
Training
[102,   100] loss: 5.153e-04
[102,   200] loss: 5.183e-04
Validation
[102,   100] loss: 4.853e-04
[102,   200] loss: 4.853e-04
Training loss: 0.001, train NMSE: -2.640e+00
Validation loss: 0.000, valid_NMSE: -2.501e+00

Best validation loss: -2.501256227493286

Saving best model for epoch: 102

--------------------------------------------------
[INFO]: Epoch 103 of 200
Training
[103,   100] loss: 5.168e-04
[103,   200] loss: 5.139e-04
Validation
[103,   100] loss: 4.855e-04
[103,   200] loss: 4.855e-04
Training loss: 0.001, train NMSE: -2.603e+00
Validation loss: 0.000, valid_NMSE: -2.496e+00
--------------------------------------------------
[INFO]: Epoch 104 of 200
Training
[104,   100] loss: 5.109e-04
[104,   200] loss: 5.188e-04
Validation
[104,   100] loss: 4.855e-04
[104,   200] loss: 4.855e-04
Training loss: 0.001, train NMSE: -2.811e+00
Validation loss: 0.000, valid_NMSE: -2.502e+00

Best validation loss: -2.5019545555114746

Saving best model for epoch: 104

--------------------------------------------------
[INFO]: Epoch 105 of 200
Training
[105,   100] loss: 5.143e-04
[105,   200] loss: 5.139e-04
Validation
[105,   100] loss: 4.847e-04
[105,   200] loss: 4.847e-04
Training loss: 0.001, train NMSE: -2.763e+00
Validation loss: 0.000, valid_NMSE: -2.495e+00
--------------------------------------------------
[INFO]: Epoch 106 of 200
Training
[106,   100] loss: 5.114e-04
[106,   200] loss: 5.147e-04
Validation
[106,   100] loss: 4.838e-04
[106,   200] loss: 4.838e-04
Training loss: 0.001, train NMSE: -2.595e+00
Validation loss: 0.000, valid_NMSE: -2.496e+00
--------------------------------------------------
[INFO]: Epoch 107 of 200
Training
[107,   100] loss: 5.127e-04
[107,   200] loss: 5.108e-04
Validation
[107,   100] loss: 4.854e-04
[107,   200] loss: 4.854e-04
Training loss: 0.001, train NMSE: -2.848e+00
Validation loss: 0.000, valid_NMSE: -2.483e+00
--------------------------------------------------
[INFO]: Epoch 108 of 200
Training
[108,   100] loss: 5.118e-04
[108,   200] loss: 5.111e-04
Validation
[108,   100] loss: 4.859e-04
[108,   200] loss: 4.859e-04
Training loss: 0.001, train NMSE: -2.485e+00
Validation loss: 0.000, valid_NMSE: -2.487e+00
--------------------------------------------------
[INFO]: Epoch 109 of 200
Training
[109,   100] loss: 5.099e-04
[109,   200] loss: 5.107e-04
Validation
[109,   100] loss: 4.829e-04
[109,   200] loss: 4.829e-04
Training loss: 0.001, train NMSE: -2.941e+00
Validation loss: 0.000, valid_NMSE: -2.524e+00

Best validation loss: -2.523958206176758

Saving best model for epoch: 109

--------------------------------------------------
[INFO]: Epoch 110 of 200
Training
[110,   100] loss: 5.111e-04
[110,   200] loss: 5.092e-04
Validation
[110,   100] loss: 4.837e-04
[110,   200] loss: 4.837e-04
Training loss: 0.001, train NMSE: -2.574e+00
Validation loss: 0.000, valid_NMSE: -2.500e+00
--------------------------------------------------
[INFO]: Epoch 111 of 200
Training
[111,   100] loss: 5.094e-04
[111,   200] loss: 5.077e-04
Validation
[111,   100] loss: 4.834e-04
[111,   200] loss: 4.834e-04
Training loss: 0.001, train NMSE: -2.661e+00
Validation loss: 0.000, valid_NMSE: -2.492e+00
--------------------------------------------------
[INFO]: Epoch 112 of 200
Training
[112,   100] loss: 5.064e-04
[112,   200] loss: 5.100e-04
Validation
[112,   100] loss: 4.828e-04
[112,   200] loss: 4.828e-04
Training loss: 0.001, train NMSE: -2.714e+00
Validation loss: 0.000, valid_NMSE: -2.497e+00
--------------------------------------------------
[INFO]: Epoch 113 of 200
Training
[113,   100] loss: 5.067e-04
[113,   200] loss: 5.074e-04
Validation
[113,   100] loss: 4.814e-04
[113,   200] loss: 4.814e-04
Training loss: 0.001, train NMSE: -2.748e+00
Validation loss: 0.000, valid_NMSE: -2.552e+00

Best validation loss: -2.5517141819000244

Saving best model for epoch: 113

--------------------------------------------------
[INFO]: Epoch 114 of 200
Training
[114,   100] loss: 5.041e-04
[114,   200] loss: 5.084e-04
Validation
[114,   100] loss: 4.816e-04
[114,   200] loss: 4.816e-04
Training loss: 0.001, train NMSE: -2.708e+00
Validation loss: 0.000, valid_NMSE: -2.530e+00
--------------------------------------------------
[INFO]: Epoch 115 of 200
Training
[115,   100] loss: 5.031e-04
[115,   200] loss: 5.087e-04
Validation
[115,   100] loss: 4.806e-04
[115,   200] loss: 4.806e-04
Training loss: 0.001, train NMSE: -2.672e+00
Validation loss: 0.000, valid_NMSE: -2.539e+00
--------------------------------------------------
[INFO]: Epoch 116 of 200
Training
[116,   100] loss: 5.056e-04
[116,   200] loss: 5.051e-04
Validation
[116,   100] loss: 4.804e-04
[116,   200] loss: 4.804e-04
Training loss: 0.001, train NMSE: -2.837e+00
Validation loss: 0.000, valid_NMSE: -2.546e+00
--------------------------------------------------
[INFO]: Epoch 117 of 200
Training
[117,   100] loss: 5.061e-04
[117,   200] loss: 5.028e-04
Validation
[117,   100] loss: 4.789e-04
[117,   200] loss: 4.789e-04
Training loss: 0.001, train NMSE: -2.819e+00
Validation loss: 0.000, valid_NMSE: -2.548e+00
--------------------------------------------------
[INFO]: Epoch 118 of 200
Training
[118,   100] loss: 5.034e-04
[118,   200] loss: 5.045e-04
Validation
[118,   100] loss: 4.803e-04
[118,   200] loss: 4.803e-04
Training loss: 0.001, train NMSE: -3.089e+00
Validation loss: 0.000, valid_NMSE: -2.541e+00
--------------------------------------------------
[INFO]: Epoch 119 of 200
Training
[119,   100] loss: 5.041e-04
[119,   200] loss: 5.015e-04
Validation
[119,   100] loss: 4.828e-04
[119,   200] loss: 4.828e-04
Training loss: 0.001, train NMSE: -2.575e+00
Validation loss: 0.000, valid_NMSE: -2.513e+00
--------------------------------------------------
[INFO]: Epoch 120 of 200
Training
[120,   100] loss: 5.027e-04
[120,   200] loss: 5.024e-04
Validation
[120,   100] loss: 4.797e-04
[120,   200] loss: 4.797e-04
Training loss: 0.001, train NMSE: -2.864e+00
Validation loss: 0.000, valid_NMSE: -2.536e+00
--------------------------------------------------
[INFO]: Epoch 121 of 200
Training
[121,   100] loss: 5.012e-04
[121,   200] loss: 5.021e-04
Validation
[121,   100] loss: 4.793e-04
[121,   200] loss: 4.793e-04
Training loss: 0.001, train NMSE: -2.867e+00
Validation loss: 0.000, valid_NMSE: -2.553e+00

Best validation loss: -2.552534341812134

Saving best model for epoch: 121

--------------------------------------------------
[INFO]: Epoch 122 of 200
Training
[122,   100] loss: 5.015e-04
[122,   200] loss: 4.994e-04
Validation
[122,   100] loss: 4.797e-04
[122,   200] loss: 4.797e-04
Training loss: 0.001, train NMSE: -2.913e+00
Validation loss: 0.000, valid_NMSE: -2.541e+00
--------------------------------------------------
[INFO]: Epoch 123 of 200
Training
[123,   100] loss: 5.001e-04
[123,   200] loss: 4.999e-04
Validation
[123,   100] loss: 4.776e-04
[123,   200] loss: 4.776e-04
Training loss: 0.000, train NMSE: -2.697e+00
Validation loss: 0.000, valid_NMSE: -2.580e+00

Best validation loss: -2.5797109603881836

Saving best model for epoch: 123

--------------------------------------------------
[INFO]: Epoch 124 of 200
Training
[124,   100] loss: 5.010e-04
[124,   200] loss: 4.994e-04
Validation
[124,   100] loss: 4.817e-04
[124,   200] loss: 4.817e-04
Training loss: 0.001, train NMSE: -2.927e+00
Validation loss: 0.000, valid_NMSE: -2.511e+00
--------------------------------------------------
[INFO]: Epoch 125 of 200
Training
[125,   100] loss: 4.953e-04
[125,   200] loss: 5.029e-04
Validation
[125,   100] loss: 4.776e-04
[125,   200] loss: 4.776e-04
Training loss: 0.000, train NMSE: -2.627e+00
Validation loss: 0.000, valid_NMSE: -2.571e+00
--------------------------------------------------
[INFO]: Epoch 126 of 200
Training
[126,   100] loss: 4.950e-04
[126,   200] loss: 5.006e-04
Validation
[126,   100] loss: 4.775e-04
[126,   200] loss: 4.775e-04
Training loss: 0.000, train NMSE: -2.692e+00
Validation loss: 0.000, valid_NMSE: -2.560e+00
--------------------------------------------------
[INFO]: Epoch 127 of 200
Training
[127,   100] loss: 4.956e-04
[127,   200] loss: 5.000e-04
Validation
[127,   100] loss: 4.760e-04
[127,   200] loss: 4.760e-04
Training loss: 0.000, train NMSE: -2.963e+00
Validation loss: 0.000, valid_NMSE: -2.577e+00
--------------------------------------------------
[INFO]: Epoch 128 of 200
Training
[128,   100] loss: 4.970e-04
[128,   200] loss: 4.960e-04
Validation
[128,   100] loss: 4.781e-04
[128,   200] loss: 4.781e-04
Training loss: 0.000, train NMSE: -2.661e+00
Validation loss: 0.000, valid_NMSE: -2.539e+00
--------------------------------------------------
[INFO]: Epoch 129 of 200
Training
[129,   100] loss: 4.931e-04
[129,   200] loss: 4.992e-04
Validation
[129,   100] loss: 4.766e-04
[129,   200] loss: 4.766e-04
Training loss: 0.000, train NMSE: -2.818e+00
Validation loss: 0.000, valid_NMSE: -2.575e+00
--------------------------------------------------
[INFO]: Epoch 130 of 200
Training
[130,   100] loss: 4.925e-04
[130,   200] loss: 4.991e-04
Validation
[130,   100] loss: 4.785e-04
[130,   200] loss: 4.785e-04
Training loss: 0.000, train NMSE: -2.760e+00
Validation loss: 0.000, valid_NMSE: -2.544e+00
--------------------------------------------------
[INFO]: Epoch 131 of 200
Training
[131,   100] loss: 4.952e-04
[131,   200] loss: 4.953e-04
Validation
[131,   100] loss: 4.760e-04
[131,   200] loss: 4.760e-04
Training loss: 0.000, train NMSE: -2.838e+00
Validation loss: 0.000, valid_NMSE: -2.586e+00

Best validation loss: -2.586184501647949

Saving best model for epoch: 131

--------------------------------------------------
[INFO]: Epoch 132 of 200
Training
[132,   100] loss: 4.918e-04
[132,   200] loss: 4.976e-04
Validation
[132,   100] loss: 4.793e-04
[132,   200] loss: 4.793e-04
Training loss: 0.000, train NMSE: -3.054e+00
Validation loss: 0.000, valid_NMSE: -2.518e+00
--------------------------------------------------
[INFO]: Epoch 133 of 200
Training
[133,   100] loss: 4.937e-04
[133,   200] loss: 4.930e-04
Validation
[133,   100] loss: 4.743e-04
[133,   200] loss: 4.743e-04
Training loss: 0.000, train NMSE: -2.965e+00
Validation loss: 0.000, valid_NMSE: -2.582e+00
--------------------------------------------------
[INFO]: Epoch 134 of 200
Training
[134,   100] loss: 4.913e-04
[134,   200] loss: 4.943e-04
Validation
[134,   100] loss: 4.754e-04
[134,   200] loss: 4.754e-04
Training loss: 0.000, train NMSE: -2.845e+00
Validation loss: 0.000, valid_NMSE: -2.588e+00

Best validation loss: -2.5877580642700195

Saving best model for epoch: 134

--------------------------------------------------
[INFO]: Epoch 135 of 200
Training
[135,   100] loss: 4.914e-04
[135,   200] loss: 4.933e-04
Validation
[135,   100] loss: 4.730e-04
[135,   200] loss: 4.730e-04
Training loss: 0.000, train NMSE: -3.083e+00
Validation loss: 0.000, valid_NMSE: -2.617e+00

Best validation loss: -2.6167287826538086

Saving best model for epoch: 135

--------------------------------------------------
[INFO]: Epoch 136 of 200
Training
[136,   100] loss: 4.915e-04
[136,   200] loss: 4.920e-04
Validation
[136,   100] loss: 4.762e-04
[136,   200] loss: 4.762e-04
Training loss: 0.000, train NMSE: -2.932e+00
Validation loss: 0.000, valid_NMSE: -2.558e+00
--------------------------------------------------
[INFO]: Epoch 137 of 200
Training
[137,   100] loss: 4.897e-04
[137,   200] loss: 4.926e-04
Validation
[137,   100] loss: 4.742e-04
[137,   200] loss: 4.742e-04
Training loss: 0.000, train NMSE: -2.840e+00
Validation loss: 0.000, valid_NMSE: -2.585e+00
--------------------------------------------------
[INFO]: Epoch 138 of 200
Training
[138,   100] loss: 4.896e-04
[138,   200] loss: 4.914e-04
Validation
[138,   100] loss: 4.740e-04
[138,   200] loss: 4.740e-04
Training loss: 0.000, train NMSE: -2.903e+00
Validation loss: 0.000, valid_NMSE: -2.580e+00
--------------------------------------------------
[INFO]: Epoch 139 of 200
Training
[139,   100] loss: 4.892e-04
[139,   200] loss: 4.910e-04
Validation
[139,   100] loss: 4.752e-04
[139,   200] loss: 4.752e-04
Training loss: 0.000, train NMSE: -3.002e+00
Validation loss: 0.000, valid_NMSE: -2.576e+00
--------------------------------------------------
[INFO]: Epoch 140 of 200
Training
[140,   100] loss: 4.895e-04
[140,   200] loss: 4.895e-04
Validation
[140,   100] loss: 4.733e-04
[140,   200] loss: 4.733e-04
Training loss: 0.000, train NMSE: -2.899e+00
Validation loss: 0.000, valid_NMSE: -2.601e+00
--------------------------------------------------
[INFO]: Epoch 141 of 200
Training
[141,   100] loss: 4.930e-04
[141,   200] loss: 4.857e-04
Validation
[141,   100] loss: 4.751e-04
[141,   200] loss: 4.751e-04
Training loss: 0.000, train NMSE: -3.156e+00
Validation loss: 0.000, valid_NMSE: -2.561e+00
--------------------------------------------------
[INFO]: Epoch 142 of 200
Training
[142,   100] loss: 4.883e-04
[142,   200] loss: 4.879e-04
Validation
[142,   100] loss: 4.728e-04
[142,   200] loss: 4.728e-04
Training loss: 0.000, train NMSE: -2.561e+00
Validation loss: 0.000, valid_NMSE: -2.591e+00
--------------------------------------------------
[INFO]: Epoch 143 of 200
Training
[143,   100] loss: 4.839e-04
[143,   200] loss: 4.910e-04
Validation
[143,   100] loss: 4.748e-04
[143,   200] loss: 4.748e-04
Training loss: 0.000, train NMSE: -2.791e+00
Validation loss: 0.000, valid_NMSE: -2.575e+00
--------------------------------------------------
[INFO]: Epoch 144 of 200
Training
[144,   100] loss: 4.892e-04
[144,   200] loss: 4.852e-04
Validation
[144,   100] loss: 4.697e-04
[144,   200] loss: 4.697e-04
Training loss: 0.000, train NMSE: -2.806e+00
Validation loss: 0.000, valid_NMSE: -2.638e+00

Best validation loss: -2.637732982635498

Saving best model for epoch: 144

--------------------------------------------------
[INFO]: Epoch 145 of 200
Training
[145,   100] loss: 4.870e-04
[145,   200] loss: 4.865e-04
Validation
[145,   100] loss: 4.713e-04
[145,   200] loss: 4.713e-04
Training loss: 0.000, train NMSE: -2.764e+00
Validation loss: 0.000, valid_NMSE: -2.621e+00
--------------------------------------------------
[INFO]: Epoch 146 of 200
Training
[146,   100] loss: 4.842e-04
[146,   200] loss: 4.879e-04
Validation
[146,   100] loss: 4.773e-04
[146,   200] loss: 4.773e-04
Training loss: 0.000, train NMSE: -3.031e+00
Validation loss: 0.000, valid_NMSE: -2.526e+00
--------------------------------------------------
[INFO]: Epoch 147 of 200
Training
[147,   100] loss: 4.878e-04
[147,   200] loss: 4.846e-04
Validation
[147,   100] loss: 4.707e-04
[147,   200] loss: 4.707e-04
Training loss: 0.000, train NMSE: -2.876e+00
Validation loss: 0.000, valid_NMSE: -2.620e+00
--------------------------------------------------
[INFO]: Epoch 148 of 200
Training
[148,   100] loss: 4.809e-04
[148,   200] loss: 4.887e-04
Validation
[148,   100] loss: 4.705e-04
[148,   200] loss: 4.705e-04
Training loss: 0.000, train NMSE: -2.808e+00
Validation loss: 0.000, valid_NMSE: -2.614e+00
--------------------------------------------------
[INFO]: Epoch 149 of 200
Training
[149,   100] loss: 4.853e-04
[149,   200] loss: 4.834e-04
Validation
[149,   100] loss: 4.693e-04
[149,   200] loss: 4.693e-04
Training loss: 0.000, train NMSE: -2.679e+00
Validation loss: 0.000, valid_NMSE: -2.625e+00
--------------------------------------------------
[INFO]: Epoch 150 of 200
Training
[150,   100] loss: 4.828e-04
[150,   200] loss: 4.849e-04
Validation
[150,   100] loss: 4.693e-04
[150,   200] loss: 4.693e-04
Training loss: 0.000, train NMSE: -2.785e+00
Validation loss: 0.000, valid_NMSE: -2.633e+00
--------------------------------------------------
[INFO]: Epoch 151 of 200
Training
[151,   100] loss: 4.825e-04
[151,   200] loss: 4.845e-04
Validation
[151,   100] loss: 4.688e-04
[151,   200] loss: 4.688e-04
Training loss: 0.000, train NMSE: -2.728e+00
Validation loss: 0.000, valid_NMSE: -2.618e+00
--------------------------------------------------
[INFO]: Epoch 152 of 200
Training
[152,   100] loss: 4.805e-04
[152,   200] loss: 4.845e-04
Validation
[152,   100] loss: 4.734e-04
[152,   200] loss: 4.734e-04
Training loss: 0.000, train NMSE: -2.886e+00
Validation loss: 0.000, valid_NMSE: -2.568e+00
--------------------------------------------------
[INFO]: Epoch 153 of 200
Training
[153,   100] loss: 4.853e-04
[153,   200] loss: 4.803e-04
Validation
[153,   100] loss: 4.702e-04
[153,   200] loss: 4.702e-04
Training loss: 0.000, train NMSE: -2.732e+00
Validation loss: 0.000, valid_NMSE: -2.612e+00
--------------------------------------------------
[INFO]: Epoch 154 of 200
Training
[154,   100] loss: 4.776e-04
[154,   200] loss: 4.861e-04
Validation
[154,   100] loss: 4.730e-04
[154,   200] loss: 4.730e-04
Training loss: 0.000, train NMSE: -2.912e+00
Validation loss: 0.000, valid_NMSE: -2.595e+00
--------------------------------------------------
[INFO]: Epoch 155 of 200
Training
[155,   100] loss: 4.789e-04
[155,   200] loss: 4.834e-04
Validation
[155,   100] loss: 4.681e-04
[155,   200] loss: 4.681e-04
Training loss: 0.000, train NMSE: -2.760e+00
Validation loss: 0.000, valid_NMSE: -2.632e+00
--------------------------------------------------
[INFO]: Epoch 156 of 200
Training
[156,   100] loss: 4.809e-04
[156,   200] loss: 4.807e-04
Validation
[156,   100] loss: 4.680e-04
[156,   200] loss: 4.680e-04
Training loss: 0.000, train NMSE: -2.740e+00
Validation loss: 0.000, valid_NMSE: -2.637e+00
--------------------------------------------------
[INFO]: Epoch 157 of 200
Training
[157,   100] loss: 4.759e-04
[157,   200] loss: 4.858e-04
Validation
[157,   100] loss: 4.699e-04
[157,   200] loss: 4.699e-04
Training loss: 0.000, train NMSE: -2.711e+00
Validation loss: 0.000, valid_NMSE: -2.602e+00
--------------------------------------------------
[INFO]: Epoch 158 of 200
Training
[158,   100] loss: 4.796e-04
[158,   200] loss: 4.801e-04
Validation
[158,   100] loss: 4.714e-04
[158,   200] loss: 4.714e-04
Training loss: 0.000, train NMSE: -2.991e+00
Validation loss: 0.000, valid_NMSE: -2.575e+00
--------------------------------------------------
[INFO]: Epoch 159 of 200
Training
[159,   100] loss: 4.781e-04
[159,   200] loss: 4.813e-04
Validation
[159,   100] loss: 4.692e-04
[159,   200] loss: 4.692e-04
Training loss: 0.000, train NMSE: -2.860e+00
Validation loss: 0.000, valid_NMSE: -2.618e+00
--------------------------------------------------
[INFO]: Epoch 160 of 200
Training
[160,   100] loss: 4.794e-04
[160,   200] loss: 4.789e-04
Validation
[160,   100] loss: 4.704e-04
[160,   200] loss: 4.704e-04
Training loss: 0.000, train NMSE: -3.084e+00
Validation loss: 0.000, valid_NMSE: -2.597e+00
--------------------------------------------------
[INFO]: Epoch 161 of 200
Training
[161,   100] loss: 4.816e-04
[161,   200] loss: 4.756e-04
Validation
[161,   100] loss: 4.660e-04
[161,   200] loss: 4.660e-04
Training loss: 0.000, train NMSE: -2.964e+00
Validation loss: 0.000, valid_NMSE: -2.644e+00

Best validation loss: -2.6439836025238037

Saving best model for epoch: 161

--------------------------------------------------
[INFO]: Epoch 162 of 200
Training
[162,   100] loss: 4.769e-04
[162,   200] loss: 4.795e-04
Validation
[162,   100] loss: 4.706e-04
[162,   200] loss: 4.706e-04
Training loss: 0.000, train NMSE: -2.864e+00
Validation loss: 0.000, valid_NMSE: -2.593e+00
--------------------------------------------------
[INFO]: Epoch 163 of 200
Training
[163,   100] loss: 4.774e-04
[163,   200] loss: 4.778e-04
Validation
[163,   100] loss: 4.671e-04
[163,   200] loss: 4.671e-04
Training loss: 0.000, train NMSE: -2.846e+00
Validation loss: 0.000, valid_NMSE: -2.648e+00

Best validation loss: -2.647613525390625

Saving best model for epoch: 163

--------------------------------------------------
[INFO]: Epoch 164 of 200
Training
[164,   100] loss: 4.789e-04
[164,   200] loss: 4.757e-04
Validation
[164,   100] loss: 4.670e-04
[164,   200] loss: 4.670e-04
Training loss: 0.000, train NMSE: -3.231e+00
Validation loss: 0.000, valid_NMSE: -2.647e+00
--------------------------------------------------
[INFO]: Epoch 165 of 200
Training
[165,   100] loss: 4.791e-04
[165,   200] loss: 4.749e-04
Validation
[165,   100] loss: 4.662e-04
[165,   200] loss: 4.662e-04
Training loss: 0.000, train NMSE: -2.997e+00
Validation loss: 0.000, valid_NMSE: -2.655e+00

Best validation loss: -2.6554176807403564

Saving best model for epoch: 165

--------------------------------------------------
[INFO]: Epoch 166 of 200
Training
[166,   100] loss: 4.741e-04
[166,   200] loss: 4.771e-04
Validation
[166,   100] loss: 4.678e-04
[166,   200] loss: 4.678e-04
Training loss: 0.000, train NMSE: -2.672e+00
Validation loss: 0.000, valid_NMSE: -2.631e+00
--------------------------------------------------
[INFO]: Epoch 167 of 200
Training
[167,   100] loss: 4.768e-04
[167,   200] loss: 4.743e-04
Validation
[167,   100] loss: 4.659e-04
[167,   200] loss: 4.659e-04
Training loss: 0.000, train NMSE: -2.930e+00
Validation loss: 0.000, valid_NMSE: -2.653e+00
--------------------------------------------------
[INFO]: Epoch 168 of 200
Training
[168,   100] loss: 4.761e-04
[168,   200] loss: 4.757e-04
Validation
[168,   100] loss: 4.663e-04
[168,   200] loss: 4.663e-04
Training loss: 0.000, train NMSE: -3.129e+00
Validation loss: 0.000, valid_NMSE: -2.637e+00
--------------------------------------------------
[INFO]: Epoch 169 of 200
Training
[169,   100] loss: 4.731e-04
[169,   200] loss: 4.764e-04
Validation
[169,   100] loss: 4.658e-04
[169,   200] loss: 4.658e-04
Training loss: 0.000, train NMSE: -2.907e+00
Validation loss: 0.000, valid_NMSE: -2.648e+00
--------------------------------------------------
[INFO]: Epoch 170 of 200
Training
[170,   100] loss: 4.746e-04
[170,   200] loss: 4.736e-04
Validation
[170,   100] loss: 4.642e-04
[170,   200] loss: 4.642e-04
Training loss: 0.000, train NMSE: -3.312e+00
Validation loss: 0.000, valid_NMSE: -2.669e+00

Best validation loss: -2.6689610481262207

Saving best model for epoch: 170

--------------------------------------------------
[INFO]: Epoch 171 of 200
Training
[171,   100] loss: 4.719e-04
[171,   200] loss: 4.757e-04
Validation
[171,   100] loss: 4.707e-04
[171,   200] loss: 4.707e-04
Training loss: 0.000, train NMSE: -2.898e+00
Validation loss: 0.000, valid_NMSE: -2.590e+00
--------------------------------------------------
[INFO]: Epoch 172 of 200
Training
[172,   100] loss: 4.738e-04
[172,   200] loss: 4.739e-04
Validation
[172,   100] loss: 4.647e-04
[172,   200] loss: 4.647e-04
Training loss: 0.000, train NMSE: -3.082e+00
Validation loss: 0.000, valid_NMSE: -2.665e+00
--------------------------------------------------
[INFO]: Epoch 173 of 200
Training
[173,   100] loss: 4.731e-04
[173,   200] loss: 4.733e-04
Validation
[173,   100] loss: 4.648e-04
[173,   200] loss: 4.648e-04
Training loss: 0.000, train NMSE: -2.621e+00
Validation loss: 0.000, valid_NMSE: -2.647e+00
--------------------------------------------------
[INFO]: Epoch 174 of 200
Training
[174,   100] loss: 4.719e-04
[174,   200] loss: 4.741e-04
Validation
[174,   100] loss: 4.655e-04
[174,   200] loss: 4.655e-04
Training loss: 0.000, train NMSE: -2.932e+00
Validation loss: 0.000, valid_NMSE: -2.661e+00
--------------------------------------------------
[INFO]: Epoch 175 of 200
Training
[175,   100] loss: 4.695e-04
[175,   200] loss: 4.737e-04
Validation
[175,   100] loss: 4.624e-04
[175,   200] loss: 4.624e-04
Training loss: 0.000, train NMSE: -3.086e+00
Validation loss: 0.000, valid_NMSE: -2.685e+00

Best validation loss: -2.68502140045166

Saving best model for epoch: 175

--------------------------------------------------
[INFO]: Epoch 176 of 200
Training
[176,   100] loss: 4.686e-04
[176,   200] loss: 4.742e-04
Validation
[176,   100] loss: 4.644e-04
[176,   200] loss: 4.644e-04
Training loss: 0.000, train NMSE: -2.942e+00
Validation loss: 0.000, valid_NMSE: -2.666e+00
--------------------------------------------------
[INFO]: Epoch 177 of 200
Training
[177,   100] loss: 4.692e-04
[177,   200] loss: 4.727e-04
Validation
[177,   100] loss: 4.622e-04
[177,   200] loss: 4.622e-04
Training loss: 0.000, train NMSE: -2.890e+00
Validation loss: 0.000, valid_NMSE: -2.687e+00

Best validation loss: -2.6872732639312744

Saving best model for epoch: 177

--------------------------------------------------
[INFO]: Epoch 178 of 200
Training
[178,   100] loss: 4.668e-04
[178,   200] loss: 4.738e-04
Validation
[178,   100] loss: 4.647e-04
[178,   200] loss: 4.647e-04
Training loss: 0.000, train NMSE: -3.263e+00
Validation loss: 0.000, valid_NMSE: -2.661e+00
--------------------------------------------------
[INFO]: Epoch 179 of 200
Training
[179,   100] loss: 4.691e-04
[179,   200] loss: 4.717e-04
Validation
[179,   100] loss: 4.662e-04
[179,   200] loss: 4.662e-04
Training loss: 0.000, train NMSE: -2.924e+00
Validation loss: 0.000, valid_NMSE: -2.670e+00
--------------------------------------------------
[INFO]: Epoch 180 of 200
Training
[180,   100] loss: 4.719e-04
[180,   200] loss: 4.691e-04
Validation
[180,   100] loss: 4.637e-04
[180,   200] loss: 4.637e-04
Training loss: 0.000, train NMSE: -3.066e+00
Validation loss: 0.000, valid_NMSE: -2.673e+00
--------------------------------------------------
[INFO]: Epoch 181 of 200
Training
[181,   100] loss: 4.708e-04
[181,   200] loss: 4.682e-04
Validation
[181,   100] loss: 4.650e-04
[181,   200] loss: 4.650e-04
Training loss: 0.000, train NMSE: -3.080e+00
Validation loss: 0.000, valid_NMSE: -2.653e+00
--------------------------------------------------
[INFO]: Epoch 182 of 200
Training
[182,   100] loss: 4.702e-04
[182,   200] loss: 4.707e-04
Validation
[182,   100] loss: 4.645e-04
[182,   200] loss: 4.645e-04
Training loss: 0.000, train NMSE: -3.158e+00
Validation loss: 0.000, valid_NMSE: -2.651e+00
--------------------------------------------------
[INFO]: Epoch 183 of 200
Training
[183,   100] loss: 4.729e-04
[183,   200] loss: 4.655e-04
Validation
[183,   100] loss: 4.647e-04
[183,   200] loss: 4.647e-04
Training loss: 0.000, train NMSE: -3.042e+00
Validation loss: 0.000, valid_NMSE: -2.645e+00
--------------------------------------------------
[INFO]: Epoch 184 of 200
Training
[184,   100] loss: 4.701e-04
[184,   200] loss: 4.668e-04
Validation
[184,   100] loss: 4.639e-04
[184,   200] loss: 4.639e-04
Training loss: 0.000, train NMSE: -3.230e+00
Validation loss: 0.000, valid_NMSE: -2.655e+00
--------------------------------------------------
[INFO]: Epoch 185 of 200
Training
[185,   100] loss: 4.664e-04
[185,   200] loss: 4.692e-04
Validation
[185,   100] loss: 4.633e-04
[185,   200] loss: 4.633e-04
Training loss: 0.000, train NMSE: -3.043e+00
Validation loss: 0.000, valid_NMSE: -2.652e+00
--------------------------------------------------
[INFO]: Epoch 186 of 200
Training
[186,   100] loss: 4.677e-04
[186,   200] loss: 4.675e-04
Validation
[186,   100] loss: 4.687e-04
[186,   200] loss: 4.687e-04
Training loss: 0.000, train NMSE: -2.910e+00
Validation loss: 0.000, valid_NMSE: -2.597e+00
--------------------------------------------------
[INFO]: Epoch 187 of 200
Training
[187,   100] loss: 4.691e-04
[187,   200] loss: 4.657e-04
Validation
[187,   100] loss: 4.616e-04
[187,   200] loss: 4.616e-04
Training loss: 0.000, train NMSE: -3.176e+00
Validation loss: 0.000, valid_NMSE: -2.698e+00

Best validation loss: -2.6977837085723877

Saving best model for epoch: 187

--------------------------------------------------
[INFO]: Epoch 188 of 200
Training
[188,   100] loss: 4.703e-04
[188,   200] loss: 4.629e-04
Validation
[188,   100] loss: 4.641e-04
[188,   200] loss: 4.641e-04
Training loss: 0.000, train NMSE: -3.032e+00
Validation loss: 0.000, valid_NMSE: -2.661e+00
--------------------------------------------------
[INFO]: Epoch 189 of 200
Training
[189,   100] loss: 4.678e-04
[189,   200] loss: 4.658e-04
Validation
[189,   100] loss: 4.598e-04
[189,   200] loss: 4.598e-04
Training loss: 0.000, train NMSE: -3.023e+00
Validation loss: 0.000, valid_NMSE: -2.724e+00

Best validation loss: -2.7237069606781006

Saving best model for epoch: 189

--------------------------------------------------
[INFO]: Epoch 190 of 200
Training
[190,   100] loss: 4.634e-04
[190,   200] loss: 4.684e-04
Validation
[190,   100] loss: 4.613e-04
[190,   200] loss: 4.613e-04
Training loss: 0.000, train NMSE: -3.188e+00
Validation loss: 0.000, valid_NMSE: -2.710e+00
--------------------------------------------------
[INFO]: Epoch 191 of 200
Training
[191,   100] loss: 4.655e-04
[191,   200] loss: 4.677e-04
Validation
[191,   100] loss: 4.621e-04
[191,   200] loss: 4.621e-04
Training loss: 0.000, train NMSE: -3.184e+00
Validation loss: 0.000, valid_NMSE: -2.671e+00
--------------------------------------------------
[INFO]: Epoch 192 of 200
Training
[192,   100] loss: 4.676e-04
[192,   200] loss: 4.635e-04
Validation
[192,   100] loss: 4.621e-04
[192,   200] loss: 4.621e-04
Training loss: 0.000, train NMSE: -2.995e+00
Validation loss: 0.000, valid_NMSE: -2.685e+00
--------------------------------------------------
[INFO]: Epoch 193 of 200
Training
[193,   100] loss: 4.663e-04
[193,   200] loss: 4.641e-04
Validation
[193,   100] loss: 4.610e-04
[193,   200] loss: 4.610e-04
Training loss: 0.000, train NMSE: -2.804e+00
Validation loss: 0.000, valid_NMSE: -2.681e+00
--------------------------------------------------
[INFO]: Epoch 194 of 200
Training/home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE
  warn(f"Failed to load image Python extension: {e}")

[194,   100] loss: 4.657e-04
[194,   200] loss: 4.636e-04
Validation
[194,   100] loss: 4.611e-04
[194,   200] loss: 4.611e-04
Training loss: 0.000, train NMSE: -3.121e+00
Validation loss: 0.000, valid_NMSE: -2.677e+00
--------------------------------------------------
[INFO]: Epoch 195 of 200
Training
[195,   100] loss: 4.648e-04
[195,   200] loss: 4.627e-04
Validation
[195,   100] loss: 4.625e-04
[195,   200] loss: 4.625e-04
Training loss: 0.000, train NMSE: -3.465e+00
Validation loss: 0.000, valid_NMSE: -2.692e+00
--------------------------------------------------
[INFO]: Epoch 196 of 200
Training
[196,   100] loss: 4.628e-04
[196,   200] loss: 4.649e-04
Validation
[196,   100] loss: 4.614e-04
[196,   200] loss: 4.614e-04
Training loss: 0.000, train NMSE: -2.992e+00
Validation loss: 0.000, valid_NMSE: -2.670e+00
--------------------------------------------------
[INFO]: Epoch 197 of 200
Training
[197,   100] loss: 4.617e-04
[197,   200] loss: 4.644e-04
Validation
[197,   100] loss: 4.602e-04
[197,   200] loss: 4.602e-04
Training loss: 0.000, train NMSE: -2.934e+00
Validation loss: 0.000, valid_NMSE: -2.701e+00
--------------------------------------------------
[INFO]: Epoch 198 of 200
Training
[198,   100] loss: 4.612e-04
[198,   200] loss: 4.649e-04
Validation
[198,   100] loss: 4.663e-04
[198,   200] loss: 4.663e-04
Training loss: 0.000, train NMSE: -3.061e+00
Validation loss: 0.000, valid_NMSE: -2.607e+00
--------------------------------------------------
[INFO]: Epoch 199 of 200
Training
[199,   100] loss: 4.617e-04
[199,   200] loss: 4.642e-04
Validation
[199,   100] loss: 4.646e-04
[199,   200] loss: 4.646e-04
Training loss: 0.000, train NMSE: -3.153e+00
Validation loss: 0.000, valid_NMSE: -2.631e+00
--------------------------------------------------
[INFO]: Epoch 200 of 200
Training
[200,   100] loss: 4.660e-04
[200,   200] loss: 4.591e-04
Validation
[200,   100] loss: 4.591e-04
[200,   200] loss: 4.591e-04
Training loss: 0.000, train NMSE: -3.247e+00
Validation loss: 0.000, valid_NMSE: -2.712e+00
--------------------------------------------------
Saving final model
TRAINING COMPLETE
