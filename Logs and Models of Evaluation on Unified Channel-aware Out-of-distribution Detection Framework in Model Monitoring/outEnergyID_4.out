1.13.1+cu117
outEnergyID
Dadicated Mode outEnergyID
Dedicated Mode outEnergyID
trainset len 112000 valset len 48000
New_trainset len 40000 valset len 48000
2,660,505 training parameters.

2,660,505 training parameters.

[INFO]: Epoch 1 of 200
Training
[1,   100] loss: 8.369e-04
[1,   200] loss: 6.862e-04
Validation
[1,   100] loss: 5.255e-04
[1,   200] loss: 5.255e-04
Training loss: 0.001, train NMSE: -1.790e+00
Validation loss: 0.001, valid_NMSE: -2.004e+00

Best validation loss: -2.0040626525878906

Saving best model for epoch: 1

--------------------------------------------------
[INFO]: Epoch 2 of 200
Training
[2,   100] loss: 5.643e-04
[2,   200] loss: 5.108e-04
Validation
[2,   100] loss: 4.143e-04
[2,   200] loss: 4.143e-04
Training loss: 0.001, train NMSE: -2.692e+00
Validation loss: 0.000, valid_NMSE: -3.144e+00

Best validation loss: -3.1437172889709473

Saving best model for epoch: 2

--------------------------------------------------
[INFO]: Epoch 3 of 200
Training
[3,   100] loss: 4.663e-04
[3,   200] loss: 4.391e-04
Validation
[3,   100] loss: 3.630e-04
[3,   200] loss: 3.630e-04
Training loss: 0.000, train NMSE: -3.278e+00
Validation loss: 0.000, valid_NMSE: -3.804e+00

Best validation loss: -3.8042263984680176

Saving best model for epoch: 3

--------------------------------------------------
[INFO]: Epoch 4 of 200
Training
[4,   100] loss: 4.144e-04
[4,   200] loss: 3.894e-04
Validation
[4,   100] loss: 3.272e-04
[4,   200] loss: 3.272e-04
Training loss: 0.000, train NMSE: -4.283e+00
Validation loss: 0.000, valid_NMSE: -4.311e+00

Best validation loss: -4.311383247375488

Saving best model for epoch: 4

--------------------------------------------------
[INFO]: Epoch 5 of 200
Training
[5,   100] loss: 3.694e-04
[5,   200] loss: 3.615e-04
Validation
[5,   100] loss: 2.998e-04
[5,   200] loss: 2.998e-04
Training loss: 0.000, train NMSE: -4.611e+00
Validation loss: 0.000, valid_NMSE: -4.759e+00

Best validation loss: -4.759498596191406

Saving best model for epoch: 5

--------------------------------------------------
[INFO]: Epoch 6 of 200
Training
[6,   100] loss: 3.441e-04
[6,   200] loss: 3.305e-04
Validation
[6,   100] loss: 2.796e-04
[6,   200] loss: 2.796e-04
Training loss: 0.000, train NMSE: -4.737e+00
Validation loss: 0.000, valid_NMSE: -5.119e+00

Best validation loss: -5.118911266326904

Saving best model for epoch: 6

--------------------------------------------------
[INFO]: Epoch 7 of 200
Training
[7,   100] loss: 3.185e-04
[7,   200] loss: 3.114e-04
Validation
[7,   100] loss: 2.639e-04
[7,   200] loss: 2.639e-04
Training loss: 0.000, train NMSE: -5.131e+00
Validation loss: 0.000, valid_NMSE: -5.442e+00

Best validation loss: -5.441858291625977

Saving best model for epoch: 7

--------------------------------------------------
[INFO]: Epoch 8 of 200
Training
[8,   100] loss: 3.000e-04
[8,   200] loss: 2.943e-04
Validation
[8,   100] loss: 2.496e-04
[8,   200] loss: 2.496e-04
Training loss: 0.000, train NMSE: -5.153e+00
Validation loss: 0.000, valid_NMSE: -5.711e+00

Best validation loss: -5.711268424987793

Saving best model for epoch: 8

--------------------------------------------------
[INFO]: Epoch 9 of 200
Training
[9,   100] loss: 2.855e-04
[9,   200] loss: 2.796e-04
Validation
[9,   100] loss: 2.392e-04
[9,   200] loss: 2.392e-04
Training loss: 0.000, train NMSE: -5.537e+00
Validation loss: 0.000, valid_NMSE: -5.929e+00

Best validation loss: -5.928645610809326

Saving best model for epoch: 9

--------------------------------------------------
[INFO]: Epoch 10 of 200
Training
[10,   100] loss: 2.706e-04
[10,   200] loss: 2.690e-04
Validation
[10,   100] loss: 2.291e-04
[10,   200] loss: 2.291e-04
Training loss: 0.000, train NMSE: -5.629e+00
Validation loss: 0.000, valid_NMSE: -6.135e+00

Best validation loss: -6.134671688079834

Saving best model for epoch: 10

--------------------------------------------------
[INFO]: Epoch 11 of 200
Training
[11,   100] loss: 2.601e-04
[11,   200] loss: 2.583e-04
Validation
[11,   100] loss: 2.212e-04
[11,   200] loss: 2.212e-04
Training loss: 0.000, train NMSE: -5.990e+00
Validation loss: 0.000, valid_NMSE: -6.306e+00

Best validation loss: -6.306292533874512

Saving best model for epoch: 11

--------------------------------------------------
[INFO]: Epoch 12 of 200
Training
[12,   100] loss: 2.483e-04
[12,   200] loss: 2.509e-04
Validation
[12,   100] loss: 2.140e-04
[12,   200] loss: 2.140e-04
Training loss: 0.000, train NMSE: -5.752e+00
Validation loss: 0.000, valid_NMSE: -6.438e+00

Best validation loss: -6.437619209289551

Saving best model for epoch: 12

--------------------------------------------------
[INFO]: Epoch 13 of 200
Training
[13,   100] loss: 2.400e-04
[13,   200] loss: 2.429e-04
Validation
[13,   100] loss: 2.079e-04
[13,   200] loss: 2.079e-04
Training loss: 0.000, train NMSE: -6.007e+00
Validation loss: 0.000, valid_NMSE: -6.565e+00

Best validation loss: -6.564736366271973

Saving best model for epoch: 13

--------------------------------------------------
[INFO]: Epoch 14 of 200
Training
[14,   100] loss: 2.350e-04
[14,   200] loss: 2.333e-04
Validation
[14,   100] loss: 2.019e-04
[14,   200] loss: 2.019e-04
Training loss: 0.000, train NMSE: -6.118e+00
Validation loss: 0.000, valid_NMSE: -6.713e+00

Best validation loss: -6.713313102722168

Saving best model for epoch: 14

--------------------------------------------------
[INFO]: Epoch 15 of 200
Training
[15,   100] loss: 2.280e-04
[15,   200] loss: 2.272e-04
Validation
[15,   100] loss: 1.968e-04
[15,   200] loss: 1.968e-04
Training loss: 0.000, train NMSE: -6.355e+00
Validation loss: 0.000, valid_NMSE: -6.818e+00

Best validation loss: -6.817777156829834

Saving best model for epoch: 15

--------------------------------------------------
[INFO]: Epoch 16 of 200
Training
[16,   100] loss: 2.227e-04
[16,   200] loss: 2.205e-04
Validation
[16,   100] loss: 1.917e-04
[16,   200] loss: 1.917e-04
Training loss: 0.000, train NMSE: -6.425e+00
Validation loss: 0.000, valid_NMSE: -6.934e+00

Best validation loss: -6.93389368057251

Saving best model for epoch: 16

--------------------------------------------------
[INFO]: Epoch 17 of 200
Training
[17,   100] loss: 2.172e-04
[17,   200] loss: 2.150e-04
Validation
[17,   100] loss: 1.880e-04
[17,   200] loss: 1.880e-04
Training loss: 0.000, train NMSE: -6.446e+00
Validation loss: 0.000, valid_NMSE: -6.998e+00

Best validation loss: -6.998176574707031

Saving best model for epoch: 17

--------------------------------------------------
[INFO]: Epoch 18 of 200
Training
[18,   100] loss: 2.147e-04
[18,   200] loss: 2.077e-04
Validation
[18,   100] loss: 1.853e-04
[18,   200] loss: 1.853e-04
Training loss: 0.000, train NMSE: -6.678e+00
Validation loss: 0.000, valid_NMSE: -7.070e+00

Best validation loss: -7.069737911224365

Saving best model for epoch: 18

--------------------------------------------------
[INFO]: Epoch 19 of 200
Training
[19,   100] loss: 2.085e-04
[19,   200] loss: 2.052e-04
Validation
[19,   100] loss: 1.803e-04
[19,   200] loss: 1.803e-04
Training loss: 0.000, train NMSE: -6.834e+00
Validation loss: 0.000, valid_NMSE: -7.198e+00

Best validation loss: -7.197604179382324

Saving best model for epoch: 19

--------------------------------------------------
[INFO]: Epoch 20 of 200
Training
[20,   100] loss: 2.003e-04
[20,   200] loss: 2.051e-04
Validation
[20,   100] loss: 1.769e-04
[20,   200] loss: 1.769e-04
Training loss: 0.000, train NMSE: -6.620e+00
Validation loss: 0.000, valid_NMSE: -7.277e+00

Best validation loss: -7.276670932769775

Saving best model for epoch: 20

--------------------------------------------------
[INFO]: Epoch 21 of 200
Training
[21,   100] loss: 1.982e-04
[21,   200] loss: 1.991e-04
Validation
[21,   100] loss: 1.738e-04
[21,   200] loss: 1.738e-04
Training loss: 0.000, train NMSE: -7.464e+00
Validation loss: 0.000, valid_NMSE: -7.341e+00

Best validation loss: -7.34114933013916

Saving best model for epoch: 21

--------------------------------------------------
[INFO]: Epoch 22 of 200
Training
[22,   100] loss: 1.954e-04
[22,   200] loss: 1.951e-04
Validation
[22,   100] loss: 1.720e-04
[22,   200] loss: 1.720e-04
Training loss: 0.000, train NMSE: -6.322e+00
Validation loss: 0.000, valid_NMSE: -7.372e+00

Best validation loss: -7.371662139892578

Saving best model for epoch: 22

--------------------------------------------------
[INFO]: Epoch 23 of 200
Training
[23,   100] loss: 1.915e-04
[23,   200] loss: 1.924e-04
Validation
[23,   100] loss: 1.687e-04
[23,   200] loss: 1.687e-04
Training loss: 0.000, train NMSE: -6.239e+00
Validation loss: 0.000, valid_NMSE: -7.452e+00

Best validation loss: -7.451944351196289

Saving best model for epoch: 23

--------------------------------------------------
[INFO]: Epoch 24 of 200
Training
[24,   100] loss: 1.876e-04
[24,   200] loss: 1.900e-04
Validation
[24,   100] loss: 1.660e-04
[24,   200] loss: 1.660e-04
Training loss: 0.000, train NMSE: -7.016e+00
Validation loss: 0.000, valid_NMSE: -7.511e+00

Best validation loss: -7.511405944824219

Saving best model for epoch: 24

--------------------------------------------------
[INFO]: Epoch 25 of 200
Training
[25,   100] loss: 1.876e-04
[25,   200] loss: 1.848e-04
Validation
[25,   100] loss: 1.639e-04
[25,   200] loss: 1.639e-04
Training loss: 0.000, train NMSE: -7.073e+00
Validation loss: 0.000, valid_NMSE: -7.555e+00

Best validation loss: -7.555186748504639

Saving best model for epoch: 25

--------------------------------------------------
[INFO]: Epoch 26 of 200
Training
[26,   100] loss: 1.851e-04
[26,   200] loss: 1.817e-04
Validation
[26,   100] loss: 1.623e-04
[26,   200] loss: 1.623e-04
Training loss: 0.000, train NMSE: -7.458e+00
Validation loss: 0.000, valid_NMSE: -7.601e+00

Best validation loss: -7.600856304168701

Saving best model for epoch: 26

--------------------------------------------------
[INFO]: Epoch 27 of 200
Training
[27,   100] loss: 1.798e-04
[27,   200] loss: 1.816e-04
Validation
[27,   100] loss: 1.600e-04
[27,   200] loss: 1.600e-04
Training loss: 0.000, train NMSE: -6.945e+00
Validation loss: 0.000, valid_NMSE: -7.673e+00

Best validation loss: -7.673348426818848

Saving best model for epoch: 27

--------------------------------------------------
[INFO]: Epoch 28 of 200
Training
[28,   100] loss: 1.799e-04
[28,   200] loss: 1.765e-04
Validation
[28,   100] loss: 1.577e-04
[28,   200] loss: 1.577e-04
Training loss: 0.000, train NMSE: -7.377e+00
Validation loss: 0.000, valid_NMSE: -7.722e+00

Best validation loss: -7.72240686416626

Saving best model for epoch: 28

--------------------------------------------------
[INFO]: Epoch 29 of 200
Training
[29,   100] loss: 1.749e-04
[29,   200] loss: 1.769e-04
Validation
[29,   100] loss: 1.559e-04
[29,   200] loss: 1.559e-04
Training loss: 0.000, train NMSE: -7.190e+00
Validation loss: 0.000, valid_NMSE: -7.756e+00

Best validation loss: -7.756180286407471

Saving best model for epoch: 29

--------------------------------------------------
[INFO]: Epoch 30 of 200
Training
[30,   100] loss: 1.720e-04
[30,   200] loss: 1.749e-04
Validation
[30,   100] loss: 1.545e-04
[30,   200] loss: 1.545e-04
Training loss: 0.000, train NMSE: -7.140e+00
Validation loss: 0.000, valid_NMSE: -7.781e+00

Best validation loss: -7.781424045562744

Saving best model for epoch: 30

--------------------------------------------------
[INFO]: Epoch 31 of 200
Training
[31,   100] loss: 1.699e-04
[31,   200] loss: 1.728e-04
Validation
[31,   100] loss: 1.520e-04
[31,   200] loss: 1.520e-04
Training loss: 0.000, train NMSE: -7.033e+00
Validation loss: 0.000, valid_NMSE: -7.857e+00

Best validation loss: -7.857475757598877

Saving best model for epoch: 31

--------------------------------------------------
[INFO]: Epoch 32 of 200
Training
[32,   100] loss: 1.688e-04
[32,   200] loss: 1.693e-04
Validation
[32,   100] loss: 1.501e-04
[32,   200] loss: 1.501e-04
Training loss: 0.000, train NMSE: -7.371e+00
Validation loss: 0.000, valid_NMSE: -7.908e+00

Best validation loss: -7.907583236694336

Saving best model for epoch: 32

--------------------------------------------------
[INFO]: Epoch 33 of 200
Training
[33,   100] loss: 1.668e-04
[33,   200] loss: 1.672e-04
Validation
[33,   100] loss: 1.489e-04
[33,   200] loss: 1.489e-04
Training loss: 0.000, train NMSE: -7.684e+00
Validation loss: 0.000, valid_NMSE: -7.953e+00

Best validation loss: -7.9532623291015625

Saving best model for epoch: 33

--------------------------------------------------
[INFO]: Epoch 34 of 200
Training
[34,   100] loss: 1.672e-04
[34,   200] loss: 1.628e-04
Validation
[34,   100] loss: 1.470e-04
[34,   200] loss: 1.470e-04
Training loss: 0.000, train NMSE: -7.364e+00
Validation loss: 0.000, valid_NMSE: -7.983e+00

Best validation loss: -7.983152389526367

Saving best model for epoch: 34

--------------------------------------------------
[INFO]: Epoch 35 of 200
Training
[35,   100] loss: 1.625e-04
[35,   200] loss: 1.631e-04
Validation
[35,   100] loss: 1.457e-04
[35,   200] loss: 1.457e-04
Training loss: 0.000, train NMSE: -8.261e+00
Validation loss: 0.000, valid_NMSE: -8.025e+00

Best validation loss: -8.025410652160645

Saving best model for epoch: 35

--------------------------------------------------
[INFO]: Epoch 36 of 200
Training
[36,   100] loss: 1.594e-04
[36,   200] loss: 1.620e-04
Validation
[36,   100] loss: 1.433e-04
[36,   200] loss: 1.433e-04
Training loss: 0.000, train NMSE: -7.710e+00
Validation loss: 0.000, valid_NMSE: -8.078e+00

Best validation loss: -8.077920913696289

Saving best model for epoch: 36

--------------------------------------------------
[INFO]: Epoch 37 of 200
Training
[37,   100] loss: 1.601e-04
[37,   200] loss: 1.579e-04
Validation
[37,   100] loss: 1.420e-04
[37,   200] loss: 1.420e-04
Training loss: 0.000, train NMSE: -8.268e+00
Validation loss: 0.000, valid_NMSE: -8.103e+00

Best validation loss: -8.103060722351074

Saving best model for epoch: 37

--------------------------------------------------
[INFO]: Epoch 38 of 200
Training
[38,   100] loss: 1.563e-04
[38,   200] loss: 1.576e-04
Validation
[38,   100] loss: 1.406e-04
[38,   200] loss: 1.406e-04
Training loss: 0.000, train NMSE: -7.537e+00
Validation loss: 0.000, valid_NMSE: -8.136e+00

Best validation loss: -8.13647747039795

Saving best model for epoch: 38

--------------------------------------------------
[INFO]: Epoch 39 of 200
Training
[39,   100] loss: 1.546e-04
[39,   200] loss: 1.555e-04
Validation
[39,   100] loss: 1.393e-04
[39,   200] loss: 1.393e-04
Training loss: 0.000, train NMSE: -7.177e+00
Validation loss: 0.000, valid_NMSE: -8.184e+00

Best validation loss: -8.183988571166992

Saving best model for epoch: 39

--------------------------------------------------
[INFO]: Epoch 40 of 200
Training
[40,   100] loss: 1.511e-04
[40,   200] loss: 1.552e-04
Validation
[40,   100] loss: 1.374e-04
[40,   200] loss: 1.374e-04
Training loss: 0.000, train NMSE: -7.663e+00
Validation loss: 0.000, valid_NMSE: -8.235e+00

Best validation loss: -8.234918594360352

Saving best model for epoch: 40

--------------------------------------------------
[INFO]: Epoch 41 of 200
Training
[41,   100] loss: 1.508e-04
[41,   200] loss: 1.518e-04
Validation
[41,   100] loss: 1.362e-04
[41,   200] loss: 1.362e-04
Training loss: 0.000, train NMSE: -8.122e+00
Validation loss: 0.000, valid_NMSE: -8.274e+00

Best validation loss: -8.274032592773438

Saving best model for epoch: 41

--------------------------------------------------
[INFO]: Epoch 42 of 200
Training
[42,   100] loss: 1.480e-04
[42,   200] loss: 1.514e-04
Validation
[42,   100] loss: 1.353e-04
[42,   200] loss: 1.353e-04
Training loss: 0.000, train NMSE: -8.344e+00
Validation loss: 0.000, valid_NMSE: -8.295e+00

Best validation loss: -8.294515609741211

Saving best model for epoch: 42

--------------------------------------------------
[INFO]: Epoch 43 of 200
Training
[43,   100] loss: 1.488e-04
[43,   200] loss: 1.469e-04
Validation
[43,   100] loss: 1.332e-04
[43,   200] loss: 1.332e-04
Training loss: 0.000, train NMSE: -8.353e+00
Validation loss: 0.000, valid_NMSE: -8.366e+00

Best validation loss: -8.366228103637695

Saving best model for epoch: 43

--------------------------------------------------
[INFO]: Epoch 44 of 200
Training
[44,   100] loss: 1.442e-04
[44,   200] loss: 1.488e-04
Validation
[44,   100] loss: 1.319e-04
[44,   200] loss: 1.319e-04
Training loss: 0.000, train NMSE: -7.943e+00
Validation loss: 0.000, valid_NMSE: -8.384e+00

Best validation loss: -8.38418197631836

Saving best model for epoch: 44

--------------------------------------------------
[INFO]: Epoch 45 of 200
Training
[45,   100] loss: 1.424e-04
[45,   200] loss: 1.468e-04
Validation
[45,   100] loss: 1.307e-04
[45,   200] loss: 1.307e-04
Training loss: 0.000, train NMSE: -7.957e+00
Validation loss: 0.000, valid_NMSE: -8.427e+00

Best validation loss: -8.426663398742676

Saving best model for epoch: 45

--------------------------------------------------
[INFO]: Epoch 46 of 200
Training
[46,   100] loss: 1.437e-04
[46,   200] loss: 1.425e-04
Validation
[46,   100] loss: 1.296e-04
[46,   200] loss: 1.296e-04
Training loss: 0.000, train NMSE: -8.530e+00
Validation loss: 0.000, valid_NMSE: -8.449e+00

Best validation loss: -8.449199676513672

Saving best model for epoch: 46

--------------------------------------------------
[INFO]: Epoch 47 of 200
Training
[47,   100] loss: 1.442e-04
[47,   200] loss: 1.395e-04
Validation
[47,   100] loss: 1.283e-04
[47,   200] loss: 1.283e-04
Training loss: 0.000, train NMSE: -8.314e+00
Validation loss: 0.000, valid_NMSE: -8.511e+00

Best validation loss: -8.510712623596191

Saving best model for epoch: 47

--------------------------------------------------
[INFO]: Epoch 48 of 200
Training
[48,   100] loss: 1.427e-04
[48,   200] loss: 1.385e-04
Validation
[48,   100] loss: 1.275e-04
[48,   200] loss: 1.275e-04
Training loss: 0.000, train NMSE: -9.006e+00
Validation loss: 0.000, valid_NMSE: -8.566e+00

Best validation loss: -8.56644344329834

Saving best model for epoch: 48

--------------------------------------------------
[INFO]: Epoch 49 of 200
Training
[49,   100] loss: 1.408e-04
[49,   200] loss: 1.373e-04
Validation
[49,   100] loss: 1.261e-04
[49,   200] loss: 1.261e-04
Training loss: 0.000, train NMSE: -8.205e+00
Validation loss: 0.000, valid_NMSE: -8.587e+00

Best validation loss: -8.58706283569336

Saving best model for epoch: 49

--------------------------------------------------
[INFO]: Epoch 50 of 200
Training
[50,   100] loss: 1.389e-04
[50,   200] loss: 1.370e-04
Validation
[50,   100] loss: 1.255e-04
[50,   200] loss: 1.255e-04
Training loss: 0.000, train NMSE: -9.095e+00
Validation loss: 0.000, valid_NMSE: -8.600e+00

Best validation loss: -8.600336074829102

Saving best model for epoch: 50

--------------------------------------------------
[INFO]: Epoch 51 of 200
Training
[51,   100] loss: 1.385e-04
[51,   200] loss: 1.340e-04
Validation
[51,   100] loss: 1.243e-04
[51,   200] loss: 1.243e-04
Training loss: 0.000, train NMSE: -8.507e+00
Validation loss: 0.000, valid_NMSE: -8.659e+00

Best validation loss: -8.659136772155762

Saving best model for epoch: 51

--------------------------------------------------
[INFO]: Epoch 52 of 200
Training
[52,   100] loss: 1.341e-04
[52,   200] loss: 1.360e-04
Validation
[52,   100] loss: 1.232e-04
[52,   200] loss: 1.232e-04
Training loss: 0.000, train NMSE: -9.047e+00
Validation loss: 0.000, valid_NMSE: -8.699e+00

Best validation loss: -8.699326515197754

Saving best model for epoch: 52

--------------------------------------------------
[INFO]: Epoch 53 of 200
Training
[53,   100] loss: 1.336e-04
[53,   200] loss: 1.339e-04
Validation
[53,   100] loss: 1.223e-04
[53,   200] loss: 1.223e-04
Training loss: 0.000, train NMSE: -8.013e+00
Validation loss: 0.000, valid_NMSE: -8.743e+00

Best validation loss: -8.743265151977539

Saving best model for epoch: 53

--------------------------------------------------
[INFO]: Epoch 54 of 200
Training
[54,   100] loss: 1.319e-04
[54,   200] loss: 1.332e-04
Validation
[54,   100] loss: 1.214e-04
[54,   200] loss: 1.214e-04
Training loss: 0.000, train NMSE: -8.321e+00
Validation loss: 0.000, valid_NMSE: -8.783e+00

Best validation loss: -8.782590866088867

Saving best model for epoch: 54

--------------------------------------------------
[INFO]: Epoch 55 of 200
Training
[55,   100] loss: 1.321e-04
[55,   200] loss: 1.304e-04
Validation
[55,   100] loss: 1.200e-04
[55,   200] loss: 1.200e-04
Training loss: 0.000, train NMSE: -9.211e+00
Validation loss: 0.000, valid_NMSE: -8.805e+00

Best validation loss: -8.804916381835938

Saving best model for epoch: 55

--------------------------------------------------
[INFO]: Epoch 56 of 200
Training
[56,   100] loss: 1.298e-04
[56,   200] loss: 1.303e-04
Validation
[56,   100] loss: 1.202e-04
[56,   200] loss: 1.202e-04
Training loss: 0.000, train NMSE: -9.309e+00
Validation loss: 0.000, valid_NMSE: -8.784e+00
--------------------------------------------------
[INFO]: Epoch 57 of 200
Training
[57,   100] loss: 1.283e-04
[57,   200] loss: 1.296e-04
Validation
[57,   100] loss: 1.193e-04
[57,   200] loss: 1.193e-04
Training loss: 0.000, train NMSE: -8.852e+00
Validation loss: 0.000, valid_NMSE: -8.823e+00

Best validation loss: -8.822914123535156

Saving best model for epoch: 57

--------------------------------------------------
[INFO]: Epoch 58 of 200
Training
[58,   100] loss: 1.271e-04
[58,   200] loss: 1.286e-04
Validation
[58,   100] loss: 1.176e-04
[58,   200] loss: 1.176e-04
Training loss: 0.000, train NMSE: -8.856e+00
Validation loss: 0.000, valid_NMSE: -8.907e+00

Best validation loss: -8.907048225402832

Saving best model for epoch: 58

--------------------------------------------------
[INFO]: Epoch 59 of 200
Training
[59,   100] loss: 1.263e-04
[59,   200] loss: 1.269e-04
Validation
[59,   100] loss: 1.171e-04
[59,   200] loss: 1.171e-04
Training loss: 0.000, train NMSE: -8.090e+00
Validation loss: 0.000, valid_NMSE: -8.915e+00

Best validation loss: -8.914968490600586

Saving best model for epoch: 59

--------------------------------------------------
[INFO]: Epoch 60 of 200
Training
[60,   100] loss: 1.273e-04
[60,   200] loss: 1.242e-04
Validation
[60,   100] loss: 1.162e-04
[60,   200] loss: 1.162e-04
Training loss: 0.000, train NMSE: -8.527e+00
Validation loss: 0.000, valid_NMSE: -8.957e+00

Best validation loss: -8.9572172164917

Saving best model for epoch: 60

--------------------------------------------------
[INFO]: Epoch 61 of 200
Training
[61,   100] loss: 1.244e-04
[61,   200] loss: 1.249e-04
Validation
[61,   100] loss: 1.153e-04
[61,   200] loss: 1.153e-04
Training loss: 0.000, train NMSE: -9.257e+00
Validation loss: 0.000, valid_NMSE: -8.984e+00

Best validation loss: -8.983563423156738

Saving best model for epoch: 61

--------------------------------------------------
[INFO]: Epoch 62 of 200
Training
[62,   100] loss: 1.225e-04
[62,   200] loss: 1.247e-04
Validation
[62,   100] loss: 1.146e-04
[62,   200] loss: 1.146e-04
Training loss: 0.000, train NMSE: -7.836e+00
Validation loss: 0.000, valid_NMSE: -9.039e+00

Best validation loss: -9.038604736328125

Saving best model for epoch: 62

--------------------------------------------------
[INFO]: Epoch 63 of 200
Training
[63,   100] loss: 1.229e-04
[63,   200] loss: 1.221e-04
Validation
[63,   100] loss: 1.137e-04
[63,   200] loss: 1.137e-04
Training loss: 0.000, train NMSE: -9.332e+00
Validation loss: 0.000, valid_NMSE: -9.062e+00

Best validation loss: -9.062347412109375

Saving best model for epoch: 63

--------------------------------------------------
[INFO]: Epoch 64 of 200
Training
[64,   100] loss: 1.212e-04
[64,   200] loss: 1.224e-04
Validation
[64,   100] loss: 1.137e-04
[64,   200] loss: 1.137e-04
Training loss: 0.000, train NMSE: -9.070e+00
Validation loss: 0.000, valid_NMSE: -9.066e+00

Best validation loss: -9.065876007080078

Saving best model for epoch: 64

--------------------------------------------------
[INFO]: Epoch 65 of 200
Training
[65,   100] loss: 1.210e-04
[65,   200] loss: 1.205e-04
Validation
[65,   100] loss: 1.127e-04
[65,   200] loss: 1.127e-04
Training loss: 0.000, train NMSE: -9.222e+00
Validation loss: 0.000, valid_NMSE: -9.102e+00

Best validation loss: -9.102109909057617

Saving best model for epoch: 65

--------------------------------------------------
[INFO]: Epoch 66 of 200
Training
[66,   100] loss: 1.191e-04
[66,   200] loss: 1.205e-04
Validation
[66,   100] loss: 1.125e-04
[66,   200] loss: 1.125e-04
Training loss: 0.000, train NMSE: -9.020e+00
Validation loss: 0.000, valid_NMSE: -9.120e+00

Best validation loss: -9.120360374450684

Saving best model for epoch: 66

--------------------------------------------------
[INFO]: Epoch 67 of 200
Training
[67,   100] loss: 1.181e-04
[67,   200] loss: 1.197e-04
Validation
[67,   100] loss: 1.118e-04
[67,   200] loss: 1.118e-04
Training loss: 0.000, train NMSE: -9.443e+00
Validation loss: 0.000, valid_NMSE: -9.153e+00

Best validation loss: -9.15336799621582

Saving best model for epoch: 67

--------------------------------------------------
[INFO]: Epoch 68 of 200
Training
[68,   100] loss: 1.157e-04
[68,   200] loss: 1.204e-04
Validation
[68,   100] loss: 1.110e-04
[68,   200] loss: 1.110e-04
Training loss: 0.000, train NMSE: -8.313e+00
Validation loss: 0.000, valid_NMSE: -9.162e+00

Best validation loss: -9.161917686462402

Saving best model for epoch: 68

--------------------------------------------------
[INFO]: Epoch 69 of 200
Training
[69,   100] loss: 1.177e-04
[69,   200] loss: 1.164e-04
Validation
[69,   100] loss: 1.103e-04
[69,   200] loss: 1.103e-04
Training loss: 0.000, train NMSE: -8.458e+00
Validation loss: 0.000, valid_NMSE: -9.205e+00

Best validation loss: -9.204501152038574

Saving best model for epoch: 69

--------------------------------------------------
[INFO]: Epoch 70 of 200
Training
[70,   100] loss: 1.155e-04
[70,   200] loss: 1.168e-04
Validation
[70,   100] loss: 1.105e-04
[70,   200] loss: 1.105e-04
Training loss: 0.000, train NMSE: -8.803e+00
Validation loss: 0.000, valid_NMSE: -9.169e+00
--------------------------------------------------
[INFO]: Epoch 71 of 200
Training
[71,   100] loss: 1.156e-04
[71,   200] loss: 1.149e-04
Validation
[71,   100] loss: 1.092e-04
[71,   200] loss: 1.092e-04
Training loss: 0.000, train NMSE: -8.750e+00
Validation loss: 0.000, valid_NMSE: -9.238e+00

Best validation loss: -9.237870216369629

Saving best model for epoch: 71

--------------------------------------------------
[INFO]: Epoch 72 of 200
Training
[72,   100] loss: 1.142e-04
[72,   200] loss: 1.149e-04
Validation
[72,   100] loss: 1.082e-04
[72,   200] loss: 1.082e-04
Training loss: 0.000, train NMSE: -9.049e+00
Validation loss: 0.000, valid_NMSE: -9.305e+00

Best validation loss: -9.305294036865234

Saving best model for epoch: 72

--------------------------------------------------
[INFO]: Epoch 73 of 200
Training
[73,   100] loss: 1.129e-04
[73,   200] loss: 1.141e-04
Validation
[73,   100] loss: 1.081e-04
[73,   200] loss: 1.081e-04
Training loss: 0.000, train NMSE: -9.650e+00
Validation loss: 0.000, valid_NMSE: -9.287e+00
--------------------------------------------------
[INFO]: Epoch 74 of 200
Training
[74,   100] loss: 1.133e-04
[74,   200] loss: 1.121e-04
Validation
[74,   100] loss: 1.074e-04
[74,   200] loss: 1.074e-04
Training loss: 0.000, train NMSE: -9.446e+00
Validation loss: 0.000, valid_NMSE: -9.340e+00

Best validation loss: -9.339887619018555

Saving best model for epoch: 74

--------------------------------------------------
[INFO]: Epoch 75 of 200
Training
[75,   100] loss: 1.121e-04
[75,   200] loss: 1.118e-04
Validation
[75,   100] loss: 1.081e-04
[75,   200] loss: 1.081e-04
Training loss: 0.000, train NMSE: -9.014e+00
Validation loss: 0.000, valid_NMSE: -9.257e+00
--------------------------------------------------
[INFO]: Epoch 76 of 200
Training
[76,   100] loss: 1.107e-04
[76,   200] loss: 1.117e-04
Validation
[76,   100] loss: 1.063e-04
[76,   200] loss: 1.063e-04
Training loss: 0.000, train NMSE: -9.279e+00
Validation loss: 0.000, valid_NMSE: -9.364e+00

Best validation loss: -9.364049911499023

Saving best model for epoch: 76

--------------------------------------------------
[INFO]: Epoch 77 of 200
Training
[77,   100] loss: 1.100e-04
[77,   200] loss: 1.106e-04
Validation
[77,   100] loss: 1.058e-04
[77,   200] loss: 1.058e-04
Training loss: 0.000, train NMSE: -9.162e+00
Validation loss: 0.000, valid_NMSE: -9.342e+00
--------------------------------------------------
[INFO]: Epoch 78 of 200
Training
[78,   100] loss: 1.088e-04
[78,   200] loss: 1.104e-04
Validation
[78,   100] loss: 1.057e-04
[78,   200] loss: 1.057e-04
Training loss: 0.000, train NMSE: -9.560e+00
Validation loss: 0.000, valid_NMSE: -9.366e+00

Best validation loss: -9.36603832244873

Saving best model for epoch: 78

--------------------------------------------------
[INFO]: Epoch 79 of 200
Training
[79,   100] loss: 1.094e-04
[79,   200] loss: 1.084e-04
Validation
[79,   100] loss: 1.047e-04
[79,   200] loss: 1.047e-04
Training loss: 0.000, train NMSE: -9.090e+00
Validation loss: 0.000, valid_NMSE: -9.398e+00

Best validation loss: -9.398090362548828

Saving best model for epoch: 79

--------------------------------------------------
[INFO]: Epoch 80 of 200
Training
[80,   100] loss: 1.065e-04
[80,   200] loss: 1.097e-04
Validation
[80,   100] loss: 1.043e-04
[80,   200] loss: 1.043e-04
Training loss: 0.000, train NMSE: -9.602e+00
Validation loss: 0.000, valid_NMSE: -9.439e+00

Best validation loss: -9.439452171325684

Saving best model for epoch: 80

--------------------------------------------------
[INFO]: Epoch 81 of 200
Training
[81,   100] loss: 1.058e-04
[81,   200] loss: 1.092e-04
Validation
[81,   100] loss: 1.042e-04
[81,   200] loss: 1.042e-04
Training loss: 0.000, train NMSE: -9.091e+00
Validation loss: 0.000, valid_NMSE: -9.422e+00
--------------------------------------------------
[INFO]: Epoch 82 of 200
Training
[82,   100] loss: 1.054e-04
[82,   200] loss: 1.081e-04
Validation
[82,   100] loss: 1.041e-04
[82,   200] loss: 1.041e-04
Training loss: 0.000, train NMSE: -9.340e+00
Validation loss: 0.000, valid_NMSE: -9.436e+00
--------------------------------------------------
[INFO]: Epoch 83 of 200
Training
[83,   100] loss: 1.052e-04
[83,   200] loss: 1.063e-04
Validation
[83,   100] loss: 1.028e-04
[83,   200] loss: 1.028e-04
Training loss: 0.000, train NMSE: -9.715e+00
Validation loss: 0.000, valid_NMSE: -9.480e+00

Best validation loss: -9.480039596557617

Saving best model for epoch: 83

--------------------------------------------------
[INFO]: Epoch 84 of 200
Training
[84,   100] loss: 1.049e-04
[84,   200] loss: 1.054e-04
Validation
[84,   100] loss: 1.031e-04
[84,   200] loss: 1.031e-04
Training loss: 0.000, train NMSE: -1.007e+01
Validation loss: 0.000, valid_NMSE: -9.437e+00
--------------------------------------------------
[INFO]: Epoch 85 of 200
Training
[85,   100] loss: 1.038e-04
[85,   200] loss: 1.053e-04
Validation
[85,   100] loss: 1.019e-04
[85,   200] loss: 1.019e-04
Training loss: 0.000, train NMSE: -9.799e+00
Validation loss: 0.000, valid_NMSE: -9.498e+00

Best validation loss: -9.49799633026123

Saving best model for epoch: 85

--------------------------------------------------
[INFO]: Epoch 86 of 200
Training
[86,   100] loss: 1.035e-04
[86,   200] loss: 1.040e-04
Validation
[86,   100] loss: 1.014e-04
[86,   200] loss: 1.014e-04
Training loss: 0.000, train NMSE: -9.962e+00
Validation loss: 0.000, valid_NMSE: -9.508e+00

Best validation loss: -9.5081787109375

Saving best model for epoch: 86

--------------------------------------------------
[INFO]: Epoch 87 of 200
Training
[87,   100] loss: 1.020e-04
[87,   200] loss: 1.041e-04
Validation
[87,   100] loss: 1.011e-04
[87,   200] loss: 1.011e-04
Training loss: 0.000, train NMSE: -9.666e+00
Validation loss: 0.000, valid_NMSE: -9.515e+00

Best validation loss: -9.515268325805664

Saving best model for epoch: 87

--------------------------------------------------
[INFO]: Epoch 88 of 200
Training
[88,   100] loss: 1.024e-04
[88,   200] loss: 1.024e-04
Validation
[88,   100] loss: 1.020e-04
[88,   200] loss: 1.020e-04
Training loss: 0.000, train NMSE: -9.773e+00
Validation loss: 0.000, valid_NMSE: -9.440e+00
--------------------------------------------------
[INFO]: Epoch 89 of 200
Training
[89,   100] loss: 1.012e-04
[89,   200] loss: 1.019e-04
Validation
[89,   100] loss: 1.007e-04
[89,   200] loss: 1.007e-04
Training loss: 0.000, train NMSE: -1.007e+01
Validation loss: 0.000, valid_NMSE: -9.499e+00
--------------------------------------------------
[INFO]: Epoch 90 of 200
Training
[90,   100] loss: 9.958e-05
[90,   200] loss: 1.018e-04
Validation
[90,   100] loss: 1.002e-04
[90,   200] loss: 1.002e-04
Training loss: 0.000, train NMSE: -9.632e+00
Validation loss: 0.000, valid_NMSE: -9.517e+00

Best validation loss: -9.517271041870117

Saving best model for epoch: 90

--------------------------------------------------
[INFO]: Epoch 91 of 200
Training
[91,   100] loss: 9.960e-05
[91,   200] loss: 1.001e-04
Validation
[91,   100] loss: 9.931e-05
[91,   200] loss: 9.931e-05
Training loss: 0.000, train NMSE: -1.042e+01
Validation loss: 0.000, valid_NMSE: -9.548e+00

Best validation loss: -9.548470497131348

Saving best model for epoch: 91

--------------------------------------------------
[INFO]: Epoch 92 of 200
Training
[92,   100] loss: 9.946e-05
[92,   200] loss: 9.939e-05
Validation
[92,   100] loss: 9.901e-05
[92,   200] loss: 9.901e-05
Training loss: 0.000, train NMSE: -9.895e+00
Validation loss: 0.000, valid_NMSE: -9.551e+00

Best validation loss: -9.551319122314453

Saving best model for epoch: 92

--------------------------------------------------
[INFO]: Epoch 93 of 200
Training
[93,   100] loss: 9.762e-05
[93,   200] loss: 9.940e-05
Validation
[93,   100] loss: 9.877e-05
[93,   200] loss: 9.877e-05
Training loss: 0.000, train NMSE: -9.794e+00
Validation loss: 0.000, valid_NMSE: -9.570e+00

Best validation loss: -9.570305824279785

Saving best model for epoch: 93

--------------------------------------------------
[INFO]: Epoch 94 of 200
Training
[94,   100] loss: 9.695e-05
[94,   200] loss: 9.833e-05
Validation
[94,   100] loss: 9.771e-05
[94,   200] loss: 9.771e-05
Training loss: 0.000, train NMSE: -1.037e+01
Validation loss: 0.000, valid_NMSE: -9.607e+00

Best validation loss: -9.607244491577148

Saving best model for epoch: 94

--------------------------------------------------
[INFO]: Epoch 95 of 200
Training
[95,   100] loss: 9.672e-05
[95,   200] loss: 9.708e-05
Validation
[95,   100] loss: 9.772e-05
[95,   200] loss: 9.772e-05
Training loss: 0.000, train NMSE: -9.620e+00
Validation loss: 0.000, valid_NMSE: -9.617e+00

Best validation loss: -9.61735725402832

Saving best model for epoch: 95

--------------------------------------------------
[INFO]: Epoch 96 of 200
Training
[96,   100] loss: 9.564e-05
[96,   200] loss: 9.691e-05
Validation
[96,   100] loss: 9.670e-05
[96,   200] loss: 9.670e-05
Training loss: 0.000, train NMSE: -1.035e+01
Validation loss: 0.000, valid_NMSE: -9.653e+00

Best validation loss: -9.652566909790039

Saving best model for epoch: 96

--------------------------------------------------
[INFO]: Epoch 97 of 200
Training
[97,   100] loss: 9.453e-05
[97,   200] loss: 9.697e-05
Validation
[97,   100] loss: 9.748e-05
[97,   200] loss: 9.748e-05
Training loss: 0.000, train NMSE: -9.661e+00
Validation loss: 0.000, valid_NMSE: -9.591e+00
--------------------------------------------------
[INFO]: Epoch 98 of 200
Training
[98,   100] loss: 9.411e-05
[98,   200] loss: 9.582e-05
Validation
[98,   100] loss: 9.618e-05
[98,   200] loss: 9.618e-05
Training loss: 0.000, train NMSE: -1.021e+01
Validation loss: 0.000, valid_NMSE: -9.658e+00

Best validation loss: -9.658470153808594

Saving best model for epoch: 98

--------------------------------------------------
[INFO]: Epoch 99 of 200
Training
[99,   100] loss: 9.488e-05
[99,   200] loss: 9.365e-05
Validation
[99,   100] loss: 9.598e-05
[99,   200] loss: 9.598e-05
Training loss: 0.000, train NMSE: -9.557e+00
Validation loss: 0.000, valid_NMSE: -9.650e+00
--------------------------------------------------
[INFO]: Epoch 100 of 200
Training
[100,   100] loss: 9.346e-05
[100,   200] loss: 9.422e-05
Validation
[100,   100] loss: 9.513e-05
[100,   200] loss: 9.513e-05
Training loss: 0.000, train NMSE: -9.677e+00
Validation loss: 0.000, valid_NMSE: -9.676e+00

Best validation loss: -9.676490783691406

Saving best model for epoch: 100

--------------------------------------------------
[INFO]: Epoch 101 of 200
Training
[101,   100] loss: 9.310e-05
[101,   200] loss: 9.296e-05
Validation
[101,   100] loss: 9.505e-05
[101,   200] loss: 9.505e-05
Training loss: 0.000, train NMSE: -1.019e+01
Validation loss: 0.000, valid_NMSE: -9.708e+00

Best validation loss: -9.707818031311035

Saving best model for epoch: 101

--------------------------------------------------
[INFO]: Epoch 102 of 200
Training
[102,   100] loss: 9.295e-05
[102,   200] loss: 9.244e-05
Validation
[102,   100] loss: 9.525e-05
[102,   200] loss: 9.525e-05
Training loss: 0.000, train NMSE: -9.768e+00
Validation loss: 0.000, valid_NMSE: -9.650e+00
--------------------------------------------------
[INFO]: Epoch 103 of 200
Training
[103,   100] loss: 9.014e-05
[103,   200] loss: 9.366e-05
Validation
[103,   100] loss: 9.402e-05
[103,   200] loss: 9.402e-05
Training loss: 0.000, train NMSE: -1.040e+01
Validation loss: 0.000, valid_NMSE: -9.728e+00

Best validation loss: -9.727848052978516

Saving best model for epoch: 103

--------------------------------------------------
[INFO]: Epoch 104 of 200
Training
[104,   100] loss: 9.062e-05
[104,   200] loss: 9.236e-05
Validation
[104,   100] loss: 9.458e-05
[104,   200] loss: 9.458e-05
Training loss: 0.000, train NMSE: -1.005e+01
Validation loss: 0.000, valid_NMSE: -9.683e+00
--------------------------------------------------
[INFO]: Epoch 105 of 200
Training
[105,   100] loss: 8.985e-05
[105,   200] loss: 9.210e-05
Validation
[105,   100] loss: 9.278e-05
[105,   200] loss: 9.278e-05
Training loss: 0.000, train NMSE: -1.025e+01
Validation loss: 0.000, valid_NMSE: -9.767e+00

Best validation loss: -9.76714038848877

Saving best model for epoch: 105

--------------------------------------------------
[INFO]: Epoch 106 of 200
Training
[106,   100] loss: 9.056e-05
[106,   200] loss: 9.018e-05
Validation
[106,   100] loss: 9.341e-05
[106,   200] loss: 9.341e-05
Training loss: 0.000, train NMSE: -1.037e+01
Validation loss: 0.000, valid_NMSE: -9.730e+00
--------------------------------------------------
[INFO]: Epoch 107 of 200
Training
[107,   100] loss: 8.960e-05
[107,   200] loss: 8.994e-05
Validation
[107,   100] loss: 9.288e-05
[107,   200] loss: 9.288e-05
Training loss: 0.000, train NMSE: -9.795e+00
Validation loss: 0.000, valid_NMSE: -9.752e+00
--------------------------------------------------
[INFO]: Epoch 108 of 200
Training
[108,   100] loss: 8.906e-05
[108,   200] loss: 8.965e-05
Validation
[108,   100] loss: 9.229e-05
[108,   200] loss: 9.229e-05
Training loss: 0.000, train NMSE: -1.088e+01
Validation loss: 0.000, valid_NMSE: -9.783e+00

Best validation loss: -9.782734870910645

Saving best model for epoch: 108

--------------------------------------------------
[INFO]: Epoch 109 of 200
Training
[109,   100] loss: 8.829e-05
[109,   200] loss: 8.915e-05
Validation
[109,   100] loss: 9.194e-05
[109,   200] loss: 9.194e-05
Training loss: 0.000, train NMSE: -1.010e+01
Validation loss: 0.000, valid_NMSE: -9.767e+00
--------------------------------------------------
[INFO]: Epoch 110 of 200
Training
[110,   100] loss: 8.841e-05
[110,   200] loss: 8.846e-05
Validation
[110,   100] loss: 9.213e-05
[110,   200] loss: 9.213e-05
Training loss: 0.000, train NMSE: -9.706e+00
Validation loss: 0.000, valid_NMSE: -9.772e+00
--------------------------------------------------
[INFO]: Epoch 111 of 200
Training
[111,   100] loss: 8.734e-05
[111,   200] loss: 8.834e-05
Validation
[111,   100] loss: 9.325e-05
[111,   200] loss: 9.325e-05
Training loss: 0.000, train NMSE: -1.033e+01
Validation loss: 0.000, valid_NMSE: -9.674e+00
--------------------------------------------------
[INFO]: Epoch 112 of 200
Training
[112,   100] loss: 8.759e-05
[112,   200] loss: 8.705e-05
Validation
[112,   100] loss: 9.185e-05
[112,   200] loss: 9.185e-05
Training loss: 0.000, train NMSE: -1.010e+01
Validation loss: 0.000, valid_NMSE: -9.733e+00
--------------------------------------------------
[INFO]: Epoch 113 of 200
Training
[113,   100] loss: 8.639e-05
[113,   200] loss: 8.730e-05
Validation
[113,   100] loss: 9.161e-05
[113,   200] loss: 9.161e-05
Training loss: 0.000, train NMSE: -1.034e+01
Validation loss: 0.000, valid_NMSE: -9.785e+00

Best validation loss: -9.78512954711914

Saving best model for epoch: 113

--------------------------------------------------
[INFO]: Epoch 114 of 200
Training
[114,   100] loss: 8.639e-05
[114,   200] loss: 8.676e-05
Validation
[114,   100] loss: 9.095e-05
[114,   200] loss: 9.095e-05
Training loss: 0.000, train NMSE: -1.076e+01
Validation loss: 0.000, valid_NMSE: -9.809e+00

Best validation loss: -9.808804512023926

Saving best model for epoch: 114

--------------------------------------------------
[INFO]: Epoch 115 of 200
Training
[115,   100] loss: 8.641e-05
[115,   200] loss: 8.637e-05
Validation
[115,   100] loss: 9.137e-05
[115,   200] loss: 9.137e-05
Training loss: 0.000, train NMSE: -1.044e+01
Validation loss: 0.000, valid_NMSE: -9.734e+00
--------------------------------------------------
[INFO]: Epoch 116 of 200
Training
[116,   100] loss: 8.461e-05
[116,   200] loss: 8.660e-05
Validation
[116,   100] loss: 9.012e-05
[116,   200] loss: 9.012e-05
Training loss: 0.000, train NMSE: -1.097e+01
Validation loss: 0.000, valid_NMSE: -9.810e+00

Best validation loss: -9.810382843017578

Saving best model for epoch: 116

--------------------------------------------------
[INFO]: Epoch 117 of 200
Training
[117,   100] loss: 8.414e-05
[117,   200] loss: 8.608e-05
Validation
[117,   100] loss: 9.112e-05
[117,   200] loss: 9.112e-05
Training loss: 0.000, train NMSE: -1.054e+01
Validation loss: 0.000, valid_NMSE: -9.742e+00
--------------------------------------------------
[INFO]: Epoch 118 of 200
Training
[118,   100] loss: 8.479e-05
[118,   200] loss: 8.493e-05
Validation
[118,   100] loss: 9.043e-05
[118,   200] loss: 9.043e-05
Training loss: 0.000, train NMSE: -1.004e+01
Validation loss: 0.000, valid_NMSE: -9.765e+00
--------------------------------------------------
[INFO]: Epoch 119 of 200
Training
[119,   100] loss: 8.485e-05
[119,   200] loss: 8.381e-05
Validation
[119,   100] loss: 9.136e-05
[119,   200] loss: 9.136e-05
Training loss: 0.000, train NMSE: -1.115e+01
Validation loss: 0.000, valid_NMSE: -9.703e+00
--------------------------------------------------
[INFO]: Epoch 120 of 200
Training
[120,   100] loss: 8.400e-05
[120,   200] loss: 8.461e-05
Validation
[120,   100] loss: 8.961e-05
[120,   200] loss: 8.961e-05
Training loss: 0.000, train NMSE: -1.053e+01
Validation loss: 0.000, valid_NMSE: -9.817e+00

Best validation loss: -9.817045211791992

Saving best model for epoch: 120

--------------------------------------------------
[INFO]: Epoch 121 of 200
Training
[121,   100] loss: 8.374e-05
[121,   200] loss: 8.355e-05
Validation
[121,   100] loss: 8.970e-05
[121,   200] loss: 8.970e-05
Training loss: 0.000, train NMSE: -1.049e+01
Validation loss: 0.000, valid_NMSE: -9.804e+00
--------------------------------------------------
[INFO]: Epoch 122 of 200
Training
[122,   100] loss: 8.285e-05
[122,   200] loss: 8.383e-05
Validation
[122,   100] loss: 8.909e-05
[122,   200] loss: 8.909e-05
Training loss: 0.000, train NMSE: -1.045e+01
Validation loss: 0.000, valid_NMSE: -9.862e+00

Best validation loss: -9.861859321594238

Saving best model for epoch: 122

--------------------------------------------------
[INFO]: Epoch 123 of 200
Training
[123,   100] loss: 8.241e-05
[123,   200] loss: 8.327e-05
Validation
[123,   100] loss: 9.082e-05
[123,   200] loss: 9.082e-05
Training loss: 0.000, train NMSE: -9.572e+00
Validation loss: 0.000, valid_NMSE: -9.754e+00
--------------------------------------------------
[INFO]: Epoch 124 of 200
Training
[124,   100] loss: 8.245e-05
[124,   200] loss: 8.279e-05
Validation
[124,   100] loss: 8.844e-05
[124,   200] loss: 8.844e-05
Training loss: 0.000, train NMSE: -1.009e+01
Validation loss: 0.000, valid_NMSE: -9.874e+00

Best validation loss: -9.87387752532959

Saving best model for epoch: 124

--------------------------------------------------
[INFO]: Epoch 125 of 200
Training
[125,   100] loss: 8.133e-05
[125,   200] loss: 8.315e-05
Validation
[125,   100] loss: 8.811e-05
[125,   200] loss: 8.811e-05
Training loss: 0.000, train NMSE: -1.044e+01
Validation loss: 0.000, valid_NMSE: -9.899e+00

Best validation loss: -9.89870548248291

Saving best model for epoch: 125

--------------------------------------------------
[INFO]: Epoch 126 of 200
Training
[126,   100] loss: 8.115e-05
[126,   200] loss: 8.238e-05
Validation
[126,   100] loss: 8.855e-05
[126,   200] loss: 8.855e-05
Training loss: 0.000, train NMSE: -1.027e+01
Validation loss: 0.000, valid_NMSE: -9.822e+00
--------------------------------------------------
[INFO]: Epoch 127 of 200
Training
[127,   100] loss: 8.104e-05
[127,   200] loss: 8.170e-05
Validation
[127,   100] loss: 8.802e-05
[127,   200] loss: 8.802e-05
Training loss: 0.000, train NMSE: -1.060e+01
Validation loss: 0.000, valid_NMSE: -9.854e+00
--------------------------------------------------
[INFO]: Epoch 128 of 200
Training
[128,   100] loss: 8.023e-05
[128,   200] loss: 8.208e-05
Validation
[128,   100] loss: 8.827e-05
[128,   200] loss: 8.827e-05
Training loss: 0.000, train NMSE: -1.108e+01
Validation loss: 0.000, valid_NMSE: -9.838e+00
--------------------------------------------------
[INFO]: Epoch 129 of 200
Training
[129,   100] loss: 8.134e-05
[129,   200] loss: 8.003e-05
Validation
[129,   100] loss: 8.811e-05
[129,   200] loss: 8.811e-05
Training loss: 0.000, train NMSE: -1.028e+01
Validation loss: 0.000, valid_NMSE: -9.893e+00
--------------------------------------------------
[INFO]: Epoch 130 of 200
Training
[130,   100] loss: 8.056e-05
[130,   200] loss: 8.060e-05
Validation
[130,   100] loss: 8.735e-05
[130,   200] loss: 8.735e-05
Training loss: 0.000, train NMSE: -1.108e+01
Validation loss: 0.000, valid_NMSE: -9.890e+00
--------------------------------------------------
[INFO]: Epoch 131 of 200
Training
[131,   100] loss: 7.858e-05
[131,   200] loss: 8.150e-05
Validation
[131,   100] loss: 8.739e-05
[131,   200] loss: 8.739e-05
Training loss: 0.000, train NMSE: -1.099e+01
Validation loss: 0.000, valid_NMSE: -9.916e+00

Best validation loss: -9.915872573852539

Saving best model for epoch: 131

--------------------------------------------------
[INFO]: Epoch 132 of 200
Training
[132,   100] loss: 7.908e-05
[132,   200] loss: 8.028e-05
Validation
[132,   100] loss: 8.674e-05
[132,   200] loss: 8.674e-05
Training loss: 0.000, train NMSE: -1.082e+01
Validation loss: 0.000, valid_NMSE: -9.936e+00

Best validation loss: -9.93593978881836

Saving best model for epoch: 132

--------------------------------------------------
[INFO]: Epoch 133 of 200
Training
[133,   100] loss: 7.895e-05
[133,   200] loss: 7.978e-05
Validation
[133,   100] loss: 8.711e-05
[133,   200] loss: 8.711e-05
Training loss: 0.000, train NMSE: -1.079e+01
Validation loss: 0.000, valid_NMSE: -9.915e+00
--------------------------------------------------
[INFO]: Epoch 134 of 200
Training
[134,   100] loss: 7.928e-05
[134,   200] loss: 7.872e-05
Validation
[134,   100] loss: 8.707e-05
[134,   200] loss: 8.707e-05
Training loss: 0.000, train NMSE: -1.040e+01
Validation loss: 0.000, valid_NMSE: -9.906e+00
--------------------------------------------------
[INFO]: Epoch 135 of 200
Training
[135,   100] loss: 7.874e-05
[135,   200] loss: 7.894e-05
Validation
[135,   100] loss: 8.627e-05
[135,   200] loss: 8.627e-05
Training loss: 0.000, train NMSE: -1.057e+01
Validation loss: 0.000, valid_NMSE: -9.935e+00
--------------------------------------------------
[INFO]: Epoch 136 of 200
Training
[136,   100] loss: 7.859e-05
[136,   200] loss: 7.866e-05
Validation
[136,   100] loss: 8.657e-05
[136,   200] loss: 8.657e-05
Training loss: 0.000, train NMSE: -1.132e+01
Validation loss: 0.000, valid_NMSE: -9.913e+00
--------------------------------------------------
[INFO]: Epoch 137 of 200
Training
[137,   100] loss: 7.749e-05
[137,   200] loss: 7.910e-05
Validation
[137,   100] loss: 8.668e-05
[137,   200] loss: 8.668e-05
Training loss: 0.000, train NMSE: -1.099e+01
Validation loss: 0.000, valid_NMSE: -9.900e+00
--------------------------------------------------
[INFO]: Epoch 138 of 200
Training
[138,   100] loss: 7.737e-05
[138,   200] loss: 7.816e-05
Validation
[138,   100] loss: 8.571e-05
[138,   200] loss: 8.571e-05
Training loss: 0.000, train NMSE: -1.053e+01
Validation loss: 0.000, valid_NMSE: -9.986e+00

Best validation loss: -9.98569107055664

Saving best model for epoch: 138

--------------------------------------------------
[INFO]: Epoch 139 of 200
Training
[139,   100] loss: 7.703e-05
[139,   200] loss: 7.828e-05
Validation
[139,   100] loss: 8.576e-05
[139,   200] loss: 8.576e-05
Training loss: 0.000, train NMSE: -1.121e+01
Validation loss: 0.000, valid_NMSE: -9.954e+00
--------------------------------------------------
[INFO]: Epoch 140 of 200
Training
[140,   100] loss: 7.655e-05
[140,   200] loss: 7.786e-05
Validation
[140,   100] loss: 8.562e-05
[140,   200] loss: 8.562e-05
Training loss: 0.000, train NMSE: -1.065e+01
Validation loss: 0.000, valid_NMSE: -9.947e+00
--------------------------------------------------
[INFO]: Epoch 141 of 200
Training
[141,   100] loss: 7.727e-05
[141,   200] loss: 7.673e-05
Validation
[141,   100] loss: 8.557e-05
[141,   200] loss: 8.557e-05
Training loss: 0.000, train NMSE: -1.153e+01
Validation loss: 0.000, valid_NMSE: -9.970e+00
--------------------------------------------------
[INFO]: Epoch 142 of 200
Training
[142,   100] loss: 7.656e-05
[142,   200] loss: 7.651e-05
Validation
[142,   100] loss: 8.535e-05
[142,   200] loss: 8.535e-05
Training loss: 0.000, train NMSE: -9.840e+00
Validation loss: 0.000, valid_NMSE: -9.969e+00
--------------------------------------------------
[INFO]: Epoch 143 of 200
Training
[143,   100] loss: 7.643e-05
[143,   200] loss: 7.590e-05
Validation
[143,   100] loss: 8.545e-05
[143,   200] loss: 8.545e-05
Training loss: 0.000, train NMSE: -1.136e+01
Validation loss: 0.000, valid_NMSE: -9.952e+00
--------------------------------------------------
[INFO]: Epoch 144 of 200
Training
[144,   100] loss: 7.630e-05
[144,   200] loss: 7.600e-05
Validation
[144,   100] loss: 8.550e-05
[144,   200] loss: 8.550e-05
Training loss: 0.000, train NMSE: -1.079e+01
Validation loss: 0.000, valid_NMSE: -9.951e+00
--------------------------------------------------
[INFO]: Epoch 145 of 200
Training
[145,   100] loss: 7.593e-05
[145,   200] loss: 7.583e-05
Validation
[145,   100] loss: 8.482e-05
[145,   200] loss: 8.482e-05
Training loss: 0.000, train NMSE: -1.023e+01
Validation loss: 0.000, valid_NMSE: -1.002e+01

Best validation loss: -10.022183418273926

Saving best model for epoch: 145

--------------------------------------------------
[INFO]: Epoch 146 of 200
Training
[146,   100] loss: 7.564e-05
[146,   200] loss: 7.554e-05
Validation
[146,   100] loss: 8.439e-05
[146,   200] loss: 8.439e-05
Training loss: 0.000, train NMSE: -1.160e+01
Validation loss: 0.000, valid_NMSE: -1.005e+01

Best validation loss: -10.045478820800781

Saving best model for epoch: 146

--------------------------------------------------
[INFO]: Epoch 147 of 200
Training
[147,   100] loss: 7.553e-05
[147,   200] loss: 7.514e-05
Validation
[147,   100] loss: 8.466e-05
[147,   200] loss: 8.466e-05
Training loss: 0.000, train NMSE: -1.105e+01
Validation loss: 0.000, valid_NMSE: -1.002e+01
--------------------------------------------------
[INFO]: Epoch 148 of 200
Training
[148,   100] loss: 7.509e-05
[148,   200] loss: 7.487e-05
Validation
[148,   100] loss: 8.452e-05
[148,   200] loss: 8.452e-05
Training loss: 0.000, train NMSE: -1.081e+01
Validation loss: 0.000, valid_NMSE: -1.000e+01
--------------------------------------------------
[INFO]: Epoch 149 of 200
Training
[149,   100] loss: 7.509e-05
[149,   200] loss: 7.430e-05
Validation
[149,   100] loss: 8.429e-05
[149,   200] loss: 8.429e-05
Training loss: 0.000, train NMSE: -1.117e+01
Validation loss: 0.000, valid_NMSE: -1.002e+01
--------------------------------------------------
[INFO]: Epoch 150 of 200
Training
[150,   100] loss: 7.340e-05
[150,   200] loss: 7.505e-05
Validation
[150,   100] loss: 8.391e-05
[150,   200] loss: 8.391e-05
Training loss: 0.000, train NMSE: -1.213e+01
Validation loss: 0.000, valid_NMSE: -1.006e+01

Best validation loss: -10.058241844177246

Saving best model for epoch: 150

--------------------------------------------------
[INFO]: Epoch 151 of 200
Training
[151,   100] loss: 7.323e-05
[151,   200] loss: 7.549e-05
Validation
[151,   100] loss: 8.551e-05
[151,   200] loss: 8.551e-05
Training loss: 0.000, train NMSE: -1.070e+01
Validation loss: 0.000, valid_NMSE: -9.944e+00
--------------------------------------------------
[INFO]: Epoch 152 of 200
Training
[152,   100] loss: 7.396e-05
[152,   200] loss: 7.385e-05
Validation
[152,   100] loss: 8.462e-05
[152,   200] loss: 8.462e-05
Training loss: 0.000, train NMSE: -1.120e+01
Validation loss: 0.000, valid_NMSE: -9.977e+00
--------------------------------------------------
[INFO]: Epoch 153 of 200
Training
[153,   100] loss: 7.391e-05
[153,   200] loss: 7.354e-05
Validation
[153,   100] loss: 8.357e-05
[153,   200] loss: 8.357e-05
Training loss: 0.000, train NMSE: -1.070e+01
Validation loss: 0.000, valid_NMSE: -1.006e+01
--------------------------------------------------
[INFO]: Epoch 154 of 200
Training
[154,   100] loss: 7.392e-05
[154,   200] loss: 7.319e-05
Validation
[154,   100] loss: 8.369e-05
[154,   200] loss: 8.369e-05
Training loss: 0.000, train NMSE: -1.131e+01
Validation loss: 0.000, valid_NMSE: -1.002e+01
--------------------------------------------------
[INFO]: Epoch 155 of 200
Training
[155,   100] loss: 7.325e-05
[155,   200] loss: 7.343e-05
Validation
[155,   100] loss: 8.417e-05
[155,   200] loss: 8.417e-05
Training loss: 0.000, train NMSE: -1.104e+01
Validation loss: 0.000, valid_NMSE: -9.957e+00
--------------------------------------------------
[INFO]: Epoch 156 of 200
Training
[156,   100] loss: 7.329e-05
[156,   200] loss: 7.243e-05
Validation
[156,   100] loss: 8.321e-05
[156,   200] loss: 8.321e-05
Training loss: 0.000, train NMSE: -1.111e+01
Validation loss: 0.000, valid_NMSE: -1.006e+01

Best validation loss: -10.062385559082031

Saving best model for epoch: 156

--------------------------------------------------
[INFO]: Epoch 157 of 200
Training
[157,   100] loss: 7.276e-05
[157,   200] loss: 7.256e-05
Validation
[157,   100] loss: 8.347e-05
[157,   200] loss: 8.347e-05
Training loss: 0.000, train NMSE: -1.079e+01
Validation loss: 0.000, valid_NMSE: -1.005e+01
--------------------------------------------------
[INFO]: Epoch 158 of 200
Training
[158,   100] loss: 7.230e-05
[158,   200] loss: 7.303e-05
Validation
[158,   100] loss: 8.512e-05
[158,   200] loss: 8.512e-05
Training loss: 0.000, train NMSE: -1.137e+01
Validation loss: 0.000, valid_NMSE: -9.916e+00
--------------------------------------------------
[INFO]: Epoch 159 of 200
Training
[159,   100] loss: 7.152e-05
[159,   200] loss: 7.312e-05
Validation
[159,   100] loss: 8.338e-05
[159,   200] loss: 8.338e-05
Training loss: 0.000, train NMSE: -1.094e+01
Validation loss: 0.000, valid_NMSE: -1.003e+01
--------------------------------------------------
[INFO]: Epoch 160 of 200
Training
[160,   100] loss: 7.289e-05
[160,   200] loss: 7.149e-05
Validation
[160,   100] loss: 8.251e-05
[160,   200] loss: 8.251e-05
Training loss: 0.000, train NMSE: -1.115e+01
Validation loss: 0.000, valid_NMSE: -1.010e+01

Best validation loss: -10.098175048828125

Saving best model for epoch: 160

--------------------------------------------------
[INFO]: Epoch 161 of 200
Training
[161,   100] loss: 7.161e-05
[161,   200] loss: 7.192e-05
Validation
[161,   100] loss: 8.272e-05
[161,   200] loss: 8.272e-05
Training loss: 0.000, train NMSE: -1.075e+01
Validation loss: 0.000, valid_NMSE: -1.005e+01
--------------------------------------------------
[INFO]: Epoch 162 of 200
Training
[162,   100] loss: 7.195e-05
[162,   200] loss: 7.105e-05
Validation
[162,   100] loss: 8.281e-05
[162,   200] loss: 8.281e-05
Training loss: 0.000, train NMSE: -1.100e+01
Validation loss: 0.000, valid_NMSE: -1.010e+01

Best validation loss: -10.101272583007812

Saving best model for epoch: 162

--------------------------------------------------
[INFO]: Epoch 163 of 200
Training
[163,   100] loss: 7.110e-05
[163,   200] loss: 7.156e-05
Validation
[163,   100] loss: 8.318e-05
[163,   200] loss: 8.318e-05
Training loss: 0.000, train NMSE: -1.145e+01
Validation loss: 0.000, valid_NMSE: -1.005e+01
--------------------------------------------------
[INFO]: Epoch 164 of 200
Training
[164,   100] loss: 7.148e-05
[164,   200] loss: 7.106e-05
Validation
[164,   100] loss: 8.294e-05
[164,   200] loss: 8.294e-05
Training loss: 0.000, train NMSE: -1.119e+01
Validation loss: 0.000, valid_NMSE: -1.007e+01
--------------------------------------------------
[INFO]: Epoch 165 of 200
Training
[165,   100] loss: 7.112e-05
[165,   200] loss: 7.083e-05
Validation
[165,   100] loss: 8.349e-05
[165,   200] loss: 8.349e-05
Training loss: 0.000, train NMSE: -1.126e+01
Validation loss: 0.000, valid_NMSE: -9.994e+00
--------------------------------------------------
[INFO]: Epoch 166 of 200
Training
[166,   100] loss: 6.981e-05
[166,   200] loss: 7.162e-05
Validation
[166,   100] loss: 8.272e-05
[166,   200] loss: 8.272e-05
Training loss: 0.000, train NMSE: -1.099e+01
Validation loss: 0.000, valid_NMSE: -1.006e+01
--------------------------------------------------
[INFO]: Epoch 167 of 200
Training
[167,   100] loss: 7.107e-05
[167,   200] loss: 6.982e-05
Validation
[167,   100] loss: 8.309e-05
[167,   200] loss: 8.309e-05
Training loss: 0.000, train NMSE: -1.149e+01
Validation loss: 0.000, valid_NMSE: -1.003e+01
--------------------------------------------------
[INFO]: Epoch 168 of 200
Training
[168,   100] loss: 6.983e-05
[168,   200] loss: 7.108e-05
Validation
[168,   100] loss: 8.292e-05
[168,   200] loss: 8.292e-05
Training loss: 0.000, train NMSE: -1.119e+01
Validation loss: 0.000, valid_NMSE: -1.002e+01
--------------------------------------------------
[INFO]: Epoch 169 of 200
Training
[169,   100] loss: 6.966e-05
[169,   200] loss: 7.055e-05
Validation
[169,   100] loss: 8.250e-05
[169,   200] loss: 8.250e-05
Training loss: 0.000, train NMSE: -1.106e+01
Validation loss: 0.000, valid_NMSE: -1.004e+01
--------------------------------------------------
[INFO]: Epoch 170 of 200
Training
[170,   100] loss: 6.870e-05
[170,   200] loss: 7.088e-05
Validation
[170,   100] loss: 8.168e-05
[170,   200] loss: 8.168e-05
Training loss: 0.000, train NMSE: -1.145e+01
Validation loss: 0.000, valid_NMSE: -1.012e+01

Best validation loss: -10.119561195373535

Saving best model for epoch: 170

--------------------------------------------------
[INFO]: Epoch 171 of 200
Training
[171,   100] loss: 6.818e-05
[171,   200] loss: 7.115e-05
Validation
[171,   100] loss: 8.175e-05
[171,   200] loss: 8.175e-05
Training loss: 0.000, train NMSE: -1.110e+01
Validation loss: 0.000, valid_NMSE: -1.008e+01
--------------------------------------------------
[INFO]: Epoch 172 of 200
Training
[172,   100] loss: 7.013e-05
[172,   200] loss: 6.900e-05
Validation
[172,   100] loss: 8.166e-05
[172,   200] loss: 8.166e-05
Training loss: 0.000, train NMSE: -1.071e+01
Validation loss: 0.000, valid_NMSE: -1.009e+01
--------------------------------------------------
[INFO]: Epoch 173 of 200
Training
[173,   100] loss: 6.925e-05
[173,   200] loss: 6.948e-05
Validation
[173,   100] loss: 8.205e-05
[173,   200] loss: 8.205e-05
Training loss: 0.000, train NMSE: -1.085e+01
Validation loss: 0.000, valid_NMSE: -1.006e+01
--------------------------------------------------
[INFO]: Epoch 174 of 200
Training
[174,   100] loss: 6.910e-05
[174,   200] loss: 6.922e-05
Validation
[174,   100] loss: 8.152e-05
[174,   200] loss: 8.152e-05
Training loss: 0.000, train NMSE: -1.174e+01
Validation loss: 0.000, valid_NMSE: -1.011e+01
--------------------------------------------------
[INFO]: Epoch 175 of 200
Training
[175,   100] loss: 6.946e-05
[175,   200] loss: 6.891e-05
Validation
[175,   100] loss: 8.135e-05
[175,   200] loss: 8.135e-05
Training loss: 0.000, train NMSE: -1.159e+01
Validation loss: 0.000, valid_NMSE: -1.014e+01

Best validation loss: -10.140801429748535

Saving best model for epoch: 175

--------------------------------------------------
[INFO]: Epoch 176 of 200
Training
[176,   100] loss: 6.897e-05
[176,   200] loss: 6.828e-05
Validation
[176,   100] loss: 8.180e-05
[176,   200] loss: 8.180e-05
Training loss: 0.000, train NMSE: -1.201e+01
Validation loss: 0.000, valid_NMSE: -1.011e+01
--------------------------------------------------
[INFO]: Epoch 177 of 200
Training
[177,   100] loss: 6.840e-05
[177,   200] loss: 6.890e-05
Validation
[177,   100] loss: 8.262e-05
[177,   200] loss: 8.262e-05
Training loss: 0.000, train NMSE: -1.163e+01
Validation loss: 0.000, valid_NMSE: -1.000e+01
--------------------------------------------------
[INFO]: Epoch 178 of 200
Training
[178,   100] loss: 6.855e-05
[178,   200] loss: 6.810e-05
Validation
[178,   100] loss: 8.159e-05
[178,   200] loss: 8.159e-05
Training loss: 0.000, train NMSE: -1.118e+01
Validation loss: 0.000, valid_NMSE: -1.008e+01
--------------------------------------------------
[INFO]: Epoch 179 of 200
Training
[179,   100] loss: 6.685e-05
[179,   200] loss: 6.935e-05
Validation
[179,   100] loss: 8.127e-05
[179,   200] loss: 8.127e-05
Training loss: 0.000, train NMSE: -1.147e+01
Validation loss: 0.000, valid_NMSE: -1.011e+01
--------------------------------------------------
[INFO]: Epoch 180 of 200
Training
[180,   100] loss: 6.795e-05
[180,   200] loss: 6.802e-05
Validation
[180,   100] loss: 8.100e-05
[180,   200] loss: 8.100e-05
Training loss: 0.000, train NMSE: -1.132e+01
Validation loss: 0.000, valid_NMSE: -1.011e+01
--------------------------------------------------
[INFO]: Epoch 181 of 200
Training
[181,   100] loss: 6.781e-05
[181,   200] loss: 6.775e-05
Validation
[181,   100] loss: 8.103e-05
[181,   200] loss: 8.103e-05
Training loss: 0.000, train NMSE: -1.158e+01
Validation loss: 0.000, valid_NMSE: -1.010e+01
--------------------------------------------------
[INFO]: Epoch 182 of 200
Training
[182,   100] loss: 6.694e-05
[182,   200] loss: 6.814e-05
Validation
[182,   100] loss: 8.137e-05
[182,   200] loss: 8.137e-05
Training loss: 0.000, train NMSE: -1.089e+01
Validation loss: 0.000, valid_NMSE: -1.010e+01
--------------------------------------------------
[INFO]: Epoch 183 of 200
Training
[183,   100] loss: 6.745e-05
[183,   200] loss: 6.778e-05
Validation
[183,   100] loss: 8.039e-05
[183,   200] loss: 8.039e-05
Training loss: 0.000, train NMSE: -1.190e+01
Validation loss: 0.000, valid_NMSE: -1.020e+01

Best validation loss: -10.197419166564941

Saving best model for epoch: 183

--------------------------------------------------
[INFO]: Epoch 184 of 200
Training
[184,   100] loss: 6.783e-05
[184,   200] loss: 6.677e-05
Validation
[184,   100] loss: 8.066e-05
[184,   200] loss: 8.066e-05
Training loss: 0.000, train NMSE: -1.141e+01
Validation loss: 0.000, valid_NMSE: -1.018e+01
--------------------------------------------------
[INFO]: Epoch 185 of 200
Training
[185,   100] loss: 6.686e-05
[185,   200] loss: 6.697e-05
Validation
[185,   100] loss: 8.057e-05
[185,   200] loss: 8.057e-05
Training loss: 0.000, train NMSE: -1.085e+01
Validation loss: 0.000, valid_NMSE: -1.015e+01
--------------------------------------------------
[INFO]: Epoch 186 of 200
Training
[186,   100] loss: 6.583e-05
[186,   200] loss: 6.805e-05
Validation
[186,   100] loss: 8.111e-05
[186,   200] loss: 8.111e-05
Training loss: 0.000, train NMSE: -1.196e+01
Validation loss: 0.000, valid_NMSE: -1.013e+01
--------------------------------------------------
[INFO]: Epoch 187 of 200
Training
[187,   100] loss: 6.685e-05
[187,   200] loss: 6.686e-05
Validation
[187,   100] loss: 8.034e-05
[187,   200] loss: 8.034e-05
Training loss: 0.000, train NMSE: -1.131e+01
Validation loss: 0.000, valid_NMSE: -1.017e+01
--------------------------------------------------
[INFO]: Epoch 188 of 200
Training
[188,   100] loss: 6.645e-05
[188,   200] loss: 6.681e-05
Validation
[188,   100] loss: 8.070e-05
[188,   200] loss: 8.070e-05
Training loss: 0.000, train NMSE: -1.182e+01
Validation loss: 0.000, valid_NMSE: -1.013e+01
--------------------------------------------------
[INFO]: Epoch 189 of 200
Training
[189,   100] loss: 6.656e-05
[189,   200] loss: 6.617e-05
Validation
[189,   100] loss: 7.992e-05
[189,   200] loss: 7.992e-05
Training loss: 0.000, train NMSE: -1.215e+01
Validation loss: 0.000, valid_NMSE: -1.022e+01

Best validation loss: -10.220771789550781

Saving best model for epoch: 189

--------------------------------------------------/home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE
  warn(f"Failed to load image Python extension: {e}")

[INFO]: Epoch 190 of 200
Training
[190,   100] loss: 6.680e-05
[190,   200] loss: 6.598e-05
Validation
[190,   100] loss: 8.006e-05
[190,   200] loss: 8.006e-05
Training loss: 0.000, train NMSE: -1.194e+01
Validation loss: 0.000, valid_NMSE: -1.019e+01
--------------------------------------------------
[INFO]: Epoch 191 of 200
Training
[191,   100] loss: 6.557e-05
[191,   200] loss: 6.681e-05
Validation
[191,   100] loss: 8.036e-05
[191,   200] loss: 8.036e-05
Training loss: 0.000, train NMSE: -1.152e+01
Validation loss: 0.000, valid_NMSE: -1.016e+01
--------------------------------------------------
[INFO]: Epoch 192 of 200
Training
[192,   100] loss: 6.613e-05
[192,   200] loss: 6.554e-05
Validation
[192,   100] loss: 8.013e-05
[192,   200] loss: 8.013e-05
Training loss: 0.000, train NMSE: -1.092e+01
Validation loss: 0.000, valid_NMSE: -1.016e+01
--------------------------------------------------
[INFO]: Epoch 193 of 200
Training
[193,   100] loss: 6.578e-05
[193,   200] loss: 6.569e-05
Validation
[193,   100] loss: 8.116e-05
[193,   200] loss: 8.116e-05
Training loss: 0.000, train NMSE: -1.154e+01
Validation loss: 0.000, valid_NMSE: -1.013e+01
--------------------------------------------------
[INFO]: Epoch 194 of 200
Training
[194,   100] loss: 6.512e-05
[194,   200] loss: 6.591e-05
Validation
[194,   100] loss: 7.964e-05
[194,   200] loss: 7.964e-05
Training loss: 0.000, train NMSE: -1.218e+01
Validation loss: 0.000, valid_NMSE: -1.021e+01
--------------------------------------------------
[INFO]: Epoch 195 of 200
Training
[195,   100] loss: 6.556e-05
[195,   200] loss: 6.582e-05
Validation
[195,   100] loss: 8.028e-05
[195,   200] loss: 8.028e-05
Training loss: 0.000, train NMSE: -1.111e+01
Validation loss: 0.000, valid_NMSE: -1.015e+01
--------------------------------------------------
[INFO]: Epoch 196 of 200
Training
[196,   100] loss: 6.474e-05
[196,   200] loss: 6.578e-05
Validation
[196,   100] loss: 7.908e-05
[196,   200] loss: 7.908e-05
Training loss: 0.000, train NMSE: -1.217e+01
Validation loss: 0.000, valid_NMSE: -1.027e+01

Best validation loss: -10.265861511230469

Saving best model for epoch: 196

--------------------------------------------------
[INFO]: Epoch 197 of 200
Training
[197,   100] loss: 6.502e-05
[197,   200] loss: 6.524e-05
Validation
[197,   100] loss: 7.988e-05
[197,   200] loss: 7.988e-05
Training loss: 0.000, train NMSE: -1.115e+01
Validation loss: 0.000, valid_NMSE: -1.021e+01
--------------------------------------------------
[INFO]: Epoch 198 of 200
Training
[198,   100] loss: 6.418e-05
[198,   200] loss: 6.558e-05
Validation
[198,   100] loss: 7.986e-05
[198,   200] loss: 7.986e-05
Training loss: 0.000, train NMSE: -1.145e+01
Validation loss: 0.000, valid_NMSE: -1.020e+01
--------------------------------------------------
[INFO]: Epoch 199 of 200
Training
[199,   100] loss: 6.505e-05
[199,   200] loss: 6.452e-05
Validation
[199,   100] loss: 8.014e-05
[199,   200] loss: 8.014e-05
Training loss: 0.000, train NMSE: -1.178e+01
Validation loss: 0.000, valid_NMSE: -1.013e+01
--------------------------------------------------
[INFO]: Epoch 200 of 200
Training
[200,   100] loss: 6.432e-05
[200,   200] loss: 6.512e-05
Validation
[200,   100] loss: 8.007e-05
[200,   200] loss: 8.007e-05
Training loss: 0.000, train NMSE: -1.180e+01
Validation loss: 0.000, valid_NMSE: -1.019e+01
--------------------------------------------------
Saving final model
TRAINING COMPLETE
