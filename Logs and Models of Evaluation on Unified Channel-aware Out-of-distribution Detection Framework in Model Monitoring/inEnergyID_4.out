1.13.1+cu117
inEnergyID
Dadicated Mode inEnergyID
Dedicated Mode inEnergyID
trainset len 112000 valset len 48000
New_trainset len 40000 valset len 48000
2,660,505 training parameters.

2,660,505 training parameters.

[INFO]: Epoch 1 of 200
Training
[1,   100] loss: 9.163e-05
[1,   200] loss: 6.409e-05
Validation
[1,   100] loss: 4.786e-05
[1,   200] loss: 4.688e-05
Training loss: 0.000, train NMSE: -9.789e+00
Validation loss: 0.000, valid_NMSE: -1.069e+01

Best validation loss: -10.686578750610352

Saving best model for epoch: 1

--------------------------------------------------
[INFO]: Epoch 2 of 200
Training
[2,   100] loss: 4.775e-05
[2,   200] loss: 3.984e-05
Validation
[2,   100] loss: 3.358e-05
[2,   200] loss: 3.272e-05
Training loss: 0.000, train NMSE: -1.109e+01
Validation loss: 0.000, valid_NMSE: -1.242e+01

Best validation loss: -12.416027069091797

Saving best model for epoch: 2

--------------------------------------------------
[INFO]: Epoch 3 of 200
Training
[3,   100] loss: 3.468e-05
[3,   200] loss: 3.178e-05
Validation
[3,   100] loss: 2.760e-05
[3,   200] loss: 2.697e-05
Training loss: 0.000, train NMSE: -1.265e+01
Validation loss: 0.000, valid_NMSE: -1.327e+01

Best validation loss: -13.269524574279785

Saving best model for epoch: 3

--------------------------------------------------
[INFO]: Epoch 4 of 200
Training
[4,   100] loss: 2.869e-05
[4,   200] loss: 2.601e-05
Validation
[4,   100] loss: 2.340e-05
[4,   200] loss: 2.297e-05
Training loss: 0.000, train NMSE: -1.323e+01
Validation loss: 0.000, valid_NMSE: -1.392e+01

Best validation loss: -13.922919273376465

Saving best model for epoch: 4

--------------------------------------------------
[INFO]: Epoch 5 of 200
Training
[5,   100] loss: 2.354e-05
[5,   200] loss: 2.251e-05
Validation
[5,   100] loss: 2.017e-05
[5,   200] loss: 1.989e-05
Training loss: 0.000, train NMSE: -1.427e+01
Validation loss: 0.000, valid_NMSE: -1.444e+01

Best validation loss: -14.444905281066895

Saving best model for epoch: 5

--------------------------------------------------
[INFO]: Epoch 6 of 200
Training
[6,   100] loss: 2.034e-05
[6,   200] loss: 1.884e-05
Validation
[6,   100] loss: 1.795e-05
[6,   200] loss: 1.783e-05
Training loss: 0.000, train NMSE: -1.463e+01
Validation loss: 0.000, valid_NMSE: -1.492e+01

Best validation loss: -14.91950511932373

Saving best model for epoch: 6

--------------------------------------------------
[INFO]: Epoch 7 of 200
Training
[7,   100] loss: 1.750e-05
[7,   200] loss: 1.667e-05
Validation
[7,   100] loss: 1.621e-05
[7,   200] loss: 1.610e-05
Training loss: 0.000, train NMSE: -1.554e+01
Validation loss: 0.000, valid_NMSE: -1.528e+01

Best validation loss: -15.28375244140625

Saving best model for epoch: 7

--------------------------------------------------
[INFO]: Epoch 8 of 200
Training
[8,   100] loss: 1.548e-05
[8,   200] loss: 1.472e-05
Validation
[8,   100] loss: 1.411e-05
[8,   200] loss: 1.403e-05
Training loss: 0.000, train NMSE: -1.514e+01
Validation loss: 0.000, valid_NMSE: -1.576e+01

Best validation loss: -15.763416290283203

Saving best model for epoch: 8

--------------------------------------------------
[INFO]: Epoch 9 of 200
Training
[9,   100] loss: 1.365e-05
[9,   200] loss: 1.318e-05
Validation
[9,   100] loss: 1.303e-05
[9,   200] loss: 1.299e-05
Training loss: 0.000, train NMSE: -1.544e+01
Validation loss: 0.000, valid_NMSE: -1.605e+01

Best validation loss: -16.04847526550293

Saving best model for epoch: 9

--------------------------------------------------
[INFO]: Epoch 10 of 200
Training
[10,   100] loss: 1.239e-05
[10,   200] loss: 1.199e-05
Validation
[10,   100] loss: 1.164e-05
[10,   200] loss: 1.162e-05
Training loss: 0.000, train NMSE: -1.606e+01
Validation loss: 0.000, valid_NMSE: -1.663e+01

Best validation loss: -16.629568099975586

Saving best model for epoch: 10

--------------------------------------------------
[INFO]: Epoch 11 of 200
Training
[11,   100] loss: 1.104e-05
[11,   200] loss: 1.114e-05
Validation
[11,   100] loss: 1.061e-05
[11,   200] loss: 1.058e-05
Training loss: 0.000, train NMSE: -1.639e+01
Validation loss: 0.000, valid_NMSE: -1.689e+01

Best validation loss: -16.89287567138672

Saving best model for epoch: 11

--------------------------------------------------
[INFO]: Epoch 12 of 200
Training
[12,   100] loss: 1.034e-05
[12,   200] loss: 1.000e-05
Validation
[12,   100] loss: 9.837e-06
[12,   200] loss: 9.811e-06
Training loss: 0.000, train NMSE: -1.733e+01
Validation loss: 0.000, valid_NMSE: -1.724e+01

Best validation loss: -17.239469528198242

Saving best model for epoch: 12

--------------------------------------------------
[INFO]: Epoch 13 of 200
Training
[13,   100] loss: 9.445e-06
[13,   200] loss: 9.229e-06
Validation
[13,   100] loss: 9.186e-06
[13,   200] loss: 9.177e-06
Training loss: 0.000, train NMSE: -1.731e+01
Validation loss: 0.000, valid_NMSE: -1.739e+01

Best validation loss: -17.38684844970703

Saving best model for epoch: 13

--------------------------------------------------
[INFO]: Epoch 14 of 200
Training
[14,   100] loss: 8.781e-06
[14,   200] loss: 8.655e-06
Validation
[14,   100] loss: 8.583e-06
[14,   200] loss: 8.564e-06
Training loss: 0.000, train NMSE: -1.806e+01
Validation loss: 0.000, valid_NMSE: -1.776e+01

Best validation loss: -17.757707595825195

Saving best model for epoch: 14

--------------------------------------------------
[INFO]: Epoch 15 of 200
Training
[15,   100] loss: 8.008e-06
[15,   200] loss: 8.118e-06
Validation
[15,   100] loss: 8.029e-06
[15,   200] loss: 8.014e-06
Training loss: 0.000, train NMSE: -1.831e+01
Validation loss: 0.000, valid_NMSE: -1.812e+01

Best validation loss: -18.124765396118164

Saving best model for epoch: 15

--------------------------------------------------
[INFO]: Epoch 16 of 200
Training
[16,   100] loss: 7.720e-06
[16,   200] loss: 7.516e-06
Validation
[16,   100] loss: 7.686e-06
[16,   200] loss: 7.666e-06
Training loss: 0.000, train NMSE: -1.832e+01
Validation loss: 0.000, valid_NMSE: -1.829e+01

Best validation loss: -18.28677749633789

Saving best model for epoch: 16

--------------------------------------------------
[INFO]: Epoch 17 of 200
Training
[17,   100] loss: 7.233e-06
[17,   200] loss: 7.147e-06
Validation
[17,   100] loss: 7.118e-06
[17,   200] loss: 7.099e-06
Training loss: 0.000, train NMSE: -1.802e+01
Validation loss: 0.000, valid_NMSE: -1.841e+01

Best validation loss: -18.412424087524414

Saving best model for epoch: 17

--------------------------------------------------
[INFO]: Epoch 18 of 200
Training
[18,   100] loss: 6.824e-06
[18,   200] loss: 6.690e-06
Validation
[18,   100] loss: 6.857e-06
[18,   200] loss: 6.826e-06
Training loss: 0.000, train NMSE: -1.850e+01
Validation loss: 0.000, valid_NMSE: -1.870e+01

Best validation loss: -18.696138381958008

Saving best model for epoch: 18

--------------------------------------------------
[INFO]: Epoch 19 of 200
Training
[19,   100] loss: 6.324e-06
[19,   200] loss: 6.352e-06
Validation
[19,   100] loss: 6.457e-06
[19,   200] loss: 6.426e-06
Training loss: 0.000, train NMSE: -1.891e+01
Validation loss: 0.000, valid_NMSE: -1.874e+01

Best validation loss: -18.740589141845703

Saving best model for epoch: 19

--------------------------------------------------
[INFO]: Epoch 20 of 200
Training
[20,   100] loss: 6.080e-06
[20,   200] loss: 5.940e-06
Validation
[20,   100] loss: 6.052e-06
[20,   200] loss: 6.019e-06
Training loss: 0.000, train NMSE: -1.918e+01
Validation loss: 0.000, valid_NMSE: -1.917e+01

Best validation loss: -19.165164947509766

Saving best model for epoch: 20

--------------------------------------------------
[INFO]: Epoch 21 of 200
Training
[21,   100] loss: 5.742e-06
[21,   200] loss: 5.705e-06
Validation
[21,   100] loss: 5.741e-06
[21,   200] loss: 5.697e-06
Training loss: 0.000, train NMSE: -1.925e+01
Validation loss: 0.000, valid_NMSE: -1.923e+01

Best validation loss: -19.23067283630371

Saving best model for epoch: 21

--------------------------------------------------
[INFO]: Epoch 22 of 200
Training
[22,   100] loss: 5.444e-06
[22,   200] loss: 5.518e-06
Validation
[22,   100] loss: 5.577e-06
[22,   200] loss: 5.535e-06
Training loss: 0.000, train NMSE: -1.958e+01
Validation loss: 0.000, valid_NMSE: -1.943e+01

Best validation loss: -19.434206008911133

Saving best model for epoch: 22

--------------------------------------------------
[INFO]: Epoch 23 of 200
Training
[23,   100] loss: 5.251e-06
[23,   200] loss: 5.188e-06
Validation
[23,   100] loss: 5.275e-06
[23,   200] loss: 5.244e-06
Training loss: 0.000, train NMSE: -2.024e+01
Validation loss: 0.000, valid_NMSE: -1.966e+01

Best validation loss: -19.65856170654297

Saving best model for epoch: 23

--------------------------------------------------
[INFO]: Epoch 24 of 200
Training
[24,   100] loss: 4.948e-06
[24,   200] loss: 4.990e-06
Validation
[24,   100] loss: 5.049e-06
[24,   200] loss: 5.010e-06
Training loss: 0.000, train NMSE: -1.968e+01
Validation loss: 0.000, valid_NMSE: -1.987e+01

Best validation loss: -19.87422752380371

Saving best model for epoch: 24

--------------------------------------------------
[INFO]: Epoch 25 of 200
Training
[25,   100] loss: 4.863e-06
[25,   200] loss: 4.725e-06
Validation
[25,   100] loss: 4.905e-06
[25,   200] loss: 4.869e-06
Training loss: 0.000, train NMSE: -2.098e+01
Validation loss: 0.000, valid_NMSE: -1.980e+01
--------------------------------------------------
[INFO]: Epoch 26 of 200
Training
[26,   100] loss: 4.519e-06
[26,   200] loss: 4.612e-06
Validation
[26,   100] loss: 4.690e-06
[26,   200] loss: 4.664e-06
Training loss: 0.000, train NMSE: -2.027e+01
Validation loss: 0.000, valid_NMSE: -2.013e+01

Best validation loss: -20.128276824951172

Saving best model for epoch: 26

--------------------------------------------------
[INFO]: Epoch 27 of 200
Training
[27,   100] loss: 4.447e-06
[27,   200] loss: 4.412e-06
Validation
[27,   100] loss: 4.709e-06
[27,   200] loss: 4.665e-06
Training loss: 0.000, train NMSE: -2.091e+01
Validation loss: 0.000, valid_NMSE: -2.008e+01
--------------------------------------------------
[INFO]: Epoch 28 of 200
Training
[28,   100] loss: 4.246e-06
[28,   200] loss: 4.173e-06
Validation
[28,   100] loss: 4.373e-06
[28,   200] loss: 4.342e-06
Training loss: 0.000, train NMSE: -2.049e+01
Validation loss: 0.000, valid_NMSE: -2.058e+01

Best validation loss: -20.58221435546875

Saving best model for epoch: 28

--------------------------------------------------
[INFO]: Epoch 29 of 200
Training
[29,   100] loss: 4.149e-06
[29,   200] loss: 4.054e-06
Validation
[29,   100] loss: 4.155e-06
[29,   200] loss: 4.118e-06
Training loss: 0.000, train NMSE: -2.090e+01
Validation loss: 0.000, valid_NMSE: -2.060e+01

Best validation loss: -20.595922470092773

Saving best model for epoch: 29

--------------------------------------------------
[INFO]: Epoch 30 of 200
Training
[30,   100] loss: 3.942e-06
[30,   200] loss: 3.949e-06
Validation
[30,   100] loss: 4.352e-06
[30,   200] loss: 4.315e-06
Training loss: 0.000, train NMSE: -2.096e+01
Validation loss: 0.000, valid_NMSE: -2.060e+01

Best validation loss: -20.59654998779297

Saving best model for epoch: 30

--------------------------------------------------
[INFO]: Epoch 31 of 200
Training
[31,   100] loss: 3.830e-06
[31,   200] loss: 3.824e-06
Validation
[31,   100] loss: 4.127e-06
[31,   200] loss: 4.096e-06
Training loss: 0.000, train NMSE: -2.147e+01
Validation loss: 0.000, valid_NMSE: -2.075e+01

Best validation loss: -20.751256942749023

Saving best model for epoch: 31

--------------------------------------------------
[INFO]: Epoch 32 of 200
Training
[32,   100] loss: 3.735e-06
[32,   200] loss: 3.623e-06
Validation
[32,   100] loss: 3.761e-06
[32,   200] loss: 3.727e-06
Training loss: 0.000, train NMSE: -2.199e+01
Validation loss: 0.000, valid_NMSE: -2.089e+01

Best validation loss: -20.888362884521484

Saving best model for epoch: 32

--------------------------------------------------
[INFO]: Epoch 33 of 200
Training
[33,   100] loss: 3.586e-06
[33,   200] loss: 3.649e-06
Validation
[33,   100] loss: 3.711e-06
[33,   200] loss: 3.694e-06
Training loss: 0.000, train NMSE: -2.154e+01
Validation loss: 0.000, valid_NMSE: -2.106e+01

Best validation loss: -21.0593318939209

Saving best model for epoch: 33

--------------------------------------------------
[INFO]: Epoch 34 of 200
Training
[34,   100] loss: 3.443e-06
[34,   200] loss: 3.562e-06
Validation
[34,   100] loss: 3.662e-06
[34,   200] loss: 3.637e-06
Training loss: 0.000, train NMSE: -2.200e+01
Validation loss: 0.000, valid_NMSE: -2.110e+01

Best validation loss: -21.09756088256836

Saving best model for epoch: 34

--------------------------------------------------
[INFO]: Epoch 35 of 200
Training
[35,   100] loss: 3.333e-06
[35,   200] loss: 3.404e-06
Validation
[35,   100] loss: 3.553e-06
[35,   200] loss: 3.524e-06
Training loss: 0.000, train NMSE: -2.165e+01
Validation loss: 0.000, valid_NMSE: -2.112e+01

Best validation loss: -21.11809730529785

Saving best model for epoch: 35

--------------------------------------------------
[INFO]: Epoch 36 of 200
Training
[36,   100] loss: 3.278e-06
[36,   200] loss: 3.283e-06
Validation
[36,   100] loss: 3.430e-06
[36,   200] loss: 3.404e-06
Training loss: 0.000, train NMSE: -2.190e+01
Validation loss: 0.000, valid_NMSE: -2.141e+01

Best validation loss: -21.40911102294922

Saving best model for epoch: 36

--------------------------------------------------
[INFO]: Epoch 37 of 200
Training
[37,   100] loss: 3.212e-06
[37,   200] loss: 3.133e-06
Validation
[37,   100] loss: 3.277e-06
[37,   200] loss: 3.250e-06
Training loss: 0.000, train NMSE: -2.230e+01
Validation loss: 0.000, valid_NMSE: -2.149e+01

Best validation loss: -21.488439559936523

Saving best model for epoch: 37

--------------------------------------------------
[INFO]: Epoch 38 of 200
Training
[38,   100] loss: 3.100e-06
[38,   200] loss: 3.127e-06
Validation
[38,   100] loss: 3.247e-06
[38,   200] loss: 3.223e-06
Training loss: 0.000, train NMSE: -2.272e+01
Validation loss: 0.000, valid_NMSE: -2.165e+01

Best validation loss: -21.64923667907715

Saving best model for epoch: 38

--------------------------------------------------
[INFO]: Epoch 39 of 200
Training
[39,   100] loss: 3.019e-06
[39,   200] loss: 3.031e-06
Validation
[39,   100] loss: 3.103e-06
[39,   200] loss: 3.076e-06
Training loss: 0.000, train NMSE: -2.256e+01
Validation loss: 0.000, valid_NMSE: -2.178e+01

Best validation loss: -21.782733917236328

Saving best model for epoch: 39

--------------------------------------------------
[INFO]: Epoch 40 of 200
Training
[40,   100] loss: 2.888e-06
[40,   200] loss: 2.958e-06
Validation
[40,   100] loss: 3.005e-06
[40,   200] loss: 2.990e-06
Training loss: 0.000, train NMSE: -2.236e+01
Validation loss: 0.000, valid_NMSE: -2.181e+01

Best validation loss: -21.812488555908203

Saving best model for epoch: 40

--------------------------------------------------
[INFO]: Epoch 41 of 200
Training
[41,   100] loss: 2.905e-06
[41,   200] loss: 2.933e-06
Validation
[41,   100] loss: 3.040e-06
[41,   200] loss: 3.029e-06
Training loss: 0.000, train NMSE: -2.277e+01
Validation loss: 0.000, valid_NMSE: -2.164e+01
--------------------------------------------------
[INFO]: Epoch 42 of 200
Training
[42,   100] loss: 2.767e-06
[42,   200] loss: 2.836e-06
Validation
[42,   100] loss: 2.881e-06
[42,   200] loss: 2.860e-06
Training loss: 0.000, train NMSE: -2.259e+01
Validation loss: 0.000, valid_NMSE: -2.210e+01

Best validation loss: -22.10073471069336

Saving best model for epoch: 42

--------------------------------------------------
[INFO]: Epoch 43 of 200
Training
[43,   100] loss: 2.699e-06
[43,   200] loss: 2.719e-06
Validation
[43,   100] loss: 2.898e-06
[43,   200] loss: 2.888e-06
Training loss: 0.000, train NMSE: -2.256e+01
Validation loss: 0.000, valid_NMSE: -2.203e+01
--------------------------------------------------
[INFO]: Epoch 44 of 200
Training
[44,   100] loss: 2.706e-06
[44,   200] loss: 2.697e-06
Validation
[44,   100] loss: 2.762e-06
[44,   200] loss: 2.745e-06
Training loss: 0.000, train NMSE: -2.261e+01
Validation loss: 0.000, valid_NMSE: -2.213e+01

Best validation loss: -22.13483428955078

Saving best model for epoch: 44

--------------------------------------------------
[INFO]: Epoch 45 of 200
Training
[45,   100] loss: 2.658e-06
[45,   200] loss: 2.594e-06
Validation
[45,   100] loss: 2.738e-06
[45,   200] loss: 2.720e-06
Training loss: 0.000, train NMSE: -2.327e+01
Validation loss: 0.000, valid_NMSE: -2.226e+01

Best validation loss: -22.2645206451416

Saving best model for epoch: 45

--------------------------------------------------
[INFO]: Epoch 46 of 200
Training
[46,   100] loss: 2.546e-06
[46,   200] loss: 2.545e-06
Validation
[46,   100] loss: 2.824e-06
[46,   200] loss: 2.804e-06
Training loss: 0.000, train NMSE: -2.267e+01
Validation loss: 0.000, valid_NMSE: -2.184e+01
--------------------------------------------------
[INFO]: Epoch 47 of 200
Training
[47,   100] loss: 2.538e-06
[47,   200] loss: 2.485e-06
Validation
[47,   100] loss: 2.793e-06
[47,   200] loss: 2.776e-06
Training loss: 0.000, train NMSE: -2.259e+01
Validation loss: 0.000, valid_NMSE: -2.225e+01
--------------------------------------------------
[INFO]: Epoch 48 of 200
Training
[48,   100] loss: 2.473e-06
[48,   200] loss: 2.506e-06
Validation
[48,   100] loss: 2.623e-06
[48,   200] loss: 2.602e-06
Training loss: 0.000, train NMSE: -2.272e+01
Validation loss: 0.000, valid_NMSE: -2.256e+01

Best validation loss: -22.557382583618164

Saving best model for epoch: 48

--------------------------------------------------
[INFO]: Epoch 49 of 200
Training
[49,   100] loss: 2.366e-06
[49,   200] loss: 2.432e-06
Validation
[49,   100] loss: 2.525e-06
[49,   200] loss: 2.510e-06
Training loss: 0.000, train NMSE: -2.290e+01
Validation loss: 0.000, valid_NMSE: -2.256e+01

Best validation loss: -22.563812255859375

Saving best model for epoch: 49

--------------------------------------------------
[INFO]: Epoch 50 of 200
Training
[50,   100] loss: 2.316e-06
[50,   200] loss: 2.370e-06
Validation
[50,   100] loss: 2.453e-06
[50,   200] loss: 2.440e-06
Training loss: 0.000, train NMSE: -2.348e+01
Validation loss: 0.000, valid_NMSE: -2.271e+01

Best validation loss: -22.706239700317383

Saving best model for epoch: 50

--------------------------------------------------
[INFO]: Epoch 51 of 200
Training
[51,   100] loss: 2.339e-06
[51,   200] loss: 2.289e-06
Validation
[51,   100] loss: 2.423e-06
[51,   200] loss: 2.411e-06
Training loss: 0.000, train NMSE: -2.333e+01
Validation loss: 0.000, valid_NMSE: -2.242e+01
--------------------------------------------------
[INFO]: Epoch 52 of 200
Training
[52,   100] loss: 2.325e-06
[52,   200] loss: 2.296e-06
Validation
[52,   100] loss: 2.468e-06
[52,   200] loss: 2.458e-06
Training loss: 0.000, train NMSE: -2.326e+01
Validation loss: 0.000, valid_NMSE: -2.268e+01
--------------------------------------------------
[INFO]: Epoch 53 of 200
Training
[53,   100] loss: 2.238e-06
[53,   200] loss: 2.220e-06
Validation
[53,   100] loss: 2.340e-06
[53,   200] loss: 2.325e-06
Training loss: 0.000, train NMSE: -2.401e+01
Validation loss: 0.000, valid_NMSE: -2.274e+01

Best validation loss: -22.744770050048828

Saving best model for epoch: 53

--------------------------------------------------
[INFO]: Epoch 54 of 200
Training
[54,   100] loss: 2.179e-06
[54,   200] loss: 2.219e-06
Validation
[54,   100] loss: 2.332e-06
[54,   200] loss: 2.303e-06
Training loss: 0.000, train NMSE: -2.321e+01
Validation loss: 0.000, valid_NMSE: -2.290e+01

Best validation loss: -22.896862030029297

Saving best model for epoch: 54

--------------------------------------------------
[INFO]: Epoch 55 of 200
Training
[55,   100] loss: 2.137e-06
[55,   200] loss: 2.180e-06
Validation
[55,   100] loss: 2.274e-06
[55,   200] loss: 2.255e-06
Training loss: 0.000, train NMSE: -2.343e+01
Validation loss: 0.000, valid_NMSE: -2.286e+01
--------------------------------------------------
[INFO]: Epoch 56 of 200
Training
[56,   100] loss: 2.114e-06
[56,   200] loss: 2.160e-06
Validation
[56,   100] loss: 2.277e-06
[56,   200] loss: 2.247e-06
Training loss: 0.000, train NMSE: -2.401e+01
Validation loss: 0.000, valid_NMSE: -2.304e+01

Best validation loss: -23.044710159301758

Saving best model for epoch: 56

--------------------------------------------------
[INFO]: Epoch 57 of 200
Training
[57,   100] loss: 2.129e-06
[57,   200] loss: 2.138e-06
Validation
[57,   100] loss: 2.308e-06
[57,   200] loss: 2.283e-06
Training loss: 0.000, train NMSE: -2.313e+01
Validation loss: 0.000, valid_NMSE: -2.261e+01
--------------------------------------------------
[INFO]: Epoch 58 of 200
Training
[58,   100] loss: 2.066e-06
[58,   200] loss: 2.041e-06
Validation
[58,   100] loss: 2.102e-06
[58,   200] loss: 2.081e-06
Training loss: 0.000, train NMSE: -2.441e+01
Validation loss: 0.000, valid_NMSE: -2.334e+01

Best validation loss: -23.338478088378906

Saving best model for epoch: 58

--------------------------------------------------
[INFO]: Epoch 59 of 200
Training
[59,   100] loss: 2.020e-06
[59,   200] loss: 2.024e-06
Validation
[59,   100] loss: 2.148e-06
[59,   200] loss: 2.123e-06
Training loss: 0.000, train NMSE: -2.332e+01
Validation loss: 0.000, valid_NMSE: -2.305e+01
--------------------------------------------------
[INFO]: Epoch 60 of 200
Training
[60,   100] loss: 1.961e-06
[60,   200] loss: 2.034e-06
Validation
[60,   100] loss: 2.117e-06
[60,   200] loss: 2.091e-06
Training loss: 0.000, train NMSE: -2.415e+01
Validation loss: 0.000, valid_NMSE: -2.329e+01
--------------------------------------------------
[INFO]: Epoch 61 of 200
Training
[61,   100] loss: 1.939e-06
[61,   200] loss: 2.052e-06
Validation
[61,   100] loss: 2.114e-06
[61,   200] loss: 2.079e-06
Training loss: 0.000, train NMSE: -2.388e+01
Validation loss: 0.000, valid_NMSE: -2.336e+01

Best validation loss: -23.358051300048828

Saving best model for epoch: 61

--------------------------------------------------
[INFO]: Epoch 62 of 200
Training
[62,   100] loss: 1.956e-06
[62,   200] loss: 1.939e-06
Validation
[62,   100] loss: 2.109e-06
[62,   200] loss: 2.018e-06
Training loss: 0.000, train NMSE: -2.426e+01
Validation loss: 0.000, valid_NMSE: -2.335e+01
--------------------------------------------------
[INFO]: Epoch 63 of 200
Training
[63,   100] loss: 1.898e-06
[63,   200] loss: 1.947e-06
Validation
[63,   100] loss: 2.033e-06
[63,   200] loss: 1.992e-06
Training loss: 0.000, train NMSE: -2.410e+01
Validation loss: 0.000, valid_NMSE: -2.330e+01
--------------------------------------------------
[INFO]: Epoch 64 of 200
Training
[64,   100] loss: 1.904e-06
[64,   200] loss: 1.906e-06
Validation
[64,   100] loss: 2.099e-06
[64,   200] loss: 2.014e-06
Training loss: 0.000, train NMSE: -2.381e+01
Validation loss: 0.000, valid_NMSE: -2.320e+01
--------------------------------------------------
[INFO]: Epoch 65 of 200
Training
[65,   100] loss: 1.828e-06
[65,   200] loss: 1.897e-06
Validation
[65,   100] loss: 2.075e-06
[65,   200] loss: 1.975e-06
Training loss: 0.000, train NMSE: -2.454e+01
Validation loss: 0.000, valid_NMSE: -2.349e+01

Best validation loss: -23.489341735839844

Saving best model for epoch: 65

--------------------------------------------------
[INFO]: Epoch 66 of 200
Training
[66,   100] loss: 1.860e-06
[66,   200] loss: 1.838e-06
Validation
[66,   100] loss: 1.929e-06
[66,   200] loss: 1.890e-06
Training loss: 0.000, train NMSE: -2.365e+01
Validation loss: 0.000, valid_NMSE: -2.362e+01

Best validation loss: -23.620765686035156

Saving best model for epoch: 66

--------------------------------------------------
[INFO]: Epoch 67 of 200
Training
[67,   100] loss: 1.788e-06
[67,   200] loss: 1.826e-06
Validation
[67,   100] loss: 1.994e-06
[67,   200] loss: 1.965e-06
Training loss: 0.000, train NMSE: -2.439e+01
Validation loss: 0.000, valid_NMSE: -2.342e+01
--------------------------------------------------
[INFO]: Epoch 68 of 200
Training
[68,   100] loss: 1.831e-06
[68,   200] loss: 1.794e-06
Validation
[68,   100] loss: 1.940e-06
[68,   200] loss: 1.873e-06
Training loss: 0.000, train NMSE: -2.451e+01
Validation loss: 0.000, valid_NMSE: -2.333e+01
--------------------------------------------------
[INFO]: Epoch 69 of 200
Training
[69,   100] loss: 1.763e-06
[69,   200] loss: 1.790e-06
Validation
[69,   100] loss: 2.134e-06
[69,   200] loss: 1.829e-06
Training loss: 0.000, train NMSE: -2.437e+01
Validation loss: 0.000, valid_NMSE: -2.357e+01
--------------------------------------------------
[INFO]: Epoch 70 of 200
Training
[70,   100] loss: 1.795e-06
[70,   200] loss: 1.751e-06
Validation
[70,   100] loss: 2.059e-06
[70,   200] loss: 1.826e-06
Training loss: 0.000, train NMSE: -2.480e+01
Validation loss: 0.000, valid_NMSE: -2.376e+01

Best validation loss: -23.76082420349121

Saving best model for epoch: 70

--------------------------------------------------
[INFO]: Epoch 71 of 200
Training
[71,   100] loss: 1.707e-06
[71,   200] loss: 1.755e-06
Validation
[71,   100] loss: 2.201e-06
[71,   200] loss: 1.802e-06
Training loss: 0.000, train NMSE: -2.437e+01
Validation loss: 0.000, valid_NMSE: -2.367e+01
--------------------------------------------------
[INFO]: Epoch 72 of 200
Training
[72,   100] loss: 1.730e-06
[72,   200] loss: 1.725e-06
Validation
[72,   100] loss: 2.110e-06
[72,   200] loss: 1.779e-06
Training loss: 0.000, train NMSE: -2.516e+01
Validation loss: 0.000, valid_NMSE: -2.367e+01
--------------------------------------------------
[INFO]: Epoch 73 of 200
Training
[73,   100] loss: 1.683e-06
[73,   200] loss: 1.717e-06
Validation
[73,   100] loss: 2.062e-06
[73,   200] loss: 1.776e-06
Training loss: 0.000, train NMSE: -2.474e+01
Validation loss: 0.000, valid_NMSE: -2.388e+01

Best validation loss: -23.875038146972656

Saving best model for epoch: 73

--------------------------------------------------
[INFO]: Epoch 74 of 200
Training
[74,   100] loss: 1.677e-06
[74,   200] loss: 1.674e-06
Validation
[74,   100] loss: 2.240e-06
[74,   200] loss: 1.706e-06
Training loss: 0.000, train NMSE: -2.529e+01
Validation loss: 0.000, valid_NMSE: -2.400e+01

Best validation loss: -23.996307373046875

Saving best model for epoch: 74

--------------------------------------------------
[INFO]: Epoch 75 of 200
Training
[75,   100] loss: 1.642e-06
[75,   200] loss: 1.676e-06
Validation
[75,   100] loss: 2.290e-06
[75,   200] loss: 1.805e-06
Training loss: 0.000, train NMSE: -2.523e+01
Validation loss: 0.000, valid_NMSE: -2.399e+01
--------------------------------------------------
[INFO]: Epoch 76 of 200
Training
[76,   100] loss: 1.642e-06
[76,   200] loss: 1.659e-06
Validation
[76,   100] loss: 2.026e-06
[76,   200] loss: 1.703e-06
Training loss: 0.000, train NMSE: -2.483e+01
Validation loss: 0.000, valid_NMSE: -2.387e+01
--------------------------------------------------
[INFO]: Epoch 77 of 200
Training
[77,   100] loss: 1.612e-06
[77,   200] loss: 1.646e-06
Validation
[77,   100] loss: 2.280e-06
[77,   200] loss: 1.755e-06
Training loss: 0.000, train NMSE: -2.461e+01
Validation loss: 0.000, valid_NMSE: -2.423e+01

Best validation loss: -24.23314666748047

Saving best model for epoch: 77

--------------------------------------------------
[INFO]: Epoch 78 of 200
Training
[78,   100] loss: 1.604e-06
[78,   200] loss: 1.647e-06
Validation
[78,   100] loss: 2.236e-06
[78,   200] loss: 1.688e-06
Training loss: 0.000, train NMSE: -2.481e+01
Validation loss: 0.000, valid_NMSE: -2.414e+01
--------------------------------------------------
[INFO]: Epoch 79 of 200
Training
[79,   100] loss: 1.645e-06
[79,   200] loss: 1.602e-06
Validation
[79,   100] loss: 2.214e-06
[79,   200] loss: 1.678e-06
Training loss: 0.000, train NMSE: -2.497e+01
Validation loss: 0.000, valid_NMSE: -2.421e+01
--------------------------------------------------
[INFO]: Epoch 80 of 200
Training
[80,   100] loss: 1.565e-06
[80,   200] loss: 1.571e-06
Validation
[80,   100] loss: 2.206e-06
[80,   200] loss: 1.665e-06
Training loss: 0.000, train NMSE: -2.441e+01
Validation loss: 0.000, valid_NMSE: -2.415e+01
--------------------------------------------------
[INFO]: Epoch 81 of 200
Training
[81,   100] loss: 1.544e-06
[81,   200] loss: 1.550e-06
Validation
[81,   100] loss: 2.191e-06
[81,   200] loss: 1.631e-06
Training loss: 0.000, train NMSE: -2.484e+01
Validation loss: 0.000, valid_NMSE: -2.412e+01
--------------------------------------------------
[INFO]: Epoch 82 of 200
Training
[82,   100] loss: 1.552e-06
[82,   200] loss: 1.537e-06
Validation
[82,   100] loss: 2.278e-06
[82,   200] loss: 1.593e-06
Training loss: 0.000, train NMSE: -2.532e+01
Validation loss: 0.000, valid_NMSE: -2.446e+01

Best validation loss: -24.457294464111328

Saving best model for epoch: 82

--------------------------------------------------
[INFO]: Epoch 83 of 200
Training
[83,   100] loss: 1.529e-06
[83,   200] loss: 1.551e-06
Validation
[83,   100] loss: 2.319e-06
[83,   200] loss: 1.620e-06
Training loss: 0.000, train NMSE: -2.539e+01
Validation loss: 0.000, valid_NMSE: -2.386e+01
--------------------------------------------------
[INFO]: Epoch 84 of 200
Training
[84,   100] loss: 1.550e-06
[84,   200] loss: 1.535e-06
Validation
[84,   100] loss: 2.413e-06
[84,   200] loss: 1.633e-06
Training loss: 0.000, train NMSE: -2.530e+01
Validation loss: 0.000, valid_NMSE: -2.381e+01
--------------------------------------------------
[INFO]: Epoch 85 of 200
Training
[85,   100] loss: 1.547e-06
[85,   200] loss: 1.488e-06
Validation
[85,   100] loss: 2.327e-06
[85,   200] loss: 1.587e-06
Training loss: 0.000, train NMSE: -2.501e+01
Validation loss: 0.000, valid_NMSE: -2.439e+01
--------------------------------------------------
[INFO]: Epoch 86 of 200
Training
[86,   100] loss: 1.475e-06
[86,   200] loss: 1.528e-06
Validation
[86,   100] loss: 2.185e-06
[86,   200] loss: 1.628e-06
Training loss: 0.000, train NMSE: -2.573e+01
Validation loss: 0.000, valid_NMSE: -2.407e+01
--------------------------------------------------
[INFO]: Epoch 87 of 200
Training
[87,   100] loss: 1.504e-06
[87,   200] loss: 1.480e-06
Validation
[87,   100] loss: 2.225e-06
[87,   200] loss: 1.600e-06
Training loss: 0.000, train NMSE: -2.548e+01
Validation loss: 0.000, valid_NMSE: -2.415e+01
--------------------------------------------------
[INFO]: Epoch 88 of 200
Training
[88,   100] loss: 1.473e-06
[88,   200] loss: 1.483e-06
Validation
[88,   100] loss: 2.172e-06
[88,   200] loss: 1.559e-06
Training loss: 0.000, train NMSE: -2.513e+01
Validation loss: 0.000, valid_NMSE: -2.433e+01
--------------------------------------------------
[INFO]: Epoch 89 of 200
Training
[89,   100] loss: 1.434e-06
[89,   200] loss: 1.469e-06
Validation
[89,   100] loss: 2.225e-06
[89,   200] loss: 1.549e-06
Training loss: 0.000, train NMSE: -2.506e+01
Validation loss: 0.000, valid_NMSE: -2.408e+01
--------------------------------------------------
[INFO]: Epoch 90 of 200
Training
[90,   100] loss: 1.445e-06
[90,   200] loss: 1.454e-06
Validation
[90,   100] loss: 2.146e-06
[90,   200] loss: 1.488e-06
Training loss: 0.000, train NMSE: -2.517e+01
Validation loss: 0.000, valid_NMSE: -2.455e+01

Best validation loss: -24.554607391357422

Saving best model for epoch: 90

--------------------------------------------------
[INFO]: Epoch 91 of 200
Training
[91,   100] loss: 1.454e-06
[91,   200] loss: 1.438e-06
Validation
[91,   100] loss: 2.016e-06
[91,   200] loss: 1.549e-06
Training loss: 0.000, train NMSE: -2.507e+01
Validation loss: 0.000, valid_NMSE: -2.443e+01
--------------------------------------------------
[INFO]: Epoch 92 of 200
Training
[92,   100] loss: 1.440e-06
[92,   200] loss: 1.436e-06
Validation
[92,   100] loss: 2.297e-06
[92,   200] loss: 1.495e-06
Training loss: 0.000, train NMSE: -2.502e+01
Validation loss: 0.000, valid_NMSE: -2.456e+01

Best validation loss: -24.556045532226562

Saving best model for epoch: 92

--------------------------------------------------
[INFO]: Epoch 93 of 200
Training
[93,   100] loss: 1.403e-06
[93,   200] loss: 1.442e-06
Validation
[93,   100] loss: 2.302e-06
[93,   200] loss: 1.494e-06
Training loss: 0.000, train NMSE: -2.610e+01
Validation loss: 0.000, valid_NMSE: -2.462e+01

Best validation loss: -24.619829177856445

Saving best model for epoch: 93

--------------------------------------------------
[INFO]: Epoch 94 of 200
Training
[94,   100] loss: 1.393e-06
[94,   200] loss: 1.421e-06
Validation
[94,   100] loss: 2.107e-06
[94,   200] loss: 1.443e-06
Training loss: 0.000, train NMSE: -2.541e+01
Validation loss: 0.000, valid_NMSE: -2.465e+01

Best validation loss: -24.650745391845703

Saving best model for epoch: 94

--------------------------------------------------
[INFO]: Epoch 95 of 200
Training
[95,   100] loss: 1.398e-06
[95,   200] loss: 1.398e-06
Validation
[95,   100] loss: 2.493e-06
[95,   200] loss: 1.527e-06
Training loss: 0.000, train NMSE: -2.546e+01
Validation loss: 0.000, valid_NMSE: -2.469e+01

Best validation loss: -24.686439514160156

Saving best model for epoch: 95

--------------------------------------------------
[INFO]: Epoch 96 of 200
Training
[96,   100] loss: 1.385e-06
[96,   200] loss: 1.366e-06
Validation
[96,   100] loss: 2.177e-06
[96,   200] loss: 1.442e-06
Training loss: 0.000, train NMSE: -2.493e+01
Validation loss: 0.000, valid_NMSE: -2.452e+01
--------------------------------------------------
[INFO]: Epoch 97 of 200
Training
[97,   100] loss: 1.380e-06
[97,   200] loss: 1.386e-06
Validation
[97,   100] loss: 2.231e-06
[97,   200] loss: 1.463e-06
Training loss: 0.000, train NMSE: -2.623e+01
Validation loss: 0.000, valid_NMSE: -2.441e+01
--------------------------------------------------
[INFO]: Epoch 98 of 200
Training
[98,   100] loss: 1.360e-06
[98,   200] loss: 1.377e-06
Validation
[98,   100] loss: 2.220e-06
[98,   200] loss: 1.434e-06
Training loss: 0.000, train NMSE: -2.573e+01
Validation loss: 0.000, valid_NMSE: -2.457e+01
--------------------------------------------------
[INFO]: Epoch 99 of 200
Training
[99,   100] loss: 1.374e-06
[99,   200] loss: 1.355e-06
Validation
[99,   100] loss: 2.198e-06
[99,   200] loss: 1.399e-06
Training loss: 0.000, train NMSE: -2.592e+01
Validation loss: 0.000, valid_NMSE: -2.469e+01

Best validation loss: -24.686946868896484

Saving best model for epoch: 99

--------------------------------------------------
[INFO]: Epoch 100 of 200
Training
[100,   100] loss: 1.342e-06
[100,   200] loss: 1.323e-06
Validation
[100,   100] loss: 2.124e-06
[100,   200] loss: 1.436e-06
Training loss: 0.000, train NMSE: -2.573e+01
Validation loss: 0.000, valid_NMSE: -2.473e+01

Best validation loss: -24.726713180541992

Saving best model for epoch: 100

--------------------------------------------------
[INFO]: Epoch 101 of 200
Training
[101,   100] loss: 1.343e-06
[101,   200] loss: 1.315e-06
Validation
[101,   100] loss: 2.239e-06
[101,   200] loss: 1.393e-06
Training loss: 0.000, train NMSE: -2.638e+01
Validation loss: 0.000, valid_NMSE: -2.460e+01
--------------------------------------------------
[INFO]: Epoch 102 of 200
Training
[102,   100] loss: 1.318e-06
[102,   200] loss: 1.337e-06
Validation
[102,   100] loss: 2.248e-06
[102,   200] loss: 1.399e-06
Training loss: 0.000, train NMSE: -2.589e+01
Validation loss: 0.000, valid_NMSE: -2.464e+01
--------------------------------------------------
[INFO]: Epoch 103 of 200
Training
[103,   100] loss: 1.299e-06
[103,   200] loss: 1.346e-06
Validation
[103,   100] loss: 2.036e-06
[103,   200] loss: 1.471e-06
Training loss: 0.000, train NMSE: -2.533e+01
Validation loss: 0.000, valid_NMSE: -2.461e+01
--------------------------------------------------
[INFO]: Epoch 104 of 200
Training
[104,   100] loss: 1.345e-06
[104,   200] loss: 1.307e-06
Validation
[104,   100] loss: 2.224e-06
[104,   200] loss: 1.368e-06
Training loss: 0.000, train NMSE: -2.592e+01
Validation loss: 0.000, valid_NMSE: -2.500e+01

Best validation loss: -25.00251007080078

Saving best model for epoch: 104

--------------------------------------------------
[INFO]: Epoch 105 of 200
Training
[105,   100] loss: 1.298e-06
[105,   200] loss: 1.305e-06
Validation
[105,   100] loss: 2.221e-06
[105,   200] loss: 1.390e-06
Training loss: 0.000, train NMSE: -2.556e+01
Validation loss: 0.000, valid_NMSE: -2.509e+01

Best validation loss: -25.090534210205078

Saving best model for epoch: 105

--------------------------------------------------
[INFO]: Epoch 106 of 200
Training
[106,   100] loss: 1.306e-06
[106,   200] loss: 1.300e-06
Validation
[106,   100] loss: 2.173e-06
[106,   200] loss: 1.372e-06
Training loss: 0.000, train NMSE: -2.653e+01
Validation loss: 0.000, valid_NMSE: -2.492e+01
--------------------------------------------------
[INFO]: Epoch 107 of 200
Training
[107,   100] loss: 1.251e-06
[107,   200] loss: 1.322e-06
Validation
[107,   100] loss: 2.143e-06
[107,   200] loss: 1.327e-06
Training loss: 0.000, train NMSE: -2.546e+01
Validation loss: 0.000, valid_NMSE: -2.501e+01
--------------------------------------------------
[INFO]: Epoch 108 of 200
Training
[108,   100] loss: 1.266e-06
[108,   200] loss: 1.247e-06
Validation
[108,   100] loss: 2.197e-06
[108,   200] loss: 1.320e-06
Training loss: 0.000, train NMSE: -2.594e+01
Validation loss: 0.000, valid_NMSE: -2.488e+01
--------------------------------------------------
[INFO]: Epoch 109 of 200
Training
[109,   100] loss: 1.278e-06
[109,   200] loss: 1.263e-06
Validation
[109,   100] loss: 2.104e-06
[109,   200] loss: 1.334e-06
Training loss: 0.000, train NMSE: -2.597e+01
Validation loss: 0.000, valid_NMSE: -2.514e+01

Best validation loss: -25.141599655151367

Saving best model for epoch: 109

--------------------------------------------------
[INFO]: Epoch 110 of 200
Training
[110,   100] loss: 1.247e-06
[110,   200] loss: 1.311e-06
Validation
[110,   100] loss: 1.828e-06
[110,   200] loss: 1.332e-06
Training loss: 0.000, train NMSE: -2.530e+01
Validation loss: 0.000, valid_NMSE: -2.496e+01
--------------------------------------------------
[INFO]: Epoch 111 of 200
Training
[111,   100] loss: 1.256e-06
[111,   200] loss: 1.280e-06
Validation
[111,   100] loss: 2.095e-06
[111,   200] loss: 1.322e-06
Training loss: 0.000, train NMSE: -2.597e+01
Validation loss: 0.000, valid_NMSE: -2.486e+01
--------------------------------------------------
[INFO]: Epoch 112 of 200
Training
[112,   100] loss: 1.241e-06
[112,   200] loss: 1.246e-06
Validation
[112,   100] loss: 2.049e-06
[112,   200] loss: 1.312e-06
Training loss: 0.000, train NMSE: -2.613e+01
Validation loss: 0.000, valid_NMSE: -2.510e+01
--------------------------------------------------
[INFO]: Epoch 113 of 200
Training
[113,   100] loss: 1.207e-06
[113,   200] loss: 1.248e-06
Validation
[113,   100] loss: 2.163e-06
[113,   200] loss: 1.267e-06
Training loss: 0.000, train NMSE: -2.590e+01
Validation loss: 0.000, valid_NMSE: -2.525e+01

Best validation loss: -25.250558853149414

Saving best model for epoch: 113

--------------------------------------------------
[INFO]: Epoch 114 of 200
Training
[114,   100] loss: 1.210e-06
[114,   200] loss: 1.223e-06
Validation
[114,   100] loss: 1.903e-06
[114,   200] loss: 1.266e-06
Training loss: 0.000, train NMSE: -2.625e+01
Validation loss: 0.000, valid_NMSE: -2.527e+01

Best validation loss: -25.27172088623047

Saving best model for epoch: 114

--------------------------------------------------
[INFO]: Epoch 115 of 200
Training
[115,   100] loss: 1.205e-06
[115,   200] loss: 1.206e-06
Validation
[115,   100] loss: 2.090e-06
[115,   200] loss: 1.265e-06
Training loss: 0.000, train NMSE: -2.589e+01
Validation loss: 0.000, valid_NMSE: -2.550e+01

Best validation loss: -25.49797821044922

Saving best model for epoch: 115

--------------------------------------------------
[INFO]: Epoch 116 of 200
Training
[116,   100] loss: 1.209e-06
[116,   200] loss: 1.201e-06
Validation
[116,   100] loss: 1.865e-06
[116,   200] loss: 1.256e-06
Training loss: 0.000, train NMSE: -2.629e+01
Validation loss: 0.000, valid_NMSE: -2.513e+01
--------------------------------------------------
[INFO]: Epoch 117 of 200
Training
[117,   100] loss: 1.196e-06
[117,   200] loss: 1.200e-06
Validation
[117,   100] loss: 2.133e-06
[117,   200] loss: 1.236e-06
Training loss: 0.000, train NMSE: -2.636e+01
Validation loss: 0.000, valid_NMSE: -2.508e+01
--------------------------------------------------
[INFO]: Epoch 118 of 200
Training
[118,   100] loss: 1.214e-06
[118,   200] loss: 1.191e-06
Validation
[118,   100] loss: 1.722e-06
[118,   200] loss: 1.233e-06
Training loss: 0.000, train NMSE: -2.580e+01
Validation loss: 0.000, valid_NMSE: -2.538e+01
--------------------------------------------------
[INFO]: Epoch 119 of 200
Training
[119,   100] loss: 1.192e-06
[119,   200] loss: 1.203e-06
Validation
[119,   100] loss: 1.963e-06
[119,   200] loss: 1.279e-06
Training loss: 0.000, train NMSE: -2.640e+01
Validation loss: 0.000, valid_NMSE: -2.505e+01
--------------------------------------------------
[INFO]: Epoch 120 of 200
Training
[120,   100] loss: 1.174e-06
[120,   200] loss: 1.199e-06
Validation
[120,   100] loss: 2.021e-06
[120,   200] loss: 1.236e-06
Training loss: 0.000, train NMSE: -2.623e+01
Validation loss: 0.000, valid_NMSE: -2.517e+01
--------------------------------------------------
[INFO]: Epoch 121 of 200
Training
[121,   100] loss: 1.191e-06
[121,   200] loss: 1.175e-06
Validation
[121,   100] loss: 1.884e-06
[121,   200] loss: 1.219e-06
Training loss: 0.000, train NMSE: -2.710e+01
Validation loss: 0.000, valid_NMSE: -2.520e+01
--------------------------------------------------
[INFO]: Epoch 122 of 200
Training
[122,   100] loss: 1.216e-06
[122,   200] loss: 1.189e-06
Validation
[122,   100] loss: 2.101e-06
[122,   200] loss: 1.227e-06
Training loss: 0.000, train NMSE: -2.632e+01
Validation loss: 0.000, valid_NMSE: -2.528e+01
--------------------------------------------------
[INFO]: Epoch 123 of 200
Training
[123,   100] loss: 1.184e-06
[123,   200] loss: 1.172e-06
Validation
[123,   100] loss: 2.136e-06
[123,   200] loss: 1.228e-06
Training loss: 0.000, train NMSE: -2.676e+01
Validation loss: 0.000, valid_NMSE: -2.535e+01
--------------------------------------------------
[INFO]: Epoch 124 of 200
Training
[124,   100] loss: 1.142e-06
[124,   200] loss: 1.168e-06
Validation
[124,   100] loss: 1.955e-06
[124,   200] loss: 1.217e-06
Training loss: 0.000, train NMSE: -2.614e+01
Validation loss: 0.000, valid_NMSE: -2.552e+01

Best validation loss: -25.519819259643555

Saving best model for epoch: 124

--------------------------------------------------
[INFO]: Epoch 125 of 200
Training
[125,   100] loss: 1.138e-06
[125,   200] loss: 1.191e-06
Validation
[125,   100] loss: 2.190e-06
[125,   200] loss: 1.225e-06
Training loss: 0.000, train NMSE: -2.626e+01
Validation loss: 0.000, valid_NMSE: -2.562e+01

Best validation loss: -25.616943359375

Saving best model for epoch: 125

--------------------------------------------------
[INFO]: Epoch 126 of 200
Training
[126,   100] loss: 1.133e-06
[126,   200] loss: 1.141e-06
Validation
[126,   100] loss: 2.165e-06
[126,   200] loss: 1.244e-06
Training loss: 0.000, train NMSE: -2.606e+01
Validation loss: 0.000, valid_NMSE: -2.546e+01
--------------------------------------------------
[INFO]: Epoch 127 of 200
Training
[127,   100] loss: 1.132e-06
[127,   200] loss: 1.131e-06
Validation
[127,   100] loss: 2.022e-06
[127,   200] loss: 1.182e-06
Training loss: 0.000, train NMSE: -2.627e+01
Validation loss: 0.000, valid_NMSE: -2.540e+01
--------------------------------------------------
[INFO]: Epoch 128 of 200
Training
[128,   100] loss: 1.113e-06
[128,   200] loss: 1.140e-06
Validation
[128,   100] loss: 2.007e-06
[128,   200] loss: 1.180e-06
Training loss: 0.000, train NMSE: -2.659e+01
Validation loss: 0.000, valid_NMSE: -2.547e+01
--------------------------------------------------
[INFO]: Epoch 129 of 200
Training
[129,   100] loss: 1.143e-06
[129,   200] loss: 1.147e-06
Validation
[129,   100] loss: 1.895e-06
[129,   200] loss: 1.209e-06
Training loss: 0.000, train NMSE: -2.604e+01
Validation loss: 0.000, valid_NMSE: -2.517e+01
--------------------------------------------------
[INFO]: Epoch 130 of 200
Training
[130,   100] loss: 1.120e-06
[130,   200] loss: 1.124e-06
Validation
[130,   100] loss: 1.991e-06
[130,   200] loss: 1.175e-06
Training loss: 0.000, train NMSE: -2.674e+01
Validation loss: 0.000, valid_NMSE: -2.525e+01
--------------------------------------------------
[INFO]: Epoch 131 of 200
Training
[131,   100] loss: 1.097e-06
[131,   200] loss: 1.144e-06
Validation
[131,   100] loss: 1.582e-06
[131,   200] loss: 1.162e-06
Training loss: 0.000, train NMSE: -2.635e+01
Validation loss: 0.000, valid_NMSE: -2.493e+01
--------------------------------------------------
[INFO]: Epoch 132 of 200
Training
[132,   100] loss: 1.107e-06
[132,   200] loss: 1.102e-06
Validation
[132,   100] loss: 1.739e-06
[132,   200] loss: 1.165e-06
Training loss: 0.000, train NMSE: -2.647e+01
Validation loss: 0.000, valid_NMSE: -2.534e+01
--------------------------------------------------
[INFO]: Epoch 133 of 200
Training
[133,   100] loss: 1.091e-06
[133,   200] loss: 1.113e-06
Validation
[133,   100] loss: 1.317e-06
[133,   200] loss: 1.161e-06
Training loss: 0.000, train NMSE: -2.684e+01
Validation loss: 0.000, valid_NMSE: -2.512e+01
--------------------------------------------------
[INFO]: Epoch 134 of 200
Training
[134,   100] loss: 1.123e-06
[134,   200] loss: 1.136e-06
Validation
[134,   100] loss: 1.415e-06
[134,   200] loss: 1.181e-06
Training loss: 0.000, train NMSE: -2.624e+01
Validation loss: 0.000, valid_NMSE: -2.532e+01
--------------------------------------------------
[INFO]: Epoch 135 of 200
Training
[135,   100] loss: 1.096e-06
[135,   200] loss: 1.098e-06
Validation
[135,   100] loss: 1.263e-06
[135,   200] loss: 1.158e-06
Training loss: 0.000, train NMSE: -2.677e+01
Validation loss: 0.000, valid_NMSE: -2.554e+01
--------------------------------------------------
[INFO]: Epoch 136 of 200
Training
[136,   100] loss: 1.075e-06
[136,   200] loss: 1.075e-06
Validation
[136,   100] loss: 1.534e-06
[136,   200] loss: 1.127e-06
Training loss: 0.000, train NMSE: -2.607e+01
Validation loss: 0.000, valid_NMSE: -2.552e+01
--------------------------------------------------
[INFO]: Epoch 137 of 200
Training
[137,   100] loss: 1.088e-06
[137,   200] loss: 1.097e-06
Validation
[137,   100] loss: 1.797e-06
[137,   200] loss: 1.141e-06
Training loss: 0.000, train NMSE: -2.652e+01
Validation loss: 0.000, valid_NMSE: -2.558e+01
--------------------------------------------------
[INFO]: Epoch 138 of 200
Training
[138,   100] loss: 1.078e-06
[138,   200] loss: 1.084e-06
Validation
[138,   100] loss: 1.794e-06
[138,   200] loss: 1.115e-06
Training loss: 0.000, train NMSE: -2.663e+01
Validation loss: 0.000, valid_NMSE: -2.574e+01

Best validation loss: -25.74362564086914

Saving best model for epoch: 138

--------------------------------------------------
[INFO]: Epoch 139 of 200
Training
[139,   100] loss: 1.055e-06
[139,   200] loss: 1.077e-06
Validation
[139,   100] loss: 1.288e-06
[139,   200] loss: 1.183e-06
Training loss: 0.000, train NMSE: -2.635e+01
Validation loss: 0.000, valid_NMSE: -2.510e+01
--------------------------------------------------
[INFO]: Epoch 140 of 200
Training
[140,   100] loss: 1.071e-06
[140,   200] loss: 1.075e-06
Validation
[140,   100] loss: 1.768e-06
[140,   200] loss: 1.108e-06
Training loss: 0.000, train NMSE: -2.643e+01
Validation loss: 0.000, valid_NMSE: -2.585e+01

Best validation loss: -25.849531173706055

Saving best model for epoch: 140

--------------------------------------------------
[INFO]: Epoch 141 of 200
Training
[141,   100] loss: 1.071e-06
[141,   200] loss: 1.072e-06
Validation
[141,   100] loss: 2.042e-06
[141,   200] loss: 1.149e-06
Training loss: 0.000, train NMSE: -2.658e+01
Validation loss: 0.000, valid_NMSE: -2.535e+01
--------------------------------------------------
[INFO]: Epoch 142 of 200
Training
[142,   100] loss: 1.072e-06
[142,   200] loss: 1.075e-06
Validation
[142,   100] loss: 1.776e-06
[142,   200] loss: 1.118e-06
Training loss: 0.000, train NMSE: -2.693e+01
Validation loss: 0.000, valid_NMSE: -2.558e+01
--------------------------------------------------
[INFO]: Epoch 143 of 200
Training
[143,   100] loss: 1.060e-06
[143,   200] loss: 1.054e-06
Validation
[143,   100] loss: 1.526e-06
[143,   200] loss: 1.140e-06
Training loss: 0.000, train NMSE: -2.599e+01
Validation loss: 0.000, valid_NMSE: -2.545e+01
--------------------------------------------------
[INFO]: Epoch 144 of 200
Training
[144,   100] loss: 1.041e-06
[144,   200] loss: 1.066e-06
Validation
[144,   100] loss: 1.863e-06
[144,   200] loss: 1.108e-06
Training loss: 0.000, train NMSE: -2.700e+01
Validation loss: 0.000, valid_NMSE: -2.563e+01
--------------------------------------------------
[INFO]: Epoch 145 of 200
Training
[145,   100] loss: 1.057e-06
[145,   200] loss: 1.081e-06
Validation
[145,   100] loss: 1.685e-06
[145,   200] loss: 1.154e-06
Training loss: 0.000, train NMSE: -2.639e+01
Validation loss: 0.000, valid_NMSE: -2.569e+01
--------------------------------------------------
[INFO]: Epoch 146 of 200
Training
[146,   100] loss: 1.051e-06
[146,   200] loss: 1.076e-06
Validation
[146,   100] loss: 1.782e-06
[146,   200] loss: 1.114e-06
Training loss: 0.000, train NMSE: -2.637e+01
Validation loss: 0.000, valid_NMSE: -2.592e+01

Best validation loss: -25.92059326171875

Saving best model for epoch: 146

--------------------------------------------------
[INFO]: Epoch 147 of 200
Training
[147,   100] loss: 1.050e-06
[147,   200] loss: 1.042e-06
Validation
[147,   100] loss: 2.042e-06
[147,   200] loss: 1.128e-06
Training loss: 0.000, train NMSE: -2.584e+01
Validation loss: 0.000, valid_NMSE: -2.565e+01
--------------------------------------------------
[INFO]: Epoch 148 of 200
Training
[148,   100] loss: 1.015e-06
[148,   200] loss: 1.024e-06
Validation
[148,   100] loss: 1.756e-06
[148,   200] loss: 1.065e-06
Training loss: 0.000, train NMSE: -2.722e+01
Validation loss: 0.000, valid_NMSE: -2.574e+01
--------------------------------------------------
[INFO]: Epoch 149 of 200
Training
[149,   100] loss: 1.015e-06
[149,   200] loss: 1.020e-06
Validation
[149,   100] loss: 1.509e-06
[149,   200] loss: 1.088e-06
Training loss: 0.000, train NMSE: -2.716e+01
Validation loss: 0.000, valid_NMSE: -2.558e+01
--------------------------------------------------
[INFO]: Epoch 150 of 200
Training
[150,   100] loss: 1.007e-06
[150,   200] loss: 1.016e-06
Validation
[150,   100] loss: 1.442e-06
[150,   200] loss: 1.097e-06
Training loss: 0.000, train NMSE: -2.646e+01
Validation loss: 0.000, valid_NMSE: -2.598e+01

Best validation loss: -25.984079360961914

Saving best model for epoch: 150

--------------------------------------------------
[INFO]: Epoch 151 of 200
Training
[151,   100] loss: 1.016e-06
[151,   200] loss: 1.013e-06
Validation
[151,   100] loss: 1.481e-06
[151,   200] loss: 1.152e-06
Training loss: 0.000, train NMSE: -2.705e+01
Validation loss: 0.000, valid_NMSE: -2.580e+01
--------------------------------------------------
[INFO]: Epoch 152 of 200
Training
[152,   100] loss: 1.010e-06
[152,   200] loss: 1.028e-06
Validation
[152,   100] loss: 1.636e-06
[152,   200] loss: 1.079e-06
Training loss: 0.000, train NMSE: -2.664e+01
Validation loss: 0.000, valid_NMSE: -2.600e+01

Best validation loss: -26.000978469848633

Saving best model for epoch: 152

--------------------------------------------------
[INFO]: Epoch 153 of 200
Training
[153,   100] loss: 1.024e-06
[153,   200] loss: 1.030e-06
Validation
[153,   100] loss: 1.297e-06
[153,   200] loss: 1.099e-06
Training loss: 0.000, train NMSE: -2.646e+01
Validation loss: 0.000, valid_NMSE: -2.572e+01
--------------------------------------------------
[INFO]: Epoch 154 of 200
Training
[154,   100] loss: 1.023e-06
[154,   200] loss: 1.026e-06
Validation
[154,   100] loss: 1.532e-06
[154,   200] loss: 1.069e-06
Training loss: 0.000, train NMSE: -2.720e+01
Validation loss: 0.000, valid_NMSE: -2.594e+01
--------------------------------------------------
[INFO]: Epoch 155 of 200
Training
[155,   100] loss: 9.987e-07
[155,   200] loss: 1.013e-06
Validation
[155,   100] loss: 1.463e-06
[155,   200] loss: 1.055e-06
Training loss: 0.000, train NMSE: -2.707e+01
Validation loss: 0.000, valid_NMSE: -2.600e+01

Best validation loss: -26.003955841064453

Saving best model for epoch: 155

--------------------------------------------------
[INFO]: Epoch 156 of 200
Training
[156,   100] loss: 9.810e-07
[156,   200] loss: 1.021e-06
Validation
[156,   100] loss: 1.769e-06
[156,   200] loss: 1.024e-06
Training loss: 0.000, train NMSE: -2.705e+01
Validation loss: 0.000, valid_NMSE: -2.593e+01
--------------------------------------------------
[INFO]: Epoch 157 of 200
Training
[157,   100] loss: 1.009e-06
[157,   200] loss: 1.017e-06
Validation
[157,   100] loss: 1.862e-06
[157,   200] loss: 1.271e-06
Training loss: 0.000, train NMSE: -2.643e+01
Validation loss: 0.000, valid_NMSE: -2.459e+01
--------------------------------------------------
[INFO]: Epoch 158 of 200
Training
[158,   100] loss: 1.022e-06
[158,   200] loss: 9.976e-07
Validation
[158,   100] loss: 1.884e-06
[158,   200] loss: 1.047e-06
Training loss: 0.000, train NMSE: -2.648e+01
Validation loss: 0.000, valid_NMSE: -2.582e+01
--------------------------------------------------
[INFO]: Epoch 159 of 200
Training
[159,   100] loss: 1.020e-06
[159,   200] loss: 1.004e-06
Validation
[159,   100] loss: 1.545e-06
[159,   200] loss: 1.065e-06
Training loss: 0.000, train NMSE: -2.700e+01
Validation loss: 0.000, valid_NMSE: -2.583e+01
--------------------------------------------------
[INFO]: Epoch 160 of 200
Training
[160,   100] loss: 9.775e-07
[160,   200] loss: 1.002e-06
Validation
[160,   100] loss: 1.829e-06
[160,   200] loss: 1.010e-06
Training loss: 0.000, train NMSE: -2.749e+01
Validation loss: 0.000, valid_NMSE: -2.598e+01
--------------------------------------------------
[INFO]: Epoch 161 of 200
Training
[161,   100] loss: 9.646e-07
[161,   200] loss: 9.840e-07
Validation
[161,   100] loss: 1.813e-06
[161,   200] loss: 1.163e-06
Training loss: 0.000, train NMSE: -2.665e+01
Validation loss: 0.000, valid_NMSE: -2.598e+01
--------------------------------------------------
[INFO]: Epoch 162 of 200
Training
[162,   100] loss: 9.614e-07
[162,   200] loss: 9.665e-07
Validation
[162,   100] loss: 1.802e-06
[162,   200] loss: 1.023e-06
Training loss: 0.000, train NMSE: -2.719e+01
Validation loss: 0.000, valid_NMSE: -2.603e+01

Best validation loss: -26.02533721923828

Saving best model for epoch: 162

--------------------------------------------------
[INFO]: Epoch 163 of 200
Training
[163,   100] loss: 9.693e-07
[163,   200] loss: 9.675e-07
Validation
[163,   100] loss: 1.460e-06
[163,   200] loss: 1.034e-06
Training loss: 0.000, train NMSE: -2.649e+01
Validation loss: 0.000, valid_NMSE: -2.580e+01
--------------------------------------------------
[INFO]: Epoch 164 of 200
Training
[164,   100] loss: 9.440e-07
[164,   200] loss: 9.846e-07
Validation
[164,   100] loss: 1.813e-06
[164,   200] loss: 1.001e-06
Training loss: 0.000, train NMSE: -2.773e+01
Validation loss: 0.000, valid_NMSE: -2.596e+01
--------------------------------------------------
[INFO]: Epoch 165 of 200
Training
[165,   100] loss: 9.638e-07
[165,   200] loss: 9.672e-07
Validation
[165,   100] loss: 1.567e-06
[165,   200] loss: 1.050e-06
Training loss: 0.000, train NMSE: -2.720e+01
Validation loss: 0.000, valid_NMSE: -2.609e+01

Best validation loss: -26.0866641998291

Saving best model for epoch: 165

--------------------------------------------------
[INFO]: Epoch 166 of 200
Training
[166,   100] loss: 9.522e-07
[166,   200] loss: 9.713e-07
Validation
[166,   100] loss: 1.596e-06
[166,   200] loss: 1.006e-06
Training loss: 0.000, train NMSE: -2.735e+01
Validation loss: 0.000, valid_NMSE: -2.601e+01
--------------------------------------------------
[INFO]: Epoch 167 of 200
Training
[167,   100] loss: 9.405e-07
[167,   200] loss: 9.635e-07
Validation
[167,   100] loss: 1.450e-06
[167,   200] loss: 1.029e-06
Training loss: 0.000, train NMSE: -2.736e+01
Validation loss: 0.000, valid_NMSE: -2.592e+01
--------------------------------------------------
[INFO]: Epoch 168 of 200
Training
[168,   100] loss: 9.760e-07
[168,   200] loss: 9.674e-07
Validation
[168,   100] loss: 1.625e-06
[168,   200] loss: 1.048e-06
Training loss: 0.000, train NMSE: -2.688e+01
Validation loss: 0.000, valid_NMSE: -2.577e+01
--------------------------------------------------
[INFO]: Epoch 169 of 200
Training
[169,   100] loss: 9.387e-07
[169,   200] loss: 9.581e-07
Validation
[169,   100] loss: 1.585e-06
[169,   200] loss: 9.691e-07
Training loss: 0.000, train NMSE: -2.762e+01
Validation loss: 0.000, valid_NMSE: -2.636e+01

Best validation loss: -26.36186408996582

Saving best model for epoch: 169

--------------------------------------------------
[INFO]: Epoch 170 of 200
Training
[170,   100] loss: 9.379e-07
[170,   200] loss: 9.303e-07
Validation
[170,   100] loss: 1.623e-06
[170,   200] loss: 9.650e-07
Training loss: 0.000, train NMSE: -2.751e+01
Validation loss: 0.000, valid_NMSE: -2.628e+01
--------------------------------------------------
[INFO]: Epoch 171 of 200
Training
[171,   100] loss: 9.342e-07
[171,   200] loss: 9.624e-07
Validation
[171,   100] loss: 1.797e-06
[171,   200] loss: 1.042e-06
Training loss: 0.000, train NMSE: -2.730e+01
Validation loss: 0.000, valid_NMSE: -2.578e+01
--------------------------------------------------
[INFO]: Epoch 172 of 200
Training
[172,   100] loss: 9.352e-07
[172,   200] loss: 9.486e-07
Validation
[172,   100] loss: 1.609e-06
[172,   200] loss: 9.828e-07
Training loss: 0.000, train NMSE: -2.758e+01
Validation loss: 0.000, valid_NMSE: -2.612e+01
--------------------------------------------------
[INFO]: Epoch 173 of 200
Training
[173,   100] loss: 9.473e-07
[173,   200] loss: 9.353e-07
Validation
[173,   100] loss: 1.553e-06
[173,   200] loss: 9.796e-07
Training loss: 0.000, train NMSE: -2.653e+01
Validation loss: 0.000, valid_NMSE: -2.628e+01
--------------------------------------------------
[INFO]: Epoch 174 of 200
Training
[174,   100] loss: 9.118e-07
[174,   200] loss: 9.602e-07
Validation
[174,   100] loss: 1.754e-06
[174,   200] loss: 9.824e-07
Training loss: 0.000, train NMSE: -2.709e+01
Validation loss: 0.000, valid_NMSE: -2.572e+01
--------------------------------------------------
[INFO]: Epoch 175 of 200
Training
[175,   100] loss: 9.164e-07
[175,   200] loss: 9.316e-07
Validation
[175,   100] loss: 1.681e-06
[175,   200] loss: 9.682e-07
Training loss: 0.000, train NMSE: -2.725e+01
Validation loss: 0.000, valid_NMSE: -2.621e+01
--------------------------------------------------
[INFO]: Epoch 176 of 200
Training
[176,   100] loss: 9.224e-07
[176,   200] loss: 9.197e-07
Validation
[176,   100] loss: 1.660e-06
[176,   200] loss: 9.864e-07
Training loss: 0.000, train NMSE: -2.760e+01
Validation loss: 0.000, valid_NMSE: -2.602e+01
--------------------------------------------------
[INFO]: Epoch 177 of 200
Training
[177,   100] loss: 9.145e-07
[177,   200] loss: 9.399e-07
Validation
[177,   100] loss: 1.606e-06
[177,   200] loss: 1.067e-06
Training loss: 0.000, train NMSE: -2.767e+01
Validation loss: 0.000, valid_NMSE: -2.617e+01
--------------------------------------------------
[INFO]: Epoch 178 of 200
Training
[178,   100] loss: 9.332e-07
[178,   200] loss: 9.128e-07
Validation
[178,   100] loss: 1.312e-06
[178,   200] loss: 9.606e-07
Training loss: 0.000, train NMSE: -2.774e+01
Validation loss: 0.000, valid_NMSE: -2.629e+01
--------------------------------------------------
[INFO]: Epoch 179 of 200
Training
[179,   100] loss: 9.165e-07
[179,   200] loss: 9.222e-07
Validation
[179,   100] loss: 1.653e-06
[179,   200] loss: 9.676e-07
Training loss: 0.000, train NMSE: -2.651e+01
Validation loss: 0.000, valid_NMSE: -2.604e+01
--------------------------------------------------
[INFO]: Epoch 180 of 200
Training
[180,   100] loss: 9.070e-07
[180,   200] loss: 9.476e-07
Validation
[180,   100] loss: 1.233e-06
[180,   200] loss: 9.992e-07
Training loss: 0.000, train NMSE: -2.692e+01
Validation loss: 0.000, valid_NMSE: -2.594e+01
--------------------------------------------------
[INFO]: Epoch 181 of 200
Training
[181,   100] loss: 9.038e-07
[181,   200] loss: 9.234e-07
Validation
[181,   100] loss: 1.726e-06
[181,   200] loss: 1.015e-06
Training loss: 0.000, train NMSE: -2.669e+01
Validation loss: 0.000, valid_NMSE: -2.593e+01
--------------------------------------------------
[INFO]: Epoch 182 of 200
Training
[182,   100] loss: 9.089e-07
[182,   200] loss: 9.149e-07
Validation
[182,   100] loss: 1.706e-06
[182,   200] loss: 1.023e-06
Training loss: 0.000, train NMSE: -2.706e+01
Validation loss: 0.000, valid_NMSE: -2.550e+01
--------------------------------------------------
[INFO]: Epoch 183 of 200
Training
[183,   100] loss: 9.188e-07
[183,   200] loss: 9.211e-07
Validation
[183,   100] loss: 1.341e-06
[183,   200] loss: 9.545e-07
Training loss: 0.000, train NMSE: -2.704e+01
Validation loss: 0.000, valid_NMSE: -2.607e+01
--------------------------------------------------
[INFO]: Epoch 184 of 200
Training
[184,   100] loss: 8.922e-07
[184,   200] loss: 9.159e-07
Validation
[184,   100] loss: 1.164e-06
[184,   200] loss: 9.360e-07
Training loss: 0.000, train NMSE: -2.706e+01
Validation loss: 0.000, valid_NMSE: -2.625e+01
--------------------------------------------------
[INFO]: Epoch 185 of 200
Training
[185,   100] loss: 9.122e-07
[185,   200] loss: 9.052e-07
Validation
[185,   100] loss: 1.118e-06
[185,   200] loss: 9.680e-07
Training loss: 0.000, train NMSE: -2.695e+01
Validation loss: 0.000, valid_NMSE: -2.603e+01
--------------------------------------------------
[INFO]: Epoch 186 of 200
Training
[186,   100] loss: 8.609e-07
[186,   200] loss: 9.219e-07
Validation
[186,   100] loss: 1.074e-06
[186,   200] loss: 9.427e-07
Training loss: 0.000, train NMSE: -2.712e+01
Validation loss: 0.000, valid_NMSE: -2.619e+01
--------------------------------------------------
[INFO]: Epoch 187 of 200
Training
[187,   100] loss: 8.826e-07
[187,   200] loss: 8.998e-07
Validation
[187,   100] loss: 1.301e-06
[187,   200] loss: 9.624e-07
Training loss: 0.000, train NMSE: -2.779e+01
Validation loss: 0.000, valid_NMSE: -2.610e+01
--------------------------------------------------
[INFO]: Epoch 188 of 200
Training
[188,   100] loss: 9.048e-07
[188,   200] loss: 8.903e-07
Validation
[188,   100] loss: 1.336e-06
[188,   200] loss: 9.354e-07
Training loss: 0.000, train NMSE: -2.710e+01
Validation loss: 0.000, valid_NMSE: -2.637e+01

Best validation loss: -26.373920440673828

Saving best model for epoch: 188

--------------------------------------------------
[INFO]: Epoch 189 of 200
Training
[189,   100] loss: 8.724e-07
[189,   200] loss: 9.045e-07
Validation
[189,   100] loss: 1.300e-06
[189,   200] loss: 9.458e-07
Training loss: 0.000, train NMSE: -2.688e+01
Validation loss: 0.000, valid_NMSE: -2.603e+01
--------------------------------------------------
[INFO]: Epoch 190 of 200
Training
[190,   100] loss: 8.607e-07
[190,   200] loss: 8.956e-07
Validation
[190,   100] loss: 1.063e-06
[190,   200] loss: 9.783e-07
Training loss: 0.000, train NMSE: -2.834e+01
Validation loss: 0.000, valid_NMSE: -2.561e+01
--------------------------------------------------
[INFO]: Epoch 191 of 200
Training
[191,   100] loss: 8.708e-07
[191,   200] loss: 8.934e-07
Validation
[191,   100] loss: 1.106e-06
[191,   200] loss: 9.294e-07
Training loss: 0.000, train NMSE: -2.798e+01
Validation loss: 0.000, valid_NMSE: -2.635e+01
--------------------------------------------------
[INFO]: Epoch 192 of 200
Training
[192,   100] loss: 8.945e-07
[192,   200] loss: 8.814e-07
Validation
[192,   100] loss: 1.022e-06
[192,   200] loss: 9.097e-07
Training loss: 0.000, train NMSE: -2.718e+01
Validation loss: 0.000, valid_NMSE: -2.610e+01
--------------------------------------------------
[INFO]: Epoch 193 of 200
Training
[193,   100] loss: 8.929e-07
[193,   200] loss: 8.807e-07
Validation
[193,   100] loss: 9.719e-07
[193,   200] loss: 9.527e-07
Training loss: 0.000, train NMSE: -2.732e+01
Validation loss: 0.000, valid_NMSE: -2.592e+01
--------------------------------------------------
[INFO]: Epoch 194 of 200
Training
[194,   100] loss: 8.731e-07
[194,   200] loss: 8.897e-07
Validation
[194,   100] loss: 1.011e-06
[194,   200] loss: 9.291e-07
Training loss: 0.000, train NMSE: -2.740e+01
Validation loss: 0.000, valid_NMSE: -2.630e+01
--------------------------------------------------
[INFO]: Epoch 195 of 200
Training
[195,   100] loss: 9.036e-07
[195,   200] loss: 8.796e-07
Validation
[195,   100] loss: 9.990e-07
[195,   200] loss: 9.365e-07
Training loss: 0.000, train NMSE: -2.725e+01
Validation loss: 0.000, valid_NMSE: -2.643e+01

Best validation loss: -26.42641830444336

Saving best model for epoch: 195

--------------------------------------------------
[INFO]: Epoch 196 of 200
Training
[196,   100] loss: 8.475e-07
[196,   200] loss: 8.750e-07
Validation
[196,   100] loss: 1.089e-06
[196,   200] loss: 9.267e-07
Training loss: 0.000, train NMSE: -2.802e+01
Validation loss: 0.000, valid_NMSE: -2.619e+01
--------------------------------------------------
[INFO]: Epoch 197 of 200
Training
[197,   100] loss: 8.920e-07
[197,   200] loss: 8.702e-07
Validation
[197,   100] loss: 1.155e-06
[197,   200] loss: 9.145e-07/home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE
  warn(f"Failed to load image Python extension: {e}")

Training loss: 0.000, train NMSE: -2.711e+01
Validation loss: 0.000, valid_NMSE: -2.634e+01
--------------------------------------------------
[INFO]: Epoch 198 of 200
Training
[198,   100] loss: 8.853e-07
[198,   200] loss: 8.860e-07
Validation
[198,   100] loss: 9.982e-07
[198,   200] loss: 9.399e-07
Training loss: 0.000, train NMSE: -2.768e+01
Validation loss: 0.000, valid_NMSE: -2.671e+01

Best validation loss: -26.70834732055664

Saving best model for epoch: 198

--------------------------------------------------
[INFO]: Epoch 199 of 200
Training
[199,   100] loss: 8.729e-07
[199,   200] loss: 8.580e-07
Validation
[199,   100] loss: 9.235e-07
[199,   200] loss: 8.941e-07
Training loss: 0.000, train NMSE: -2.726e+01
Validation loss: 0.000, valid_NMSE: -2.640e+01
--------------------------------------------------
[INFO]: Epoch 200 of 200
Training
[200,   100] loss: 8.535e-07
[200,   200] loss: 8.729e-07
Validation
[200,   100] loss: 1.016e-06
[200,   200] loss: 9.060e-07
Training loss: 0.000, train NMSE: -2.783e+01
Validation loss: 0.000, valid_NMSE: -2.663e+01
--------------------------------------------------
Saving final model
TRAINING COMPLETE
