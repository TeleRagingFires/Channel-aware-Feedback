1.13.1+cu117
inEnergyID
Dadicated Mode inEnergyID
Dedicated Mode inEnergyID
trainset len 112000 valset len 48000
New_trainset len 40000 valset len 48000
825,049 training parameters.

825,049 training parameters.

[INFO]: Epoch 1 of 200
Training
[1,   100] loss: 2.937e-04
[1,   200] loss: 2.464e-04
Validation
[1,   100] loss: 2.101e-04
[1,   200] loss: 2.100e-04
Training loss: 0.000, train NMSE: -3.336e+00
Validation loss: 0.000, valid_NMSE: -3.759e+00

Best validation loss: -3.7586846351623535

Saving best model for epoch: 1

--------------------------------------------------
[INFO]: Epoch 2 of 200
Training
[2,   100] loss: 2.169e-04
[2,   200] loss: 2.001e-04
Validation
[2,   100] loss: 1.753e-04
[2,   200] loss: 1.746e-04
Training loss: 0.000, train NMSE: -3.752e+00
Validation loss: 0.000, valid_NMSE: -4.690e+00

Best validation loss: -4.690410137176514

Saving best model for epoch: 2

--------------------------------------------------
[INFO]: Epoch 3 of 200
Training
[3,   100] loss: 1.880e-04
[3,   200] loss: 1.777e-04
Validation
[3,   100] loss: 1.574e-04
[3,   200] loss: 1.566e-04
Training loss: 0.000, train NMSE: -4.858e+00
Validation loss: 0.000, valid_NMSE: -5.257e+00

Best validation loss: -5.256558418273926

Saving best model for epoch: 3

--------------------------------------------------
[INFO]: Epoch 4 of 200
Training
[4,   100] loss: 1.689e-04
[4,   200] loss: 1.592e-04
Validation
[4,   100] loss: 1.417e-04
[4,   200] loss: 1.407e-04
Training loss: 0.000, train NMSE: -5.225e+00
Validation loss: 0.000, valid_NMSE: -5.748e+00

Best validation loss: -5.7483744621276855

Saving best model for epoch: 4

--------------------------------------------------
[INFO]: Epoch 5 of 200
Training
[5,   100] loss: 1.519e-04
[5,   200] loss: 1.449e-04
Validation
[5,   100] loss: 1.279e-04
[5,   200] loss: 1.271e-04
Training loss: 0.000, train NMSE: -5.392e+00
Validation loss: 0.000, valid_NMSE: -6.181e+00

Best validation loss: -6.1811065673828125

Saving best model for epoch: 5

--------------------------------------------------
[INFO]: Epoch 6 of 200
Training
[6,   100] loss: 1.353e-04
[6,   200] loss: 1.292e-04
Validation
[6,   100] loss: 1.148e-04
[6,   200] loss: 1.136e-04
Training loss: 0.000, train NMSE: -6.339e+00
Validation loss: 0.000, valid_NMSE: -6.640e+00

Best validation loss: -6.640076637268066

Saving best model for epoch: 6

--------------------------------------------------
[INFO]: Epoch 7 of 200
Training
[7,   100] loss: 1.205e-04
[7,   200] loss: 1.153e-04
Validation
[7,   100] loss: 1.063e-04
[7,   200] loss: 1.050e-04
Training loss: 0.000, train NMSE: -6.563e+00
Validation loss: 0.000, valid_NMSE: -6.891e+00

Best validation loss: -6.890589714050293

Saving best model for epoch: 7

--------------------------------------------------
[INFO]: Epoch 8 of 200
Training
[8,   100] loss: 1.105e-04
[8,   200] loss: 1.081e-04
Validation
[8,   100] loss: 9.854e-05
[8,   200] loss: 9.739e-05
Training loss: 0.000, train NMSE: -7.254e+00
Validation loss: 0.000, valid_NMSE: -7.259e+00

Best validation loss: -7.258910179138184

Saving best model for epoch: 8

--------------------------------------------------
[INFO]: Epoch 9 of 200
Training
[9,   100] loss: 1.047e-04
[9,   200] loss: 1.047e-04
Validation
[9,   100] loss: 9.672e-05
[9,   200] loss: 9.549e-05
Training loss: 0.000, train NMSE: -6.307e+00
Validation loss: 0.000, valid_NMSE: -7.379e+00

Best validation loss: -7.3793816566467285

Saving best model for epoch: 9

--------------------------------------------------
[INFO]: Epoch 10 of 200
Training
[10,   100] loss: 1.005e-04
[10,   200] loss: 1.016e-04
Validation
[10,   100] loss: 9.388e-05
[10,   200] loss: 9.262e-05
Training loss: 0.000, train NMSE: -7.239e+00
Validation loss: 0.000, valid_NMSE: -7.551e+00

Best validation loss: -7.550845623016357

Saving best model for epoch: 10

--------------------------------------------------
[INFO]: Epoch 11 of 200
Training
[11,   100] loss: 9.889e-05
[11,   200] loss: 9.892e-05
Validation
[11,   100] loss: 9.449e-05
[11,   200] loss: 9.331e-05
Training loss: 0.000, train NMSE: -7.679e+00
Validation loss: 0.000, valid_NMSE: -7.566e+00

Best validation loss: -7.565545082092285

Saving best model for epoch: 11

--------------------------------------------------
[INFO]: Epoch 12 of 200
Training
[12,   100] loss: 9.578e-05
[12,   200] loss: 9.745e-05
Validation
[12,   100] loss: 9.007e-05
[12,   200] loss: 8.885e-05
Training loss: 0.000, train NMSE: -7.129e+00
Validation loss: 0.000, valid_NMSE: -7.603e+00

Best validation loss: -7.603240489959717

Saving best model for epoch: 12

--------------------------------------------------
[INFO]: Epoch 13 of 200
Training
[13,   100] loss: 9.453e-05
[13,   200] loss: 9.585e-05
Validation
[13,   100] loss: 8.996e-05
[13,   200] loss: 8.879e-05
Training loss: 0.000, train NMSE: -7.324e+00
Validation loss: 0.000, valid_NMSE: -7.714e+00

Best validation loss: -7.713677883148193

Saving best model for epoch: 13

--------------------------------------------------
[INFO]: Epoch 14 of 200
Training
[14,   100] loss: 9.504e-05
[14,   200] loss: 9.429e-05
Validation
[14,   100] loss: 8.811e-05
[14,   200] loss: 8.701e-05
Training loss: 0.000, train NMSE: -7.195e+00
Validation loss: 0.000, valid_NMSE: -7.786e+00

Best validation loss: -7.785902500152588

Saving best model for epoch: 14

--------------------------------------------------
[INFO]: Epoch 15 of 200
Training
[15,   100] loss: 9.207e-05
[15,   200] loss: 9.445e-05
Validation
[15,   100] loss: 8.888e-05
[15,   200] loss: 8.749e-05
Training loss: 0.000, train NMSE: -7.032e+00
Validation loss: 0.000, valid_NMSE: -7.890e+00

Best validation loss: -7.889683246612549

Saving best model for epoch: 15

--------------------------------------------------
[INFO]: Epoch 16 of 200
Training
[16,   100] loss: 9.257e-05
[16,   200] loss: 9.157e-05
Validation
[16,   100] loss: 8.756e-05
[16,   200] loss: 8.618e-05
Training loss: 0.000, train NMSE: -6.940e+00
Validation loss: 0.000, valid_NMSE: -7.877e+00
--------------------------------------------------
[INFO]: Epoch 17 of 200
Training
[17,   100] loss: 9.207e-05
[17,   200] loss: 9.121e-05
Validation
[17,   100] loss: 8.652e-05
[17,   200] loss: 8.513e-05
Training loss: 0.000, train NMSE: -7.913e+00
Validation loss: 0.000, valid_NMSE: -7.950e+00

Best validation loss: -7.950294017791748

Saving best model for epoch: 17

--------------------------------------------------
[INFO]: Epoch 18 of 200
Training
[18,   100] loss: 9.041e-05
[18,   200] loss: 9.011e-05
Validation
[18,   100] loss: 8.539e-05
[18,   200] loss: 8.400e-05
Training loss: 0.000, train NMSE: -8.068e+00
Validation loss: 0.000, valid_NMSE: -7.946e+00
--------------------------------------------------
[INFO]: Epoch 19 of 200
Training
[19,   100] loss: 8.962e-05
[19,   200] loss: 8.923e-05
Validation
[19,   100] loss: 8.464e-05
[19,   200] loss: 8.316e-05
Training loss: 0.000, train NMSE: -7.717e+00
Validation loss: 0.000, valid_NMSE: -8.078e+00

Best validation loss: -8.077752113342285

Saving best model for epoch: 19

--------------------------------------------------
[INFO]: Epoch 20 of 200
Training
[20,   100] loss: 8.917e-05
[20,   200] loss: 8.905e-05
Validation
[20,   100] loss: 8.450e-05
[20,   200] loss: 8.306e-05
Training loss: 0.000, train NMSE: -8.301e+00
Validation loss: 0.000, valid_NMSE: -8.090e+00

Best validation loss: -8.090065956115723

Saving best model for epoch: 20

--------------------------------------------------
[INFO]: Epoch 21 of 200
Training
[21,   100] loss: 8.819e-05
[21,   200] loss: 8.801e-05
Validation
[21,   100] loss: 8.384e-05
[21,   200] loss: 8.235e-05
Training loss: 0.000, train NMSE: -8.132e+00
Validation loss: 0.000, valid_NMSE: -7.993e+00
--------------------------------------------------
[INFO]: Epoch 22 of 200
Training
[22,   100] loss: 8.795e-05
[22,   200] loss: 8.716e-05
Validation
[22,   100] loss: 8.446e-05
[22,   200] loss: 8.303e-05
Training loss: 0.000, train NMSE: -7.839e+00
Validation loss: 0.000, valid_NMSE: -8.130e+00

Best validation loss: -8.129629135131836

Saving best model for epoch: 22

--------------------------------------------------
[INFO]: Epoch 23 of 200
Training
[23,   100] loss: 8.719e-05
[23,   200] loss: 8.795e-05
Validation
[23,   100] loss: 8.548e-05
[23,   200] loss: 8.399e-05
Training loss: 0.000, train NMSE: -7.972e+00
Validation loss: 0.000, valid_NMSE: -8.071e+00
--------------------------------------------------
[INFO]: Epoch 24 of 200
Training
[24,   100] loss: 8.599e-05
[24,   200] loss: 8.786e-05
Validation
[24,   100] loss: 8.304e-05
[24,   200] loss: 8.152e-05
Training loss: 0.000, train NMSE: -7.915e+00
Validation loss: 0.000, valid_NMSE: -8.217e+00

Best validation loss: -8.217162132263184

Saving best model for epoch: 24

--------------------------------------------------
[INFO]: Epoch 25 of 200
Training
[25,   100] loss: 8.670e-05
[25,   200] loss: 8.566e-05
Validation
[25,   100] loss: 8.311e-05
[25,   200] loss: 8.159e-05
Training loss: 0.000, train NMSE: -7.301e+00
Validation loss: 0.000, valid_NMSE: -8.200e+00
--------------------------------------------------
[INFO]: Epoch 26 of 200
Training
[26,   100] loss: 8.490e-05
[26,   200] loss: 8.645e-05
Validation
[26,   100] loss: 8.370e-05
[26,   200] loss: 8.218e-05
Training loss: 0.000, train NMSE: -7.927e+00
Validation loss: 0.000, valid_NMSE: -8.167e+00
--------------------------------------------------
[INFO]: Epoch 27 of 200
Training
[27,   100] loss: 8.574e-05
[27,   200] loss: 8.556e-05
Validation
[27,   100] loss: 8.160e-05
[27,   200] loss: 8.006e-05
Training loss: 0.000, train NMSE: -8.262e+00
Validation loss: 0.000, valid_NMSE: -8.257e+00

Best validation loss: -8.257000923156738

Saving best model for epoch: 27

--------------------------------------------------
[INFO]: Epoch 28 of 200
Training
[28,   100] loss: 8.467e-05
[28,   200] loss: 8.586e-05
Validation
[28,   100] loss: 8.223e-05
[28,   200] loss: 8.073e-05
Training loss: 0.000, train NMSE: -7.913e+00
Validation loss: 0.000, valid_NMSE: -8.274e+00

Best validation loss: -8.273815155029297

Saving best model for epoch: 28

--------------------------------------------------
[INFO]: Epoch 29 of 200
Training
[29,   100] loss: 8.411e-05
[29,   200] loss: 8.505e-05
Validation
[29,   100] loss: 8.090e-05
[29,   200] loss: 7.945e-05
Training loss: 0.000, train NMSE: -7.956e+00
Validation loss: 0.000, valid_NMSE: -8.277e+00

Best validation loss: -8.277167320251465

Saving best model for epoch: 29

--------------------------------------------------
[INFO]: Epoch 30 of 200
Training
[30,   100] loss: 8.361e-05
[30,   200] loss: 8.497e-05
Validation
[30,   100] loss: 8.463e-05
[30,   200] loss: 8.318e-05
Training loss: 0.000, train NMSE: -7.640e+00
Validation loss: 0.000, valid_NMSE: -8.175e+00
--------------------------------------------------
[INFO]: Epoch 31 of 200
Training
[31,   100] loss: 8.457e-05
[31,   200] loss: 8.334e-05
Validation
[31,   100] loss: 8.248e-05
[31,   200] loss: 8.088e-05
Training loss: 0.000, train NMSE: -7.728e+00
Validation loss: 0.000, valid_NMSE: -8.212e+00
--------------------------------------------------
[INFO]: Epoch 32 of 200
Training
[32,   100] loss: 8.370e-05
[32,   200] loss: 8.341e-05
Validation
[32,   100] loss: 8.034e-05
[32,   200] loss: 7.880e-05
Training loss: 0.000, train NMSE: -7.827e+00
Validation loss: 0.000, valid_NMSE: -8.397e+00

Best validation loss: -8.397446632385254

Saving best model for epoch: 32

--------------------------------------------------
[INFO]: Epoch 33 of 200
Training
[33,   100] loss: 8.228e-05
[33,   200] loss: 8.442e-05
Validation
[33,   100] loss: 8.175e-05
[33,   200] loss: 8.025e-05
Training loss: 0.000, train NMSE: -8.362e+00
Validation loss: 0.000, valid_NMSE: -8.346e+00
--------------------------------------------------
[INFO]: Epoch 34 of 200
Training
[34,   100] loss: 8.288e-05
[34,   200] loss: 8.236e-05
Validation
[34,   100] loss: 8.075e-05
[34,   200] loss: 7.922e-05
Training loss: 0.000, train NMSE: -8.126e+00
Validation loss: 0.000, valid_NMSE: -8.396e+00
--------------------------------------------------
[INFO]: Epoch 35 of 200
Training
[35,   100] loss: 8.258e-05
[35,   200] loss: 8.151e-05
Validation
[35,   100] loss: 7.910e-05
[35,   200] loss: 7.753e-05
Training loss: 0.000, train NMSE: -8.209e+00
Validation loss: 0.000, valid_NMSE: -8.445e+00

Best validation loss: -8.444680213928223

Saving best model for epoch: 35

--------------------------------------------------
[INFO]: Epoch 36 of 200
Training
[36,   100] loss: 8.087e-05
[36,   200] loss: 8.292e-05
Validation
[36,   100] loss: 7.834e-05
[36,   200] loss: 7.682e-05
Training loss: 0.000, train NMSE: -7.598e+00
Validation loss: 0.000, valid_NMSE: -8.418e+00
--------------------------------------------------
[INFO]: Epoch 37 of 200
Training
[37,   100] loss: 8.159e-05
[37,   200] loss: 8.184e-05
Validation
[37,   100] loss: 7.859e-05
[37,   200] loss: 7.709e-05
Training loss: 0.000, train NMSE: -7.813e+00
Validation loss: 0.000, valid_NMSE: -8.490e+00

Best validation loss: -8.489665985107422

Saving best model for epoch: 37

--------------------------------------------------
[INFO]: Epoch 38 of 200
Training
[38,   100] loss: 8.149e-05
[38,   200] loss: 8.084e-05
Validation
[38,   100] loss: 7.889e-05
[38,   200] loss: 7.736e-05
Training loss: 0.000, train NMSE: -8.438e+00
Validation loss: 0.000, valid_NMSE: -8.468e+00
--------------------------------------------------
[INFO]: Epoch 39 of 200
Training
[39,   100] loss: 8.043e-05
[39,   200] loss: 8.025e-05
Validation
[39,   100] loss: 7.781e-05
[39,   200] loss: 7.633e-05
Training loss: 0.000, train NMSE: -8.496e+00
Validation loss: 0.000, valid_NMSE: -8.502e+00

Best validation loss: -8.501811027526855

Saving best model for epoch: 39

--------------------------------------------------
[INFO]: Epoch 40 of 200
Training
[40,   100] loss: 8.002e-05
[40,   200] loss: 8.026e-05
Validation
[40,   100] loss: 7.775e-05
[40,   200] loss: 7.625e-05
Training loss: 0.000, train NMSE: -7.788e+00
Validation loss: 0.000, valid_NMSE: -8.560e+00

Best validation loss: -8.560335159301758

Saving best model for epoch: 40

--------------------------------------------------
[INFO]: Epoch 41 of 200
Training
[41,   100] loss: 7.902e-05
[41,   200] loss: 8.043e-05
Validation
[41,   100] loss: 7.692e-05
[41,   200] loss: 7.547e-05
Training loss: 0.000, train NMSE: -8.564e+00
Validation loss: 0.000, valid_NMSE: -8.580e+00

Best validation loss: -8.580368041992188

Saving best model for epoch: 41

--------------------------------------------------
[INFO]: Epoch 42 of 200
Training
[42,   100] loss: 7.919e-05
[42,   200] loss: 7.925e-05
Validation
[42,   100] loss: 7.647e-05
[42,   200] loss: 7.496e-05
Training loss: 0.000, train NMSE: -8.816e+00
Validation loss: 0.000, valid_NMSE: -8.591e+00

Best validation loss: -8.5910062789917

Saving best model for epoch: 42

--------------------------------------------------
[INFO]: Epoch 43 of 200
Training
[43,   100] loss: 7.845e-05
[43,   200] loss: 7.988e-05
Validation
[43,   100] loss: 7.670e-05
[43,   200] loss: 7.534e-05
Training loss: 0.000, train NMSE: -8.431e+00
Validation loss: 0.000, valid_NMSE: -8.586e+00
--------------------------------------------------
[INFO]: Epoch 44 of 200
Training
[44,   100] loss: 7.865e-05
[44,   200] loss: 7.750e-05
Validation
[44,   100] loss: 7.630e-05
[44,   200] loss: 7.482e-05
Training loss: 0.000, train NMSE: -8.452e+00
Validation loss: 0.000, valid_NMSE: -8.707e+00

Best validation loss: -8.70724105834961

Saving best model for epoch: 44

--------------------------------------------------
[INFO]: Epoch 45 of 200
Training
[45,   100] loss: 7.850e-05
[45,   200] loss: 7.905e-05
Validation
[45,   100] loss: 7.713e-05
[45,   200] loss: 7.569e-05
Training loss: 0.000, train NMSE: -9.054e+00
Validation loss: 0.000, valid_NMSE: -8.602e+00
--------------------------------------------------
[INFO]: Epoch 46 of 200
Training
[46,   100] loss: 7.771e-05
[46,   200] loss: 7.797e-05
Validation
[46,   100] loss: 7.633e-05
[46,   200] loss: 7.495e-05
Training loss: 0.000, train NMSE: -8.678e+00
Validation loss: 0.000, valid_NMSE: -8.697e+00
--------------------------------------------------
[INFO]: Epoch 47 of 200
Training
[47,   100] loss: 7.678e-05
[47,   200] loss: 7.835e-05
Validation
[47,   100] loss: 7.979e-05
[47,   200] loss: 7.851e-05
Training loss: 0.000, train NMSE: -7.943e+00
Validation loss: 0.000, valid_NMSE: -8.435e+00
--------------------------------------------------
[INFO]: Epoch 48 of 200
Training
[48,   100] loss: 7.722e-05
[48,   200] loss: 7.750e-05
Validation
[48,   100] loss: 7.717e-05
[48,   200] loss: 7.581e-05
Training loss: 0.000, train NMSE: -7.996e+00
Validation loss: 0.000, valid_NMSE: -8.647e+00
--------------------------------------------------
[INFO]: Epoch 49 of 200
Training
[49,   100] loss: 7.803e-05
[49,   200] loss: 7.642e-05
Validation
[49,   100] loss: 7.557e-05
[49,   200] loss: 7.416e-05
Training loss: 0.000, train NMSE: -8.074e+00
Validation loss: 0.000, valid_NMSE: -8.754e+00

Best validation loss: -8.754154205322266

Saving best model for epoch: 49

--------------------------------------------------
[INFO]: Epoch 50 of 200
Training
[50,   100] loss: 7.581e-05
[50,   200] loss: 7.843e-05
Validation
[50,   100] loss: 7.534e-05
[50,   200] loss: 7.395e-05
Training loss: 0.000, train NMSE: -9.042e+00
Validation loss: 0.000, valid_NMSE: -8.772e+00

Best validation loss: -8.771873474121094

Saving best model for epoch: 50

--------------------------------------------------
[INFO]: Epoch 51 of 200
Training
[51,   100] loss: 7.565e-05
[51,   200] loss: 7.712e-05
Validation
[51,   100] loss: 7.401e-05
[51,   200] loss: 7.264e-05
Training loss: 0.000, train NMSE: -8.554e+00
Validation loss: 0.000, valid_NMSE: -8.774e+00

Best validation loss: -8.77383041381836

Saving best model for epoch: 51

--------------------------------------------------
[INFO]: Epoch 52 of 200
Training
[52,   100] loss: 7.665e-05
[52,   200] loss: 7.582e-05
Validation
[52,   100] loss: 7.466e-05
[52,   200] loss: 7.329e-05
Training loss: 0.000, train NMSE: -8.263e+00
Validation loss: 0.000, valid_NMSE: -8.835e+00

Best validation loss: -8.835168838500977

Saving best model for epoch: 52

--------------------------------------------------
[INFO]: Epoch 53 of 200
Training
[53,   100] loss: 7.490e-05
[53,   200] loss: 7.668e-05
Validation
[53,   100] loss: 7.352e-05
[53,   200] loss: 7.222e-05
Training loss: 0.000, train NMSE: -8.584e+00
Validation loss: 0.000, valid_NMSE: -8.829e+00
--------------------------------------------------
[INFO]: Epoch 54 of 200
Training
[54,   100] loss: 7.429e-05
[54,   200] loss: 7.686e-05
Validation
[54,   100] loss: 7.314e-05
[54,   200] loss: 7.186e-05
Training loss: 0.000, train NMSE: -8.555e+00
Validation loss: 0.000, valid_NMSE: -8.911e+00

Best validation loss: -8.911364555358887

Saving best model for epoch: 54

--------------------------------------------------
[INFO]: Epoch 55 of 200
Training
[55,   100] loss: 7.518e-05
[55,   200] loss: 7.601e-05
Validation
[55,   100] loss: 7.419e-05
[55,   200] loss: 7.297e-05
Training loss: 0.000, train NMSE: -8.403e+00
Validation loss: 0.000, valid_NMSE: -8.844e+00
--------------------------------------------------
[INFO]: Epoch 56 of 200
Training
[56,   100] loss: 7.542e-05
[56,   200] loss: 7.512e-05
Validation
[56,   100] loss: 7.245e-05
[56,   200] loss: 7.117e-05
Training loss: 0.000, train NMSE: -8.418e+00
Validation loss: 0.000, valid_NMSE: -8.883e+00
--------------------------------------------------
[INFO]: Epoch 57 of 200
Training
[57,   100] loss: 7.511e-05
[57,   200] loss: 7.501e-05
Validation
[57,   100] loss: 7.368e-05
[57,   200] loss: 7.240e-05
Training loss: 0.000, train NMSE: -8.696e+00
Validation loss: 0.000, valid_NMSE: -8.862e+00
--------------------------------------------------
[INFO]: Epoch 58 of 200
Training
[58,   100] loss: 7.400e-05
[58,   200] loss: 7.570e-05
Validation
[58,   100] loss: 7.219e-05
[58,   200] loss: 7.090e-05
Training loss: 0.000, train NMSE: -7.913e+00
Validation loss: 0.000, valid_NMSE: -8.939e+00

Best validation loss: -8.938668251037598

Saving best model for epoch: 58

--------------------------------------------------
[INFO]: Epoch 59 of 200
Training
[59,   100] loss: 7.324e-05
[59,   200] loss: 7.622e-05
Validation
[59,   100] loss: 7.319e-05
[59,   200] loss: 7.191e-05
Training loss: 0.000, train NMSE: -9.063e+00
Validation loss: 0.000, valid_NMSE: -8.889e+00
--------------------------------------------------
[INFO]: Epoch 60 of 200
Training
[60,   100] loss: 7.396e-05
[60,   200] loss: 7.460e-05
Validation
[60,   100] loss: 7.224e-05
[60,   200] loss: 7.089e-05
Training loss: 0.000, train NMSE: -8.747e+00
Validation loss: 0.000, valid_NMSE: -8.946e+00

Best validation loss: -8.945698738098145

Saving best model for epoch: 60

--------------------------------------------------
[INFO]: Epoch 61 of 200
Training
[61,   100] loss: 7.277e-05
[61,   200] loss: 7.491e-05
Validation
[61,   100] loss: 7.234e-05
[61,   200] loss: 7.107e-05
Training loss: 0.000, train NMSE: -8.534e+00
Validation loss: 0.000, valid_NMSE: -8.952e+00

Best validation loss: -8.952402114868164

Saving best model for epoch: 61

--------------------------------------------------
[INFO]: Epoch 62 of 200
Training
[62,   100] loss: 7.335e-05
[62,   200] loss: 7.460e-05
Validation
[62,   100] loss: 7.377e-05
[62,   200] loss: 7.255e-05
Training loss: 0.000, train NMSE: -8.652e+00
Validation loss: 0.000, valid_NMSE: -8.963e+00

Best validation loss: -8.962843894958496

Saving best model for epoch: 62

--------------------------------------------------
[INFO]: Epoch 63 of 200
Training
[63,   100] loss: 7.385e-05
[63,   200] loss: 7.393e-05
Validation
[63,   100] loss: 7.169e-05
[63,   200] loss: 7.048e-05
Training loss: 0.000, train NMSE: -8.697e+00
Validation loss: 0.000, valid_NMSE: -9.007e+00

Best validation loss: -9.007171630859375

Saving best model for epoch: 63

--------------------------------------------------
[INFO]: Epoch 64 of 200
Training
[64,   100] loss: 7.264e-05
[64,   200] loss: 7.424e-05
Validation
[64,   100] loss: 7.245e-05
[64,   200] loss: 7.113e-05
Training loss: 0.000, train NMSE: -8.977e+00
Validation loss: 0.000, valid_NMSE: -9.007e+00
--------------------------------------------------
[INFO]: Epoch 65 of 200
Training
[65,   100] loss: 7.424e-05
[65,   200] loss: 7.289e-05
Validation
[65,   100] loss: 7.272e-05
[65,   200] loss: 7.147e-05
Training loss: 0.000, train NMSE: -8.511e+00
Validation loss: 0.000, valid_NMSE: -8.977e+00
--------------------------------------------------
[INFO]: Epoch 66 of 200
Training
[66,   100] loss: 7.244e-05
[66,   200] loss: 7.376e-05
Validation
[66,   100] loss: 7.146e-05
[66,   200] loss: 7.027e-05
Training loss: 0.000, train NMSE: -8.727e+00
Validation loss: 0.000, valid_NMSE: -9.015e+00

Best validation loss: -9.014606475830078

Saving best model for epoch: 66

--------------------------------------------------
[INFO]: Epoch 67 of 200
Training
[67,   100] loss: 7.239e-05
[67,   200] loss: 7.301e-05
Validation
[67,   100] loss: 7.198e-05
[67,   200] loss: 7.080e-05
Training loss: 0.000, train NMSE: -8.008e+00
Validation loss: 0.000, valid_NMSE: -8.987e+00
--------------------------------------------------
[INFO]: Epoch 68 of 200
Training
[68,   100] loss: 7.380e-05
[68,   200] loss: 7.162e-05
Validation
[68,   100] loss: 7.087e-05
[68,   200] loss: 6.967e-05
Training loss: 0.000, train NMSE: -8.600e+00
Validation loss: 0.000, valid_NMSE: -9.089e+00

Best validation loss: -9.088679313659668

Saving best model for epoch: 68

--------------------------------------------------
[INFO]: Epoch 69 of 200
Training
[69,   100] loss: 7.212e-05
[69,   200] loss: 7.325e-05
Validation
[69,   100] loss: 7.103e-05
[69,   200] loss: 6.985e-05
Training loss: 0.000, train NMSE: -8.195e+00
Validation loss: 0.000, valid_NMSE: -9.115e+00

Best validation loss: -9.114546775817871

Saving best model for epoch: 69

--------------------------------------------------
[INFO]: Epoch 70 of 200
Training
[70,   100] loss: 7.313e-05
[70,   200] loss: 7.232e-05
Validation
[70,   100] loss: 7.153e-05
[70,   200] loss: 7.038e-05
Training loss: 0.000, train NMSE: -8.631e+00
Validation loss: 0.000, valid_NMSE: -9.046e+00
--------------------------------------------------
[INFO]: Epoch 71 of 200
Training
[71,   100] loss: 7.265e-05
[71,   200] loss: 7.189e-05
Validation
[71,   100] loss: 7.243e-05
[71,   200] loss: 7.131e-05
Training loss: 0.000, train NMSE: -8.838e+00
Validation loss: 0.000, valid_NMSE: -9.029e+00
--------------------------------------------------
[INFO]: Epoch 72 of 200
Training
[72,   100] loss: 7.217e-05
[72,   200] loss: 7.224e-05
Validation
[72,   100] loss: 7.149e-05
[72,   200] loss: 7.030e-05
Training loss: 0.000, train NMSE: -7.879e+00
Validation loss: 0.000, valid_NMSE: -9.068e+00
--------------------------------------------------
[INFO]: Epoch 73 of 200
Training
[73,   100] loss: 7.211e-05
[73,   200] loss: 7.168e-05
Validation
[73,   100] loss: 7.142e-05
[73,   200] loss: 7.027e-05
Training loss: 0.000, train NMSE: -8.715e+00
Validation loss: 0.000, valid_NMSE: -9.069e+00
--------------------------------------------------
[INFO]: Epoch 74 of 200
Training
[74,   100] loss: 7.083e-05
[74,   200] loss: 7.258e-05
Validation
[74,   100] loss: 7.092e-05
[74,   200] loss: 6.977e-05
Training loss: 0.000, train NMSE: -8.705e+00
Validation loss: 0.000, valid_NMSE: -9.112e+00
--------------------------------------------------
[INFO]: Epoch 75 of 200
Training
[75,   100] loss: 7.139e-05
[75,   200] loss: 7.254e-05
Validation
[75,   100] loss: 7.034e-05
[75,   200] loss: 6.917e-05
Training loss: 0.000, train NMSE: -8.604e+00
Validation loss: 0.000, valid_NMSE: -9.101e+00
--------------------------------------------------
[INFO]: Epoch 76 of 200
Training
[76,   100] loss: 7.036e-05
[76,   200] loss: 7.285e-05
Validation
[76,   100] loss: 6.994e-05
[76,   200] loss: 6.876e-05
Training loss: 0.000, train NMSE: -8.160e+00
Validation loss: 0.000, valid_NMSE: -9.096e+00
--------------------------------------------------
[INFO]: Epoch 77 of 200
Training
[77,   100] loss: 7.217e-05
[77,   200] loss: 7.108e-05
Validation
[77,   100] loss: 7.037e-05
[77,   200] loss: 6.918e-05
Training loss: 0.000, train NMSE: -8.658e+00
Validation loss: 0.000, valid_NMSE: -9.171e+00

Best validation loss: -9.170790672302246

Saving best model for epoch: 77

--------------------------------------------------
[INFO]: Epoch 78 of 200
Training
[78,   100] loss: 7.085e-05
[78,   200] loss: 7.232e-05
Validation
[78,   100] loss: 7.143e-05
[78,   200] loss: 7.029e-05
Training loss: 0.000, train NMSE: -8.870e+00
Validation loss: 0.000, valid_NMSE: -9.088e+00
--------------------------------------------------
[INFO]: Epoch 79 of 200
Training
[79,   100] loss: 7.130e-05
[79,   200] loss: 7.112e-05
Validation
[79,   100] loss: 7.199e-05
[79,   200] loss: 7.087e-05
Training loss: 0.000, train NMSE: -8.337e+00
Validation loss: 0.000, valid_NMSE: -9.064e+00
--------------------------------------------------
[INFO]: Epoch 80 of 200
Training
[80,   100] loss: 7.137e-05
[80,   200] loss: 7.120e-05
Validation
[80,   100] loss: 6.972e-05
[80,   200] loss: 6.856e-05
Training loss: 0.000, train NMSE: -9.183e+00
Validation loss: 0.000, valid_NMSE: -9.101e+00
--------------------------------------------------
[INFO]: Epoch 81 of 200
Training
[81,   100] loss: 7.141e-05
[81,   200] loss: 7.038e-05
Validation
[81,   100] loss: 6.931e-05
[81,   200] loss: 6.818e-05
Training loss: 0.000, train NMSE: -8.536e+00
Validation loss: 0.000, valid_NMSE: -9.157e+00
--------------------------------------------------
[INFO]: Epoch 82 of 200
Training
[82,   100] loss: 7.046e-05
[82,   200] loss: 7.128e-05
Validation
[82,   100] loss: 6.982e-05
[82,   200] loss: 6.870e-05
Training loss: 0.000, train NMSE: -8.537e+00
Validation loss: 0.000, valid_NMSE: -9.144e+00
--------------------------------------------------
[INFO]: Epoch 83 of 200
Training
[83,   100] loss: 7.008e-05
[83,   200] loss: 7.109e-05
Validation
[83,   100] loss: 6.953e-05
[83,   200] loss: 6.841e-05
Training loss: 0.000, train NMSE: -8.643e+00
Validation loss: 0.000, valid_NMSE: -9.196e+00

Best validation loss: -9.195724487304688

Saving best model for epoch: 83

--------------------------------------------------
[INFO]: Epoch 84 of 200
Training
[84,   100] loss: 6.999e-05
[84,   200] loss: 7.162e-05
Validation
[84,   100] loss: 7.088e-05
[84,   200] loss: 6.980e-05
Training loss: 0.000, train NMSE: -8.846e+00
Validation loss: 0.000, valid_NMSE: -9.111e+00
--------------------------------------------------
[INFO]: Epoch 85 of 200
Training
[85,   100] loss: 6.996e-05
[85,   200] loss: 7.108e-05
Validation
[85,   100] loss: 6.927e-05
[85,   200] loss: 6.819e-05
Training loss: 0.000, train NMSE: -8.137e+00
Validation loss: 0.000, valid_NMSE: -9.160e+00
--------------------------------------------------
[INFO]: Epoch 86 of 200
Training
[86,   100] loss: 7.009e-05
[86,   200] loss: 7.094e-05
Validation
[86,   100] loss: 6.910e-05
[86,   200] loss: 6.796e-05
Training loss: 0.000, train NMSE: -9.162e+00
Validation loss: 0.000, valid_NMSE: -9.153e+00
--------------------------------------------------
[INFO]: Epoch 87 of 200
Training
[87,   100] loss: 7.067e-05
[87,   200] loss: 6.948e-05
Validation
[87,   100] loss: 6.989e-05
[87,   200] loss: 6.872e-05
Training loss: 0.000, train NMSE: -8.752e+00
Validation loss: 0.000, valid_NMSE: -9.155e+00
--------------------------------------------------
[INFO]: Epoch 88 of 200
Training
[88,   100] loss: 7.059e-05
[88,   200] loss: 6.980e-05
Validation
[88,   100] loss: 7.205e-05
[88,   200] loss: 7.078e-05
Training loss: 0.000, train NMSE: -8.403e+00
Validation loss: 0.000, valid_NMSE: -8.941e+00
--------------------------------------------------
[INFO]: Epoch 89 of 200
Training
[89,   100] loss: 7.052e-05
[89,   200] loss: 6.980e-05
Validation
[89,   100] loss: 6.927e-05
[89,   200] loss: 6.806e-05
Training loss: 0.000, train NMSE: -8.413e+00
Validation loss: 0.000, valid_NMSE: -9.163e+00
--------------------------------------------------
[INFO]: Epoch 90 of 200
Training
[90,   100] loss: 6.957e-05
[90,   200] loss: 7.003e-05
Validation
[90,   100] loss: 6.846e-05
[90,   200] loss: 6.738e-05
Training loss: 0.000, train NMSE: -8.631e+00
Validation loss: 0.000, valid_NMSE: -9.206e+00

Best validation loss: -9.206321716308594

Saving best model for epoch: 90

--------------------------------------------------
[INFO]: Epoch 91 of 200
Training
[91,   100] loss: 7.087e-05
[91,   200] loss: 6.971e-05
Validation
[91,   100] loss: 6.983e-05
[91,   200] loss: 6.874e-05
Training loss: 0.000, train NMSE: -9.410e+00
Validation loss: 0.000, valid_NMSE: -9.098e+00
--------------------------------------------------
[INFO]: Epoch 92 of 200
Training
[92,   100] loss: 6.993e-05
[92,   200] loss: 6.991e-05
Validation
[92,   100] loss: 7.058e-05
[92,   200] loss: 6.938e-05
Training loss: 0.000, train NMSE: -8.808e+00
Validation loss: 0.000, valid_NMSE: -9.163e+00
--------------------------------------------------
[INFO]: Epoch 93 of 200
Training
[93,   100] loss: 6.951e-05
[93,   200] loss: 6.991e-05
Validation
[93,   100] loss: 6.910e-05
[93,   200] loss: 6.801e-05
Training loss: 0.000, train NMSE: -9.545e+00
Validation loss: 0.000, valid_NMSE: -9.172e+00
--------------------------------------------------
[INFO]: Epoch 94 of 200
Training
[94,   100] loss: 6.952e-05
[94,   200] loss: 6.956e-05
Validation
[94,   100] loss: 6.991e-05
[94,   200] loss: 6.878e-05
Training loss: 0.000, train NMSE: -9.302e+00
Validation loss: 0.000, valid_NMSE: -9.159e+00
--------------------------------------------------
[INFO]: Epoch 95 of 200
Training
[95,   100] loss: 6.942e-05
[95,   200] loss: 6.950e-05
Validation
[95,   100] loss: 7.117e-05
[95,   200] loss: 7.009e-05
Training loss: 0.000, train NMSE: -8.234e+00
Validation loss: 0.000, valid_NMSE: -9.064e+00
--------------------------------------------------
[INFO]: Epoch 96 of 200
Training
[96,   100] loss: 6.957e-05
[96,   200] loss: 6.904e-05
Validation
[96,   100] loss: 7.053e-05
[96,   200] loss: 6.936e-05
Training loss: 0.000, train NMSE: -8.741e+00
Validation loss: 0.000, valid_NMSE: -9.142e+00
--------------------------------------------------
[INFO]: Epoch 97 of 200
Training
[97,   100] loss: 6.876e-05
[97,   200] loss: 6.980e-05
Validation
[97,   100] loss: 6.864e-05
[97,   200] loss: 6.748e-05
Training loss: 0.000, train NMSE: -8.833e+00
Validation loss: 0.000, valid_NMSE: -9.204e+00
--------------------------------------------------
[INFO]: Epoch 98 of 200
Training
[98,   100] loss: 6.854e-05
[98,   200] loss: 6.973e-05
Validation
[98,   100] loss: 6.912e-05
[98,   200] loss: 6.795e-05
Training loss: 0.000, train NMSE: -8.991e+00
Validation loss: 0.000, valid_NMSE: -9.209e+00

Best validation loss: -9.209075927734375

Saving best model for epoch: 98

--------------------------------------------------
[INFO]: Epoch 99 of 200
Training
[99,   100] loss: 6.931e-05
[99,   200] loss: 6.855e-05
Validation
[99,   100] loss: 6.903e-05
[99,   200] loss: 6.784e-05
Training loss: 0.000, train NMSE: -9.210e+00
Validation loss: 0.000, valid_NMSE: -9.184e+00
--------------------------------------------------
[INFO]: Epoch 100 of 200
Training
[100,   100] loss: 6.852e-05
[100,   200] loss: 6.950e-05
Validation
[100,   100] loss: 7.085e-05
[100,   200] loss: 6.973e-05
Training loss: 0.000, train NMSE: -9.305e+00
Validation loss: 0.000, valid_NMSE: -9.104e+00
--------------------------------------------------
[INFO]: Epoch 101 of 200
Training
[101,   100] loss: 6.851e-05
[101,   200] loss: 6.892e-05
Validation
[101,   100] loss: 7.149e-05
[101,   200] loss: 7.037e-05
Training loss: 0.000, train NMSE: -9.533e+00
Validation loss: 0.000, valid_NMSE: -9.034e+00
--------------------------------------------------
[INFO]: Epoch 102 of 200
Training
[102,   100] loss: 6.767e-05
[102,   200] loss: 6.992e-05
Validation
[102,   100] loss: 6.809e-05
[102,   200] loss: 6.701e-05
Training loss: 0.000, train NMSE: -8.711e+00
Validation loss: 0.000, valid_NMSE: -9.222e+00

Best validation loss: -9.221721649169922

Saving best model for epoch: 102

--------------------------------------------------
[INFO]: Epoch 103 of 200
Training
[103,   100] loss: 6.830e-05
[103,   200] loss: 6.866e-05
Validation
[103,   100] loss: 6.839e-05
[103,   200] loss: 6.718e-05
Training loss: 0.000, train NMSE: -8.898e+00
Validation loss: 0.000, valid_NMSE: -9.230e+00

Best validation loss: -9.229732513427734

Saving best model for epoch: 103

--------------------------------------------------
[INFO]: Epoch 104 of 200
Training
[104,   100] loss: 6.879e-05
[104,   200] loss: 6.901e-05
Validation
[104,   100] loss: 6.855e-05
[104,   200] loss: 6.743e-05
Training loss: 0.000, train NMSE: -8.999e+00
Validation loss: 0.000, valid_NMSE: -9.166e+00
--------------------------------------------------
[INFO]: Epoch 105 of 200
Training
[105,   100] loss: 6.866e-05
[105,   200] loss: 6.851e-05
Validation
[105,   100] loss: 7.005e-05
[105,   200] loss: 6.892e-05
Training loss: 0.000, train NMSE: -8.702e+00
Validation loss: 0.000, valid_NMSE: -9.129e+00
--------------------------------------------------
[INFO]: Epoch 106 of 200
Training
[106,   100] loss: 6.782e-05
[106,   200] loss: 6.879e-05
Validation
[106,   100] loss: 7.011e-05
[106,   200] loss: 6.892e-05
Training loss: 0.000, train NMSE: -8.607e+00
Validation loss: 0.000, valid_NMSE: -9.130e+00
--------------------------------------------------
[INFO]: Epoch 107 of 200
Training
[107,   100] loss: 6.772e-05
[107,   200] loss: 6.952e-05
Validation
[107,   100] loss: 6.919e-05
[107,   200] loss: 6.802e-05
Training loss: 0.000, train NMSE: -9.000e+00
Validation loss: 0.000, valid_NMSE: -9.160e+00
--------------------------------------------------
[INFO]: Epoch 108 of 200
Training
[108,   100] loss: 6.709e-05
[108,   200] loss: 7.012e-05
Validation
[108,   100] loss: 6.867e-05
[108,   200] loss: 6.751e-05
Training loss: 0.000, train NMSE: -8.811e+00
Validation loss: 0.000, valid_NMSE: -9.216e+00
--------------------------------------------------
[INFO]: Epoch 109 of 200
Training
[109,   100] loss: 6.799e-05
[109,   200] loss: 6.827e-05
Validation
[109,   100] loss: 6.781e-05
[109,   200] loss: 6.669e-05
Training loss: 0.000, train NMSE: -8.872e+00
Validation loss: 0.000, valid_NMSE: -9.236e+00

Best validation loss: -9.235981941223145

Saving best model for epoch: 109

--------------------------------------------------
[INFO]: Epoch 110 of 200
Training
[110,   100] loss: 6.749e-05
[110,   200] loss: 6.854e-05
Validation
[110,   100] loss: 6.805e-05
[110,   200] loss: 6.693e-05
Training loss: 0.000, train NMSE: -8.888e+00
Validation loss: 0.000, valid_NMSE: -9.218e+00
--------------------------------------------------
[INFO]: Epoch 111 of 200
Training
[111,   100] loss: 6.771e-05
[111,   200] loss: 6.830e-05
Validation
[111,   100] loss: 6.751e-05
[111,   200] loss: 6.642e-05
Training loss: 0.000, train NMSE: -8.934e+00
Validation loss: 0.000, valid_NMSE: -9.217e+00
--------------------------------------------------
[INFO]: Epoch 112 of 200
Training
[112,   100] loss: 6.797e-05
[112,   200] loss: 6.759e-05
Validation
[112,   100] loss: 6.985e-05
[112,   200] loss: 6.861e-05
Training loss: 0.000, train NMSE: -9.449e+00
Validation loss: 0.000, valid_NMSE: -9.119e+00
--------------------------------------------------
[INFO]: Epoch 113 of 200
Training
[113,   100] loss: 6.831e-05
[113,   200] loss: 6.798e-05
Validation
[113,   100] loss: 6.861e-05
[113,   200] loss: 6.746e-05
Training loss: 0.000, train NMSE: -8.572e+00
Validation loss: 0.000, valid_NMSE: -9.171e+00
--------------------------------------------------
[INFO]: Epoch 114 of 200
Training
[114,   100] loss: 6.811e-05
[114,   200] loss: 6.744e-05
Validation
[114,   100] loss: 7.032e-05
[114,   200] loss: 6.918e-05
Training loss: 0.000, train NMSE: -9.298e+00
Validation loss: 0.000, valid_NMSE: -9.122e+00
--------------------------------------------------
[INFO]: Epoch 115 of 200
Training
[115,   100] loss: 6.817e-05
[115,   200] loss: 6.757e-05
Validation
[115,   100] loss: 6.837e-05
[115,   200] loss: 6.724e-05
Training loss: 0.000, train NMSE: -8.777e+00
Validation loss: 0.000, valid_NMSE: -9.208e+00
--------------------------------------------------
[INFO]: Epoch 116 of 200
Training
[116,   100] loss: 6.744e-05
[116,   200] loss: 6.773e-05
Validation
[116,   100] loss: 6.798e-05
[116,   200] loss: 6.685e-05
Training loss: 0.000, train NMSE: -8.689e+00
Validation loss: 0.000, valid_NMSE: -9.171e+00
--------------------------------------------------
[INFO]: Epoch 117 of 200
Training
[117,   100] loss: 6.657e-05
[117,   200] loss: 6.813e-05
Validation
[117,   100] loss: 6.769e-05
[117,   200] loss: 6.658e-05
Training loss: 0.000, train NMSE: -8.616e+00
Validation loss: 0.000, valid_NMSE: -9.196e+00
--------------------------------------------------
[INFO]: Epoch 118 of 200
Training
[118,   100] loss: 6.869e-05
[118,   200] loss: 6.752e-05
Validation
[118,   100] loss: 7.076e-05
[118,   200] loss: 6.959e-05
Training loss: 0.000, train NMSE: -8.894e+00
Validation loss: 0.000, valid_NMSE: -9.063e+00
--------------------------------------------------
[INFO]: Epoch 119 of 200
Training
[119,   100] loss: 6.734e-05
[119,   200] loss: 6.703e-05
Validation
[119,   100] loss: 6.886e-05
[119,   200] loss: 6.780e-05
Training loss: 0.000, train NMSE: -8.779e+00
Validation loss: 0.000, valid_NMSE: -9.127e+00
--------------------------------------------------
[INFO]: Epoch 120 of 200
Training
[120,   100] loss: 6.745e-05
[120,   200] loss: 6.797e-05
Validation
[120,   100] loss: 6.850e-05
[120,   200] loss: 6.741e-05
Training loss: 0.000, train NMSE: -9.205e+00
Validation loss: 0.000, valid_NMSE: -9.197e+00
--------------------------------------------------
[INFO]: Epoch 121 of 200
Training
[121,   100] loss: 6.703e-05
[121,   200] loss: 6.779e-05
Validation
[121,   100] loss: 6.820e-05
[121,   200] loss: 6.708e-05
Training loss: 0.000, train NMSE: -9.098e+00
Validation loss: 0.000, valid_NMSE: -9.201e+00
--------------------------------------------------
[INFO]: Epoch 122 of 200
Training
[122,   100] loss: 6.658e-05
[122,   200] loss: 6.697e-05
Validation
[122,   100] loss: 6.840e-05
[122,   200] loss: 6.722e-05
Training loss: 0.000, train NMSE: -8.567e+00
Validation loss: 0.000, valid_NMSE: -9.212e+00
--------------------------------------------------
[INFO]: Epoch 123 of 200
Training
[123,   100] loss: 6.705e-05
[123,   200] loss: 6.711e-05
Validation
[123,   100] loss: 6.952e-05
[123,   200] loss: 6.838e-05
Training loss: 0.000, train NMSE: -9.058e+00
Validation loss: 0.000, valid_NMSE: -9.161e+00
--------------------------------------------------
[INFO]: Epoch 124 of 200
Training
[124,   100] loss: 6.665e-05
[124,   200] loss: 6.714e-05
Validation
[124,   100] loss: 6.721e-05
[124,   200] loss: 6.604e-05
Training loss: 0.000, train NMSE: -9.860e+00
Validation loss: 0.000, valid_NMSE: -9.241e+00

Best validation loss: -9.241423606872559

Saving best model for epoch: 124

--------------------------------------------------
[INFO]: Epoch 125 of 200
Training
[125,   100] loss: 6.716e-05
[125,   200] loss: 6.711e-05
Validation
[125,   100] loss: 6.812e-05
[125,   200] loss: 6.692e-05
Training loss: 0.000, train NMSE: -9.102e+00
Validation loss: 0.000, valid_NMSE: -9.211e+00
--------------------------------------------------
[INFO]: Epoch 126 of 200
Training
[126,   100] loss: 6.766e-05
[126,   200] loss: 6.625e-05
Validation
[126,   100] loss: 6.735e-05
[126,   200] loss: 6.624e-05
Training loss: 0.000, train NMSE: -9.122e+00
Validation loss: 0.000, valid_NMSE: -9.206e+00
--------------------------------------------------
[INFO]: Epoch 127 of 200
Training
[127,   100] loss: 6.753e-05
[127,   200] loss: 6.635e-05
Validation
[127,   100] loss: 6.792e-05
[127,   200] loss: 6.670e-05
Training loss: 0.000, train NMSE: -9.750e+00
Validation loss: 0.000, valid_NMSE: -9.210e+00
--------------------------------------------------
[INFO]: Epoch 128 of 200
Training
[128,   100] loss: 6.734e-05
[128,   200] loss: 6.557e-05
Validation
[128,   100] loss: 6.774e-05
[128,   200] loss: 6.664e-05
Training loss: 0.000, train NMSE: -8.976e+00
Validation loss: 0.000, valid_NMSE: -9.218e+00
--------------------------------------------------
[INFO]: Epoch 129 of 200
Training
[129,   100] loss: 6.723e-05
[129,   200] loss: 6.593e-05
Validation
[129,   100] loss: 6.836e-05
[129,   200] loss: 6.721e-05
Training loss: 0.000, train NMSE: -9.375e+00
Validation loss: 0.000, valid_NMSE: -9.202e+00
--------------------------------------------------
[INFO]: Epoch 130 of 200
Training
[130,   100] loss: 6.715e-05
[130,   200] loss: 6.583e-05
Validation
[130,   100] loss: 6.768e-05
[130,   200] loss: 6.649e-05
Training loss: 0.000, train NMSE: -9.017e+00
Validation loss: 0.000, valid_NMSE: -9.224e+00
--------------------------------------------------
[INFO]: Epoch 131 of 200
Training
[131,   100] loss: 6.670e-05
[131,   200] loss: 6.606e-05
Validation
[131,   100] loss: 6.779e-05
[131,   200] loss: 6.663e-05
Training loss: 0.000, train NMSE: -9.170e+00
Validation loss: 0.000, valid_NMSE: -9.241e+00
--------------------------------------------------
[INFO]: Epoch 132 of 200
Training
[132,   100] loss: 6.573e-05
[132,   200] loss: 6.704e-05
Validation
[132,   100] loss: 6.719e-05
[132,   200] loss: 6.612e-05
Training loss: 0.000, train NMSE: -8.693e+00
Validation loss: 0.000, valid_NMSE: -9.150e+00
--------------------------------------------------
[INFO]: Epoch 133 of 200
Training
[133,   100] loss: 6.574e-05
[133,   200] loss: 6.712e-05
Validation
[133,   100] loss: 7.020e-05
[133,   200] loss: 6.899e-05
Training loss: 0.000, train NMSE: -9.101e+00
Validation loss: 0.000, valid_NMSE: -9.039e+00
--------------------------------------------------
[INFO]: Epoch 134 of 200
Training
[134,   100] loss: 6.617e-05
[134,   200] loss: 6.637e-05
Validation
[134,   100] loss: 6.810e-05
[134,   200] loss: 6.695e-05
Training loss: 0.000, train NMSE: -9.822e+00
Validation loss: 0.000, valid_NMSE: -9.206e+00
--------------------------------------------------
[INFO]: Epoch 135 of 200
Training
[135,   100] loss: 6.505e-05
[135,   200] loss: 6.655e-05
Validation
[135,   100] loss: 6.848e-05
[135,   200] loss: 6.735e-05
Training loss: 0.000, train NMSE: -9.327e+00
Validation loss: 0.000, valid_NMSE: -9.210e+00
--------------------------------------------------
[INFO]: Epoch 136 of 200
Training
[136,   100] loss: 6.578e-05
[136,   200] loss: 6.639e-05
Validation
[136,   100] loss: 6.909e-05
[136,   200] loss: 6.793e-05
Training loss: 0.000, train NMSE: -9.506e+00
Validation loss: 0.000, valid_NMSE: -9.119e+00
--------------------------------------------------
[INFO]: Epoch 137 of 200
Training
[137,   100] loss: 6.734e-05
[137,   200] loss: 6.511e-05
Validation
[137,   100] loss: 6.713e-05
[137,   200] loss: 6.599e-05
Training loss: 0.000, train NMSE: -9.320e+00
Validation loss: 0.000, valid_NMSE: -9.237e+00
--------------------------------------------------
[INFO]: Epoch 138 of 200
Training
[138,   100] loss: 6.576e-05
[138,   200] loss: 6.640e-05
Validation
[138,   100] loss: 6.835e-05
[138,   200] loss: 6.715e-05
Training loss: 0.000, train NMSE: -9.003e+00
Validation loss: 0.000, valid_NMSE: -9.157e+00
--------------------------------------------------
[INFO]: Epoch 139 of 200
Training
[139,   100] loss: 6.643e-05
[139,   200] loss: 6.534e-05
Validation
[139,   100] loss: 6.824e-05
[139,   200] loss: 6.708e-05
Training loss: 0.000, train NMSE: -8.463e+00
Validation loss: 0.000, valid_NMSE: -9.190e+00
--------------------------------------------------
[INFO]: Epoch 140 of 200
Training
[140,   100] loss: 6.604e-05
[140,   200] loss: 6.580e-05
Validation
[140,   100] loss: 6.716e-05
[140,   200] loss: 6.600e-05
Training loss: 0.000, train NMSE: -9.288e+00
Validation loss: 0.000, valid_NMSE: -9.213e+00
--------------------------------------------------
[INFO]: Epoch 141 of 200
Training
[141,   100] loss: 6.558e-05
[141,   200] loss: 6.555e-05
Validation
[141,   100] loss: 6.740e-05
[141,   200] loss: 6.629e-05
Training loss: 0.000, train NMSE: -8.554e+00
Validation loss: 0.000, valid_NMSE: -9.188e+00
--------------------------------------------------
[INFO]: Epoch 142 of 200
Training
[142,   100] loss: 6.568e-05
[142,   200] loss: 6.555e-05
Validation
[142,   100] loss: 6.737e-05
[142,   200] loss: 6.620e-05
Training loss: 0.000, train NMSE: -9.658e+00
Validation loss: 0.000, valid_NMSE: -9.205e+00
--------------------------------------------------
[INFO]: Epoch 143 of 200
Training
[143,   100] loss: 6.464e-05
[143,   200] loss: 6.665e-05
Validation
[143,   100] loss: 6.921e-05
[143,   200] loss: 6.803e-05
Training loss: 0.000, train NMSE: -8.565e+00
Validation loss: 0.000, valid_NMSE: -9.124e+00
--------------------------------------------------
[INFO]: Epoch 144 of 200
Training
[144,   100] loss: 6.535e-05
[144,   200] loss: 6.579e-05
Validation
[144,   100] loss: 6.708e-05
[144,   200] loss: 6.604e-05
Training loss: 0.000, train NMSE: -9.096e+00
Validation loss: 0.000, valid_NMSE: -9.206e+00
--------------------------------------------------
[INFO]: Epoch 145 of 200
Training
[145,   100] loss: 6.504e-05
[145,   200] loss: 6.622e-05
Validation
[145,   100] loss: 6.749e-05
[145,   200] loss: 6.635e-05
Training loss: 0.000, train NMSE: -9.221e+00
Validation loss: 0.000, valid_NMSE: -9.256e+00

Best validation loss: -9.255681991577148

Saving best model for epoch: 145

--------------------------------------------------
[INFO]: Epoch 146 of 200
Training
[146,   100] loss: 6.577e-05
[146,   200] loss: 6.473e-05
Validation
[146,   100] loss: 6.718e-05
[146,   200] loss: 6.602e-05
Training loss: 0.000, train NMSE: -8.841e+00
Validation loss: 0.000, valid_NMSE: -9.249e+00
--------------------------------------------------
[INFO]: Epoch 147 of 200
Training
[147,   100] loss: 6.549e-05
[147,   200] loss: 6.484e-05
Validation
[147,   100] loss: 6.707e-05
[147,   200] loss: 6.589e-05
Training loss: 0.000, train NMSE: -8.655e+00
Validation loss: 0.000, valid_NMSE: -9.219e+00
--------------------------------------------------
[INFO]: Epoch 148 of 200
Training
[148,   100] loss: 6.410e-05
[148,   200] loss: 6.650e-05
Validation
[148,   100] loss: 6.728e-05
[148,   200] loss: 6.615e-05
Training loss: 0.000, train NMSE: -8.726e+00
Validation loss: 0.000, valid_NMSE: -9.225e+00
--------------------------------------------------
[INFO]: Epoch 149 of 200
Training
[149,   100] loss: 6.463e-05
[149,   200] loss: 6.573e-05
Validation
[149,   100] loss: 6.822e-05
[149,   200] loss: 6.705e-05
Training loss: 0.000, train NMSE: -9.015e+00
Validation loss: 0.000, valid_NMSE: -9.212e+00
--------------------------------------------------
[INFO]: Epoch 150 of 200
Training
[150,   100] loss: 6.409e-05
[150,   200] loss: 6.590e-05
Validation
[150,   100] loss: 6.961e-05
[150,   200] loss: 6.839e-05
Training loss: 0.000, train NMSE: -9.256e+00
Validation loss: 0.000, valid_NMSE: -9.099e+00
--------------------------------------------------
[INFO]: Epoch 151 of 200
Training
[151,   100] loss: 6.486e-05
[151,   200] loss: 6.490e-05
Validation
[151,   100] loss: 6.792e-05
[151,   200] loss: 6.674e-05
Training loss: 0.000, train NMSE: -9.671e+00
Validation loss: 0.000, valid_NMSE: -9.195e+00
--------------------------------------------------
[INFO]: Epoch 152 of 200
Training
[152,   100] loss: 6.495e-05
[152,   200] loss: 6.478e-05
Validation
[152,   100] loss: 6.905e-05
[152,   200] loss: 6.786e-05
Training loss: 0.000, train NMSE: -9.362e+00
Validation loss: 0.000, valid_NMSE: -9.138e+00
--------------------------------------------------
[INFO]: Epoch 153 of 200
Training
[153,   100] loss: 6.527e-05
[153,   200] loss: 6.471e-05
Validation
[153,   100] loss: 6.728e-05
[153,   200] loss: 6.615e-05
Training loss: 0.000, train NMSE: -9.114e+00
Validation loss: 0.000, valid_NMSE: -9.219e+00
--------------------------------------------------
[INFO]: Epoch 154 of 200
Training
[154,   100] loss: 6.419e-05
[154,   200] loss: 6.475e-05
Validation
[154,   100] loss: 6.690e-05
[154,   200] loss: 6.577e-05
Training loss: 0.000, train NMSE: -8.717e+00
Validation loss: 0.000, valid_NMSE: -9.245e+00
--------------------------------------------------
[INFO]: Epoch 155 of 200
Training
[155,   100] loss: 6.370e-05
[155,   200] loss: 6.599e-05
Validation
[155,   100] loss: 7.145e-05
[155,   200] loss: 7.029e-05
Training loss: 0.000, train NMSE: -9.523e+00
Validation loss: 0.000, valid_NMSE: -8.979e+00
--------------------------------------------------
[INFO]: Epoch 156 of 200
Training
[156,   100] loss: 6.426e-05
[156,   200] loss: 6.533e-05
Validation
[156,   100] loss: 6.779e-05
[156,   200] loss: 6.668e-05
Training loss: 0.000, train NMSE: -9.073e+00
Validation loss: 0.000, valid_NMSE: -9.156e+00
--------------------------------------------------
[INFO]: Epoch 157 of 200
Training
[157,   100] loss: 6.432e-05
[157,   200] loss: 6.467e-05
Validation
[157,   100] loss: 6.727e-05
[157,   200] loss: 6.613e-05
Training loss: 0.000, train NMSE: -9.361e+00
Validation loss: 0.000, valid_NMSE: -9.199e+00
--------------------------------------------------
[INFO]: Epoch 158 of 200
Training
[158,   100] loss: 6.445e-05
[158,   200] loss: 6.446e-05
Validation
[158,   100] loss: 6.924e-05
[158,   200] loss: 6.814e-05
Training loss: 0.000, train NMSE: -9.479e+00
Validation loss: 0.000, valid_NMSE: -9.104e+00
--------------------------------------------------
[INFO]: Epoch 159 of 200
Training
[159,   100] loss: 6.514e-05
[159,   200] loss: 6.349e-05
Validation
[159,   100] loss: 6.754e-05
[159,   200] loss: 6.650e-05
Training loss: 0.000, train NMSE: -9.244e+00
Validation loss: 0.000, valid_NMSE: -9.182e+00
--------------------------------------------------
[INFO]: Epoch 160 of 200
Training
[160,   100] loss: 6.522e-05
[160,   200] loss: 6.325e-05
Validation
[160,   100] loss: 6.839e-05
[160,   200] loss: 6.727e-05
Training loss: 0.000, train NMSE: -8.613e+00
Validation loss: 0.000, valid_NMSE: -9.172e+00
--------------------------------------------------
[INFO]: Epoch 161 of 200
Training
[161,   100] loss: 6.341e-05
[161,   200] loss: 6.444e-05
Validation
[161,   100] loss: 6.801e-05
[161,   200] loss: 6.685e-05
Training loss: 0.000, train NMSE: -9.774e+00
Validation loss: 0.000, valid_NMSE: -9.188e+00
--------------------------------------------------
[INFO]: Epoch 162 of 200
Training
[162,   100] loss: 6.484e-05
[162,   200] loss: 6.340e-05
Validation
[162,   100] loss: 6.706e-05
[162,   200] loss: 6.597e-05
Training loss: 0.000, train NMSE: -9.022e+00
Validation loss: 0.000, valid_NMSE: -9.234e+00
--------------------------------------------------
[INFO]: Epoch 163 of 200
Training
[163,   100] loss: 6.326e-05
[163,   200] loss: 6.483e-05
Validation
[163,   100] loss: 6.772e-05
[163,   200] loss: 6.659e-05
Training loss: 0.000, train NMSE: -8.407e+00
Validation loss: 0.000, valid_NMSE: -9.222e+00
--------------------------------------------------
[INFO]: Epoch 164 of 200
Training
[164,   100] loss: 6.424e-05
[164,   200] loss: 6.413e-05
Validation
[164,   100] loss: 6.666e-05
[164,   200] loss: 6.552e-05
Training loss: 0.000, train NMSE: -8.874e+00
Validation loss: 0.000, valid_NMSE: -9.220e+00
--------------------------------------------------
[INFO]: Epoch 165 of 200
Training
[165,   100] loss: 6.410e-05
[165,   200] loss: 6.402e-05
Validation
[165,   100] loss: 6.813e-05
[165,   200] loss: 6.702e-05
Training loss: 0.000, train NMSE: -9.552e+00
Validation loss: 0.000, valid_NMSE: -9.163e+00
--------------------------------------------------
[INFO]: Epoch 166 of 200
Training
[166,   100] loss: 6.412e-05
[166,   200] loss: 6.442e-05
Validation
[166,   100] loss: 6.776e-05
[166,   200] loss: 6.665e-05
Training loss: 0.000, train NMSE: -8.908e+00
Validation loss: 0.000, valid_NMSE: -9.221e+00
--------------------------------------------------
[INFO]: Epoch 167 of 200
Training
[167,   100] loss: 6.395e-05
[167,   200] loss: 6.329e-05
Validation
[167,   100] loss: 6.732e-05
[167,   200] loss: 6.619e-05
Training loss: 0.000, train NMSE: -8.933e+00
Validation loss: 0.000, valid_NMSE: -9.223e+00
--------------------------------------------------
[INFO]: Epoch 168 of 200
Training
[168,   100] loss: 6.336e-05
[168,   200] loss: 6.397e-05
Validation
[168,   100] loss: 6.738e-05
[168,   200] loss: 6.617e-05
Training loss: 0.000, train NMSE: -8.773e+00
Validation loss: 0.000, valid_NMSE: -9.197e+00
--------------------------------------------------
[INFO]: Epoch 169 of 200
Training
[169,   100] loss: 6.337e-05
[169,   200] loss: 6.407e-05
Validation
[169,   100] loss: 6.691e-05
[169,   200] loss: 6.584e-05
Training loss: 0.000, train NMSE: -8.653e+00
Validation loss: 0.000, valid_NMSE: -9.178e+00
--------------------------------------------------
[INFO]: Epoch 170 of 200
Training
[170,   100] loss: 6.353e-05
[170,   200] loss: 6.363e-05
Validation
[170,   100] loss: 6.750e-05
[170,   200] loss: 6.639e-05
Training loss: 0.000, train NMSE: -9.173e+00
Validation loss: 0.000, valid_NMSE: -9.200e+00
--------------------------------------------------
[INFO]: Epoch 171 of 200
Training
[171,   100] loss: 6.475e-05
[171,   200] loss: 6.312e-05
Validation
[171,   100] loss: 6.660e-05
[171,   200] loss: 6.552e-05
Training loss: 0.000, train NMSE: -8.920e+00
Validation loss: 0.000, valid_NMSE: -9.217e+00
--------------------------------------------------
[INFO]: Epoch 172 of 200
Training
[172,   100] loss: 6.338e-05
[172,   200] loss: 6.354e-05
Validation
[172,   100] loss: 6.932e-05
[172,   200] loss: 6.816e-05
Training loss: 0.000, train NMSE: -9.992e+00
Validation loss: 0.000, valid_NMSE: -9.095e+00
--------------------------------------------------
[INFO]: Epoch 173 of 200
Training
[173,   100] loss: 6.409e-05
[173,   200] loss: 6.307e-05
Validation
[173,   100] loss: 6.661e-05
[173,   200] loss: 6.555e-05
Training loss: 0.000, train NMSE: -9.230e+00
Validation loss: 0.000, valid_NMSE: -9.199e+00
--------------------------------------------------
[INFO]: Epoch 174 of 200
Training
[174,   100] loss: 6.251e-05
[174,   200] loss: 6.368e-05
Validation
[174,   100] loss: 6.677e-05
[174,   200] loss: 6.569e-05
Training loss: 0.000, train NMSE: -9.203e+00
Validation loss: 0.000, valid_NMSE: -9.203e+00
--------------------------------------------------
[INFO]: Epoch 175 of 200
Training
[175,   100] loss: 6.412e-05
[175,   200] loss: 6.263e-05
Validation
[175,   100] loss: 6.793e-05
[175,   200] loss: 6.679e-05
Training loss: 0.000, train NMSE: -1.024e+01
Validation loss: 0.000, valid_NMSE: -9.193e+00
--------------------------------------------------
[INFO]: Epoch 176 of 200
Training
[176,   100] loss: 6.271e-05
[176,   200] loss: 6.360e-05
Validation
[176,   100] loss: 6.674e-05
[176,   200] loss: 6.565e-05
Training loss: 0.000, train NMSE: -9.398e+00
Validation loss: 0.000, valid_NMSE: -9.206e+00
--------------------------------------------------
[INFO]: Epoch 177 of 200
Training
[177,   100] loss: 6.368e-05
[177,   200] loss: 6.227e-05
Validation
[177,   100] loss: 6.636e-05
[177,   200] loss: 6.530e-05
Training loss: 0.000, train NMSE: -9.669e+00
Validation loss: 0.000, valid_NMSE: -9.249e+00/home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE
  warn(f"Failed to load image Python extension: {e}")

--------------------------------------------------
[INFO]: Epoch 178 of 200
Training
[178,   100] loss: 6.266e-05
[178,   200] loss: 6.347e-05
Validation
[178,   100] loss: 6.748e-05
[178,   200] loss: 6.634e-05
Training loss: 0.000, train NMSE: -9.247e+00
Validation loss: 0.000, valid_NMSE: -9.213e+00
--------------------------------------------------
[INFO]: Epoch 179 of 200
Training
[179,   100] loss: 6.267e-05
[179,   200] loss: 6.328e-05
Validation
[179,   100] loss: 6.966e-05
[179,   200] loss: 6.851e-05
Training loss: 0.000, train NMSE: -8.385e+00
Validation loss: 0.000, valid_NMSE: -9.083e+00
--------------------------------------------------
[INFO]: Epoch 180 of 200
Training
[180,   100] loss: 6.271e-05
[180,   200] loss: 6.319e-05
Validation
[180,   100] loss: 6.682e-05
[180,   200] loss: 6.580e-05
Training loss: 0.000, train NMSE: -9.513e+00
Validation loss: 0.000, valid_NMSE: -9.202e+00
--------------------------------------------------
[INFO]: Epoch 181 of 200
Training
[181,   100] loss: 6.254e-05
[181,   200] loss: 6.319e-05
Validation
[181,   100] loss: 6.734e-05
[181,   200] loss: 6.621e-05
Training loss: 0.000, train NMSE: -8.905e+00
Validation loss: 0.000, valid_NMSE: -9.199e+00
--------------------------------------------------
[INFO]: Epoch 182 of 200
Training
[182,   100] loss: 6.297e-05
[182,   200] loss: 6.264e-05
Validation
[182,   100] loss: 7.169e-05
[182,   200] loss: 7.055e-05
Training loss: 0.000, train NMSE: -9.119e+00
Validation loss: 0.000, valid_NMSE: -8.943e+00
--------------------------------------------------
[INFO]: Epoch 183 of 200
Training
[183,   100] loss: 6.242e-05
[183,   200] loss: 6.361e-05
Validation
[183,   100] loss: 6.706e-05
[183,   200] loss: 6.603e-05
Training loss: 0.000, train NMSE: -8.774e+00
Validation loss: 0.000, valid_NMSE: -9.228e+00
--------------------------------------------------
[INFO]: Epoch 184 of 200
Training
[184,   100] loss: 6.216e-05
[184,   200] loss: 6.326e-05
Validation
[184,   100] loss: 6.640e-05
[184,   200] loss: 6.532e-05
Training loss: 0.000, train NMSE: -8.771e+00
Validation loss: 0.000, valid_NMSE: -9.252e+00
--------------------------------------------------
[INFO]: Epoch 185 of 200
Training
[185,   100] loss: 6.296e-05
[185,   200] loss: 6.167e-05
Validation
[185,   100] loss: 6.758e-05
[185,   200] loss: 6.646e-05
Training loss: 0.000, train NMSE: -8.986e+00
Validation loss: 0.000, valid_NMSE: -9.230e+00
--------------------------------------------------
[INFO]: Epoch 186 of 200
Training
[186,   100] loss: 6.272e-05
[186,   200] loss: 6.295e-05
Validation
[186,   100] loss: 6.674e-05
[186,   200] loss: 6.561e-05
Training loss: 0.000, train NMSE: -9.683e+00
Validation loss: 0.000, valid_NMSE: -9.262e+00

Best validation loss: -9.261772155761719

Saving best model for epoch: 186

--------------------------------------------------
[INFO]: Epoch 187 of 200
Training
[187,   100] loss: 6.181e-05
[187,   200] loss: 6.249e-05
Validation
[187,   100] loss: 6.759e-05
[187,   200] loss: 6.641e-05
Training loss: 0.000, train NMSE: -9.542e+00
Validation loss: 0.000, valid_NMSE: -9.210e+00
--------------------------------------------------
[INFO]: Epoch 188 of 200
Training
[188,   100] loss: 6.362e-05
[188,   200] loss: 6.176e-05
Validation
[188,   100] loss: 6.727e-05
[188,   200] loss: 6.618e-05
Training loss: 0.000, train NMSE: -9.551e+00
Validation loss: 0.000, valid_NMSE: -9.233e+00
--------------------------------------------------
[INFO]: Epoch 189 of 200
Training
[189,   100] loss: 6.146e-05
[189,   200] loss: 6.318e-05
Validation
[189,   100] loss: 6.722e-05
[189,   200] loss: 6.612e-05
Training loss: 0.000, train NMSE: -9.285e+00
Validation loss: 0.000, valid_NMSE: -9.224e+00
--------------------------------------------------
[INFO]: Epoch 190 of 200
Training
[190,   100] loss: 6.109e-05
[190,   200] loss: 6.290e-05
Validation
[190,   100] loss: 6.679e-05
[190,   200] loss: 6.564e-05
Training loss: 0.000, train NMSE: -9.504e+00
Validation loss: 0.000, valid_NMSE: -9.239e+00
--------------------------------------------------
[INFO]: Epoch 191 of 200
Training
[191,   100] loss: 6.139e-05
[191,   200] loss: 6.273e-05
Validation
[191,   100] loss: 6.798e-05
[191,   200] loss: 6.691e-05
Training loss: 0.000, train NMSE: -9.559e+00
Validation loss: 0.000, valid_NMSE: -9.177e+00
--------------------------------------------------
[INFO]: Epoch 192 of 200
Training
[192,   100] loss: 6.238e-05
[192,   200] loss: 6.240e-05
Validation
[192,   100] loss: 6.650e-05
[192,   200] loss: 6.542e-05
Training loss: 0.000, train NMSE: -8.812e+00
Validation loss: 0.000, valid_NMSE: -9.226e+00
--------------------------------------------------
[INFO]: Epoch 193 of 200
Training
[193,   100] loss: 6.219e-05
[193,   200] loss: 6.187e-05
Validation
[193,   100] loss: 6.813e-05
[193,   200] loss: 6.711e-05
Training loss: 0.000, train NMSE: -9.340e+00
Validation loss: 0.000, valid_NMSE: -9.164e+00
--------------------------------------------------
[INFO]: Epoch 194 of 200
Training
[194,   100] loss: 6.308e-05
[194,   200] loss: 6.092e-05
Validation
[194,   100] loss: 6.785e-05
[194,   200] loss: 6.672e-05
Training loss: 0.000, train NMSE: -9.102e+00
Validation loss: 0.000, valid_NMSE: -9.199e+00
--------------------------------------------------
[INFO]: Epoch 195 of 200
Training
[195,   100] loss: 6.197e-05
[195,   200] loss: 6.185e-05
Validation
[195,   100] loss: 6.687e-05
[195,   200] loss: 6.584e-05
Training loss: 0.000, train NMSE: -8.902e+00
Validation loss: 0.000, valid_NMSE: -9.186e+00
--------------------------------------------------
[INFO]: Epoch 196 of 200
Training
[196,   100] loss: 6.106e-05
[196,   200] loss: 6.229e-05
Validation
[196,   100] loss: 6.833e-05
[196,   200] loss: 6.722e-05
Training loss: 0.000, train NMSE: -9.107e+00
Validation loss: 0.000, valid_NMSE: -9.179e+00
--------------------------------------------------
[INFO]: Epoch 197 of 200
Training
[197,   100] loss: 6.178e-05
[197,   200] loss: 6.194e-05
Validation
[197,   100] loss: 6.812e-05
[197,   200] loss: 6.704e-05
Training loss: 0.000, train NMSE: -9.325e+00
Validation loss: 0.000, valid_NMSE: -9.146e+00
--------------------------------------------------
[INFO]: Epoch 198 of 200
Training
[198,   100] loss: 6.141e-05
[198,   200] loss: 6.162e-05
Validation
[198,   100] loss: 6.687e-05
[198,   200] loss: 6.578e-05
Training loss: 0.000, train NMSE: -9.010e+00
Validation loss: 0.000, valid_NMSE: -9.229e+00
--------------------------------------------------
[INFO]: Epoch 199 of 200
Training
[199,   100] loss: 6.153e-05
[199,   200] loss: 6.179e-05
Validation
[199,   100] loss: 6.731e-05
[199,   200] loss: 6.616e-05
Training loss: 0.000, train NMSE: -9.507e+00
Validation loss: 0.000, valid_NMSE: -9.205e+00
--------------------------------------------------
[INFO]: Epoch 200 of 200
Training
[200,   100] loss: 6.142e-05
[200,   200] loss: 6.157e-05
Validation
[200,   100] loss: 6.676e-05
[200,   200] loss: 6.574e-05
Training loss: 0.000, train NMSE: -8.877e+00
Validation loss: 0.000, valid_NMSE: -9.225e+00
--------------------------------------------------
Saving final model
TRAINING COMPLETE
