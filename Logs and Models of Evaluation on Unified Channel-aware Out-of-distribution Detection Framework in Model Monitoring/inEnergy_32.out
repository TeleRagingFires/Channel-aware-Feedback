1.13.1+cu117
inEnergy
Dadicated Mode inEnergy
Dedicated Mode inEnergy
trainset len 112000 valset len 48000
New_trainset len 40000 valset len 48000
825,049 training parameters.

825,049 training parameters.

[INFO]: Epoch 1 of 200
Training
[1,   100] loss: 2.210e-04
[1,   200] loss: 1.738e-04
Validation
[1,   100] loss: 2.049e-04
[1,   200] loss: 2.042e-04
Training loss: 0.000, train NMSE: -4.233e+00
Validation loss: 0.000, valid_NMSE: -3.833e+00

Best validation loss: -3.833462715148926

Saving best model for epoch: 1

--------------------------------------------------
[INFO]: Epoch 2 of 200
Training
[2,   100] loss: 1.458e-04
[2,   200] loss: 1.341e-04
Validation
[2,   100] loss: 1.755e-04
[2,   200] loss: 1.745e-04
Training loss: 0.000, train NMSE: -5.039e+00
Validation loss: 0.000, valid_NMSE: -4.623e+00

Best validation loss: -4.622505187988281

Saving best model for epoch: 2

--------------------------------------------------
[INFO]: Epoch 3 of 200
Training
[3,   100] loss: 1.259e-04
[3,   200] loss: 1.204e-04
Validation
[3,   100] loss: 1.628e-04
[3,   200] loss: 1.617e-04
Training loss: 0.000, train NMSE: -5.317e+00
Validation loss: 0.000, valid_NMSE: -5.018e+00

Best validation loss: -5.017736434936523

Saving best model for epoch: 3

--------------------------------------------------
[INFO]: Epoch 4 of 200
Training
[4,   100] loss: 1.156e-04
[4,   200] loss: 1.120e-04
Validation
[4,   100] loss: 1.541e-04
[4,   200] loss: 1.530e-04
Training loss: 0.000, train NMSE: -6.013e+00
Validation loss: 0.000, valid_NMSE: -5.252e+00

Best validation loss: -5.2516913414001465

Saving best model for epoch: 4

--------------------------------------------------
[INFO]: Epoch 5 of 200
Training
[5,   100] loss: 1.087e-04
[5,   200] loss: 1.049e-04
Validation
[5,   100] loss: 1.451e-04
[5,   200] loss: 1.438e-04
Training loss: 0.000, train NMSE: -5.768e+00
Validation loss: 0.000, valid_NMSE: -5.556e+00

Best validation loss: -5.5564398765563965

Saving best model for epoch: 5

--------------------------------------------------
[INFO]: Epoch 6 of 200
Training
[6,   100] loss: 1.024e-04
[6,   200] loss: 9.785e-05
Validation
[6,   100] loss: 1.344e-04
[6,   200] loss: 1.330e-04
Training loss: 0.000, train NMSE: -6.680e+00
Validation loss: 0.000, valid_NMSE: -5.920e+00

Best validation loss: -5.919656276702881

Saving best model for epoch: 6

--------------------------------------------------
[INFO]: Epoch 7 of 200
Training
[7,   100] loss: 9.392e-05
[7,   200] loss: 9.205e-05
Validation
[7,   100] loss: 1.301e-04
[7,   200] loss: 1.284e-04
Training loss: 0.000, train NMSE: -6.674e+00
Validation loss: 0.000, valid_NMSE: -5.968e+00

Best validation loss: -5.9683990478515625

Saving best model for epoch: 7

--------------------------------------------------
[INFO]: Epoch 8 of 200
Training
[8,   100] loss: 8.824e-05
[8,   200] loss: 8.523e-05
Validation
[8,   100] loss: 1.187e-04
[8,   200] loss: 1.173e-04
Training loss: 0.000, train NMSE: -7.682e+00
Validation loss: 0.000, valid_NMSE: -6.445e+00

Best validation loss: -6.445197582244873

Saving best model for epoch: 8

--------------------------------------------------
[INFO]: Epoch 9 of 200
Training
[9,   100] loss: 8.139e-05
[9,   200] loss: 7.833e-05
Validation
[9,   100] loss: 1.146e-04
[9,   200] loss: 1.130e-04
Training loss: 0.000, train NMSE: -7.770e+00
Validation loss: 0.000, valid_NMSE: -6.401e+00
--------------------------------------------------
[INFO]: Epoch 10 of 200
Training
[10,   100] loss: 7.562e-05
[10,   200] loss: 7.410e-05
Validation
[10,   100] loss: 1.057e-04
[10,   200] loss: 1.040e-04
Training loss: 0.000, train NMSE: -7.187e+00
Validation loss: 0.000, valid_NMSE: -6.911e+00

Best validation loss: -6.911480903625488

Saving best model for epoch: 10

--------------------------------------------------
[INFO]: Epoch 11 of 200
Training
[11,   100] loss: 7.151e-05
[11,   200] loss: 7.278e-05
Validation
[11,   100] loss: 1.017e-04
[11,   200] loss: 9.992e-05
Training loss: 0.000, train NMSE: -7.754e+00
Validation loss: 0.000, valid_NMSE: -7.096e+00

Best validation loss: -7.095656871795654

Saving best model for epoch: 11

--------------------------------------------------
[INFO]: Epoch 12 of 200
Training
[12,   100] loss: 6.932e-05
[12,   200] loss: 6.919e-05
Validation
[12,   100] loss: 9.808e-05
[12,   200] loss: 9.628e-05
Training loss: 0.000, train NMSE: -8.150e+00
Validation loss: 0.000, valid_NMSE: -7.340e+00

Best validation loss: -7.340257167816162

Saving best model for epoch: 12

--------------------------------------------------
[INFO]: Epoch 13 of 200
Training
[13,   100] loss: 6.700e-05
[13,   200] loss: 6.686e-05
Validation
[13,   100] loss: 9.625e-05
[13,   200] loss: 9.445e-05
Training loss: 0.000, train NMSE: -7.616e+00
Validation loss: 0.000, valid_NMSE: -7.261e+00
--------------------------------------------------
[INFO]: Epoch 14 of 200
Training
[14,   100] loss: 6.435e-05
[14,   200] loss: 6.563e-05
Validation
[14,   100] loss: 9.437e-05
[14,   200] loss: 9.245e-05
Training loss: 0.000, train NMSE: -8.028e+00
Validation loss: 0.000, valid_NMSE: -7.347e+00

Best validation loss: -7.347407817840576

Saving best model for epoch: 14

--------------------------------------------------
[INFO]: Epoch 15 of 200
Training
[15,   100] loss: 6.365e-05
[15,   200] loss: 6.362e-05
Validation
[15,   100] loss: 9.400e-05
[15,   200] loss: 9.203e-05
Training loss: 0.000, train NMSE: -7.588e+00
Validation loss: 0.000, valid_NMSE: -7.285e+00
--------------------------------------------------
[INFO]: Epoch 16 of 200
Training
[16,   100] loss: 6.295e-05
[16,   200] loss: 6.273e-05
Validation
[16,   100] loss: 9.148e-05
[16,   200] loss: 8.949e-05
Training loss: 0.000, train NMSE: -7.262e+00
Validation loss: 0.000, valid_NMSE: -7.469e+00

Best validation loss: -7.469284534454346

Saving best model for epoch: 16

--------------------------------------------------
[INFO]: Epoch 17 of 200
Training
[17,   100] loss: 6.180e-05
[17,   200] loss: 6.190e-05
Validation
[17,   100] loss: 9.124e-05
[17,   200] loss: 8.930e-05
Training loss: 0.000, train NMSE: -7.908e+00
Validation loss: 0.000, valid_NMSE: -7.383e+00
--------------------------------------------------
[INFO]: Epoch 18 of 200
Training
[18,   100] loss: 6.168e-05
[18,   200] loss: 6.213e-05
Validation
[18,   100] loss: 9.101e-05
[18,   200] loss: 8.906e-05
Training loss: 0.000, train NMSE: -8.358e+00
Validation loss: 0.000, valid_NMSE: -7.403e+00
--------------------------------------------------
[INFO]: Epoch 19 of 200
Training
[19,   100] loss: 6.137e-05
[19,   200] loss: 6.035e-05
Validation
[19,   100] loss: 9.330e-05
[19,   200] loss: 9.147e-05
Training loss: 0.000, train NMSE: -7.849e+00
Validation loss: 0.000, valid_NMSE: -7.208e+00
--------------------------------------------------
[INFO]: Epoch 20 of 200
Training
[20,   100] loss: 6.057e-05
[20,   200] loss: 6.007e-05
Validation
[20,   100] loss: 8.935e-05
[20,   200] loss: 8.741e-05
Training loss: 0.000, train NMSE: -8.090e+00
Validation loss: 0.000, valid_NMSE: -7.536e+00

Best validation loss: -7.53589391708374

Saving best model for epoch: 20

--------------------------------------------------
[INFO]: Epoch 21 of 200
Training
[21,   100] loss: 5.991e-05
[21,   200] loss: 5.938e-05
Validation
[21,   100] loss: 8.973e-05
[21,   200] loss: 8.770e-05
Training loss: 0.000, train NMSE: -8.318e+00
Validation loss: 0.000, valid_NMSE: -7.459e+00
--------------------------------------------------
[INFO]: Epoch 22 of 200
Training
[22,   100] loss: 5.889e-05
[22,   200] loss: 5.932e-05
Validation
[22,   100] loss: 8.825e-05
[22,   200] loss: 8.628e-05
Training loss: 0.000, train NMSE: -8.762e+00
Validation loss: 0.000, valid_NMSE: -7.614e+00

Best validation loss: -7.614058494567871

Saving best model for epoch: 22

--------------------------------------------------
[INFO]: Epoch 23 of 200
Training
[23,   100] loss: 5.849e-05
[23,   200] loss: 5.956e-05
Validation
[23,   100] loss: 8.833e-05
[23,   200] loss: 8.629e-05
Training loss: 0.000, train NMSE: -8.384e+00
Validation loss: 0.000, valid_NMSE: -7.550e+00
--------------------------------------------------
[INFO]: Epoch 24 of 200
Training
[24,   100] loss: 5.886e-05
[24,   200] loss: 5.851e-05
Validation
[24,   100] loss: 8.689e-05
[24,   200] loss: 8.480e-05
Training loss: 0.000, train NMSE: -8.322e+00
Validation loss: 0.000, valid_NMSE: -7.688e+00

Best validation loss: -7.68817138671875

Saving best model for epoch: 24

--------------------------------------------------
[INFO]: Epoch 25 of 200
Training
[25,   100] loss: 5.785e-05
[25,   200] loss: 5.911e-05
Validation
[25,   100] loss: 8.626e-05
[25,   200] loss: 8.423e-05
Training loss: 0.000, train NMSE: -9.661e+00
Validation loss: 0.000, valid_NMSE: -7.722e+00

Best validation loss: -7.721533298492432

Saving best model for epoch: 25

--------------------------------------------------
[INFO]: Epoch 26 of 200
Training
[26,   100] loss: 5.809e-05
[26,   200] loss: 5.782e-05
Validation
[26,   100] loss: 9.032e-05
[26,   200] loss: 8.821e-05
Training loss: 0.000, train NMSE: -9.192e+00
Validation loss: 0.000, valid_NMSE: -7.385e+00
--------------------------------------------------
[INFO]: Epoch 27 of 200
Training
[27,   100] loss: 5.848e-05
[27,   200] loss: 5.750e-05
Validation
[27,   100] loss: 8.574e-05
[27,   200] loss: 8.374e-05
Training loss: 0.000, train NMSE: -8.650e+00
Validation loss: 0.000, valid_NMSE: -7.728e+00

Best validation loss: -7.727512836456299

Saving best model for epoch: 27

--------------------------------------------------
[INFO]: Epoch 28 of 200
Training
[28,   100] loss: 5.785e-05
[28,   200] loss: 5.704e-05
Validation
[28,   100] loss: 8.476e-05
[28,   200] loss: 8.266e-05
Training loss: 0.000, train NMSE: -9.135e+00
Validation loss: 0.000, valid_NMSE: -7.870e+00

Best validation loss: -7.869510173797607

Saving best model for epoch: 28

--------------------------------------------------
[INFO]: Epoch 29 of 200
Training
[29,   100] loss: 5.702e-05
[29,   200] loss: 5.707e-05
Validation
[29,   100] loss: 8.558e-05
[29,   200] loss: 8.358e-05
Training loss: 0.000, train NMSE: -8.627e+00
Validation loss: 0.000, valid_NMSE: -7.707e+00
--------------------------------------------------
[INFO]: Epoch 30 of 200
Training
[30,   100] loss: 5.805e-05
[30,   200] loss: 5.612e-05
Validation
[30,   100] loss: 8.493e-05
[30,   200] loss: 8.290e-05
Training loss: 0.000, train NMSE: -8.612e+00
Validation loss: 0.000, valid_NMSE: -7.778e+00
--------------------------------------------------
[INFO]: Epoch 31 of 200
Training
[31,   100] loss: 5.634e-05
[31,   200] loss: 5.669e-05
Validation
[31,   100] loss: 8.490e-05
[31,   200] loss: 8.282e-05
Training loss: 0.000, train NMSE: -8.134e+00
Validation loss: 0.000, valid_NMSE: -7.738e+00
--------------------------------------------------
[INFO]: Epoch 32 of 200
Training
[32,   100] loss: 5.684e-05
[32,   200] loss: 5.625e-05
Validation
[32,   100] loss: 8.564e-05
[32,   200] loss: 8.353e-05
Training loss: 0.000, train NMSE: -9.254e+00
Validation loss: 0.000, valid_NMSE: -7.701e+00
--------------------------------------------------
[INFO]: Epoch 33 of 200
Training
[33,   100] loss: 5.533e-05
[33,   200] loss: 5.721e-05
Validation
[33,   100] loss: 8.643e-05
[33,   200] loss: 8.432e-05
Training loss: 0.000, train NMSE: -9.075e+00
Validation loss: 0.000, valid_NMSE: -7.645e+00
--------------------------------------------------
[INFO]: Epoch 34 of 200
Training
[34,   100] loss: 5.625e-05
[34,   200] loss: 5.524e-05
Validation
[34,   100] loss: 8.394e-05
[34,   200] loss: 8.197e-05
Training loss: 0.000, train NMSE: -8.738e+00
Validation loss: 0.000, valid_NMSE: -7.837e+00
--------------------------------------------------
[INFO]: Epoch 35 of 200
Training
[35,   100] loss: 5.498e-05
[35,   200] loss: 5.627e-05
Validation
[35,   100] loss: 8.633e-05
[35,   200] loss: 8.416e-05
Training loss: 0.000, train NMSE: -8.553e+00
Validation loss: 0.000, valid_NMSE: -7.578e+00
--------------------------------------------------
[INFO]: Epoch 36 of 200
Training
[36,   100] loss: 5.576e-05
[36,   200] loss: 5.535e-05
Validation
[36,   100] loss: 8.442e-05
[36,   200] loss: 8.245e-05
Training loss: 0.000, train NMSE: -8.901e+00
Validation loss: 0.000, valid_NMSE: -7.746e+00
--------------------------------------------------
[INFO]: Epoch 37 of 200
Training
[37,   100] loss: 5.501e-05
[37,   200] loss: 5.522e-05
Validation
[37,   100] loss: 8.672e-05
[37,   200] loss: 8.479e-05
Training loss: 0.000, train NMSE: -8.723e+00
Validation loss: 0.000, valid_NMSE: -7.543e+00
--------------------------------------------------
[INFO]: Epoch 38 of 200
Training
[38,   100] loss: 5.465e-05
[38,   200] loss: 5.412e-05
Validation
[38,   100] loss: 8.053e-05
[38,   200] loss: 7.850e-05
Training loss: 0.000, train NMSE: -9.139e+00
Validation loss: 0.000, valid_NMSE: -8.029e+00

Best validation loss: -8.029112815856934

Saving best model for epoch: 38

--------------------------------------------------
[INFO]: Epoch 39 of 200
Training
[39,   100] loss: 5.413e-05
[39,   200] loss: 5.358e-05
Validation
[39,   100] loss: 8.027e-05
[39,   200] loss: 7.832e-05
Training loss: 0.000, train NMSE: -8.296e+00
Validation loss: 0.000, valid_NMSE: -8.007e+00
--------------------------------------------------
[INFO]: Epoch 40 of 200
Training
[40,   100] loss: 5.389e-05
[40,   200] loss: 5.362e-05
Validation
[40,   100] loss: 8.030e-05
[40,   200] loss: 7.830e-05
Training loss: 0.000, train NMSE: -8.855e+00
Validation loss: 0.000, valid_NMSE: -7.999e+00
--------------------------------------------------
[INFO]: Epoch 41 of 200
Training
[41,   100] loss: 5.373e-05
[41,   200] loss: 5.307e-05
Validation
[41,   100] loss: 7.796e-05
[41,   200] loss: 7.599e-05
Training loss: 0.000, train NMSE: -8.945e+00
Validation loss: 0.000, valid_NMSE: -8.184e+00

Best validation loss: -8.183664321899414

Saving best model for epoch: 41

--------------------------------------------------
[INFO]: Epoch 42 of 200
Training
[42,   100] loss: 5.252e-05
[42,   200] loss: 5.349e-05
Validation
[42,   100] loss: 7.794e-05
[42,   200] loss: 7.598e-05
Training loss: 0.000, train NMSE: -9.419e+00
Validation loss: 0.000, valid_NMSE: -8.179e+00
--------------------------------------------------
[INFO]: Epoch 43 of 200
Training
[43,   100] loss: 5.142e-05
[43,   200] loss: 5.342e-05
Validation
[43,   100] loss: 8.183e-05
[43,   200] loss: 7.993e-05
Training loss: 0.000, train NMSE: -9.416e+00
Validation loss: 0.000, valid_NMSE: -7.873e+00
--------------------------------------------------
[INFO]: Epoch 44 of 200
Training
[44,   100] loss: 5.215e-05
[44,   200] loss: 5.255e-05
Validation
[44,   100] loss: 7.715e-05
[44,   200] loss: 7.522e-05
Training loss: 0.000, train NMSE: -9.106e+00
Validation loss: 0.000, valid_NMSE: -8.246e+00

Best validation loss: -8.245650291442871

Saving best model for epoch: 44

--------------------------------------------------
[INFO]: Epoch 45 of 200
Training
[45,   100] loss: 5.135e-05
[45,   200] loss: 5.266e-05
Validation
[45,   100] loss: 7.758e-05
[45,   200] loss: 7.565e-05
Training loss: 0.000, train NMSE: -9.229e+00
Validation loss: 0.000, valid_NMSE: -8.177e+00
--------------------------------------------------
[INFO]: Epoch 46 of 200
Training
[46,   100] loss: 5.132e-05
[46,   200] loss: 5.135e-05
Validation
[46,   100] loss: 7.786e-05
[46,   200] loss: 7.589e-05
Training loss: 0.000, train NMSE: -9.506e+00
Validation loss: 0.000, valid_NMSE: -8.147e+00
--------------------------------------------------
[INFO]: Epoch 47 of 200
Training
[47,   100] loss: 5.185e-05
[47,   200] loss: 5.115e-05
Validation
[47,   100] loss: 7.506e-05
[47,   200] loss: 7.308e-05
Training loss: 0.000, train NMSE: -9.091e+00
Validation loss: 0.000, valid_NMSE: -8.404e+00

Best validation loss: -8.403789520263672

Saving best model for epoch: 47

--------------------------------------------------
[INFO]: Epoch 48 of 200
Training
[48,   100] loss: 5.103e-05
[48,   200] loss: 5.155e-05
Validation
[48,   100] loss: 7.547e-05
[48,   200] loss: 7.355e-05
Training loss: 0.000, train NMSE: -9.149e+00
Validation loss: 0.000, valid_NMSE: -8.347e+00
--------------------------------------------------
[INFO]: Epoch 49 of 200
Training
[49,   100] loss: 5.057e-05
[49,   200] loss: 5.168e-05
Validation
[49,   100] loss: 7.544e-05
[49,   200] loss: 7.347e-05
Training loss: 0.000, train NMSE: -8.537e+00
Validation loss: 0.000, valid_NMSE: -8.359e+00
--------------------------------------------------
[INFO]: Epoch 50 of 200
Training
[50,   100] loss: 5.053e-05
[50,   200] loss: 5.127e-05
Validation
[50,   100] loss: 7.709e-05
[50,   200] loss: 7.525e-05
Training loss: 0.000, train NMSE: -9.443e+00
Validation loss: 0.000, valid_NMSE: -8.173e+00
--------------------------------------------------
[INFO]: Epoch 51 of 200
Training
[51,   100] loss: 5.077e-05
[51,   200] loss: 5.132e-05
Validation
[51,   100] loss: 7.408e-05
[51,   200] loss: 7.220e-05
Training loss: 0.000, train NMSE: -8.705e+00
Validation loss: 0.000, valid_NMSE: -8.453e+00

Best validation loss: -8.452831268310547

Saving best model for epoch: 51

--------------------------------------------------
[INFO]: Epoch 52 of 200
Training
[52,   100] loss: 5.100e-05
[52,   200] loss: 5.039e-05
Validation
[52,   100] loss: 8.313e-05
[52,   200] loss: 8.131e-05
Training loss: 0.000, train NMSE: -9.815e+00
Validation loss: 0.000, valid_NMSE: -7.675e+00
--------------------------------------------------
[INFO]: Epoch 53 of 200
Training
[53,   100] loss: 5.055e-05
[53,   200] loss: 5.067e-05
Validation
[53,   100] loss: 7.531e-05
[53,   200] loss: 7.355e-05
Training loss: 0.000, train NMSE: -9.906e+00
Validation loss: 0.000, valid_NMSE: -8.327e+00
--------------------------------------------------
[INFO]: Epoch 54 of 200
Training
[54,   100] loss: 5.025e-05
[54,   200] loss: 5.064e-05
Validation
[54,   100] loss: 7.316e-05
[54,   200] loss: 7.129e-05
Training loss: 0.000, train NMSE: -9.487e+00
Validation loss: 0.000, valid_NMSE: -8.550e+00

Best validation loss: -8.549922943115234

Saving best model for epoch: 54

--------------------------------------------------
[INFO]: Epoch 55 of 200
Training
[55,   100] loss: 5.045e-05
[55,   200] loss: 4.984e-05
Validation
[55,   100] loss: 7.639e-05
[55,   200] loss: 7.448e-05
Training loss: 0.000, train NMSE: -9.389e+00
Validation loss: 0.000, valid_NMSE: -8.226e+00
--------------------------------------------------
[INFO]: Epoch 56 of 200
Training
[56,   100] loss: 4.942e-05
[56,   200] loss: 5.025e-05
Validation
[56,   100] loss: 7.292e-05
[56,   200] loss: 7.106e-05
Training loss: 0.000, train NMSE: -9.972e+00
Validation loss: 0.000, valid_NMSE: -8.561e+00

Best validation loss: -8.560966491699219

Saving best model for epoch: 56

--------------------------------------------------
[INFO]: Epoch 57 of 200
Training
[57,   100] loss: 5.092e-05
[57,   200] loss: 4.904e-05
Validation
[57,   100] loss: 7.293e-05
[57,   200] loss: 7.102e-05
Training loss: 0.000, train NMSE: -9.611e+00
Validation loss: 0.000, valid_NMSE: -8.515e+00
--------------------------------------------------
[INFO]: Epoch 58 of 200
Training
[58,   100] loss: 5.021e-05
[58,   200] loss: 4.914e-05
Validation
[58,   100] loss: 7.384e-05
[58,   200] loss: 7.199e-05
Training loss: 0.000, train NMSE: -9.366e+00
Validation loss: 0.000, valid_NMSE: -8.466e+00
--------------------------------------------------
[INFO]: Epoch 59 of 200
Training
[59,   100] loss: 4.984e-05
[59,   200] loss: 4.919e-05
Validation
[59,   100] loss: 7.536e-05
[59,   200] loss: 7.348e-05
Training loss: 0.000, train NMSE: -9.536e+00
Validation loss: 0.000, valid_NMSE: -8.284e+00
--------------------------------------------------
[INFO]: Epoch 60 of 200
Training
[60,   100] loss: 4.994e-05
[60,   200] loss: 4.918e-05
Validation
[60,   100] loss: 7.172e-05
[60,   200] loss: 6.988e-05
Training loss: 0.000, train NMSE: -9.633e+00
Validation loss: 0.000, valid_NMSE: -8.640e+00

Best validation loss: -8.640169143676758

Saving best model for epoch: 60

--------------------------------------------------
[INFO]: Epoch 61 of 200
Training
[61,   100] loss: 4.916e-05
[61,   200] loss: 4.989e-05
Validation
[61,   100] loss: 7.205e-05
[61,   200] loss: 7.019e-05
Training loss: 0.000, train NMSE: -9.668e+00
Validation loss: 0.000, valid_NMSE: -8.663e+00

Best validation loss: -8.66312313079834

Saving best model for epoch: 61

--------------------------------------------------
[INFO]: Epoch 62 of 200
Training
[62,   100] loss: 4.942e-05
[62,   200] loss: 4.872e-05
Validation
[62,   100] loss: 7.454e-05
[62,   200] loss: 7.274e-05
Training loss: 0.000, train NMSE: -9.320e+00
Validation loss: 0.000, valid_NMSE: -8.346e+00
--------------------------------------------------
[INFO]: Epoch 63 of 200
Training
[63,   100] loss: 4.980e-05
[63,   200] loss: 4.821e-05
Validation
[63,   100] loss: 7.174e-05
[63,   200] loss: 6.981e-05
Training loss: 0.000, train NMSE: -9.203e+00
Validation loss: 0.000, valid_NMSE: -8.631e+00
--------------------------------------------------
[INFO]: Epoch 64 of 200
Training
[64,   100] loss: 4.887e-05
[64,   200] loss: 4.912e-05
Validation
[64,   100] loss: 7.336e-05
[64,   200] loss: 7.152e-05
Training loss: 0.000, train NMSE: -1.011e+01
Validation loss: 0.000, valid_NMSE: -8.521e+00
--------------------------------------------------
[INFO]: Epoch 65 of 200
Training
[65,   100] loss: 4.923e-05
[65,   200] loss: 4.914e-05
Validation
[65,   100] loss: 7.314e-05
[65,   200] loss: 7.123e-05
Training loss: 0.000, train NMSE: -9.198e+00
Validation loss: 0.000, valid_NMSE: -8.513e+00
--------------------------------------------------
[INFO]: Epoch 66 of 200
Training
[66,   100] loss: 4.980e-05
[66,   200] loss: 4.824e-05
Validation
[66,   100] loss: 7.147e-05
[66,   200] loss: 6.955e-05
Training loss: 0.000, train NMSE: -9.460e+00
Validation loss: 0.000, valid_NMSE: -8.644e+00
--------------------------------------------------
[INFO]: Epoch 67 of 200
Training
[67,   100] loss: 4.870e-05
[67,   200] loss: 4.882e-05
Validation
[67,   100] loss: 7.269e-05
[67,   200] loss: 7.082e-05
Training loss: 0.000, train NMSE: -9.109e+00
Validation loss: 0.000, valid_NMSE: -8.454e+00
--------------------------------------------------
[INFO]: Epoch 68 of 200
Training
[68,   100] loss: 4.852e-05
[68,   200] loss: 4.883e-05
Validation
[68,   100] loss: 7.106e-05
[68,   200] loss: 6.917e-05
Training loss: 0.000, train NMSE: -9.118e+00
Validation loss: 0.000, valid_NMSE: -8.694e+00

Best validation loss: -8.694204330444336

Saving best model for epoch: 68

--------------------------------------------------
[INFO]: Epoch 69 of 200
Training
[69,   100] loss: 4.809e-05
[69,   200] loss: 4.915e-05
Validation
[69,   100] loss: 7.092e-05
[69,   200] loss: 6.901e-05
Training loss: 0.000, train NMSE: -9.246e+00
Validation loss: 0.000, valid_NMSE: -8.724e+00

Best validation loss: -8.723511695861816

Saving best model for epoch: 69

--------------------------------------------------
[INFO]: Epoch 70 of 200
Training
[70,   100] loss: 4.928e-05
[70,   200] loss: 4.768e-05
Validation
[70,   100] loss: 7.373e-05
[70,   200] loss: 7.186e-05
Training loss: 0.000, train NMSE: -9.606e+00
Validation loss: 0.000, valid_NMSE: -8.353e+00
--------------------------------------------------
[INFO]: Epoch 71 of 200
Training
[71,   100] loss: 4.797e-05
[71,   200] loss: 4.935e-05
Validation
[71,   100] loss: 7.005e-05
[71,   200] loss: 6.812e-05
Training loss: 0.000, train NMSE: -9.433e+00
Validation loss: 0.000, valid_NMSE: -8.772e+00

Best validation loss: -8.772178649902344

Saving best model for epoch: 71

--------------------------------------------------
[INFO]: Epoch 72 of 200
Training
[72,   100] loss: 4.909e-05
[72,   200] loss: 4.813e-05
Validation
[72,   100] loss: 7.293e-05
[72,   200] loss: 7.119e-05
Training loss: 0.000, train NMSE: -9.852e+00
Validation loss: 0.000, valid_NMSE: -8.410e+00
--------------------------------------------------
[INFO]: Epoch 73 of 200
Training
[73,   100] loss: 4.841e-05
[73,   200] loss: 4.801e-05
Validation
[73,   100] loss: 7.227e-05
[73,   200] loss: 7.045e-05
Training loss: 0.000, train NMSE: -9.379e+00
Validation loss: 0.000, valid_NMSE: -8.533e+00
--------------------------------------------------
[INFO]: Epoch 74 of 200
Training
[74,   100] loss: 4.839e-05
[74,   200] loss: 4.831e-05
Validation
[74,   100] loss: 7.262e-05
[74,   200] loss: 7.076e-05
Training loss: 0.000, train NMSE: -9.472e+00
Validation loss: 0.000, valid_NMSE: -8.459e+00
--------------------------------------------------
[INFO]: Epoch 75 of 200
Training
[75,   100] loss: 4.849e-05
[75,   200] loss: 4.741e-05
Validation
[75,   100] loss: 7.194e-05
[75,   200] loss: 7.000e-05
Training loss: 0.000, train NMSE: -1.005e+01
Validation loss: 0.000, valid_NMSE: -8.562e+00
--------------------------------------------------
[INFO]: Epoch 76 of 200
Training
[76,   100] loss: 4.732e-05
[76,   200] loss: 4.843e-05
Validation
[76,   100] loss: 7.134e-05
[76,   200] loss: 6.951e-05
Training loss: 0.000, train NMSE: -1.011e+01
Validation loss: 0.000, valid_NMSE: -8.635e+00
--------------------------------------------------
[INFO]: Epoch 77 of 200
Training
[77,   100] loss: 4.745e-05
[77,   200] loss: 4.801e-05
Validation
[77,   100] loss: 7.400e-05
[77,   200] loss: 7.211e-05
Training loss: 0.000, train NMSE: -9.162e+00
Validation loss: 0.000, valid_NMSE: -8.364e+00
--------------------------------------------------
[INFO]: Epoch 78 of 200
Training
[78,   100] loss: 4.745e-05
[78,   200] loss: 4.834e-05
Validation
[78,   100] loss: 6.958e-05
[78,   200] loss: 6.776e-05
Training loss: 0.000, train NMSE: -1.029e+01
Validation loss: 0.000, valid_NMSE: -8.796e+00

Best validation loss: -8.796011924743652

Saving best model for epoch: 78

--------------------------------------------------
[INFO]: Epoch 79 of 200
Training
[79,   100] loss: 4.795e-05
[79,   200] loss: 4.769e-05
Validation
[79,   100] loss: 7.072e-05
[79,   200] loss: 6.898e-05
Training loss: 0.000, train NMSE: -9.183e+00
Validation loss: 0.000, valid_NMSE: -8.677e+00
--------------------------------------------------
[INFO]: Epoch 80 of 200
Training
[80,   100] loss: 4.765e-05
[80,   200] loss: 4.752e-05
Validation
[80,   100] loss: 7.151e-05
[80,   200] loss: 6.969e-05
Training loss: 0.000, train NMSE: -9.640e+00
Validation loss: 0.000, valid_NMSE: -8.602e+00
--------------------------------------------------
[INFO]: Epoch 81 of 200
Training
[81,   100] loss: 4.772e-05
[81,   200] loss: 4.796e-05
Validation
[81,   100] loss: 7.145e-05
[81,   200] loss: 6.956e-05
Training loss: 0.000, train NMSE: -8.875e+00
Validation loss: 0.000, valid_NMSE: -8.542e+00
--------------------------------------------------
[INFO]: Epoch 82 of 200
Training
[82,   100] loss: 4.797e-05
[82,   200] loss: 4.730e-05
Validation
[82,   100] loss: 7.329e-05
[82,   200] loss: 7.147e-05
Training loss: 0.000, train NMSE: -9.673e+00
Validation loss: 0.000, valid_NMSE: -8.366e+00
--------------------------------------------------
[INFO]: Epoch 83 of 200
Training
[83,   100] loss: 4.755e-05
[83,   200] loss: 4.703e-05
Validation
[83,   100] loss: 7.045e-05
[83,   200] loss: 6.862e-05
Training loss: 0.000, train NMSE: -9.953e+00
Validation loss: 0.000, valid_NMSE: -8.686e+00
--------------------------------------------------
[INFO]: Epoch 84 of 200
Training
[84,   100] loss: 4.865e-05
[84,   200] loss: 4.686e-05
Validation
[84,   100] loss: 7.130e-05
[84,   200] loss: 6.940e-05
Training loss: 0.000, train NMSE: -9.492e+00
Validation loss: 0.000, valid_NMSE: -8.616e+00
--------------------------------------------------
[INFO]: Epoch 85 of 200
Training
[85,   100] loss: 4.737e-05
[85,   200] loss: 4.738e-05
Validation
[85,   100] loss: 6.946e-05
[85,   200] loss: 6.765e-05
Training loss: 0.000, train NMSE: -9.236e+00
Validation loss: 0.000, valid_NMSE: -8.729e+00
--------------------------------------------------
[INFO]: Epoch 86 of 200
Training
[86,   100] loss: 4.719e-05
[86,   200] loss: 4.745e-05
Validation
[86,   100] loss: 7.116e-05
[86,   200] loss: 6.933e-05
Training loss: 0.000, train NMSE: -9.074e+00
Validation loss: 0.000, valid_NMSE: -8.560e+00
--------------------------------------------------
[INFO]: Epoch 87 of 200
Training
[87,   100] loss: 4.747e-05
[87,   200] loss: 4.685e-05
Validation
[87,   100] loss: 6.947e-05
[87,   200] loss: 6.764e-05
Training loss: 0.000, train NMSE: -9.585e+00
Validation loss: 0.000, valid_NMSE: -8.740e+00
--------------------------------------------------
[INFO]: Epoch 88 of 200
Training
[88,   100] loss: 4.673e-05
[88,   200] loss: 4.750e-05
Validation
[88,   100] loss: 7.154e-05
[88,   200] loss: 6.974e-05
Training loss: 0.000, train NMSE: -1.018e+01
Validation loss: 0.000, valid_NMSE: -8.543e+00
--------------------------------------------------
[INFO]: Epoch 89 of 200
Training
[89,   100] loss: 4.670e-05
[89,   200] loss: 4.744e-05
Validation
[89,   100] loss: 6.950e-05
[89,   200] loss: 6.775e-05
Training loss: 0.000, train NMSE: -9.194e+00
Validation loss: 0.000, valid_NMSE: -8.772e+00
--------------------------------------------------
[INFO]: Epoch 90 of 200
Training
[90,   100] loss: 4.638e-05
[90,   200] loss: 4.775e-05
Validation
[90,   100] loss: 6.983e-05
[90,   200] loss: 6.796e-05
Training loss: 0.000, train NMSE: -9.254e+00
Validation loss: 0.000, valid_NMSE: -8.775e+00
--------------------------------------------------
[INFO]: Epoch 91 of 200
Training
[91,   100] loss: 4.755e-05
[91,   200] loss: 4.670e-05
Validation
[91,   100] loss: 6.994e-05
[91,   200] loss: 6.808e-05
Training loss: 0.000, train NMSE: -9.721e+00
Validation loss: 0.000, valid_NMSE: -8.729e+00
--------------------------------------------------
[INFO]: Epoch 92 of 200
Training
[92,   100] loss: 4.734e-05
[92,   200] loss: 4.696e-05
Validation
[92,   100] loss: 7.715e-05
[92,   200] loss: 7.535e-05
Training loss: 0.000, train NMSE: -8.517e+00
Validation loss: 0.000, valid_NMSE: -8.021e+00
--------------------------------------------------
[INFO]: Epoch 93 of 200
Training
[93,   100] loss: 4.739e-05
[93,   200] loss: 4.693e-05
Validation
[93,   100] loss: 7.030e-05
[93,   200] loss: 6.849e-05
Training loss: 0.000, train NMSE: -9.588e+00
Validation loss: 0.000, valid_NMSE: -8.702e+00
--------------------------------------------------
[INFO]: Epoch 94 of 200
Training
[94,   100] loss: 4.655e-05
[94,   200] loss: 4.709e-05
Validation
[94,   100] loss: 6.901e-05
[94,   200] loss: 6.721e-05
Training loss: 0.000, train NMSE: -1.066e+01
Validation loss: 0.000, valid_NMSE: -8.786e+00
--------------------------------------------------
[INFO]: Epoch 95 of 200
Training
[95,   100] loss: 4.667e-05
[95,   200] loss: 4.697e-05
Validation
[95,   100] loss: 7.460e-05
[95,   200] loss: 7.278e-05
Training loss: 0.000, train NMSE: -1.012e+01
Validation loss: 0.000, valid_NMSE: -8.270e+00
--------------------------------------------------
[INFO]: Epoch 96 of 200
Training
[96,   100] loss: 4.704e-05
[96,   200] loss: 4.651e-05
Validation
[96,   100] loss: 7.084e-05
[96,   200] loss: 6.907e-05
Training loss: 0.000, train NMSE: -8.631e+00
Validation loss: 0.000, valid_NMSE: -8.627e+00
--------------------------------------------------
[INFO]: Epoch 97 of 200
Training
[97,   100] loss: 4.690e-05
[97,   200] loss: 4.681e-05
Validation
[97,   100] loss: 7.185e-05
[97,   200] loss: 7.001e-05
Training loss: 0.000, train NMSE: -8.987e+00
Validation loss: 0.000, valid_NMSE: -8.482e+00
--------------------------------------------------
[INFO]: Epoch 98 of 200
Training
[98,   100] loss: 4.643e-05
[98,   200] loss: 4.690e-05
Validation
[98,   100] loss: 6.962e-05
[98,   200] loss: 6.778e-05
Training loss: 0.000, train NMSE: -1.007e+01
Validation loss: 0.000, valid_NMSE: -8.742e+00
--------------------------------------------------
[INFO]: Epoch 99 of 200
Training
[99,   100] loss: 4.625e-05
[99,   200] loss: 4.704e-05
Validation
[99,   100] loss: 7.218e-05
[99,   200] loss: 7.033e-05
Training loss: 0.000, train NMSE: -9.374e+00
Validation loss: 0.000, valid_NMSE: -8.525e+00
--------------------------------------------------
[INFO]: Epoch 100 of 200
Training
[100,   100] loss: 4.689e-05
[100,   200] loss: 4.632e-05
Validation
[100,   100] loss: 7.058e-05
[100,   200] loss: 6.875e-05
Training loss: 0.000, train NMSE: -9.201e+00
Validation loss: 0.000, valid_NMSE: -8.611e+00
--------------------------------------------------
[INFO]: Epoch 101 of 200
Training
[101,   100] loss: 4.594e-05
[101,   200] loss: 4.716e-05
Validation
[101,   100] loss: 6.948e-05
[101,   200] loss: 6.774e-05
Training loss: 0.000, train NMSE: -9.148e+00
Validation loss: 0.000, valid_NMSE: -8.774e+00
--------------------------------------------------
[INFO]: Epoch 102 of 200
Training
[102,   100] loss: 4.664e-05
[102,   200] loss: 4.674e-05
Validation
[102,   100] loss: 6.932e-05
[102,   200] loss: 6.747e-05
Training loss: 0.000, train NMSE: -9.416e+00
Validation loss: 0.000, valid_NMSE: -8.749e+00
--------------------------------------------------
[INFO]: Epoch 103 of 200
Training
[103,   100] loss: 4.633e-05
[103,   200] loss: 4.648e-05
Validation
[103,   100] loss: 7.000e-05
[103,   200] loss: 6.822e-05
Training loss: 0.000, train NMSE: -9.968e+00
Validation loss: 0.000, valid_NMSE: -8.654e+00
--------------------------------------------------
[INFO]: Epoch 104 of 200
Training
[104,   100] loss: 4.696e-05
[104,   200] loss: 4.618e-05
Validation
[104,   100] loss: 7.283e-05
[104,   200] loss: 7.106e-05
Training loss: 0.000, train NMSE: -9.055e+00
Validation loss: 0.000, valid_NMSE: -8.379e+00
--------------------------------------------------
[INFO]: Epoch 105 of 200
Training
[105,   100] loss: 4.712e-05
[105,   200] loss: 4.543e-05
Validation
[105,   100] loss: 7.112e-05
[105,   200] loss: 6.940e-05
Training loss: 0.000, train NMSE: -9.853e+00
Validation loss: 0.000, valid_NMSE: -8.528e+00
--------------------------------------------------
[INFO]: Epoch 106 of 200
Training
[106,   100] loss: 4.641e-05
[106,   200] loss: 4.632e-05
Validation
[106,   100] loss: 7.159e-05
[106,   200] loss: 6.982e-05
Training loss: 0.000, train NMSE: -9.637e+00
Validation loss: 0.000, valid_NMSE: -8.518e+00
--------------------------------------------------
[INFO]: Epoch 107 of 200
Training
[107,   100] loss: 4.621e-05
[107,   200] loss: 4.608e-05
Validation
[107,   100] loss: 6.960e-05
[107,   200] loss: 6.782e-05
Training loss: 0.000, train NMSE: -9.834e+00
Validation loss: 0.000, valid_NMSE: -8.761e+00
--------------------------------------------------
[INFO]: Epoch 108 of 200
Training
[108,   100] loss: 4.608e-05
[108,   200] loss: 4.622e-05
Validation
[108,   100] loss: 6.927e-05
[108,   200] loss: 6.749e-05
Training loss: 0.000, train NMSE: -1.019e+01
Validation loss: 0.000, valid_NMSE: -8.736e+00
--------------------------------------------------
[INFO]: Epoch 109 of 200
Training
[109,   100] loss: 4.624e-05
[109,   200] loss: 4.588e-05
Validation
[109,   100] loss: 6.939e-05
[109,   200] loss: 6.761e-05
Training loss: 0.000, train NMSE: -1.042e+01
Validation loss: 0.000, valid_NMSE: -8.716e+00
--------------------------------------------------
[INFO]: Epoch 110 of 200
Training
[110,   100] loss: 4.588e-05
[110,   200] loss: 4.622e-05
Validation
[110,   100] loss: 6.961e-05
[110,   200] loss: 6.785e-05
Training loss: 0.000, train NMSE: -9.527e+00
Validation loss: 0.000, valid_NMSE: -8.679e+00
--------------------------------------------------
[INFO]: Epoch 111 of 200
Training
[111,   100] loss: 4.631e-05
[111,   200] loss: 4.619e-05
Validation
[111,   100] loss: 7.241e-05
[111,   200] loss: 7.063e-05
Training loss: 0.000, train NMSE: -9.485e+00
Validation loss: 0.000, valid_NMSE: -8.378e+00
--------------------------------------------------
[INFO]: Epoch 112 of 200
Training
[112,   100] loss: 4.653e-05
[112,   200] loss: 4.558e-05
Validation
[112,   100] loss: 7.307e-05
[112,   200] loss: 7.133e-05
Training loss: 0.000, train NMSE: -1.056e+01
Validation loss: 0.000, valid_NMSE: -8.349e+00
--------------------------------------------------
[INFO]: Epoch 113 of 200
Training
[113,   100] loss: 4.602e-05
[113,   200] loss: 4.600e-05
Validation
[113,   100] loss: 6.946e-05
[113,   200] loss: 6.765e-05
Training loss: 0.000, train NMSE: -9.915e+00
Validation loss: 0.000, valid_NMSE: -8.812e+00

Best validation loss: -8.81187915802002

Saving best model for epoch: 113

--------------------------------------------------
[INFO]: Epoch 114 of 200
Training
[114,   100] loss: 4.550e-05
[114,   200] loss: 4.684e-05
Validation
[114,   100] loss: 7.072e-05
[114,   200] loss: 6.897e-05
Training loss: 0.000, train NMSE: -9.129e+00
Validation loss: 0.000, valid_NMSE: -8.523e+00
--------------------------------------------------
[INFO]: Epoch 115 of 200
Training
[115,   100] loss: 4.575e-05
[115,   200] loss: 4.646e-05
Validation
[115,   100] loss: 7.249e-05
[115,   200] loss: 7.076e-05
Training loss: 0.000, train NMSE: -9.229e+00
Validation loss: 0.000, valid_NMSE: -8.458e+00
--------------------------------------------------
[INFO]: Epoch 116 of 200
Training
[116,   100] loss: 4.599e-05
[116,   200] loss: 4.543e-05
Validation
[116,   100] loss: 6.825e-05
[116,   200] loss: 6.649e-05
Training loss: 0.000, train NMSE: -9.835e+00
Validation loss: 0.000, valid_NMSE: -8.882e+00

Best validation loss: -8.882013320922852

Saving best model for epoch: 116

--------------------------------------------------
[INFO]: Epoch 117 of 200
Training
[117,   100] loss: 4.534e-05
[117,   200] loss: 4.602e-05
Validation
[117,   100] loss: 6.980e-05
[117,   200] loss: 6.806e-05
Training loss: 0.000, train NMSE: -9.622e+00
Validation loss: 0.000, valid_NMSE: -8.678e+00
--------------------------------------------------
[INFO]: Epoch 118 of 200
Training
[118,   100] loss: 4.595e-05
[118,   200] loss: 4.590e-05
Validation
[118,   100] loss: 6.869e-05
[118,   200] loss: 6.691e-05
Training loss: 0.000, train NMSE: -9.685e+00
Validation loss: 0.000, valid_NMSE: -8.795e+00
--------------------------------------------------
[INFO]: Epoch 119 of 200
Training
[119,   100] loss: 4.627e-05
[119,   200] loss: 4.605e-05
Validation
[119,   100] loss: 7.047e-05
[119,   200] loss: 6.869e-05
Training loss: 0.000, train NMSE: -1.011e+01
Validation loss: 0.000, valid_NMSE: -8.558e+00
--------------------------------------------------
[INFO]: Epoch 120 of 200
Training
[120,   100] loss: 4.591e-05
[120,   200] loss: 4.559e-05
Validation
[120,   100] loss: 7.112e-05
[120,   200] loss: 6.942e-05
Training loss: 0.000, train NMSE: -9.356e+00
Validation loss: 0.000, valid_NMSE: -8.513e+00
--------------------------------------------------
[INFO]: Epoch 121 of 200
Training
[121,   100] loss: 4.588e-05
[121,   200] loss: 4.540e-05
Validation
[121,   100] loss: 6.955e-05
[121,   200] loss: 6.786e-05
Training loss: 0.000, train NMSE: -9.368e+00
Validation loss: 0.000, valid_NMSE: -8.723e+00
--------------------------------------------------
[INFO]: Epoch 122 of 200
Training
[122,   100] loss: 4.563e-05
[122,   200] loss: 4.533e-05
Validation
[122,   100] loss: 6.834e-05
[122,   200] loss: 6.664e-05
Training loss: 0.000, train NMSE: -1.029e+01
Validation loss: 0.000, valid_NMSE: -8.842e+00
--------------------------------------------------
[INFO]: Epoch 123 of 200
Training
[123,   100] loss: 4.586e-05
[123,   200] loss: 4.562e-05
Validation
[123,   100] loss: 6.937e-05
[123,   200] loss: 6.768e-05
Training loss: 0.000, train NMSE: -9.419e+00
Validation loss: 0.000, valid_NMSE: -8.707e+00
--------------------------------------------------
[INFO]: Epoch 124 of 200
Training
[124,   100] loss: 4.547e-05
[124,   200] loss: 4.554e-05
Validation
[124,   100] loss: 6.992e-05
[124,   200] loss: 6.813e-05
Training loss: 0.000, train NMSE: -9.825e+00
Validation loss: 0.000, valid_NMSE: -8.632e+00
--------------------------------------------------
[INFO]: Epoch 125 of 200
Training
[125,   100] loss: 4.565e-05
[125,   200] loss: 4.496e-05
Validation
[125,   100] loss: 6.786e-05
[125,   200] loss: 6.616e-05
Training loss: 0.000, train NMSE: -1.008e+01
Validation loss: 0.000, valid_NMSE: -8.878e+00
--------------------------------------------------
[INFO]: Epoch 126 of 200
Training
[126,   100] loss: 4.648e-05
[126,   200] loss: 4.406e-05
Validation
[126,   100] loss: 6.938e-05
[126,   200] loss: 6.760e-05
Training loss: 0.000, train NMSE: -9.800e+00
Validation loss: 0.000, valid_NMSE: -8.719e+00
--------------------------------------------------
[INFO]: Epoch 127 of 200
Training
[127,   100] loss: 4.560e-05
[127,   200] loss: 4.532e-05
Validation
[127,   100] loss: 7.215e-05
[127,   200] loss: 7.045e-05
Training loss: 0.000, train NMSE: -1.013e+01
Validation loss: 0.000, valid_NMSE: -8.360e+00
--------------------------------------------------
[INFO]: Epoch 128 of 200
Training
[128,   100] loss: 4.514e-05
[128,   200] loss: 4.520e-05
Validation
[128,   100] loss: 6.723e-05
[128,   200] loss: 6.555e-05
Training loss: 0.000, train NMSE: -1.019e+01
Validation loss: 0.000, valid_NMSE: -8.990e+00

Best validation loss: -8.990246772766113

Saving best model for epoch: 128

--------------------------------------------------
[INFO]: Epoch 129 of 200
Training
[129,   100] loss: 4.533e-05
[129,   200] loss: 4.607e-05
Validation
[129,   100] loss: 6.975e-05
[129,   200] loss: 6.798e-05
Training loss: 0.000, train NMSE: -9.439e+00
Validation loss: 0.000, valid_NMSE: -8.683e+00
--------------------------------------------------
[INFO]: Epoch 130 of 200
Training
[130,   100] loss: 4.524e-05
[130,   200] loss: 4.563e-05
Validation
[130,   100] loss: 6.905e-05
[130,   200] loss: 6.737e-05
Training loss: 0.000, train NMSE: -9.928e+00
Validation loss: 0.000, valid_NMSE: -8.744e+00
--------------------------------------------------
[INFO]: Epoch 131 of 200
Training
[131,   100] loss: 4.536e-05
[131,   200] loss: 4.516e-05
Validation
[131,   100] loss: 6.738e-05
[131,   200] loss: 6.569e-05
Training loss: 0.000, train NMSE: -9.198e+00
Validation loss: 0.000, valid_NMSE: -8.976e+00
--------------------------------------------------
[INFO]: Epoch 132 of 200
Training
[132,   100] loss: 4.565e-05
[132,   200] loss: 4.475e-05
Validation
[132,   100] loss: 7.051e-05
[132,   200] loss: 6.878e-05
Training loss: 0.000, train NMSE: -9.426e+00
Validation loss: 0.000, valid_NMSE: -8.580e+00
--------------------------------------------------
[INFO]: Epoch 133 of 200
Training
[133,   100] loss: 4.506e-05
[133,   200] loss: 4.476e-05
Validation
[133,   100] loss: 7.022e-05
[133,   200] loss: 6.852e-05
Training loss: 0.000, train NMSE: -9.599e+00
Validation loss: 0.000, valid_NMSE: -8.659e+00
--------------------------------------------------
[INFO]: Epoch 134 of 200
Training
[134,   100] loss: 4.508e-05
[134,   200] loss: 4.517e-05
Validation
[134,   100] loss: 7.004e-05
[134,   200] loss: 6.834e-05
Training loss: 0.000, train NMSE: -9.317e+00
Validation loss: 0.000, valid_NMSE: -8.634e+00
--------------------------------------------------
[INFO]: Epoch 135 of 200
Training
[135,   100] loss: 4.513e-05
[135,   200] loss: 4.536e-05
Validation
[135,   100] loss: 6.847e-05
[135,   200] loss: 6.681e-05
Training loss: 0.000, train NMSE: -9.566e+00
Validation loss: 0.000, valid_NMSE: -8.823e+00
--------------------------------------------------
[INFO]: Epoch 136 of 200
Training
[136,   100] loss: 4.475e-05
[136,   200] loss: 4.485e-05
Validation
[136,   100] loss: 7.037e-05
[136,   200] loss: 6.873e-05
Training loss: 0.000, train NMSE: -9.330e+00
Validation loss: 0.000, valid_NMSE: -8.568e+00
--------------------------------------------------
[INFO]: Epoch 137 of 200
Training
[137,   100] loss: 4.469e-05
[137,   200] loss: 4.532e-05
Validation
[137,   100] loss: 6.770e-05
[137,   200] loss: 6.597e-05
Training loss: 0.000, train NMSE: -9.859e+00
Validation loss: 0.000, valid_NMSE: -8.936e+00
--------------------------------------------------
[INFO]: Epoch 138 of 200
Training
[138,   100] loss: 4.528e-05
[138,   200] loss: 4.449e-05
Validation
[138,   100] loss: 6.761e-05
[138,   200] loss: 6.592e-05
Training loss: 0.000, train NMSE: -1.034e+01
Validation loss: 0.000, valid_NMSE: -8.882e+00
--------------------------------------------------
[INFO]: Epoch 139 of 200
Training
[139,   100] loss: 4.501e-05
[139,   200] loss: 4.472e-05
Validation
[139,   100] loss: 6.689e-05
[139,   200] loss: 6.519e-05
Training loss: 0.000, train NMSE: -9.866e+00
Validation loss: 0.000, valid_NMSE: -8.996e+00

Best validation loss: -8.995789527893066

Saving best model for epoch: 139

--------------------------------------------------
[INFO]: Epoch 140 of 200
Training
[140,   100] loss: 4.494e-05
[140,   200] loss: 4.489e-05
Validation
[140,   100] loss: 6.928e-05
[140,   200] loss: 6.758e-05
Training loss: 0.000, train NMSE: -9.315e+00
Validation loss: 0.000, valid_NMSE: -8.692e+00
--------------------------------------------------
[INFO]: Epoch 141 of 200
Training
[141,   100] loss: 4.445e-05
[141,   200] loss: 4.572e-05
Validation
[141,   100] loss: 6.922e-05
[141,   200] loss: 6.751e-05
Training loss: 0.000, train NMSE: -9.772e+00
Validation loss: 0.000, valid_NMSE: -8.785e+00
--------------------------------------------------
[INFO]: Epoch 142 of 200
Training
[142,   100] loss: 4.453e-05
[142,   200] loss: 4.499e-05
Validation
[142,   100] loss: 6.755e-05
[142,   200] loss: 6.584e-05
Training loss: 0.000, train NMSE: -9.366e+00
Validation loss: 0.000, valid_NMSE: -8.879e+00
--------------------------------------------------
[INFO]: Epoch 143 of 200
Training
[143,   100] loss: 4.547e-05
[143,   200] loss: 4.461e-05
Validation
[143,   100] loss: 7.354e-05
[143,   200] loss: 7.177e-05
Training loss: 0.000, train NMSE: -1.070e+01
Validation loss: 0.000, valid_NMSE: -8.404e+00
--------------------------------------------------
[INFO]: Epoch 144 of 200
Training
[144,   100] loss: 4.355e-05
[144,   200] loss: 4.584e-05
Validation
[144,   100] loss: 6.945e-05
[144,   200] loss: 6.781e-05
Training loss: 0.000, train NMSE: -1.011e+01
Validation loss: 0.000, valid_NMSE: -8.669e+00
--------------------------------------------------
[INFO]: Epoch 145 of 200
Training
[145,   100] loss: 4.438e-05
[145,   200] loss: 4.550e-05
Validation
[145,   100] loss: 6.701e-05
[145,   200] loss: 6.530e-05
Training loss: 0.000, train NMSE: -1.007e+01
Validation loss: 0.000, valid_NMSE: -9.005e+00

Best validation loss: -9.005393028259277

Saving best model for epoch: 145

--------------------------------------------------
[INFO]: Epoch 146 of 200
Training
[146,   100] loss: 4.484e-05
[146,   200] loss: 4.422e-05
Validation
[146,   100] loss: 6.872e-05
[146,   200] loss: 6.698e-05
Training loss: 0.000, train NMSE: -9.803e+00
Validation loss: 0.000, valid_NMSE: -8.737e+00
--------------------------------------------------
[INFO]: Epoch 147 of 200
Training
[147,   100] loss: 4.550e-05
[147,   200] loss: 4.396e-05
Validation
[147,   100] loss: 6.766e-05
[147,   200] loss: 6.596e-05
Training loss: 0.000, train NMSE: -9.321e+00
Validation loss: 0.000, valid_NMSE: -8.847e+00
--------------------------------------------------
[INFO]: Epoch 148 of 200
Training
[148,   100] loss: 4.455e-05
[148,   200] loss: 4.412e-05
Validation
[148,   100] loss: 6.772e-05
[148,   200] loss: 6.601e-05
Training loss: 0.000, train NMSE: -1.033e+01
Validation loss: 0.000, valid_NMSE: -8.890e+00
--------------------------------------------------
[INFO]: Epoch 149 of 200
Training
[149,   100] loss: 4.439e-05
[149,   200] loss: 4.516e-05
Validation
[149,   100] loss: 6.789e-05
[149,   200] loss: 6.614e-05
Training loss: 0.000, train NMSE: -9.479e+00
Validation loss: 0.000, valid_NMSE: -8.853e+00
--------------------------------------------------
[INFO]: Epoch 150 of 200
Training
[150,   100] loss: 4.399e-05
[150,   200] loss: 4.540e-05
Validation
[150,   100] loss: 6.809e-05
[150,   200] loss: 6.640e-05
Training loss: 0.000, train NMSE: -1.039e+01
Validation loss: 0.000, valid_NMSE: -8.832e+00
--------------------------------------------------
[INFO]: Epoch 151 of 200
Training
[151,   100] loss: 4.427e-05
[151,   200] loss: 4.475e-05
Validation
[151,   100] loss: 6.813e-05
[151,   200] loss: 6.649e-05
Training loss: 0.000, train NMSE: -9.895e+00
Validation loss: 0.000, valid_NMSE: -8.818e+00
--------------------------------------------------
[INFO]: Epoch 152 of 200
Training
[152,   100] loss: 4.476e-05
[152,   200] loss: 4.384e-05
Validation
[152,   100] loss: 6.874e-05
[152,   200] loss: 6.704e-05
Training loss: 0.000, train NMSE: -9.701e+00
Validation loss: 0.000, valid_NMSE: -8.699e+00
--------------------------------------------------
[INFO]: Epoch 153 of 200
Training
[153,   100] loss: 4.434e-05
[153,   200] loss: 4.479e-05
Validation
[153,   100] loss: 7.152e-05
[153,   200] loss: 6.984e-05
Training loss: 0.000, train NMSE: -9.623e+00
Validation loss: 0.000, valid_NMSE: -8.429e+00
--------------------------------------------------
[INFO]: Epoch 154 of 200
Training
[154,   100] loss: 4.411e-05
[154,   200] loss: 4.482e-05
Validation
[154,   100] loss: 6.721e-05
[154,   200] loss: 6.555e-05
Training loss: 0.000, train NMSE: -9.391e+00
Validation loss: 0.000, valid_NMSE: -8.929e+00
--------------------------------------------------
[INFO]: Epoch 155 of 200
Training
[155,   100] loss: 4.411e-05
[155,   200] loss: 4.456e-05
Validation
[155,   100] loss: 6.705e-05
[155,   200] loss: 6.533e-05
Training loss: 0.000, train NMSE: -9.511e+00
Validation loss: 0.000, valid_NMSE: -9.008e+00

Best validation loss: -9.008471488952637

Saving best model for epoch: 155

--------------------------------------------------
[INFO]: Epoch 156 of 200
Training
[156,   100] loss: 4.422e-05
[156,   200] loss: 4.432e-05
Validation
[156,   100] loss: 6.963e-05
[156,   200] loss: 6.785e-05
Training loss: 0.000, train NMSE: -9.578e+00
Validation loss: 0.000, valid_NMSE: -8.684e+00
--------------------------------------------------
[INFO]: Epoch 157 of 200
Training
[157,   100] loss: 4.432e-05
[157,   200] loss: 4.430e-05
Validation
[157,   100] loss: 6.852e-05
[157,   200] loss: 6.678e-05
Training loss: 0.000, train NMSE: -1.030e+01
Validation loss: 0.000, valid_NMSE: -8.770e+00
--------------------------------------------------
[INFO]: Epoch 158 of 200
Training
[158,   100] loss: 4.471e-05
[158,   200] loss: 4.356e-05
Validation
[158,   100] loss: 6.962e-05
[158,   200] loss: 6.789e-05
Training loss: 0.000, train NMSE: -9.493e+00
Validation loss: 0.000, valid_NMSE: -8.671e+00
--------------------------------------------------
[INFO]: Epoch 159 of 200
Training
[159,   100] loss: 4.426e-05
[159,   200] loss: 4.403e-05
Validation
[159,   100] loss: 6.929e-05
[159,   200] loss: 6.757e-05
Training loss: 0.000, train NMSE: -1.003e+01
Validation loss: 0.000, valid_NMSE: -8.745e+00
--------------------------------------------------
[INFO]: Epoch 160 of 200
Training
[160,   100] loss: 4.391e-05
[160,   200] loss: 4.456e-05
Validation
[160,   100] loss: 6.782e-05
[160,   200] loss: 6.615e-05
Training loss: 0.000, train NMSE: -1.040e+01
Validation loss: 0.000, valid_NMSE: -8.862e+00
--------------------------------------------------
[INFO]: Epoch 161 of 200
Training
[161,   100] loss: 4.455e-05
[161,   200] loss: 4.368e-05
Validation
[161,   100] loss: 6.644e-05
[161,   200] loss: 6.476e-05
Training loss: 0.000, train NMSE: -9.711e+00
Validation loss: 0.000, valid_NMSE: -9.049e+00

Best validation loss: -9.0491304397583

Saving best model for epoch: 161

--------------------------------------------------
[INFO]: Epoch 162 of 200
Training
[162,   100] loss: 4.426e-05
[162,   200] loss: 4.400e-05
Validation
[162,   100] loss: 6.802e-05
[162,   200] loss: 6.630e-05
Training loss: 0.000, train NMSE: -9.420e+00
Validation loss: 0.000, valid_NMSE: -8.854e+00
--------------------------------------------------
[INFO]: Epoch 163 of 200
Training
[163,   100] loss: 4.402e-05
[163,   200] loss: 4.465e-05
Validation
[163,   100] loss: 7.001e-05
[163,   200] loss: 6.828e-05
Training loss: 0.000, train NMSE: -9.897e+00
Validation loss: 0.000, valid_NMSE: -8.596e+00
--------------------------------------------------
[INFO]: Epoch 164 of 200
Training
[164,   100] loss: 4.349e-05
[164,   200] loss: 4.447e-05
Validation
[164,   100] loss: 6.988e-05
[164,   200] loss: 6.819e-05
Training loss: 0.000, train NMSE: -9.814e+00
Validation loss: 0.000, valid_NMSE: -8.631e+00
--------------------------------------------------
[INFO]: Epoch 165 of 200
Training
[165,   100] loss: 4.481e-05
[165,   200] loss: 4.346e-05
Validation
[165,   100] loss: 6.628e-05
[165,   200] loss: 6.463e-05
Training loss: 0.000, train NMSE: -9.191e+00
Validation loss: 0.000, valid_NMSE: -9.034e+00
--------------------------------------------------
[INFO]: Epoch 166 of 200
Training
[166,   100] loss: 4.381e-05
[166,   200] loss: 4.438e-05
Validation
[166,   100] loss: 6.729e-05
[166,   200] loss: 6.560e-05
Training loss: 0.000, train NMSE: -9.241e+00
Validation loss: 0.000, valid_NMSE: -8.917e+00
--------------------------------------------------
[INFO]: Epoch 167 of 200
Training
[167,   100] loss: 4.343e-05
[167,   200] loss: 4.436e-05
Validation
[167,   100] loss: 6.678e-05
[167,   200] loss: 6.507e-05
Training loss: 0.000, train NMSE: -9.775e+00
Validation loss: 0.000, valid_NMSE: -8.994e+00
--------------------------------------------------
[INFO]: Epoch 168 of 200
Training
[168,   100] loss: 4.390e-05
[168,   200] loss: 4.369e-05
Validation
[168,   100] loss: 6.833e-05
[168,   200] loss: 6.661e-05
Training loss: 0.000, train NMSE: -9.931e+00
Validation loss: 0.000, valid_NMSE: -8.858e+00
--------------------------------------------------
[INFO]: Epoch 169 of 200
Training
[169,   100] loss: 4.348e-05
[169,   200] loss: 4.378e-05
Validation
[169,   100] loss: 6.837e-05
[169,   200] loss: 6.669e-05
Training loss: 0.000, train NMSE: -9.883e+00
Validation loss: 0.000, valid_NMSE: -8.803e+00
--------------------------------------------------
[INFO]: Epoch 170 of 200
Training
[170,   100] loss: 4.382e-05
[170,   200] loss: 4.460e-05
Validation
[170,   100] loss: 6.677e-05
[170,   200] loss: 6.505e-05
Training loss: 0.000, train NMSE: -9.964e+00
Validation loss: 0.000, valid_NMSE: -8.972e+00
--------------------------------------------------
[INFO]: Epoch 171 of 200
Training
[171,   100] loss: 4.325e-05
[171,   200] loss: 4.377e-05
Validation
[171,   100] loss: 6.849e-05
[171,   200] loss: 6.682e-05
Training loss: 0.000, train NMSE: -1.012e+01
Validation loss: 0.000, valid_NMSE: -8.775e+00
--------------------------------------------------
[INFO]: Epoch 172 of 200
Training
[172,   100] loss: 4.374e-05
[172,   200] loss: 4.359e-05
Validation
[172,   100] loss: 6.761e-05
[172,   200] loss: 6.591e-05
Training loss: 0.000, train NMSE: -1.025e+01
Validation loss: 0.000, valid_NMSE: -8.872e+00
--------------------------------------------------
[INFO]: Epoch 173 of 200
Training
[173,   100] loss: 4.395e-05
[173,   200] loss: 4.323e-05
Validation
[173,   100] loss: 6.775e-05
[173,   200] loss: 6.607e-05
Training loss: 0.000, train NMSE: -9.174e+00
Validation loss: 0.000, valid_NMSE: -8.918e+00
--------------------------------------------------
[INFO]: Epoch 174 of 200
Training
[174,   100] loss: 4.312e-05
[174,   200] loss: 4.463e-05
Validation
[174,   100] loss: 6.788e-05
[174,   200] loss: 6.615e-05
Training loss: 0.000, train NMSE: -1.055e+01
Validation loss: 0.000, valid_NMSE: -8.908e+00
--------------------------------------------------
[INFO]: Epoch 175 of 200
Training
[175,   100] loss: 4.331e-05
[175,   200] loss: 4.378e-05
Validation
[175,   100] loss: 6.806e-05
[175,   200] loss: 6.638e-05
Training loss: 0.000, train NMSE: -9.691e+00
Validation loss: 0.000, valid_NMSE: -8.809e+00
--------------------------------------------------
[INFO]: Epoch 176 of 200
Training
[176,   100] loss: 4.353e-05
[176,   200] loss: 4.367e-05
Validation
[176,   100] loss: 6.973e-05
[176,   200] loss: 6.797e-05
Training loss: 0.000, train NMSE: -9.286e+00
Validation loss: 0.000, valid_NMSE: -8.709e+00
--------------------------------------------------
[INFO]: Epoch 177 of 200
Training
[177,   100] loss: 4.387e-05
[177,   200] loss: 4.377e-05
Validation
[177,   100] loss: 6.732e-05
[177,   200] loss: 6.558e-05
Training loss: 0.000, train NMSE: -1.023e+01
Validation loss: 0.000, valid_NMSE: -8.885e+00
--------------------------------------------------
[INFO]: Epoch 178 of 200
Training
[178,   100] loss: 4.365e-05
[178,   200] loss: 4.361e-05
Validation
[178,   100] loss: 6.718e-05
[178,   200] loss: 6.546e-05
Training loss: 0.000, train NMSE: -9.519e+00
Validation loss: 0.000, valid_NMSE: -8.926e+00
--------------------------------------------------
[INFO]: Epoch 179 of 200
Training
[179,   100] loss: 4.309e-05
[179,   200] loss: 4.403e-05
Validation
[179,   100] loss: 6.867e-05
[179,   200] loss: 6.696e-05
Training loss: 0.000, train NMSE: -1.029e+01
Validation loss: 0.000, valid_NMSE: -8.735e+00
--------------------------------------------------
[INFO]: Epoch 180 of 200
Training
[180,   100] loss: 4.341e-05
[180,   200] loss: 4.294e-05
Validation
[180,   100] loss: 6.762e-05
[180,   200] loss: 6.596e-05
Training loss: 0.000, train NMSE: -9.665e+00
Validation loss: 0.000, valid_NMSE: -8.910e+00
--------------------------------------------------
[INFO]: Epoch 181 of 200
Training
[181,   100] loss: 4.367e-05
[181,   200] loss: 4.354e-05
Validation
[181,   100] loss: 6.838e-05
[181,   200] loss: 6.670e-05/home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE
  warn(f"Failed to load image Python extension: {e}")

Training loss: 0.000, train NMSE: -9.414e+00
Validation loss: 0.000, valid_NMSE: -8.768e+00
--------------------------------------------------
[INFO]: Epoch 182 of 200
Training
[182,   100] loss: 4.311e-05
[182,   200] loss: 4.398e-05
Validation
[182,   100] loss: 6.766e-05
[182,   200] loss: 6.596e-05
Training loss: 0.000, train NMSE: -8.975e+00
Validation loss: 0.000, valid_NMSE: -8.945e+00
--------------------------------------------------
[INFO]: Epoch 183 of 200
Training
[183,   100] loss: 4.326e-05
[183,   200] loss: 4.361e-05
Validation
[183,   100] loss: 6.849e-05
[183,   200] loss: 6.677e-05
Training loss: 0.000, train NMSE: -1.003e+01
Validation loss: 0.000, valid_NMSE: -8.797e+00
--------------------------------------------------
[INFO]: Epoch 184 of 200
Training
[184,   100] loss: 4.305e-05
[184,   200] loss: 4.417e-05
Validation
[184,   100] loss: 6.795e-05
[184,   200] loss: 6.629e-05
Training loss: 0.000, train NMSE: -9.982e+00
Validation loss: 0.000, valid_NMSE: -8.869e+00
--------------------------------------------------
[INFO]: Epoch 185 of 200
Training
[185,   100] loss: 4.350e-05
[185,   200] loss: 4.264e-05
Validation
[185,   100] loss: 6.691e-05
[185,   200] loss: 6.522e-05
Training loss: 0.000, train NMSE: -9.949e+00
Validation loss: 0.000, valid_NMSE: -8.907e+00
--------------------------------------------------
[INFO]: Epoch 186 of 200
Training
[186,   100] loss: 4.304e-05
[186,   200] loss: 4.331e-05
Validation
[186,   100] loss: 6.856e-05
[186,   200] loss: 6.690e-05
Training loss: 0.000, train NMSE: -1.016e+01
Validation loss: 0.000, valid_NMSE: -8.731e+00
--------------------------------------------------
[INFO]: Epoch 187 of 200
Training
[187,   100] loss: 4.337e-05
[187,   200] loss: 4.413e-05
Validation
[187,   100] loss: 6.804e-05
[187,   200] loss: 6.635e-05
Training loss: 0.000, train NMSE: -9.794e+00
Validation loss: 0.000, valid_NMSE: -8.755e+00
--------------------------------------------------
[INFO]: Epoch 188 of 200
Training
[188,   100] loss: 4.361e-05
[188,   200] loss: 4.303e-05
Validation
[188,   100] loss: 7.168e-05
[188,   200] loss: 6.998e-05
Training loss: 0.000, train NMSE: -1.032e+01
Validation loss: 0.000, valid_NMSE: -8.428e+00
--------------------------------------------------
[INFO]: Epoch 189 of 200
Training
[189,   100] loss: 4.341e-05
[189,   200] loss: 4.317e-05
Validation
[189,   100] loss: 6.761e-05
[189,   200] loss: 6.592e-05
Training loss: 0.000, train NMSE: -9.831e+00
Validation loss: 0.000, valid_NMSE: -8.836e+00
--------------------------------------------------
[INFO]: Epoch 190 of 200
Training
[190,   100] loss: 4.345e-05
[190,   200] loss: 4.280e-05
Validation
[190,   100] loss: 6.861e-05
[190,   200] loss: 6.687e-05
Training loss: 0.000, train NMSE: -9.457e+00
Validation loss: 0.000, valid_NMSE: -8.794e+00
--------------------------------------------------
[INFO]: Epoch 191 of 200
Training
[191,   100] loss: 4.329e-05
[191,   200] loss: 4.303e-05
Validation
[191,   100] loss: 6.792e-05
[191,   200] loss: 6.616e-05
Training loss: 0.000, train NMSE: -9.836e+00
Validation loss: 0.000, valid_NMSE: -8.859e+00
--------------------------------------------------
[INFO]: Epoch 192 of 200
Training
[192,   100] loss: 4.268e-05
[192,   200] loss: 4.309e-05
Validation
[192,   100] loss: 6.822e-05
[192,   200] loss: 6.652e-05
Training loss: 0.000, train NMSE: -9.995e+00
Validation loss: 0.000, valid_NMSE: -8.835e+00
--------------------------------------------------
[INFO]: Epoch 193 of 200
Training
[193,   100] loss: 4.314e-05
[193,   200] loss: 4.305e-05
Validation
[193,   100] loss: 6.612e-05
[193,   200] loss: 6.448e-05
Training loss: 0.000, train NMSE: -9.894e+00
Validation loss: 0.000, valid_NMSE: -9.077e+00

Best validation loss: -9.076558113098145

Saving best model for epoch: 193

--------------------------------------------------
[INFO]: Epoch 194 of 200
Training
[194,   100] loss: 4.243e-05
[194,   200] loss: 4.341e-05
Validation
[194,   100] loss: 6.729e-05
[194,   200] loss: 6.556e-05
Training loss: 0.000, train NMSE: -1.064e+01
Validation loss: 0.000, valid_NMSE: -8.888e+00
--------------------------------------------------
[INFO]: Epoch 195 of 200
Training
[195,   100] loss: 4.299e-05
[195,   200] loss: 4.290e-05
Validation
[195,   100] loss: 6.969e-05
[195,   200] loss: 6.798e-05
Training loss: 0.000, train NMSE: -1.098e+01
Validation loss: 0.000, valid_NMSE: -8.611e+00
--------------------------------------------------
[INFO]: Epoch 196 of 200
Training
[196,   100] loss: 4.238e-05
[196,   200] loss: 4.326e-05
Validation
[196,   100] loss: 6.727e-05
[196,   200] loss: 6.550e-05
Training loss: 0.000, train NMSE: -9.465e+00
Validation loss: 0.000, valid_NMSE: -8.880e+00
--------------------------------------------------
[INFO]: Epoch 197 of 200
Training
[197,   100] loss: 4.272e-05
[197,   200] loss: 4.302e-05
Validation
[197,   100] loss: 6.873e-05
[197,   200] loss: 6.700e-05
Training loss: 0.000, train NMSE: -9.782e+00
Validation loss: 0.000, valid_NMSE: -8.776e+00
--------------------------------------------------
[INFO]: Epoch 198 of 200
Training
[198,   100] loss: 4.312e-05
[198,   200] loss: 4.282e-05
Validation
[198,   100] loss: 6.902e-05
[198,   200] loss: 6.729e-05
Training loss: 0.000, train NMSE: -1.043e+01
Validation loss: 0.000, valid_NMSE: -8.731e+00
--------------------------------------------------
[INFO]: Epoch 199 of 200
Training
[199,   100] loss: 4.287e-05
[199,   200] loss: 4.298e-05
Validation
[199,   100] loss: 6.964e-05
[199,   200] loss: 6.788e-05
Training loss: 0.000, train NMSE: -1.050e+01
Validation loss: 0.000, valid_NMSE: -8.685e+00
--------------------------------------------------
[INFO]: Epoch 200 of 200
Training
[200,   100] loss: 4.373e-05
[200,   200] loss: 4.195e-05
Validation
[200,   100] loss: 7.139e-05
[200,   200] loss: 6.962e-05
Training loss: 0.000, train NMSE: -1.042e+01
Validation loss: 0.000, valid_NMSE: -8.480e+00
--------------------------------------------------
Saving final model
TRAINING COMPLETE
