1.13.1+cu117
inEnergyID
Dadicated Mode inEnergyID
Dedicated Mode inEnergyID
trainset len 112000 valset len 48000
New_trainset len 40000 valset len 48000
1,087,257 training parameters.

1,087,257 training parameters.

[INFO]: Epoch 1 of 200
Training
[1,   100] loss: 2.127e-04
[1,   200] loss: 1.758e-04
Validation
[1,   100] loss: 1.497e-04
[1,   200] loss: 1.494e-04
Training loss: 0.000, train NMSE: -5.173e+00
Validation loss: 0.000, valid_NMSE: -5.323e+00

Best validation loss: -5.323346138000488

Saving best model for epoch: 1

--------------------------------------------------
[INFO]: Epoch 2 of 200
Training
[2,   100] loss: 1.570e-04
[2,   200] loss: 1.445e-04
Validation
[2,   100] loss: 1.237e-04
[2,   200] loss: 1.231e-04
Training loss: 0.000, train NMSE: -6.254e+00
Validation loss: 0.000, valid_NMSE: -6.238e+00

Best validation loss: -6.238425254821777

Saving best model for epoch: 2

--------------------------------------------------
[INFO]: Epoch 3 of 200
Training
[3,   100] loss: 1.331e-04
[3,   200] loss: 1.261e-04
Validation
[3,   100] loss: 1.121e-04
[3,   200] loss: 1.112e-04
Training loss: 0.000, train NMSE: -6.094e+00
Validation loss: 0.000, valid_NMSE: -6.661e+00

Best validation loss: -6.660655975341797

Saving best model for epoch: 3

--------------------------------------------------
[INFO]: Epoch 4 of 200
Training
[4,   100] loss: 1.167e-04
[4,   200] loss: 1.099e-04
Validation
[4,   100] loss: 9.322e-05
[4,   200] loss: 9.279e-05
Training loss: 0.000, train NMSE: -6.384e+00
Validation loss: 0.000, valid_NMSE: -7.531e+00

Best validation loss: -7.530599594116211

Saving best model for epoch: 4

--------------------------------------------------
[INFO]: Epoch 5 of 200
Training
[5,   100] loss: 9.821e-05
[5,   200] loss: 9.138e-05
Validation
[5,   100] loss: 8.268e-05
[5,   200] loss: 8.242e-05
Training loss: 0.000, train NMSE: -7.985e+00
Validation loss: 0.000, valid_NMSE: -8.153e+00

Best validation loss: -8.153361320495605

Saving best model for epoch: 5

--------------------------------------------------
[INFO]: Epoch 6 of 200
Training
[6,   100] loss: 8.884e-05
[6,   200] loss: 8.479e-05
Validation
[6,   100] loss: 7.740e-05
[6,   200] loss: 7.701e-05
Training loss: 0.000, train NMSE: -8.234e+00
Validation loss: 0.000, valid_NMSE: -8.512e+00

Best validation loss: -8.511702537536621

Saving best model for epoch: 6

--------------------------------------------------
[INFO]: Epoch 7 of 200
Training
[7,   100] loss: 8.324e-05
[7,   200] loss: 8.054e-05
Validation
[7,   100] loss: 7.388e-05
[7,   200] loss: 7.332e-05
Training loss: 0.000, train NMSE: -8.205e+00
Validation loss: 0.000, valid_NMSE: -8.698e+00

Best validation loss: -8.697550773620605

Saving best model for epoch: 7

--------------------------------------------------
[INFO]: Epoch 8 of 200
Training
[8,   100] loss: 7.752e-05
[8,   200] loss: 7.740e-05
Validation
[8,   100] loss: 6.982e-05
[8,   200] loss: 6.929e-05
Training loss: 0.000, train NMSE: -8.317e+00
Validation loss: 0.000, valid_NMSE: -8.992e+00

Best validation loss: -8.991601943969727

Saving best model for epoch: 8

--------------------------------------------------
[INFO]: Epoch 9 of 200
Training
[9,   100] loss: 7.449e-05
[9,   200] loss: 7.179e-05
Validation
[9,   100] loss: 6.639e-05
[9,   200] loss: 6.588e-05
Training loss: 0.000, train NMSE: -9.099e+00
Validation loss: 0.000, valid_NMSE: -9.221e+00

Best validation loss: -9.221466064453125

Saving best model for epoch: 9

--------------------------------------------------
[INFO]: Epoch 10 of 200
Training
[10,   100] loss: 6.989e-05
[10,   200] loss: 6.853e-05
Validation
[10,   100] loss: 6.297e-05
[10,   200] loss: 6.243e-05
Training loss: 0.000, train NMSE: -8.959e+00
Validation loss: 0.000, valid_NMSE: -9.453e+00

Best validation loss: -9.452938079833984

Saving best model for epoch: 10

--------------------------------------------------
[INFO]: Epoch 11 of 200
Training
[11,   100] loss: 6.793e-05
[11,   200] loss: 6.360e-05
Validation
[11,   100] loss: 6.025e-05
[11,   200] loss: 5.974e-05
Training loss: 0.000, train NMSE: -9.360e+00
Validation loss: 0.000, valid_NMSE: -9.652e+00

Best validation loss: -9.651881217956543

Saving best model for epoch: 11

--------------------------------------------------
[INFO]: Epoch 12 of 200
Training
[12,   100] loss: 6.331e-05
[12,   200] loss: 6.295e-05
Validation
[12,   100] loss: 5.825e-05
[12,   200] loss: 5.784e-05
Training loss: 0.000, train NMSE: -9.515e+00
Validation loss: 0.000, valid_NMSE: -9.746e+00

Best validation loss: -9.74596118927002

Saving best model for epoch: 12

--------------------------------------------------
[INFO]: Epoch 13 of 200
Training
[13,   100] loss: 6.096e-05
[13,   200] loss: 6.065e-05
Validation
[13,   100] loss: 5.614e-05
[13,   200] loss: 5.567e-05
Training loss: 0.000, train NMSE: -9.677e+00
Validation loss: 0.000, valid_NMSE: -9.917e+00

Best validation loss: -9.917183876037598

Saving best model for epoch: 13

--------------------------------------------------
[INFO]: Epoch 14 of 200
Training
[14,   100] loss: 5.897e-05
[14,   200] loss: 5.890e-05
Validation
[14,   100] loss: 5.471e-05
[14,   200] loss: 5.426e-05
Training loss: 0.000, train NMSE: -9.622e+00
Validation loss: 0.000, valid_NMSE: -1.002e+01

Best validation loss: -10.017918586730957

Saving best model for epoch: 14

--------------------------------------------------
[INFO]: Epoch 15 of 200
Training
[15,   100] loss: 5.772e-05
[15,   200] loss: 5.692e-05
Validation
[15,   100] loss: 5.324e-05
[15,   200] loss: 5.275e-05
Training loss: 0.000, train NMSE: -9.822e+00
Validation loss: 0.000, valid_NMSE: -1.014e+01

Best validation loss: -10.13641357421875

Saving best model for epoch: 15

--------------------------------------------------
[INFO]: Epoch 16 of 200
Training
[16,   100] loss: 5.595e-05
[16,   200] loss: 5.610e-05
Validation
[16,   100] loss: 5.223e-05
[16,   200] loss: 5.172e-05
Training loss: 0.000, train NMSE: -9.696e+00
Validation loss: 0.000, valid_NMSE: -1.021e+01

Best validation loss: -10.212054252624512

Saving best model for epoch: 16

--------------------------------------------------
[INFO]: Epoch 17 of 200
Training
[17,   100] loss: 5.502e-05
[17,   200] loss: 5.424e-05
Validation
[17,   100] loss: 5.146e-05
[17,   200] loss: 5.096e-05
Training loss: 0.000, train NMSE: -1.016e+01
Validation loss: 0.000, valid_NMSE: -1.027e+01

Best validation loss: -10.27442741394043

Saving best model for epoch: 17

--------------------------------------------------
[INFO]: Epoch 18 of 200
Training
[18,   100] loss: 5.322e-05
[18,   200] loss: 5.393e-05
Validation
[18,   100] loss: 5.071e-05
[18,   200] loss: 5.022e-05
Training loss: 0.000, train NMSE: -9.346e+00
Validation loss: 0.000, valid_NMSE: -1.032e+01

Best validation loss: -10.319327354431152

Saving best model for epoch: 18

--------------------------------------------------
[INFO]: Epoch 19 of 200
Training
[19,   100] loss: 5.280e-05
[19,   200] loss: 5.225e-05
Validation
[19,   100] loss: 4.992e-05
[19,   200] loss: 4.944e-05
Training loss: 0.000, train NMSE: -1.035e+01
Validation loss: 0.000, valid_NMSE: -1.042e+01

Best validation loss: -10.424179077148438

Saving best model for epoch: 19

--------------------------------------------------
[INFO]: Epoch 20 of 200
Training
[20,   100] loss: 5.205e-05
[20,   200] loss: 5.114e-05
Validation
[20,   100] loss: 4.913e-05
[20,   200] loss: 4.870e-05
Training loss: 0.000, train NMSE: -1.015e+01
Validation loss: 0.000, valid_NMSE: -1.048e+01

Best validation loss: -10.477884292602539

Saving best model for epoch: 20

--------------------------------------------------
[INFO]: Epoch 21 of 200
Training
[21,   100] loss: 5.093e-05
[21,   200] loss: 5.048e-05
Validation
[21,   100] loss: 4.809e-05
[21,   200] loss: 4.759e-05
Training loss: 0.000, train NMSE: -1.005e+01
Validation loss: 0.000, valid_NMSE: -1.057e+01

Best validation loss: -10.574421882629395

Saving best model for epoch: 21

--------------------------------------------------
[INFO]: Epoch 22 of 200
Training
[22,   100] loss: 4.975e-05
[22,   200] loss: 5.002e-05
Validation
[22,   100] loss: 4.860e-05
[22,   200] loss: 4.813e-05
Training loss: 0.000, train NMSE: -1.052e+01
Validation loss: 0.000, valid_NMSE: -1.049e+01
--------------------------------------------------
[INFO]: Epoch 23 of 200
Training
[23,   100] loss: 4.932e-05
[23,   200] loss: 4.889e-05
Validation
[23,   100] loss: 4.715e-05
[23,   200] loss: 4.668e-05
Training loss: 0.000, train NMSE: -9.811e+00
Validation loss: 0.000, valid_NMSE: -1.062e+01

Best validation loss: -10.620208740234375

Saving best model for epoch: 23

--------------------------------------------------
[INFO]: Epoch 24 of 200
Training
[24,   100] loss: 4.841e-05
[24,   200] loss: 4.829e-05
Validation
[24,   100] loss: 4.623e-05
[24,   200] loss: 4.583e-05
Training loss: 0.000, train NMSE: -1.006e+01
Validation loss: 0.000, valid_NMSE: -1.077e+01

Best validation loss: -10.76769733428955

Saving best model for epoch: 24

--------------------------------------------------
[INFO]: Epoch 25 of 200
Training
[25,   100] loss: 4.763e-05
[25,   200] loss: 4.761e-05
Validation
[25,   100] loss: 4.612e-05
[25,   200] loss: 4.577e-05
Training loss: 0.000, train NMSE: -1.085e+01
Validation loss: 0.000, valid_NMSE: -1.077e+01

Best validation loss: -10.772700309753418

Saving best model for epoch: 25

--------------------------------------------------
[INFO]: Epoch 26 of 200
Training
[26,   100] loss: 4.695e-05
[26,   200] loss: 4.701e-05
Validation
[26,   100] loss: 4.523e-05
[26,   200] loss: 4.483e-05
Training loss: 0.000, train NMSE: -1.018e+01
Validation loss: 0.000, valid_NMSE: -1.085e+01

Best validation loss: -10.848237991333008

Saving best model for epoch: 26

--------------------------------------------------
[INFO]: Epoch 27 of 200
Training
[27,   100] loss: 4.624e-05
[27,   200] loss: 4.620e-05
Validation
[27,   100] loss: 4.491e-05
[27,   200] loss: 4.451e-05
Training loss: 0.000, train NMSE: -1.093e+01
Validation loss: 0.000, valid_NMSE: -1.083e+01
--------------------------------------------------
[INFO]: Epoch 28 of 200
Training
[28,   100] loss: 4.527e-05
[28,   200] loss: 4.596e-05
Validation
[28,   100] loss: 4.427e-05
[28,   200] loss: 4.391e-05
Training loss: 0.000, train NMSE: -1.015e+01
Validation loss: 0.000, valid_NMSE: -1.089e+01

Best validation loss: -10.889121055603027

Saving best model for epoch: 28

--------------------------------------------------
[INFO]: Epoch 29 of 200
Training
[29,   100] loss: 4.461e-05
[29,   200] loss: 4.526e-05
Validation
[29,   100] loss: 4.391e-05
[29,   200] loss: 4.365e-05
Training loss: 0.000, train NMSE: -1.107e+01
Validation loss: 0.000, valid_NMSE: -1.094e+01

Best validation loss: -10.940805435180664

Saving best model for epoch: 29

--------------------------------------------------
[INFO]: Epoch 30 of 200
Training
[30,   100] loss: 4.439e-05
[30,   200] loss: 4.440e-05
Validation
[30,   100] loss: 4.315e-05
[30,   200] loss: 4.280e-05
Training loss: 0.000, train NMSE: -1.097e+01
Validation loss: 0.000, valid_NMSE: -1.107e+01

Best validation loss: -11.071043968200684

Saving best model for epoch: 30

--------------------------------------------------
[INFO]: Epoch 31 of 200
Training
[31,   100] loss: 4.344e-05
[31,   200] loss: 4.402e-05
Validation
[31,   100] loss: 4.273e-05
[31,   200] loss: 4.237e-05
Training loss: 0.000, train NMSE: -1.155e+01
Validation loss: 0.000, valid_NMSE: -1.105e+01
--------------------------------------------------
[INFO]: Epoch 32 of 200
Training
[32,   100] loss: 4.285e-05
[32,   200] loss: 4.345e-05
Validation
[32,   100] loss: 4.227e-05
[32,   200] loss: 4.196e-05
Training loss: 0.000, train NMSE: -1.069e+01
Validation loss: 0.000, valid_NMSE: -1.107e+01
--------------------------------------------------
[INFO]: Epoch 33 of 200
Training
[33,   100] loss: 4.168e-05
[33,   200] loss: 4.337e-05
Validation
[33,   100] loss: 4.179e-05
[33,   200] loss: 4.153e-05
Training loss: 0.000, train NMSE: -1.130e+01
Validation loss: 0.000, valid_NMSE: -1.110e+01

Best validation loss: -11.095273971557617

Saving best model for epoch: 33

--------------------------------------------------
[INFO]: Epoch 34 of 200
Training
[34,   100] loss: 4.200e-05
[34,   200] loss: 4.192e-05
Validation
[34,   100] loss: 4.136e-05
[34,   200] loss: 4.107e-05
Training loss: 0.000, train NMSE: -1.115e+01
Validation loss: 0.000, valid_NMSE: -1.116e+01

Best validation loss: -11.15721321105957

Saving best model for epoch: 34

--------------------------------------------------
[INFO]: Epoch 35 of 200
Training
[35,   100] loss: 4.181e-05
[35,   200] loss: 4.124e-05
Validation
[35,   100] loss: 4.105e-05
[35,   200] loss: 4.076e-05
Training loss: 0.000, train NMSE: -1.081e+01
Validation loss: 0.000, valid_NMSE: -1.110e+01
--------------------------------------------------
[INFO]: Epoch 36 of 200
Training
[36,   100] loss: 4.052e-05
[36,   200] loss: 4.172e-05
Validation
[36,   100] loss: 4.111e-05
[36,   200] loss: 4.078e-05
Training loss: 0.000, train NMSE: -1.131e+01
Validation loss: 0.000, valid_NMSE: -1.112e+01
--------------------------------------------------
[INFO]: Epoch 37 of 200
Training
[37,   100] loss: 4.044e-05
[37,   200] loss: 4.057e-05
Validation
[37,   100] loss: 4.061e-05
[37,   200] loss: 4.038e-05
Training loss: 0.000, train NMSE: -1.120e+01
Validation loss: 0.000, valid_NMSE: -1.122e+01

Best validation loss: -11.21755599975586

Saving best model for epoch: 37

--------------------------------------------------
[INFO]: Epoch 38 of 200
Training
[38,   100] loss: 3.992e-05
[38,   200] loss: 4.008e-05
Validation
[38,   100] loss: 4.004e-05
[38,   200] loss: 3.970e-05
Training loss: 0.000, train NMSE: -1.171e+01
Validation loss: 0.000, valid_NMSE: -1.122e+01

Best validation loss: -11.219039916992188

Saving best model for epoch: 38

--------------------------------------------------
[INFO]: Epoch 39 of 200
Training
[39,   100] loss: 3.951e-05
[39,   200] loss: 3.999e-05
Validation
[39,   100] loss: 3.924e-05
[39,   200] loss: 3.898e-05
Training loss: 0.000, train NMSE: -1.136e+01
Validation loss: 0.000, valid_NMSE: -1.137e+01

Best validation loss: -11.365470886230469

Saving best model for epoch: 39

--------------------------------------------------
[INFO]: Epoch 40 of 200
Training
[40,   100] loss: 3.911e-05
[40,   200] loss: 3.918e-05
Validation
[40,   100] loss: 3.897e-05
[40,   200] loss: 3.876e-05
Training loss: 0.000, train NMSE: -1.156e+01
Validation loss: 0.000, valid_NMSE: -1.134e+01
--------------------------------------------------
[INFO]: Epoch 41 of 200
Training
[41,   100] loss: 3.856e-05
[41,   200] loss: 3.898e-05
Validation
[41,   100] loss: 3.885e-05
[41,   200] loss: 3.865e-05
Training loss: 0.000, train NMSE: -1.083e+01
Validation loss: 0.000, valid_NMSE: -1.132e+01
--------------------------------------------------
[INFO]: Epoch 42 of 200
Training
[42,   100] loss: 3.799e-05
[42,   200] loss: 3.880e-05
Validation
[42,   100] loss: 3.836e-05
[42,   200] loss: 3.813e-05
Training loss: 0.000, train NMSE: -1.091e+01
Validation loss: 0.000, valid_NMSE: -1.144e+01

Best validation loss: -11.440414428710938

Saving best model for epoch: 42

--------------------------------------------------
[INFO]: Epoch 43 of 200
Training
[43,   100] loss: 3.798e-05
[43,   200] loss: 3.823e-05
Validation
[43,   100] loss: 3.829e-05
[43,   200] loss: 3.806e-05
Training loss: 0.000, train NMSE: -1.141e+01
Validation loss: 0.000, valid_NMSE: -1.147e+01

Best validation loss: -11.472570419311523

Saving best model for epoch: 43

--------------------------------------------------
[INFO]: Epoch 44 of 200
Training
[44,   100] loss: 3.755e-05
[44,   200] loss: 3.793e-05
Validation
[44,   100] loss: 3.771e-05
[44,   200] loss: 3.751e-05
Training loss: 0.000, train NMSE: -1.142e+01
Validation loss: 0.000, valid_NMSE: -1.149e+01

Best validation loss: -11.48947525024414

Saving best model for epoch: 44

--------------------------------------------------
[INFO]: Epoch 45 of 200
Training
[45,   100] loss: 3.711e-05
[45,   200] loss: 3.766e-05
Validation
[45,   100] loss: 3.786e-05
[45,   200] loss: 3.775e-05
Training loss: 0.000, train NMSE: -1.163e+01
Validation loss: 0.000, valid_NMSE: -1.148e+01
--------------------------------------------------
[INFO]: Epoch 46 of 200
Training
[46,   100] loss: 3.717e-05
[46,   200] loss: 3.698e-05
Validation
[46,   100] loss: 3.745e-05
[46,   200] loss: 3.728e-05
Training loss: 0.000, train NMSE: -1.216e+01
Validation loss: 0.000, valid_NMSE: -1.151e+01

Best validation loss: -11.507184982299805

Saving best model for epoch: 46

--------------------------------------------------
[INFO]: Epoch 47 of 200
Training
[47,   100] loss: 3.636e-05
[47,   200] loss: 3.722e-05
Validation
[47,   100] loss: 3.722e-05
[47,   200] loss: 3.710e-05
Training loss: 0.000, train NMSE: -1.124e+01
Validation loss: 0.000, valid_NMSE: -1.151e+01

Best validation loss: -11.509590148925781

Saving best model for epoch: 47

--------------------------------------------------
[INFO]: Epoch 48 of 200
Training
[48,   100] loss: 3.637e-05
[48,   200] loss: 3.672e-05
Validation
[48,   100] loss: 3.700e-05
[48,   200] loss: 3.694e-05
Training loss: 0.000, train NMSE: -1.169e+01
Validation loss: 0.000, valid_NMSE: -1.150e+01
--------------------------------------------------
[INFO]: Epoch 49 of 200
Training
[49,   100] loss: 3.618e-05
[49,   200] loss: 3.621e-05
Validation
[49,   100] loss: 3.671e-05
[49,   200] loss: 3.655e-05
Training loss: 0.000, train NMSE: -1.122e+01
Validation loss: 0.000, valid_NMSE: -1.153e+01

Best validation loss: -11.530786514282227

Saving best model for epoch: 49

--------------------------------------------------
[INFO]: Epoch 50 of 200
Training
[50,   100] loss: 3.603e-05
[50,   200] loss: 3.568e-05
Validation
[50,   100] loss: 3.646e-05
[50,   200] loss: 3.640e-05
Training loss: 0.000, train NMSE: -1.216e+01
Validation loss: 0.000, valid_NMSE: -1.161e+01

Best validation loss: -11.609012603759766

Saving best model for epoch: 50

--------------------------------------------------
[INFO]: Epoch 51 of 200
Training
[51,   100] loss: 3.567e-05
[51,   200] loss: 3.561e-05
Validation
[51,   100] loss: 3.631e-05
[51,   200] loss: 3.623e-05
Training loss: 0.000, train NMSE: -1.193e+01
Validation loss: 0.000, valid_NMSE: -1.162e+01

Best validation loss: -11.61928939819336

Saving best model for epoch: 51

--------------------------------------------------
[INFO]: Epoch 52 of 200
Training
[52,   100] loss: 3.474e-05
[52,   200] loss: 3.597e-05
Validation
[52,   100] loss: 3.590e-05
[52,   200] loss: 3.579e-05
Training loss: 0.000, train NMSE: -1.172e+01
Validation loss: 0.000, valid_NMSE: -1.167e+01

Best validation loss: -11.672050476074219

Saving best model for epoch: 52

--------------------------------------------------
[INFO]: Epoch 53 of 200
Training
[53,   100] loss: 3.512e-05
[53,   200] loss: 3.511e-05
Validation
[53,   100] loss: 3.608e-05
[53,   200] loss: 3.599e-05
Training loss: 0.000, train NMSE: -1.127e+01
Validation loss: 0.000, valid_NMSE: -1.163e+01
--------------------------------------------------
[INFO]: Epoch 54 of 200
Training
[54,   100] loss: 3.428e-05
[54,   200] loss: 3.537e-05
Validation
[54,   100] loss: 3.625e-05
[54,   200] loss: 3.613e-05
Training loss: 0.000, train NMSE: -1.187e+01
Validation loss: 0.000, valid_NMSE: -1.156e+01
--------------------------------------------------
[INFO]: Epoch 55 of 200
Training
[55,   100] loss: 3.445e-05
[55,   200] loss: 3.479e-05
Validation
[55,   100] loss: 3.583e-05
[55,   200] loss: 3.579e-05
Training loss: 0.000, train NMSE: -1.178e+01
Validation loss: 0.000, valid_NMSE: -1.167e+01
--------------------------------------------------
[INFO]: Epoch 56 of 200
Training
[56,   100] loss: 3.436e-05
[56,   200] loss: 3.442e-05
Validation
[56,   100] loss: 3.543e-05
[56,   200] loss: 3.539e-05
Training loss: 0.000, train NMSE: -1.176e+01
Validation loss: 0.000, valid_NMSE: -1.168e+01

Best validation loss: -11.68270492553711

Saving best model for epoch: 56

--------------------------------------------------
[INFO]: Epoch 57 of 200
Training
[57,   100] loss: 3.418e-05
[57,   200] loss: 3.417e-05
Validation
[57,   100] loss: 3.545e-05
[57,   200] loss: 3.541e-05
Training loss: 0.000, train NMSE: -1.169e+01
Validation loss: 0.000, valid_NMSE: -1.166e+01
--------------------------------------------------
[INFO]: Epoch 58 of 200
Training
[58,   100] loss: 3.415e-05
[58,   200] loss: 3.375e-05
Validation
[58,   100] loss: 3.502e-05
[58,   200] loss: 3.502e-05
Training loss: 0.000, train NMSE: -1.185e+01
Validation loss: 0.000, valid_NMSE: -1.172e+01

Best validation loss: -11.724225044250488

Saving best model for epoch: 58

--------------------------------------------------
[INFO]: Epoch 59 of 200
Training
[59,   100] loss: 3.407e-05
[59,   200] loss: 3.363e-05
Validation
[59,   100] loss: 3.538e-05
[59,   200] loss: 3.538e-05
Training loss: 0.000, train NMSE: -1.204e+01
Validation loss: 0.000, valid_NMSE: -1.173e+01

Best validation loss: -11.734504699707031

Saving best model for epoch: 59

--------------------------------------------------
[INFO]: Epoch 60 of 200
Training
[60,   100] loss: 3.368e-05
[60,   200] loss: 3.355e-05
Validation
[60,   100] loss: 3.476e-05
[60,   200] loss: 3.471e-05
Training loss: 0.000, train NMSE: -1.199e+01
Validation loss: 0.000, valid_NMSE: -1.178e+01

Best validation loss: -11.776610374450684

Saving best model for epoch: 60

--------------------------------------------------
[INFO]: Epoch 61 of 200
Training
[61,   100] loss: 3.297e-05
[61,   200] loss: 3.369e-05
Validation
[61,   100] loss: 3.481e-05
[61,   200] loss: 3.483e-05
Training loss: 0.000, train NMSE: -1.257e+01
Validation loss: 0.000, valid_NMSE: -1.181e+01

Best validation loss: -11.805929183959961

Saving best model for epoch: 61

--------------------------------------------------
[INFO]: Epoch 62 of 200
Training
[62,   100] loss: 3.326e-05
[62,   200] loss: 3.299e-05
Validation
[62,   100] loss: 3.445e-05
[62,   200] loss: 3.444e-05
Training loss: 0.000, train NMSE: -1.182e+01
Validation loss: 0.000, valid_NMSE: -1.177e+01
--------------------------------------------------
[INFO]: Epoch 63 of 200
Training
[63,   100] loss: 3.333e-05
[63,   200] loss: 3.262e-05
Validation
[63,   100] loss: 3.457e-05
[63,   200] loss: 3.457e-05
Training loss: 0.000, train NMSE: -1.226e+01
Validation loss: 0.000, valid_NMSE: -1.178e+01
--------------------------------------------------
[INFO]: Epoch 64 of 200
Training
[64,   100] loss: 3.270e-05
[64,   200] loss: 3.295e-05
Validation
[64,   100] loss: 3.424e-05
[64,   200] loss: 3.425e-05
Training loss: 0.000, train NMSE: -1.205e+01
Validation loss: 0.000, valid_NMSE: -1.184e+01

Best validation loss: -11.844718933105469

Saving best model for epoch: 64

--------------------------------------------------
[INFO]: Epoch 65 of 200
Training
[65,   100] loss: 3.202e-05
[65,   200] loss: 3.318e-05
Validation
[65,   100] loss: 3.397e-05
[65,   200] loss: 3.405e-05
Training loss: 0.000, train NMSE: -1.195e+01
Validation loss: 0.000, valid_NMSE: -1.189e+01

Best validation loss: -11.88904857635498

Saving best model for epoch: 65

--------------------------------------------------
[INFO]: Epoch 66 of 200
Training
[66,   100] loss: 3.223e-05
[66,   200] loss: 3.265e-05
Validation
[66,   100] loss: 3.381e-05
[66,   200] loss: 3.383e-05
Training loss: 0.000, train NMSE: -1.170e+01
Validation loss: 0.000, valid_NMSE: -1.189e+01

Best validation loss: -11.894083023071289

Saving best model for epoch: 66

--------------------------------------------------
[INFO]: Epoch 67 of 200
Training
[67,   100] loss: 3.245e-05
[67,   200] loss: 3.203e-05
Validation
[67,   100] loss: 3.382e-05
[67,   200] loss: 3.383e-05
Training loss: 0.000, train NMSE: -1.232e+01
Validation loss: 0.000, valid_NMSE: -1.190e+01

Best validation loss: -11.89695930480957

Saving best model for epoch: 67

--------------------------------------------------
[INFO]: Epoch 68 of 200
Training
[68,   100] loss: 3.206e-05
[68,   200] loss: 3.209e-05
Validation
[68,   100] loss: 3.368e-05
[68,   200] loss: 3.372e-05
Training loss: 0.000, train NMSE: -1.129e+01
Validation loss: 0.000, valid_NMSE: -1.191e+01

Best validation loss: -11.908465385437012

Saving best model for epoch: 68

--------------------------------------------------
[INFO]: Epoch 69 of 200
Training
[69,   100] loss: 3.217e-05
[69,   200] loss: 3.163e-05
Validation
[69,   100] loss: 3.378e-05
[69,   200] loss: 3.384e-05
Training loss: 0.000, train NMSE: -1.232e+01
Validation loss: 0.000, valid_NMSE: -1.187e+01
--------------------------------------------------
[INFO]: Epoch 70 of 200
Training
[70,   100] loss: 3.143e-05
[70,   200] loss: 3.195e-05
Validation
[70,   100] loss: 3.377e-05
[70,   200] loss: 3.377e-05
Training loss: 0.000, train NMSE: -1.242e+01
Validation loss: 0.000, valid_NMSE: -1.188e+01
--------------------------------------------------
[INFO]: Epoch 71 of 200
Training
[71,   100] loss: 3.117e-05
[71,   200] loss: 3.190e-05
Validation
[71,   100] loss: 3.345e-05
[71,   200] loss: 3.352e-05
Training loss: 0.000, train NMSE: -1.249e+01
Validation loss: 0.000, valid_NMSE: -1.191e+01

Best validation loss: -11.913507461547852

Saving best model for epoch: 71

--------------------------------------------------
[INFO]: Epoch 72 of 200
Training
[72,   100] loss: 3.114e-05
[72,   200] loss: 3.164e-05
Validation
[72,   100] loss: 3.332e-05
[72,   200] loss: 3.333e-05
Training loss: 0.000, train NMSE: -1.213e+01
Validation loss: 0.000, valid_NMSE: -1.193e+01

Best validation loss: -11.934764862060547

Saving best model for epoch: 72

--------------------------------------------------
[INFO]: Epoch 73 of 200
Training
[73,   100] loss: 3.149e-05
[73,   200] loss: 3.096e-05
Validation
[73,   100] loss: 3.319e-05
[73,   200] loss: 3.330e-05
Training loss: 0.000, train NMSE: -1.202e+01
Validation loss: 0.000, valid_NMSE: -1.195e+01

Best validation loss: -11.950167655944824

Saving best model for epoch: 73

--------------------------------------------------
[INFO]: Epoch 74 of 200
Training
[74,   100] loss: 3.105e-05
[74,   200] loss: 3.118e-05
Validation
[74,   100] loss: 3.327e-05
[74,   200] loss: 3.336e-05
Training loss: 0.000, train NMSE: -1.264e+01
Validation loss: 0.000, valid_NMSE: -1.192e+01
--------------------------------------------------
[INFO]: Epoch 75 of 200
Training
[75,   100] loss: 3.115e-05
[75,   200] loss: 3.083e-05
Validation
[75,   100] loss: 3.316e-05
[75,   200] loss: 3.325e-05
Training loss: 0.000, train NMSE: -1.230e+01
Validation loss: 0.000, valid_NMSE: -1.198e+01

Best validation loss: -11.984617233276367

Saving best model for epoch: 75

--------------------------------------------------
[INFO]: Epoch 76 of 200
Training
[76,   100] loss: 3.113e-05
[76,   200] loss: 3.067e-05
Validation
[76,   100] loss: 3.288e-05
[76,   200] loss: 3.297e-05
Training loss: 0.000, train NMSE: -1.268e+01
Validation loss: 0.000, valid_NMSE: -1.198e+01
--------------------------------------------------
[INFO]: Epoch 77 of 200
Training
[77,   100] loss: 3.073e-05
[77,   200] loss: 3.055e-05
Validation
[77,   100] loss: 3.291e-05
[77,   200] loss: 3.299e-05
Training loss: 0.000, train NMSE: -1.168e+01
Validation loss: 0.000, valid_NMSE: -1.199e+01

Best validation loss: -11.993213653564453

Saving best model for epoch: 77

--------------------------------------------------
[INFO]: Epoch 78 of 200
Training
[78,   100] loss: 3.012e-05
[78,   200] loss: 3.092e-05
Validation
[78,   100] loss: 3.259e-05
[78,   200] loss: 3.266e-05
Training loss: 0.000, train NMSE: -1.201e+01
Validation loss: 0.000, valid_NMSE: -1.201e+01

Best validation loss: -12.014276504516602

Saving best model for epoch: 78

--------------------------------------------------
[INFO]: Epoch 79 of 200
Training
[79,   100] loss: 3.056e-05
[79,   200] loss: 3.029e-05
Validation
[79,   100] loss: 3.280e-05
[79,   200] loss: 3.289e-05
Training loss: 0.000, train NMSE: -1.171e+01
Validation loss: 0.000, valid_NMSE: -1.196e+01
--------------------------------------------------
[INFO]: Epoch 80 of 200
Training
[80,   100] loss: 3.011e-05
[80,   200] loss: 3.033e-05
Validation
[80,   100] loss: 3.247e-05
[80,   200] loss: 3.259e-05
Training loss: 0.000, train NMSE: -1.196e+01
Validation loss: 0.000, valid_NMSE: -1.201e+01
--------------------------------------------------
[INFO]: Epoch 81 of 200
Training
[81,   100] loss: 3.002e-05
[81,   200] loss: 3.040e-05
Validation
[81,   100] loss: 3.251e-05
[81,   200] loss: 3.266e-05
Training loss: 0.000, train NMSE: -1.248e+01
Validation loss: 0.000, valid_NMSE: -1.200e+01
--------------------------------------------------
[INFO]: Epoch 82 of 200
Training
[82,   100] loss: 2.959e-05
[82,   200] loss: 3.041e-05
Validation
[82,   100] loss: 3.234e-05
[82,   200] loss: 3.247e-05
Training loss: 0.000, train NMSE: -1.203e+01
Validation loss: 0.000, valid_NMSE: -1.207e+01

Best validation loss: -12.065850257873535

Saving best model for epoch: 82

--------------------------------------------------
[INFO]: Epoch 83 of 200
Training
[83,   100] loss: 2.951e-05
[83,   200] loss: 3.024e-05
Validation
[83,   100] loss: 3.270e-05
[83,   200] loss: 3.291e-05
Training loss: 0.000, train NMSE: -1.229e+01
Validation loss: 0.000, valid_NMSE: -1.200e+01
--------------------------------------------------
[INFO]: Epoch 84 of 200
Training
[84,   100] loss: 2.931e-05
[84,   200] loss: 3.014e-05
Validation
[84,   100] loss: 3.228e-05
[84,   200] loss: 3.240e-05
Training loss: 0.000, train NMSE: -1.259e+01
Validation loss: 0.000, valid_NMSE: -1.206e+01
--------------------------------------------------
[INFO]: Epoch 85 of 200
Training
[85,   100] loss: 2.963e-05
[85,   200] loss: 2.953e-05
Validation
[85,   100] loss: 3.215e-05
[85,   200] loss: 3.229e-05
Training loss: 0.000, train NMSE: -1.272e+01
Validation loss: 0.000, valid_NMSE: -1.207e+01

Best validation loss: -12.069869995117188

Saving best model for epoch: 85

--------------------------------------------------
[INFO]: Epoch 86 of 200
Training
[86,   100] loss: 2.931e-05
[86,   200] loss: 2.972e-05
Validation
[86,   100] loss: 3.232e-05
[86,   200] loss: 3.247e-05
Training loss: 0.000, train NMSE: -1.193e+01
Validation loss: 0.000, valid_NMSE: -1.202e+01
--------------------------------------------------
[INFO]: Epoch 87 of 200
Training
[87,   100] loss: 2.939e-05
[87,   200] loss: 2.937e-05
Validation
[87,   100] loss: 3.204e-05
[87,   200] loss: 3.222e-05
Training loss: 0.000, train NMSE: -1.235e+01
Validation loss: 0.000, valid_NMSE: -1.202e+01
--------------------------------------------------
[INFO]: Epoch 88 of 200
Training
[88,   100] loss: 2.911e-05
[88,   200] loss: 2.924e-05
Validation
[88,   100] loss: 3.192e-05
[88,   200] loss: 3.209e-05
Training loss: 0.000, train NMSE: -1.218e+01
Validation loss: 0.000, valid_NMSE: -1.210e+01

Best validation loss: -12.097535133361816

Saving best model for epoch: 88

--------------------------------------------------
[INFO]: Epoch 89 of 200
Training
[89,   100] loss: 2.940e-05
[89,   200] loss: 2.905e-05
Validation
[89,   100] loss: 3.197e-05
[89,   200] loss: 3.215e-05
Training loss: 0.000, train NMSE: -1.270e+01
Validation loss: 0.000, valid_NMSE: -1.212e+01

Best validation loss: -12.115690231323242

Saving best model for epoch: 89

--------------------------------------------------
[INFO]: Epoch 90 of 200
Training
[90,   100] loss: 2.908e-05
[90,   200] loss: 2.907e-05
Validation
[90,   100] loss: 3.192e-05
[90,   200] loss: 3.213e-05
Training loss: 0.000, train NMSE: -1.250e+01
Validation loss: 0.000, valid_NMSE: -1.202e+01
--------------------------------------------------
[INFO]: Epoch 91 of 200
Training
[91,   100] loss: 2.912e-05
[91,   200] loss: 2.880e-05
Validation
[91,   100] loss: 3.203e-05
[91,   200] loss: 3.216e-05
Training loss: 0.000, train NMSE: -1.259e+01
Validation loss: 0.000, valid_NMSE: -1.205e+01
--------------------------------------------------
[INFO]: Epoch 92 of 200
Training
[92,   100] loss: 2.852e-05
[92,   200] loss: 2.898e-05
Validation
[92,   100] loss: 3.182e-05
[92,   200] loss: 3.196e-05
Training loss: 0.000, train NMSE: -1.273e+01
Validation loss: 0.000, valid_NMSE: -1.208e+01
--------------------------------------------------
[INFO]: Epoch 93 of 200
Training
[93,   100] loss: 2.851e-05
[93,   200] loss: 2.889e-05
Validation
[93,   100] loss: 3.158e-05
[93,   200] loss: 3.169e-05
Training loss: 0.000, train NMSE: -1.284e+01
Validation loss: 0.000, valid_NMSE: -1.210e+01
--------------------------------------------------
[INFO]: Epoch 94 of 200
Training
[94,   100] loss: 2.870e-05
[94,   200] loss: 2.841e-05
Validation
[94,   100] loss: 3.153e-05
[94,   200] loss: 3.172e-05
Training loss: 0.000, train NMSE: -1.293e+01
Validation loss: 0.000, valid_NMSE: -1.212e+01

Best validation loss: -12.124855041503906

Saving best model for epoch: 94

--------------------------------------------------
[INFO]: Epoch 95 of 200
Training
[95,   100] loss: 2.838e-05
[95,   200] loss: 2.864e-05
Validation
[95,   100] loss: 3.163e-05
[95,   200] loss: 3.182e-05
Training loss: 0.000, train NMSE: -1.275e+01
Validation loss: 0.000, valid_NMSE: -1.208e+01
--------------------------------------------------
[INFO]: Epoch 96 of 200
Training
[96,   100] loss: 2.799e-05
[96,   200] loss: 2.866e-05
Validation
[96,   100] loss: 3.151e-05
[96,   200] loss: 3.171e-05
Training loss: 0.000, train NMSE: -1.338e+01
Validation loss: 0.000, valid_NMSE: -1.214e+01

Best validation loss: -12.143359184265137

Saving best model for epoch: 96

--------------------------------------------------
[INFO]: Epoch 97 of 200
Training
[97,   100] loss: 2.790e-05
[97,   200] loss: 2.844e-05
Validation
[97,   100] loss: 3.128e-05
[97,   200] loss: 3.148e-05
Training loss: 0.000, train NMSE: -1.215e+01
Validation loss: 0.000, valid_NMSE: -1.209e+01
--------------------------------------------------
[INFO]: Epoch 98 of 200
Training
[98,   100] loss: 2.793e-05
[98,   200] loss: 2.833e-05
Validation
[98,   100] loss: 3.154e-05
[98,   200] loss: 3.171e-05
Training loss: 0.000, train NMSE: -1.258e+01
Validation loss: 0.000, valid_NMSE: -1.213e+01
--------------------------------------------------
[INFO]: Epoch 99 of 200
Training
[99,   100] loss: 2.811e-05
[99,   200] loss: 2.794e-05
Validation
[99,   100] loss: 3.125e-05
[99,   200] loss: 3.145e-05
Training loss: 0.000, train NMSE: -1.298e+01
Validation loss: 0.000, valid_NMSE: -1.211e+01
--------------------------------------------------
[INFO]: Epoch 100 of 200
Training
[100,   100] loss: 2.781e-05
[100,   200] loss: 2.796e-05
Validation
[100,   100] loss: 3.140e-05
[100,   200] loss: 3.160e-05
Training loss: 0.000, train NMSE: -1.254e+01
Validation loss: 0.000, valid_NMSE: -1.211e+01
--------------------------------------------------
[INFO]: Epoch 101 of 200
Training
[101,   100] loss: 2.781e-05
[101,   200] loss: 2.777e-05
Validation
[101,   100] loss: 3.149e-05
[101,   200] loss: 3.165e-05
Training loss: 0.000, train NMSE: -1.300e+01
Validation loss: 0.000, valid_NMSE: -1.207e+01
--------------------------------------------------
[INFO]: Epoch 102 of 200
Training
[102,   100] loss: 2.759e-05
[102,   200] loss: 2.796e-05
Validation
[102,   100] loss: 3.130e-05
[102,   200] loss: 3.150e-05
Training loss: 0.000, train NMSE: -1.265e+01
Validation loss: 0.000, valid_NMSE: -1.213e+01
--------------------------------------------------
[INFO]: Epoch 103 of 200
Training
[103,   100] loss: 2.721e-05
[103,   200] loss: 2.783e-05
Validation
[103,   100] loss: 3.095e-05
[103,   200] loss: 3.115e-05
Training loss: 0.000, train NMSE: -1.289e+01
Validation loss: 0.000, valid_NMSE: -1.220e+01

Best validation loss: -12.200263977050781

Saving best model for epoch: 103

--------------------------------------------------
[INFO]: Epoch 104 of 200
Training
[104,   100] loss: 2.717e-05
[104,   200] loss: 2.798e-05
Validation
[104,   100] loss: 3.108e-05
[104,   200] loss: 3.124e-05
Training loss: 0.000, train NMSE: -1.246e+01
Validation loss: 0.000, valid_NMSE: -1.218e+01
--------------------------------------------------
[INFO]: Epoch 105 of 200
Training
[105,   100] loss: 2.712e-05
[105,   200] loss: 2.767e-05
Validation
[105,   100] loss: 3.119e-05
[105,   200] loss: 3.139e-05
Training loss: 0.000, train NMSE: -1.258e+01
Validation loss: 0.000, valid_NMSE: -1.216e+01
--------------------------------------------------
[INFO]: Epoch 106 of 200
Training
[106,   100] loss: 2.707e-05
[106,   200] loss: 2.757e-05
Validation
[106,   100] loss: 3.093e-05
[106,   200] loss: 3.111e-05
Training loss: 0.000, train NMSE: -1.268e+01
Validation loss: 0.000, valid_NMSE: -1.220e+01
--------------------------------------------------
[INFO]: Epoch 107 of 200
Training
[107,   100] loss: 2.680e-05
[107,   200] loss: 2.768e-05
Validation
[107,   100] loss: 3.098e-05
[107,   200] loss: 3.117e-05
Training loss: 0.000, train NMSE: -1.331e+01
Validation loss: 0.000, valid_NMSE: -1.219e+01
--------------------------------------------------
[INFO]: Epoch 108 of 200
Training
[108,   100] loss: 2.700e-05
[108,   200] loss: 2.724e-05
Validation
[108,   100] loss: 3.117e-05
[108,   200] loss: 3.137e-05
Training loss: 0.000, train NMSE: -1.252e+01
Validation loss: 0.000, valid_NMSE: -1.209e+01
--------------------------------------------------
[INFO]: Epoch 109 of 200
Training
[109,   100] loss: 2.706e-05
[109,   200] loss: 2.697e-05
Validation
[109,   100] loss: 3.076e-05
[109,   200] loss: 3.098e-05
Training loss: 0.000, train NMSE: -1.262e+01
Validation loss: 0.000, valid_NMSE: -1.220e+01
--------------------------------------------------
[INFO]: Epoch 110 of 200
Training
[110,   100] loss: 2.696e-05
[110,   200] loss: 2.699e-05
Validation
[110,   100] loss: 3.129e-05
[110,   200] loss: 3.152e-05
Training loss: 0.000, train NMSE: -1.286e+01
Validation loss: 0.000, valid_NMSE: -1.216e+01
--------------------------------------------------
[INFO]: Epoch 111 of 200
Training
[111,   100] loss: 2.672e-05
[111,   200] loss: 2.701e-05
Validation
[111,   100] loss: 3.078e-05
[111,   200] loss: 3.100e-05
Training loss: 0.000, train NMSE: -1.326e+01
Validation loss: 0.000, valid_NMSE: -1.219e+01
--------------------------------------------------
[INFO]: Epoch 112 of 200
Training
[112,   100] loss: 2.696e-05
[112,   200] loss: 2.649e-05
Validation
[112,   100] loss: 3.101e-05
[112,   200] loss: 3.117e-05
Training loss: 0.000, train NMSE: -1.331e+01
Validation loss: 0.000, valid_NMSE: -1.216e+01
--------------------------------------------------
[INFO]: Epoch 113 of 200
Training
[113,   100] loss: 2.684e-05
[113,   200] loss: 2.655e-05
Validation
[113,   100] loss: 3.084e-05
[113,   200] loss: 3.103e-05
Training loss: 0.000, train NMSE: -1.260e+01
Validation loss: 0.000, valid_NMSE: -1.218e+01
--------------------------------------------------
[INFO]: Epoch 114 of 200
Training
[114,   100] loss: 2.648e-05
[114,   200] loss: 2.681e-05
Validation
[114,   100] loss: 3.081e-05
[114,   200] loss: 3.099e-05
Training loss: 0.000, train NMSE: -1.297e+01
Validation loss: 0.000, valid_NMSE: -1.218e+01
--------------------------------------------------
[INFO]: Epoch 115 of 200
Training
[115,   100] loss: 2.612e-05
[115,   200] loss: 2.687e-05
Validation
[115,   100] loss: 3.091e-05
[115,   200] loss: 3.107e-05
Training loss: 0.000, train NMSE: -1.284e+01
Validation loss: 0.000, valid_NMSE: -1.214e+01
--------------------------------------------------
[INFO]: Epoch 116 of 200
Training
[116,   100] loss: 2.629e-05
[116,   200] loss: 2.671e-05
Validation
[116,   100] loss: 3.075e-05
[116,   200] loss: 3.098e-05
Training loss: 0.000, train NMSE: -1.307e+01
Validation loss: 0.000, valid_NMSE: -1.216e+01
--------------------------------------------------
[INFO]: Epoch 117 of 200
Training
[117,   100] loss: 2.611e-05
[117,   200] loss: 2.653e-05
Validation
[117,   100] loss: 3.046e-05
[117,   200] loss: 3.071e-05
Training loss: 0.000, train NMSE: -1.355e+01
Validation loss: 0.000, valid_NMSE: -1.224e+01

Best validation loss: -12.241486549377441

Saving best model for epoch: 117

--------------------------------------------------
[INFO]: Epoch 118 of 200
Training
[118,   100] loss: 2.648e-05
[118,   200] loss: 2.610e-05
Validation
[118,   100] loss: 3.061e-05
[118,   200] loss: 3.080e-05
Training loss: 0.000, train NMSE: -1.288e+01
Validation loss: 0.000, valid_NMSE: -1.222e+01
--------------------------------------------------
[INFO]: Epoch 119 of 200
Training
[119,   100] loss: 2.611e-05
[119,   200] loss: 2.620e-05
Validation
[119,   100] loss: 3.051e-05
[119,   200] loss: 3.070e-05
Training loss: 0.000, train NMSE: -1.248e+01
Validation loss: 0.000, valid_NMSE: -1.221e+01
--------------------------------------------------
[INFO]: Epoch 120 of 200
Training
[120,   100] loss: 2.577e-05
[120,   200] loss: 2.633e-05
Validation
[120,   100] loss: 3.055e-05
[120,   200] loss: 3.080e-05
Training loss: 0.000, train NMSE: -1.315e+01
Validation loss: 0.000, valid_NMSE: -1.218e+01
--------------------------------------------------
[INFO]: Epoch 121 of 200
Training
[121,   100] loss: 2.587e-05
[121,   200] loss: 2.613e-05
Validation
[121,   100] loss: 3.033e-05
[121,   200] loss: 3.057e-05
Training loss: 0.000, train NMSE: -1.295e+01
Validation loss: 0.000, valid_NMSE: -1.226e+01

Best validation loss: -12.257648468017578

Saving best model for epoch: 121

--------------------------------------------------
[INFO]: Epoch 122 of 200
Training
[122,   100] loss: 2.569e-05
[122,   200] loss: 2.607e-05
Validation
[122,   100] loss: 3.030e-05
[122,   200] loss: 3.052e-05
Training loss: 0.000, train NMSE: -1.292e+01
Validation loss: 0.000, valid_NMSE: -1.226e+01

Best validation loss: -12.260225296020508

Saving best model for epoch: 122

--------------------------------------------------
[INFO]: Epoch 123 of 200
Training
[123,   100] loss: 2.576e-05
[123,   200] loss: 2.584e-05
Validation
[123,   100] loss: 3.064e-05
[123,   200] loss: 3.085e-05
Training loss: 0.000, train NMSE: -1.316e+01
Validation loss: 0.000, valid_NMSE: -1.225e+01
--------------------------------------------------
[INFO]: Epoch 124 of 200
Training
[124,   100] loss: 2.529e-05
[124,   200] loss: 2.628e-05
Validation
[124,   100] loss: 3.029e-05
[124,   200] loss: 3.052e-05
Training loss: 0.000, train NMSE: -1.339e+01
Validation loss: 0.000, valid_NMSE: -1.227e+01

Best validation loss: -12.266655921936035

Saving best model for epoch: 124

--------------------------------------------------
[INFO]: Epoch 125 of 200
Training
[125,   100] loss: 2.537e-05
[125,   200] loss: 2.599e-05
Validation
[125,   100] loss: 3.041e-05
[125,   200] loss: 3.060e-05
Training loss: 0.000, train NMSE: -1.268e+01
Validation loss: 0.000, valid_NMSE: -1.227e+01

Best validation loss: -12.268388748168945

Saving best model for epoch: 125

--------------------------------------------------
[INFO]: Epoch 126 of 200
Training
[126,   100] loss: 2.555e-05
[126,   200] loss: 2.574e-05
Validation
[126,   100] loss: 3.038e-05
[126,   200] loss: 3.059e-05
Training loss: 0.000, train NMSE: -1.297e+01
Validation loss: 0.000, valid_NMSE: -1.224e+01
--------------------------------------------------
[INFO]: Epoch 127 of 200
Training
[127,   100] loss: 2.544e-05
[127,   200] loss: 2.558e-05
Validation
[127,   100] loss: 3.023e-05
[127,   200] loss: 3.042e-05
Training loss: 0.000, train NMSE: -1.306e+01
Validation loss: 0.000, valid_NMSE: -1.230e+01

Best validation loss: -12.295333862304688

Saving best model for epoch: 127

--------------------------------------------------
[INFO]: Epoch 128 of 200
Training
[128,   100] loss: 2.566e-05
[128,   200] loss: 2.527e-05
Validation
[128,   100] loss: 3.027e-05
[128,   200] loss: 3.047e-05
Training loss: 0.000, train NMSE: -1.328e+01
Validation loss: 0.000, valid_NMSE: -1.230e+01

Best validation loss: -12.303866386413574

Saving best model for epoch: 128

--------------------------------------------------
[INFO]: Epoch 129 of 200
Training
[129,   100] loss: 2.510e-05
[129,   200] loss: 2.568e-05
Validation
[129,   100] loss: 3.062e-05
[129,   200] loss: 3.083e-05
Training loss: 0.000, train NMSE: -1.281e+01
Validation loss: 0.000, valid_NMSE: -1.217e+01
--------------------------------------------------
[INFO]: Epoch 130 of 200
Training
[130,   100] loss: 2.499e-05
[130,   200] loss: 2.572e-05
Validation
[130,   100] loss: 3.015e-05
[130,   200] loss: 3.035e-05
Training loss: 0.000, train NMSE: -1.335e+01
Validation loss: 0.000, valid_NMSE: -1.232e+01

Best validation loss: -12.315272331237793

Saving best model for epoch: 130

--------------------------------------------------
[INFO]: Epoch 131 of 200
Training
[131,   100] loss: 2.487e-05
[131,   200] loss: 2.563e-05
Validation
[131,   100] loss: 3.039e-05
[131,   200] loss: 3.056e-05
Training loss: 0.000, train NMSE: -1.303e+01
Validation loss: 0.000, valid_NMSE: -1.227e+01
--------------------------------------------------
[INFO]: Epoch 132 of 200
Training
[132,   100] loss: 2.499e-05
[132,   200] loss: 2.541e-05
Validation
[132,   100] loss: 3.049e-05
[132,   200] loss: 3.065e-05
Training loss: 0.000, train NMSE: -1.276e+01
Validation loss: 0.000, valid_NMSE: -1.221e+01
--------------------------------------------------
[INFO]: Epoch 133 of 200
Training
[133,   100] loss: 2.493e-05
[133,   200] loss: 2.545e-05
Validation
[133,   100] loss: 3.026e-05
[133,   200] loss: 3.049e-05
Training loss: 0.000, train NMSE: -1.293e+01
Validation loss: 0.000, valid_NMSE: -1.227e+01
--------------------------------------------------
[INFO]: Epoch 134 of 200
Training
[134,   100] loss: 2.508e-05
[134,   200] loss: 2.487e-05
Validation
[134,   100] loss: 2.993e-05
[134,   200] loss: 3.016e-05
Training loss: 0.000, train NMSE: -1.313e+01
Validation loss: 0.000, valid_NMSE: -1.233e+01

Best validation loss: -12.328973770141602

Saving best model for epoch: 134

--------------------------------------------------
[INFO]: Epoch 135 of 200
Training
[135,   100] loss: 2.495e-05
[135,   200] loss: 2.490e-05
Validation
[135,   100] loss: 3.063e-05
[135,   200] loss: 3.080e-05
Training loss: 0.000, train NMSE: -1.318e+01
Validation loss: 0.000, valid_NMSE: -1.213e+01
--------------------------------------------------
[INFO]: Epoch 136 of 200
Training
[136,   100] loss: 2.480e-05
[136,   200] loss: 2.505e-05
Validation
[136,   100] loss: 2.999e-05
[136,   200] loss: 3.019e-05
Training loss: 0.000, train NMSE: -1.291e+01
Validation loss: 0.000, valid_NMSE: -1.233e+01

Best validation loss: -12.334303855895996

Saving best model for epoch: 136

--------------------------------------------------
[INFO]: Epoch 137 of 200
Training
[137,   100] loss: 2.434e-05
[137,   200] loss: 2.522e-05
Validation
[137,   100] loss: 3.014e-05
[137,   200] loss: 3.037e-05
Training loss: 0.000, train NMSE: -1.319e+01
Validation loss: 0.000, valid_NMSE: -1.230e+01
--------------------------------------------------
[INFO]: Epoch 138 of 200
Training
[138,   100] loss: 2.457e-05
[138,   200] loss: 2.483e-05
Validation
[138,   100] loss: 2.992e-05
[138,   200] loss: 3.017e-05
Training loss: 0.000, train NMSE: -1.391e+01
Validation loss: 0.000, valid_NMSE: -1.233e+01
--------------------------------------------------
[INFO]: Epoch 139 of 200
Training
[139,   100] loss: 2.452e-05
[139,   200] loss: 2.474e-05
Validation
[139,   100] loss: 3.006e-05
[139,   200] loss: 3.022e-05
Training loss: 0.000, train NMSE: -1.357e+01
Validation loss: 0.000, valid_NMSE: -1.230e+01
--------------------------------------------------
[INFO]: Epoch 140 of 200
Training
[140,   100] loss: 2.430e-05
[140,   200] loss: 2.487e-05
Validation
[140,   100] loss: 3.010e-05
[140,   200] loss: 3.031e-05
Training loss: 0.000, train NMSE: -1.314e+01
Validation loss: 0.000, valid_NMSE: -1.231e+01
--------------------------------------------------
[INFO]: Epoch 141 of 200
Training
[141,   100] loss: 2.447e-05
[141,   200] loss: 2.477e-05
Validation
[141,   100] loss: 3.030e-05
[141,   200] loss: 3.047e-05
Training loss: 0.000, train NMSE: -1.272e+01
Validation loss: 0.000, valid_NMSE: -1.225e+01
--------------------------------------------------
[INFO]: Epoch 142 of 200
Training
[142,   100] loss: 2.397e-05
[142,   200] loss: 2.491e-05
Validation
[142,   100] loss: 3.017e-05
[142,   200] loss: 3.038e-05
Training loss: 0.000, train NMSE: -1.338e+01
Validation loss: 0.000, valid_NMSE: -1.235e+01

Best validation loss: -12.346867561340332

Saving best model for epoch: 142

--------------------------------------------------
[INFO]: Epoch 143 of 200
Training
[143,   100] loss: 2.447e-05
[143,   200] loss: 2.449e-05
Validation
[143,   100] loss: 2.993e-05
[143,   200] loss: 3.015e-05
Training loss: 0.000, train NMSE: -1.318e+01
Validation loss: 0.000, valid_NMSE: -1.233e+01
--------------------------------------------------
[INFO]: Epoch 144 of 200
Training
[144,   100] loss: 2.404e-05
[144,   200] loss: 2.461e-05
Validation
[144,   100] loss: 2.993e-05
[144,   200] loss: 3.014e-05
Training loss: 0.000, train NMSE: -1.323e+01
Validation loss: 0.000, valid_NMSE: -1.231e+01
--------------------------------------------------
[INFO]: Epoch 145 of 200
Training
[145,   100] loss: 2.389e-05
[145,   200] loss: 2.457e-05
Validation
[145,   100] loss: 2.991e-05
[145,   200] loss: 3.014e-05
Training loss: 0.000, train NMSE: -1.366e+01
Validation loss: 0.000, valid_NMSE: -1.235e+01
--------------------------------------------------
[INFO]: Epoch 146 of 200
Training
[146,   100] loss: 2.414e-05
[146,   200] loss: 2.428e-05
Validation
[146,   100] loss: 3.050e-05
[146,   200] loss: 3.068e-05
Training loss: 0.000, train NMSE: -1.340e+01
Validation loss: 0.000, valid_NMSE: -1.224e+01
--------------------------------------------------
[INFO]: Epoch 147 of 200
Training
[147,   100] loss: 2.420e-05
[147,   200] loss: 2.403e-05
Validation
[147,   100] loss: 3.002e-05
[147,   200] loss: 3.023e-05
Training loss: 0.000, train NMSE: -1.355e+01
Validation loss: 0.000, valid_NMSE: -1.234e+01
--------------------------------------------------
[INFO]: Epoch 148 of 200
Training
[148,   100] loss: 2.433e-05
[148,   200] loss: 2.406e-05
Validation
[148,   100] loss: 2.964e-05
[148,   200] loss: 2.984e-05
Training loss: 0.000, train NMSE: -1.327e+01
Validation loss: 0.000, valid_NMSE: -1.236e+01

Best validation loss: -12.357903480529785

Saving best model for epoch: 148

--------------------------------------------------
[INFO]: Epoch 149 of 200
Training
[149,   100] loss: 2.401e-05
[149,   200] loss: 2.414e-05
Validation
[149,   100] loss: 2.998e-05
[149,   200] loss: 3.015e-05
Training loss: 0.000, train NMSE: -1.317e+01
Validation loss: 0.000, valid_NMSE: -1.232e+01
--------------------------------------------------
[INFO]: Epoch 150 of 200
Training
[150,   100] loss: 2.386e-05
[150,   200] loss: 2.410e-05
Validation
[150,   100] loss: 2.985e-05
[150,   200] loss: 3.004e-05
Training loss: 0.000, train NMSE: -1.328e+01
Validation loss: 0.000, valid_NMSE: -1.236e+01
--------------------------------------------------
[INFO]: Epoch 151 of 200
Training
[151,   100] loss: 2.376e-05
[151,   200] loss: 2.395e-05
Validation
[151,   100] loss: 2.975e-05
[151,   200] loss: 2.999e-05
Training loss: 0.000, train NMSE: -1.376e+01
Validation loss: 0.000, valid_NMSE: -1.239e+01

Best validation loss: -12.394881248474121

Saving best model for epoch: 151

--------------------------------------------------
[INFO]: Epoch 152 of 200
Training
[152,   100] loss: 2.376e-05
[152,   200] loss: 2.394e-05
Validation
[152,   100] loss: 2.991e-05
[152,   200] loss: 3.010e-05
Training loss: 0.000, train NMSE: -1.325e+01
Validation loss: 0.000, valid_NMSE: -1.232e+01
--------------------------------------------------
[INFO]: Epoch 153 of 200
Training
[153,   100] loss: 2.372e-05
[153,   200] loss: 2.376e-05
Validation
[153,   100] loss: 2.993e-05
[153,   200] loss: 3.019e-05
Training loss: 0.000, train NMSE: -1.340e+01
Validation loss: 0.000, valid_NMSE: -1.233e+01
--------------------------------------------------
[INFO]: Epoch 154 of 200
Training
[154,   100] loss: 2.346e-05
[154,   200] loss: 2.401e-05
Validation
[154,   100] loss: 2.984e-05
[154,   200] loss: 3.007e-05
Training loss: 0.000, train NMSE: -1.357e+01
Validation loss: 0.000, valid_NMSE: -1.237e+01
--------------------------------------------------
[INFO]: Epoch 155 of 200
Training
[155,   100] loss: 2.351e-05
[155,   200] loss: 2.384e-05
Validation
[155,   100] loss: 2.990e-05
[155,   200] loss: 3.008e-05
Training loss: 0.000, train NMSE: -1.310e+01
Validation loss: 0.000, valid_NMSE: -1.230e+01
--------------------------------------------------
[INFO]: Epoch 156 of 200
Training
[156,   100] loss: 2.348e-05
[156,   200] loss: 2.375e-05
Validation
[156,   100] loss: 2.983e-05
[156,   200] loss: 3.002e-05
Training loss: 0.000, train NMSE: -1.369e+01
Validation loss: 0.000, valid_NMSE: -1.229e+01
--------------------------------------------------
[INFO]: Epoch 157 of 200
Training
[157,   100] loss: 2.367e-05
[157,   200] loss: 2.349e-05
Validation
[157,   100] loss: 2.968e-05
[157,   200] loss: 2.989e-05
Training loss: 0.000, train NMSE: -1.329e+01
Validation loss: 0.000, valid_NMSE: -1.238e+01
--------------------------------------------------
[INFO]: Epoch 158 of 200
Training
[158,   100] loss: 2.354e-05
[158,   200] loss: 2.350e-05
Validation
[158,   100] loss: 2.991e-05
[158,   200] loss: 3.015e-05
Training loss: 0.000, train NMSE: -1.329e+01
Validation loss: 0.000, valid_NMSE: -1.236e+01
--------------------------------------------------
[INFO]: Epoch 159 of 200
Training
[159,   100] loss: 2.319e-05
[159,   200] loss: 2.369e-05
Validation
[159,   100] loss: 3.027e-05
[159,   200] loss: 3.047e-05
Training loss: 0.000, train NMSE: -1.303e+01
Validation loss: 0.000, valid_NMSE: -1.221e+01
--------------------------------------------------
[INFO]: Epoch 160 of 200
Training
[160,   100] loss: 2.327e-05
[160,   200] loss: 2.352e-05
Validation
[160,   100] loss: 2.974e-05
[160,   200] loss: 2.993e-05
Training loss: 0.000, train NMSE: -1.352e+01
Validation loss: 0.000, valid_NMSE: -1.229e+01
--------------------------------------------------
[INFO]: Epoch 161 of 200
Training
[161,   100] loss: 2.338e-05
[161,   200] loss: 2.326e-05
Validation
[161,   100] loss: 2.966e-05
[161,   200] loss: 2.989e-05
Training loss: 0.000, train NMSE: -1.366e+01
Validation loss: 0.000, valid_NMSE: -1.239e+01
--------------------------------------------------
[INFO]: Epoch 162 of 200
Training
[162,   100] loss: 2.335e-05
[162,   200] loss: 2.308e-05
Validation
[162,   100] loss: 2.988e-05
[162,   200] loss: 3.007e-05
Training loss: 0.000, train NMSE: -1.370e+01
Validation loss: 0.000, valid_NMSE: -1.230e+01
--------------------------------------------------
[INFO]: Epoch 163 of 200
Training
[163,   100] loss: 2.291e-05
[163,   200] loss: 2.368e-05
Validation
[163,   100] loss: 2.951e-05
[163,   200] loss: 2.969e-05
Training loss: 0.000, train NMSE: -1.376e+01
Validation loss: 0.000, valid_NMSE: -1.246e+01

Best validation loss: -12.45536994934082

Saving best model for epoch: 163

--------------------------------------------------
[INFO]: Epoch 164 of 200
Training
[164,   100] loss: 2.298e-05
[164,   200] loss: 2.333e-05
Validation
[164,   100] loss: 2.954e-05
[164,   200] loss: 2.976e-05
Training loss: 0.000, train NMSE: -1.322e+01
Validation loss: 0.000, valid_NMSE: -1.238e+01
--------------------------------------------------
[INFO]: Epoch 165 of 200
Training
[165,   100] loss: 2.319e-05
[165,   200] loss: 2.307e-05
Validation
[165,   100] loss: 3.031e-05
[165,   200] loss: 3.051e-05
Training loss: 0.000, train NMSE: -1.351e+01
Validation loss: 0.000, valid_NMSE: -1.224e+01
--------------------------------------------------
[INFO]: Epoch 166 of 200
Training
[166,   100] loss: 2.283e-05
[166,   200] loss: 2.335e-05
Validation
[166,   100] loss: 2.989e-05
[166,   200] loss: 3.009e-05
Training loss: 0.000, train NMSE: -1.347e+01
Validation loss: 0.000, valid_NMSE: -1.232e+01
--------------------------------------------------
[INFO]: Epoch 167 of 200
Training
[167,   100] loss: 2.253e-05
[167,   200] loss: 2.354e-05
Validation
[167,   100] loss: 2.980e-05
[167,   200] loss: 2.998e-05
Training loss: 0.000, train NMSE: -1.301e+01
Validation loss: 0.000, valid_NMSE: -1.234e+01
--------------------------------------------------
[INFO]: Epoch 168 of 200
Training
[168,   100] loss: 2.288e-05
[168,   200] loss: 2.298e-05
Validation
[168,   100] loss: 2.969e-05
[168,   200] loss: 2.989e-05
Training loss: 0.000, train NMSE: -1.334e+01
Validation loss: 0.000, valid_NMSE: -1.236e+01
--------------------------------------------------
[INFO]: Epoch 169 of 200
Training
[169,   100] loss: 2.278e-05
[169,   200] loss: 2.309e-05
Validation
[169,   100] loss: 2.981e-05
[169,   200] loss: 2.999e-05
Training loss: 0.000, train NMSE: -1.328e+01
Validation loss: 0.000, valid_NMSE: -1.236e+01
--------------------------------------------------
[INFO]: Epoch 170 of 200
Training
[170,   100] loss: 2.272e-05
[170,   200] loss: 2.287e-05
Validation
[170,   100] loss: 2.970e-05
[170,   200] loss: 2.995e-05
Training loss: 0.000, train NMSE: -1.381e+01
Validation loss: 0.000, valid_NMSE: -1.238e+01
--------------------------------------------------
[INFO]: Epoch 171 of 200
Training
[171,   100] loss: 2.287e-05
[171,   200] loss: 2.288e-05
Validation
[171,   100] loss: 2.942e-05
[171,   200] loss: 2.962e-05
Training loss: 0.000, train NMSE: -1.301e+01
Validation loss: 0.000, valid_NMSE: -1.239e+01
--------------------------------------------------
[INFO]: Epoch 172 of 200
Training
[172,   100] loss: 2.265e-05
[172,   200] loss: 2.299e-05
Validation
[172,   100] loss: 2.969e-05
[172,   200] loss: 2.991e-05
Training loss: 0.000, train NMSE: -1.315e+01
Validation loss: 0.000, valid_NMSE: -1.239e+01
--------------------------------------------------
[INFO]: Epoch 173 of 200
Training
[173,   100] loss: 2.253e-05
[173,   200] loss: 2.287e-05
Validation
[173,   100] loss: 2.982e-05
[173,   200] loss: 2.998e-05
Training loss: 0.000, train NMSE: -1.288e+01
Validation loss: 0.000, valid_NMSE: -1.233e+01
--------------------------------------------------
[INFO]: Epoch 174 of 200
Training
[174,   100] loss: 2.286e-05
[174,   200] loss: 2.236e-05
Validation
[174,   100] loss: 2.948e-05
[174,   200] loss: 2.972e-05
Training loss: 0.000, train NMSE: -1.314e+01
Validation loss: 0.000, valid_NMSE: -1.238e+01
--------------------------------------------------
[INFO]: Epoch 175 of 200
Training
[175,   100] loss: 2.246e-05
[175,   200] loss: 2.278e-05
Validation
[175,   100] loss: 2.989e-05
[175,   200] loss: 3.010e-05
Training loss: 0.000, train NMSE: -1.250e+01
Validation loss: 0.000, valid_NMSE: -1.234e+01
--------------------------------------------------
[INFO]: Epoch 176 of 200
Training
[176,   100] loss: 2.219e-05
[176,   200] loss: 2.284e-05
Validation
[176,   100] loss: 3.013e-05
[176,   200] loss: 3.033e-05
Training loss: 0.000, train NMSE: -1.359e+01
Validation loss: 0.000, valid_NMSE: -1.234e+01
--------------------------------------------------
[INFO]: Epoch 177 of 200
Training
[177,   100] loss: 2.220e-05
[177,   200] loss: 2.284e-05
Validation
[177,   100] loss: 2.972e-05
[177,   200] loss: 2.991e-05
Training loss: 0.000, train NMSE: -1.301e+01
Validation loss: 0.000, valid_NMSE: -1.242e+01
--------------------------------------------------
[INFO]: Epoch 178 of 200
Training
[178,   100] loss: 2.247e-05
[178,   200] loss: 2.260e-05
Validation
[178,   100] loss: 2.977e-05
[178,   200] loss: 2.993e-05
Training loss: 0.000, train NMSE: -1.344e+01
Validation loss: 0.000, valid_NMSE: -1.231e+01
--------------------------------------------------
[INFO]: Epoch 179 of 200
Training
[179,   100] loss: 2.271e-05
[179,   200] loss: 2.210e-05
Validation
[179,   100] loss: 2.995e-05
[179,   200] loss: 3.013e-05
Training loss: 0.000, train NMSE: -1.360e+01
Validation loss: 0.000, valid_NMSE: -1.238e+01
--------------------------------------------------
[INFO]: Epoch 180 of 200
Training
[180,   100] loss: 2.249e-05
[180,   200] loss: 2.241e-05
Validation
[180,   100] loss: 2.961e-05
[180,   200] loss: 2.982e-05
Training loss: 0.000, train NMSE: -1.336e+01
Validation loss: 0.000, valid_NMSE: -1.240e+01
--------------------------------------------------
[INFO]: Epoch 181 of 200
Training
[181,   100] loss: 2.199e-05
[181,   200] loss: 2.269e-05
Validation
[181,   100] loss: 2.956e-05
[181,   200] loss: 2.976e-05
Training loss: 0.000, train NMSE: -1.330e+01
Validation loss: 0.000, valid_NMSE: -1.241e+01
--------------------------------------------------
[INFO]: Epoch 182 of 200
Training
[182,   100] loss: 2.225e-05
[182,   200] loss: 2.220e-05
Validation
[182,   100] loss: 2.961e-05
[182,   200] loss: 2.982e-05
Training loss: 0.000, train NMSE: -1.380e+01
Validation loss: 0.000, valid_NMSE: -1.240e+01
--------------------------------------------------
[INFO]: Epoch 183 of 200
Training
[183,   100] loss: 2.208e-05
[183,   200] loss: 2.247e-05
Validation
[183,   100] loss: 2.949e-05
[183,   200] loss: 2.972e-05
Training loss: 0.000, train NMSE: -1.265e+01
Validation loss: 0.000, valid_NMSE: -1.236e+01
--------------------------------------------------
[INFO]: Epoch 184 of 200
Training
[184,   100] loss: 2.226e-05
[184,   200] loss: 2.221e-05
Validation
[184,   100] loss: 2.974e-05
[184,   200] loss: 2.998e-05
Training loss: 0.000, train NMSE: -1.363e+01
Validation loss: 0.000, valid_NMSE: -1.234e+01
--------------------------------------------------
[INFO]: Epoch 185 of 200
Training
[185,   100] loss: 2.211e-05
[185,   200] loss: 2.202e-05
Validation
[185,   100] loss: 2.985e-05
[185,   200] loss: 3.003e-05
Training loss: 0.000, train NMSE: -1.377e+01
Validation loss: 0.000, valid_NMSE: -1.234e+01
--------------------------------------------------
[INFO]: Epoch 186 of 200
Training
[186,   100] loss: 2.195e-05
[186,   200] loss: 2.233e-05
Validation
[186,   100] loss: 2.972e-05
[186,   200] loss: 2.986e-05
Training loss: 0.000, train NMSE: -1.321e+01
Validation loss: 0.000, valid_NMSE: -1.238e+01
--------------------------------------------------
[INFO]: Epoch 187 of 200
Training
[187,   100] loss: 2.221e-05
[187,   200] loss: 2.200e-05
Validation
[187,   100] loss: 2.963e-05
[187,   200] loss: 2.986e-05
Training loss: 0.000, train NMSE: -1.390e+01
Validation loss: 0.000, valid_NMSE: -1.241e+01
--------------------------------------------------
[INFO]: Epoch 188 of 200
Training
[188,   100] loss: 2.223e-05
[188,   200] loss: 2.179e-05
Validation
[188,   100] loss: 2.966e-05
[188,   200] loss: 2.989e-05
Training loss: 0.000, train NMSE: -1.370e+01
Validation loss: 0.000, valid_NMSE: -1.236e+01
--------------------------------------------------
[INFO]: Epoch 189 of 200
Training
[189,   100] loss: 2.200e-05
[189,   200] loss: 2.196e-05
Validation
[189,   100] loss: 2.957e-05
[189,   200] loss: 2.976e-05
Training loss: 0.000, train NMSE: -1.342e+01
Validation loss: 0.000, valid_NMSE: -1.239e+01
--------------------------------------------------
[INFO]: Epoch 190 of 200
Training
[190,   100] loss: 2.202e-05
[190,   200] loss: 2.189e-05
Validation
[190,   100] loss: 2.939e-05
[190,   200] loss: 2.959e-05
Training loss: 0.000, train NMSE: -1.377e+01
Validation loss: 0.000, valid_NMSE: -1.240e+01
--------------------------------------------------
[INFO]: Epoch 191 of 200
Training
[191,   100] loss: 2.158e-05
[191,   200] loss: 2.211e-05
Validation
[191,   100] loss: 2.941e-05
[191,   200] loss: 2.961e-05
Training loss: 0.000, train NMSE: -1.354e+01
Validation loss: 0.000, valid_NMSE: -1.242e+01
--------------------------------------------------
[INFO]: Epoch 192 of 200
Training
[192,   100] loss: 2.184e-05
[192,   200] loss: 2.192e-05
Validation
[192,   100] loss: 2.939e-05
[192,   200] loss: 2.957e-05
Training loss: 0.000, train NMSE: -1.434e+01
Validation loss: 0.000, valid_NMSE: -1.243e+01
--------------------------------------------------
[INFO]: Epoch 193 of 200
Training
[193,   100] loss: 2.170e-05
[193,   200] loss: 2.197e-05
Validation
[193,   100] loss: 2.928e-05
[193,   200] loss: 2.944e-05
Training loss: 0.000, train NMSE: -1.306e+01
Validation loss: 0.000, valid_NMSE: -1.244e+01
--------------------------------------------------
[INFO]: Epoch 194 of 200
Training
[194,   100] loss: 2.168e-05
[194,   200] loss: 2.186e-05
Validation
[194,   100] loss: 2.946e-05
[194,   200] loss: 2.967e-05
Training loss: 0.000, train NMSE: -1.389e+01
Validation loss: 0.000, valid_NMSE: -1.244e+01
--------------------------------------------------
[INFO]: Epoch 195 of 200
Training
[195,   100] loss: 2.162e-05
[195,   200] loss: 2.164e-05
Validation
[195,   100] loss: 2.959e-05
[195,   200] loss: 2.979e-05
Training loss: 0.000, train NMSE: -1.449e+01
Validation loss: 0.000, valid_NMSE: -1.235e+01
--------------------------------------------------
[INFO]: Epoch 196 of 200
Training
[196,   100] loss: 2.133e-05
[196,   200] loss: 2.203e-05
Validation
[196,   100] loss: 2.952e-05
[196,   200] loss: 2.967e-05
Training loss: 0.000, train NMSE: -1.340e+01
Validation loss: 0.000, valid_NMSE: -1.240e+01
--------------------------------------------------
[INFO]: Epoch 197 of 200
Training
[197,   100] loss: 2.143e-05
[197,   200] loss: 2.178e-05
Validation
[197,   100] loss: 2.930e-05
[197,   200] loss: 2.953e-05
Training loss: 0.000, train NMSE: -1.462e+01
Validation loss: 0.000, valid_NMSE: -1.240e+01
--------------------------------------------------
[INFO]: Epoch 198 of 200/home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE
  warn(f"Failed to load image Python extension: {e}")

Training
[198,   100] loss: 2.115e-05
[198,   200] loss: 2.184e-05
Validation
[198,   100] loss: 2.974e-05
[198,   200] loss: 2.996e-05
Training loss: 0.000, train NMSE: -1.366e+01
Validation loss: 0.000, valid_NMSE: -1.240e+01
--------------------------------------------------
[INFO]: Epoch 199 of 200
Training
[199,   100] loss: 2.129e-05
[199,   200] loss: 2.164e-05
Validation
[199,   100] loss: 2.952e-05
[199,   200] loss: 2.978e-05
Training loss: 0.000, train NMSE: -1.393e+01
Validation loss: 0.000, valid_NMSE: -1.235e+01
--------------------------------------------------
[INFO]: Epoch 200 of 200
Training
[200,   100] loss: 2.145e-05
[200,   200] loss: 2.146e-05
Validation
[200,   100] loss: 2.944e-05
[200,   200] loss: 2.966e-05
Training loss: 0.000, train NMSE: -1.399e+01
Validation loss: 0.000, valid_NMSE: -1.244e+01
--------------------------------------------------
Saving final model
TRAINING COMPLETE
