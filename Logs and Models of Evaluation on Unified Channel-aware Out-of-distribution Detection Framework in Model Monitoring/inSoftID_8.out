1.13.1+cu117
inSoftID
Dadicated Mode inSoftID
Dedicated Mode inSoftID
trainset len 112000 valset len 48000
New_trainset len 40000 valset len 48000
1,611,673 training parameters.

1,611,673 training parameters.

[INFO]: Epoch 1 of 200
Training
[1,   100] loss: 1.287e-04
[1,   200] loss: 1.084e-04
Validation
[1,   100] loss: 1.040e-04
[1,   200] loss: 1.030e-04
Training loss: 0.000, train NMSE: -7.061e+00
Validation loss: 0.000, valid_NMSE: -7.105e+00

Best validation loss: -7.104937553405762

Saving best model for epoch: 1

--------------------------------------------------
[INFO]: Epoch 2 of 200
Training
[2,   100] loss: 9.786e-05
[2,   200] loss: 9.066e-05
Validation
[2,   100] loss: 9.086e-05
[2,   200] loss: 8.951e-05
Training loss: 0.000, train NMSE: -7.118e+00
Validation loss: 0.000, valid_NMSE: -7.827e+00

Best validation loss: -7.826750755310059

Saving best model for epoch: 2

--------------------------------------------------
[INFO]: Epoch 3 of 200
Training
[3,   100] loss: 8.538e-05
[3,   200] loss: 7.892e-05
Validation
[3,   100] loss: 7.836e-05
[3,   200] loss: 7.660e-05
Training loss: 0.000, train NMSE: -7.763e+00
Validation loss: 0.000, valid_NMSE: -8.598e+00

Best validation loss: -8.598488807678223

Saving best model for epoch: 3

--------------------------------------------------
[INFO]: Epoch 4 of 200
Training
[4,   100] loss: 7.118e-05
[4,   200] loss: 6.250e-05
Validation
[4,   100] loss: 6.177e-05
[4,   200] loss: 6.085e-05
Training loss: 0.000, train NMSE: -9.009e+00
Validation loss: 0.000, valid_NMSE: -9.623e+00

Best validation loss: -9.62337875366211

Saving best model for epoch: 4

--------------------------------------------------
[INFO]: Epoch 5 of 200
Training
[5,   100] loss: 5.541e-05
[5,   200] loss: 5.009e-05
Validation
[5,   100] loss: 5.111e-05
[5,   200] loss: 5.038e-05
Training loss: 0.000, train NMSE: -9.915e+00
Validation loss: 0.000, valid_NMSE: -1.053e+01

Best validation loss: -10.531015396118164

Saving best model for epoch: 5

--------------------------------------------------
[INFO]: Epoch 6 of 200
Training
[6,   100] loss: 4.597e-05
[6,   200] loss: 4.341e-05
Validation
[6,   100] loss: 4.482e-05
[6,   200] loss: 4.415e-05
Training loss: 0.000, train NMSE: -1.071e+01
Validation loss: 0.000, valid_NMSE: -1.113e+01

Best validation loss: -11.126846313476562

Saving best model for epoch: 6

--------------------------------------------------
[INFO]: Epoch 7 of 200
Training
[7,   100] loss: 4.036e-05
[7,   200] loss: 3.880e-05
Validation
[7,   100] loss: 4.091e-05
[7,   200] loss: 4.027e-05
Training loss: 0.000, train NMSE: -1.157e+01
Validation loss: 0.000, valid_NMSE: -1.145e+01

Best validation loss: -11.449494361877441

Saving best model for epoch: 7

--------------------------------------------------
[INFO]: Epoch 8 of 200
Training
[8,   100] loss: 3.611e-05
[8,   200] loss: 3.534e-05
Validation
[8,   100] loss: 3.726e-05
[8,   200] loss: 3.676e-05
Training loss: 0.000, train NMSE: -1.158e+01
Validation loss: 0.000, valid_NMSE: -1.190e+01

Best validation loss: -11.897717475891113

Saving best model for epoch: 8

--------------------------------------------------
[INFO]: Epoch 9 of 200
Training
[9,   100] loss: 3.252e-05
[9,   200] loss: 3.228e-05
Validation
[9,   100] loss: 3.432e-05
[9,   200] loss: 3.396e-05
Training loss: 0.000, train NMSE: -1.227e+01
Validation loss: 0.000, valid_NMSE: -1.222e+01

Best validation loss: -12.215808868408203

Saving best model for epoch: 9

--------------------------------------------------
[INFO]: Epoch 10 of 200
Training
[10,   100] loss: 2.972e-05
[10,   200] loss: 2.965e-05
Validation
[10,   100] loss: 3.211e-05
[10,   200] loss: 3.185e-05
Training loss: 0.000, train NMSE: -1.206e+01
Validation loss: 0.000, valid_NMSE: -1.244e+01

Best validation loss: -12.439245223999023

Saving best model for epoch: 10

--------------------------------------------------
[INFO]: Epoch 11 of 200
Training
[11,   100] loss: 2.752e-05
[11,   200] loss: 2.714e-05
Validation
[11,   100] loss: 2.995e-05
[11,   200] loss: 2.975e-05
Training loss: 0.000, train NMSE: -1.343e+01
Validation loss: 0.000, valid_NMSE: -1.272e+01

Best validation loss: -12.718707084655762

Saving best model for epoch: 11

--------------------------------------------------
[INFO]: Epoch 12 of 200
Training
[12,   100] loss: 2.551e-05
[12,   200] loss: 2.514e-05
Validation
[12,   100] loss: 2.789e-05
[12,   200] loss: 2.775e-05
Training loss: 0.000, train NMSE: -1.295e+01
Validation loss: 0.000, valid_NMSE: -1.294e+01

Best validation loss: -12.944750785827637

Saving best model for epoch: 12

--------------------------------------------------
[INFO]: Epoch 13 of 200
Training
[13,   100] loss: 2.372e-05
[13,   200] loss: 2.337e-05
Validation
[13,   100] loss: 2.625e-05
[13,   200] loss: 2.609e-05
Training loss: 0.000, train NMSE: -1.300e+01
Validation loss: 0.000, valid_NMSE: -1.318e+01

Best validation loss: -13.176412582397461

Saving best model for epoch: 13

--------------------------------------------------
[INFO]: Epoch 14 of 200
Training
[14,   100] loss: 2.225e-05
[14,   200] loss: 2.169e-05
Validation
[14,   100] loss: 2.501e-05
[14,   200] loss: 2.492e-05
Training loss: 0.000, train NMSE: -1.393e+01
Validation loss: 0.000, valid_NMSE: -1.340e+01

Best validation loss: -13.39889144897461

Saving best model for epoch: 14

--------------------------------------------------
[INFO]: Epoch 15 of 200
Training
[15,   100] loss: 2.053e-05
[15,   200] loss: 2.083e-05
Validation
[15,   100] loss: 2.327e-05
[15,   200] loss: 2.316e-05
Training loss: 0.000, train NMSE: -1.384e+01
Validation loss: 0.000, valid_NMSE: -1.372e+01

Best validation loss: -13.718467712402344

Saving best model for epoch: 15

--------------------------------------------------
[INFO]: Epoch 16 of 200
Training
[16,   100] loss: 1.921e-05
[16,   200] loss: 1.958e-05
Validation
[16,   100] loss: 2.213e-05
[16,   200] loss: 2.202e-05
Training loss: 0.000, train NMSE: -1.382e+01
Validation loss: 0.000, valid_NMSE: -1.390e+01

Best validation loss: -13.902749061584473

Saving best model for epoch: 16

--------------------------------------------------
[INFO]: Epoch 17 of 200
Training
[17,   100] loss: 1.841e-05
[17,   200] loss: 1.844e-05
Validation
[17,   100] loss: 2.108e-05
[17,   200] loss: 2.099e-05
Training loss: 0.000, train NMSE: -1.418e+01
Validation loss: 0.000, valid_NMSE: -1.399e+01

Best validation loss: -13.989953994750977

Saving best model for epoch: 17

--------------------------------------------------
[INFO]: Epoch 18 of 200
Training
[18,   100] loss: 1.747e-05
[18,   200] loss: 1.757e-05
Validation
[18,   100] loss: 2.022e-05
[18,   200] loss: 2.012e-05
Training loss: 0.000, train NMSE: -1.447e+01
Validation loss: 0.000, valid_NMSE: -1.420e+01

Best validation loss: -14.203787803649902

Saving best model for epoch: 18

--------------------------------------------------
[INFO]: Epoch 19 of 200
Training
[19,   100] loss: 1.655e-05
[19,   200] loss: 1.687e-05
Validation
[19,   100] loss: 1.941e-05
[19,   200] loss: 1.931e-05
Training loss: 0.000, train NMSE: -1.447e+01
Validation loss: 0.000, valid_NMSE: -1.437e+01

Best validation loss: -14.370882034301758

Saving best model for epoch: 19

--------------------------------------------------
[INFO]: Epoch 20 of 200
Training
[20,   100] loss: 1.598e-05
[20,   200] loss: 1.603e-05
Validation
[20,   100] loss: 1.870e-05
[20,   200] loss: 1.862e-05
Training loss: 0.000, train NMSE: -1.494e+01
Validation loss: 0.000, valid_NMSE: -1.447e+01

Best validation loss: -14.469605445861816

Saving best model for epoch: 20

--------------------------------------------------
[INFO]: Epoch 21 of 200
Training
[21,   100] loss: 1.542e-05
[21,   200] loss: 1.531e-05
Validation
[21,   100] loss: 1.823e-05
[21,   200] loss: 1.814e-05
Training loss: 0.000, train NMSE: -1.509e+01
Validation loss: 0.000, valid_NMSE: -1.454e+01

Best validation loss: -14.544883728027344

Saving best model for epoch: 21

--------------------------------------------------
[INFO]: Epoch 22 of 200
Training
[22,   100] loss: 1.483e-05
[22,   200] loss: 1.492e-05
Validation
[22,   100] loss: 1.757e-05
[22,   200] loss: 1.746e-05
Training loss: 0.000, train NMSE: -1.475e+01
Validation loss: 0.000, valid_NMSE: -1.475e+01

Best validation loss: -14.752639770507812

Saving best model for epoch: 22

--------------------------------------------------
[INFO]: Epoch 23 of 200
Training
[23,   100] loss: 1.426e-05
[23,   200] loss: 1.445e-05
Validation
[23,   100] loss: 1.722e-05
[23,   200] loss: 1.714e-05
Training loss: 0.000, train NMSE: -1.503e+01
Validation loss: 0.000, valid_NMSE: -1.485e+01

Best validation loss: -14.85362434387207

Saving best model for epoch: 23

--------------------------------------------------
[INFO]: Epoch 24 of 200
Training
[24,   100] loss: 1.397e-05
[24,   200] loss: 1.387e-05
Validation
[24,   100] loss: 1.663e-05
[24,   200] loss: 1.654e-05
Training loss: 0.000, train NMSE: -1.527e+01
Validation loss: 0.000, valid_NMSE: -1.501e+01

Best validation loss: -15.005217552185059

Saving best model for epoch: 24

--------------------------------------------------
[INFO]: Epoch 25 of 200
Training
[25,   100] loss: 1.344e-05
[25,   200] loss: 1.358e-05
Validation
[25,   100] loss: 1.618e-05
[25,   200] loss: 1.611e-05
Training loss: 0.000, train NMSE: -1.526e+01
Validation loss: 0.000, valid_NMSE: -1.506e+01

Best validation loss: -15.063935279846191

Saving best model for epoch: 25

--------------------------------------------------
[INFO]: Epoch 26 of 200
Training
[26,   100] loss: 1.311e-05
[26,   200] loss: 1.330e-05
Validation
[26,   100] loss: 1.604e-05
[26,   200] loss: 1.598e-05
Training loss: 0.000, train NMSE: -1.578e+01
Validation loss: 0.000, valid_NMSE: -1.503e+01
--------------------------------------------------
[INFO]: Epoch 27 of 200
Training
[27,   100] loss: 1.287e-05
[27,   200] loss: 1.277e-05
Validation
[27,   100] loss: 1.548e-05
[27,   200] loss: 1.543e-05
Training loss: 0.000, train NMSE: -1.566e+01
Validation loss: 0.000, valid_NMSE: -1.526e+01

Best validation loss: -15.263699531555176

Saving best model for epoch: 27

--------------------------------------------------
[INFO]: Epoch 28 of 200
Training
[28,   100] loss: 1.249e-05
[28,   200] loss: 1.257e-05
Validation
[28,   100] loss: 1.507e-05
[28,   200] loss: 1.500e-05
Training loss: 0.000, train NMSE: -1.583e+01
Validation loss: 0.000, valid_NMSE: -1.533e+01

Best validation loss: -15.328775405883789

Saving best model for epoch: 28

--------------------------------------------------
[INFO]: Epoch 29 of 200
Training
[29,   100] loss: 1.209e-05
[29,   200] loss: 1.228e-05
Validation
[29,   100] loss: 1.477e-05
[29,   200] loss: 1.473e-05
Training loss: 0.000, train NMSE: -1.588e+01
Validation loss: 0.000, valid_NMSE: -1.545e+01

Best validation loss: -15.446864128112793

Saving best model for epoch: 29

--------------------------------------------------
[INFO]: Epoch 30 of 200
Training
[30,   100] loss: 1.183e-05
[30,   200] loss: 1.204e-05
Validation
[30,   100] loss: 1.461e-05
[30,   200] loss: 1.454e-05
Training loss: 0.000, train NMSE: -1.571e+01
Validation loss: 0.000, valid_NMSE: -1.549e+01

Best validation loss: -15.488943099975586

Saving best model for epoch: 30

--------------------------------------------------
[INFO]: Epoch 31 of 200
Training
[31,   100] loss: 1.158e-05
[31,   200] loss: 1.186e-05
Validation
[31,   100] loss: 1.450e-05
[31,   200] loss: 1.444e-05
Training loss: 0.000, train NMSE: -1.537e+01
Validation loss: 0.000, valid_NMSE: -1.549e+01
--------------------------------------------------
[INFO]: Epoch 32 of 200
Training
[32,   100] loss: 1.130e-05
[32,   200] loss: 1.161e-05
Validation
[32,   100] loss: 1.408e-05
[32,   200] loss: 1.403e-05
Training loss: 0.000, train NMSE: -1.592e+01
Validation loss: 0.000, valid_NMSE: -1.559e+01

Best validation loss: -15.592363357543945

Saving best model for epoch: 32

--------------------------------------------------
[INFO]: Epoch 33 of 200
Training
[33,   100] loss: 1.132e-05
[33,   200] loss: 1.133e-05
Validation
[33,   100] loss: 1.383e-05
[33,   200] loss: 1.378e-05
Training loss: 0.000, train NMSE: -1.579e+01
Validation loss: 0.000, valid_NMSE: -1.571e+01

Best validation loss: -15.7121000289917

Saving best model for epoch: 33

--------------------------------------------------
[INFO]: Epoch 34 of 200
Training
[34,   100] loss: 1.087e-05
[34,   200] loss: 1.115e-05
Validation
[34,   100] loss: 1.380e-05
[34,   200] loss: 1.376e-05
Training loss: 0.000, train NMSE: -1.660e+01
Validation loss: 0.000, valid_NMSE: -1.573e+01

Best validation loss: -15.730646133422852

Saving best model for epoch: 34

--------------------------------------------------
[INFO]: Epoch 35 of 200
Training
[35,   100] loss: 1.075e-05
[35,   200] loss: 1.093e-05
Validation
[35,   100] loss: 1.346e-05
[35,   200] loss: 1.344e-05
Training loss: 0.000, train NMSE: -1.638e+01
Validation loss: 0.000, valid_NMSE: -1.575e+01

Best validation loss: -15.74631118774414

Saving best model for epoch: 35

--------------------------------------------------
[INFO]: Epoch 36 of 200
Training
[36,   100] loss: 1.086e-05
[36,   200] loss: 1.045e-05
Validation
[36,   100] loss: 1.326e-05
[36,   200] loss: 1.323e-05
Training loss: 0.000, train NMSE: -1.699e+01
Validation loss: 0.000, valid_NMSE: -1.573e+01
--------------------------------------------------
[INFO]: Epoch 37 of 200
Training
[37,   100] loss: 1.040e-05
[37,   200] loss: 1.055e-05
Validation
[37,   100] loss: 1.305e-05
[37,   200] loss: 1.301e-05
Training loss: 0.000, train NMSE: -1.687e+01
Validation loss: 0.000, valid_NMSE: -1.595e+01

Best validation loss: -15.951448440551758

Saving best model for epoch: 37

--------------------------------------------------
[INFO]: Epoch 38 of 200
Training
[38,   100] loss: 1.021e-05
[38,   200] loss: 1.037e-05
Validation
[38,   100] loss: 1.283e-05
[38,   200] loss: 1.280e-05
Training loss: 0.000, train NMSE: -1.643e+01
Validation loss: 0.000, valid_NMSE: -1.595e+01
--------------------------------------------------
[INFO]: Epoch 39 of 200
Training
[39,   100] loss: 1.016e-05
[39,   200] loss: 1.017e-05
Validation
[39,   100] loss: 1.273e-05
[39,   200] loss: 1.272e-05
Training loss: 0.000, train NMSE: -1.716e+01
Validation loss: 0.000, valid_NMSE: -1.595e+01
--------------------------------------------------
[INFO]: Epoch 40 of 200
Training
[40,   100] loss: 9.907e-06
[40,   200] loss: 1.020e-05
Validation
[40,   100] loss: 1.263e-05
[40,   200] loss: 1.258e-05
Training loss: 0.000, train NMSE: -1.682e+01
Validation loss: 0.000, valid_NMSE: -1.604e+01

Best validation loss: -16.03701400756836

Saving best model for epoch: 40

--------------------------------------------------
[INFO]: Epoch 41 of 200
Training
[41,   100] loss: 9.814e-06
[41,   200] loss: 9.945e-06
Validation
[41,   100] loss: 1.252e-05
[41,   200] loss: 1.247e-05
Training loss: 0.000, train NMSE: -1.682e+01
Validation loss: 0.000, valid_NMSE: -1.610e+01

Best validation loss: -16.096710205078125

Saving best model for epoch: 41

--------------------------------------------------
[INFO]: Epoch 42 of 200
Training
[42,   100] loss: 9.618e-06
[42,   200] loss: 9.763e-06
Validation
[42,   100] loss: 1.239e-05
[42,   200] loss: 1.234e-05
Training loss: 0.000, train NMSE: -1.672e+01
Validation loss: 0.000, valid_NMSE: -1.611e+01

Best validation loss: -16.111766815185547

Saving best model for epoch: 42

--------------------------------------------------
[INFO]: Epoch 43 of 200
Training
[43,   100] loss: 9.753e-06
[43,   200] loss: 9.530e-06
Validation
[43,   100] loss: 1.213e-05
[43,   200] loss: 1.210e-05
Training loss: 0.000, train NMSE: -1.695e+01
Validation loss: 0.000, valid_NMSE: -1.623e+01

Best validation loss: -16.23101806640625

Saving best model for epoch: 43

--------------------------------------------------
[INFO]: Epoch 44 of 200
Training
[44,   100] loss: 9.521e-06
[44,   200] loss: 9.505e-06
Validation
[44,   100] loss: 1.210e-05
[44,   200] loss: 1.207e-05
Training loss: 0.000, train NMSE: -1.680e+01
Validation loss: 0.000, valid_NMSE: -1.616e+01
--------------------------------------------------
[INFO]: Epoch 45 of 200
Training
[45,   100] loss: 9.305e-06
[45,   200] loss: 9.474e-06
Validation
[45,   100] loss: 1.205e-05
[45,   200] loss: 1.204e-05
Training loss: 0.000, train NMSE: -1.685e+01
Validation loss: 0.000, valid_NMSE: -1.615e+01
--------------------------------------------------
[INFO]: Epoch 46 of 200
Training
[46,   100] loss: 9.334e-06
[46,   200] loss: 9.231e-06
Validation
[46,   100] loss: 1.197e-05
[46,   200] loss: 1.196e-05
Training loss: 0.000, train NMSE: -1.680e+01
Validation loss: 0.000, valid_NMSE: -1.616e+01
--------------------------------------------------
[INFO]: Epoch 47 of 200
Training
[47,   100] loss: 9.223e-06
[47,   200] loss: 9.031e-06
Validation
[47,   100] loss: 1.177e-05
[47,   200] loss: 1.174e-05
Training loss: 0.000, train NMSE: -1.673e+01
Validation loss: 0.000, valid_NMSE: -1.628e+01

Best validation loss: -16.282058715820312

Saving best model for epoch: 47

--------------------------------------------------
[INFO]: Epoch 48 of 200
Training
[48,   100] loss: 9.010e-06
[48,   200] loss: 9.142e-06
Validation
[48,   100] loss: 1.170e-05
[48,   200] loss: 1.168e-05
Training loss: 0.000, train NMSE: -1.704e+01
Validation loss: 0.000, valid_NMSE: -1.626e+01
--------------------------------------------------
[INFO]: Epoch 49 of 200
Training
[49,   100] loss: 8.830e-06
[49,   200] loss: 9.045e-06
Validation
[49,   100] loss: 1.173e-05
[49,   200] loss: 1.171e-05
Training loss: 0.000, train NMSE: -1.685e+01
Validation loss: 0.000, valid_NMSE: -1.628e+01

Best validation loss: -16.283628463745117

Saving best model for epoch: 49

--------------------------------------------------
[INFO]: Epoch 50 of 200
Training
[50,   100] loss: 8.729e-06
[50,   200] loss: 8.923e-06
Validation
[50,   100] loss: 1.166e-05
[50,   200] loss: 1.163e-05
Training loss: 0.000, train NMSE: -1.695e+01
Validation loss: 0.000, valid_NMSE: -1.627e+01
--------------------------------------------------
[INFO]: Epoch 51 of 200
Training
[51,   100] loss: 8.673e-06
[51,   200] loss: 8.836e-06
Validation
[51,   100] loss: 1.144e-05
[51,   200] loss: 1.143e-05
Training loss: 0.000, train NMSE: -1.723e+01
Validation loss: 0.000, valid_NMSE: -1.634e+01

Best validation loss: -16.342857360839844

Saving best model for epoch: 51

--------------------------------------------------
[INFO]: Epoch 52 of 200
Training
[52,   100] loss: 8.576e-06
[52,   200] loss: 8.774e-06
Validation
[52,   100] loss: 1.139e-05
[52,   200] loss: 1.138e-05
Training loss: 0.000, train NMSE: -1.719e+01
Validation loss: 0.000, valid_NMSE: -1.633e+01
--------------------------------------------------
[INFO]: Epoch 53 of 200
Training
[53,   100] loss: 8.560e-06
[53,   200] loss: 8.606e-06
Validation
[53,   100] loss: 1.124e-05
[53,   200] loss: 1.121e-05
Training loss: 0.000, train NMSE: -1.760e+01
Validation loss: 0.000, valid_NMSE: -1.647e+01

Best validation loss: -16.46971893310547

Saving best model for epoch: 53

--------------------------------------------------
[INFO]: Epoch 54 of 200
Training
[54,   100] loss: 8.457e-06
[54,   200] loss: 8.579e-06
Validation
[54,   100] loss: 1.159e-05
[54,   200] loss: 1.157e-05
Training loss: 0.000, train NMSE: -1.753e+01
Validation loss: 0.000, valid_NMSE: -1.636e+01
--------------------------------------------------
[INFO]: Epoch 55 of 200
Training
[55,   100] loss: 8.447e-06
[55,   200] loss: 8.420e-06
Validation
[55,   100] loss: 1.111e-05
[55,   200] loss: 1.109e-05
Training loss: 0.000, train NMSE: -1.786e+01
Validation loss: 0.000, valid_NMSE: -1.651e+01

Best validation loss: -16.506696701049805

Saving best model for epoch: 55

--------------------------------------------------
[INFO]: Epoch 56 of 200
Training
[56,   100] loss: 8.199e-06
[56,   200] loss: 8.418e-06
Validation
[56,   100] loss: 1.111e-05
[56,   200] loss: 1.109e-05
Training loss: 0.000, train NMSE: -1.782e+01
Validation loss: 0.000, valid_NMSE: -1.654e+01

Best validation loss: -16.543195724487305

Saving best model for epoch: 56

--------------------------------------------------
[INFO]: Epoch 57 of 200
Training
[57,   100] loss: 8.311e-06
[57,   200] loss: 8.251e-06
Validation
[57,   100] loss: 1.119e-05
[57,   200] loss: 1.114e-05
Training loss: 0.000, train NMSE: -1.799e+01
Validation loss: 0.000, valid_NMSE: -1.657e+01

Best validation loss: -16.566469192504883

Saving best model for epoch: 57

--------------------------------------------------
[INFO]: Epoch 58 of 200
Training
[58,   100] loss: 8.037e-06
[58,   200] loss: 8.395e-06
Validation
[58,   100] loss: 1.109e-05
[58,   200] loss: 1.105e-05
Training loss: 0.000, train NMSE: -1.774e+01
Validation loss: 0.000, valid_NMSE: -1.650e+01
--------------------------------------------------
[INFO]: Epoch 59 of 200
Training
[59,   100] loss: 8.089e-06
[59,   200] loss: 8.154e-06
Validation
[59,   100] loss: 1.084e-05
[59,   200] loss: 1.081e-05
Training loss: 0.000, train NMSE: -1.758e+01
Validation loss: 0.000, valid_NMSE: -1.657e+01

Best validation loss: -16.56877899169922

Saving best model for epoch: 59

--------------------------------------------------
[INFO]: Epoch 60 of 200
Training
[60,   100] loss: 8.063e-06
[60,   200] loss: 8.067e-06
Validation
[60,   100] loss: 1.081e-05
[60,   200] loss: 1.078e-05
Training loss: 0.000, train NMSE: -1.779e+01
Validation loss: 0.000, valid_NMSE: -1.663e+01

Best validation loss: -16.633634567260742

Saving best model for epoch: 60

--------------------------------------------------
[INFO]: Epoch 61 of 200
Training
[61,   100] loss: 7.852e-06
[61,   200] loss: 8.081e-06
Validation
[61,   100] loss: 1.068e-05
[61,   200] loss: 1.066e-05
Training loss: 0.000, train NMSE: -1.761e+01
Validation loss: 0.000, valid_NMSE: -1.663e+01
--------------------------------------------------
[INFO]: Epoch 62 of 200
Training
[62,   100] loss: 7.838e-06
[62,   200] loss: 7.964e-06
Validation
[62,   100] loss: 1.068e-05
[62,   200] loss: 1.067e-05
Training loss: 0.000, train NMSE: -1.854e+01
Validation loss: 0.000, valid_NMSE: -1.662e+01
--------------------------------------------------
[INFO]: Epoch 63 of 200
Training
[63,   100] loss: 7.740e-06
[63,   200] loss: 7.956e-06
Validation
[63,   100] loss: 1.071e-05
[63,   200] loss: 1.070e-05
Training loss: 0.000, train NMSE: -1.785e+01
Validation loss: 0.000, valid_NMSE: -1.658e+01
--------------------------------------------------
[INFO]: Epoch 64 of 200
Training
[64,   100] loss: 7.882e-06
[64,   200] loss: 7.717e-06
Validation
[64,   100] loss: 1.050e-05
[64,   200] loss: 1.048e-05
Training loss: 0.000, train NMSE: -1.830e+01
Validation loss: 0.000, valid_NMSE: -1.669e+01

Best validation loss: -16.69342613220215

Saving best model for epoch: 64

--------------------------------------------------
[INFO]: Epoch 65 of 200
Training
[65,   100] loss: 7.564e-06
[65,   200] loss: 7.901e-06
Validation
[65,   100] loss: 1.036e-05
[65,   200] loss: 1.033e-05
Training loss: 0.000, train NMSE: -1.812e+01
Validation loss: 0.000, valid_NMSE: -1.675e+01

Best validation loss: -16.75341033935547

Saving best model for epoch: 65

--------------------------------------------------
[INFO]: Epoch 66 of 200
Training
[66,   100] loss: 7.580e-06
[66,   200] loss: 7.729e-06
Validation
[66,   100] loss: 1.069e-05
[66,   200] loss: 1.066e-05
Training loss: 0.000, train NMSE: -1.738e+01
Validation loss: 0.000, valid_NMSE: -1.650e+01
--------------------------------------------------
[INFO]: Epoch 67 of 200
Training
[67,   100] loss: 7.604e-06
[67,   200] loss: 7.561e-06
Validation
[67,   100] loss: 1.043e-05
[67,   200] loss: 1.040e-05
Training loss: 0.000, train NMSE: -1.772e+01
Validation loss: 0.000, valid_NMSE: -1.678e+01

Best validation loss: -16.779653549194336

Saving best model for epoch: 67

--------------------------------------------------
[INFO]: Epoch 68 of 200
Training
[68,   100] loss: 7.696e-06
[68,   200] loss: 7.425e-06
Validation
[68,   100] loss: 1.045e-05
[68,   200] loss: 1.040e-05
Training loss: 0.000, train NMSE: -1.777e+01
Validation loss: 0.000, valid_NMSE: -1.675e+01
--------------------------------------------------
[INFO]: Epoch 69 of 200
Training
[69,   100] loss: 7.493e-06
[69,   200] loss: 7.525e-06
Validation
[69,   100] loss: 1.017e-05
[69,   200] loss: 1.014e-05
Training loss: 0.000, train NMSE: -1.769e+01
Validation loss: 0.000, valid_NMSE: -1.681e+01

Best validation loss: -16.80893325805664

Saving best model for epoch: 69

--------------------------------------------------
[INFO]: Epoch 70 of 200
Training
[70,   100] loss: 7.268e-06
[70,   200] loss: 7.600e-06
Validation
[70,   100] loss: 1.029e-05
[70,   200] loss: 1.026e-05
Training loss: 0.000, train NMSE: -1.776e+01
Validation loss: 0.000, valid_NMSE: -1.673e+01
--------------------------------------------------
[INFO]: Epoch 71 of 200
Training
[71,   100] loss: 7.231e-06
[71,   200] loss: 7.488e-06
Validation
[71,   100] loss: 1.012e-05
[71,   200] loss: 1.007e-05
Training loss: 0.000, train NMSE: -1.832e+01
Validation loss: 0.000, valid_NMSE: -1.687e+01

Best validation loss: -16.866243362426758

Saving best model for epoch: 71

--------------------------------------------------
[INFO]: Epoch 72 of 200
Training
[72,   100] loss: 7.236e-06
[72,   200] loss: 7.400e-06
Validation
[72,   100] loss: 1.012e-05
[72,   200] loss: 1.008e-05
Training loss: 0.000, train NMSE: -1.838e+01
Validation loss: 0.000, valid_NMSE: -1.694e+01

Best validation loss: -16.939090728759766

Saving best model for epoch: 72

--------------------------------------------------
[INFO]: Epoch 73 of 200
Training
[73,   100] loss: 7.222e-06
[73,   200] loss: 7.313e-06
Validation
[73,   100] loss: 1.003e-05
[73,   200] loss: 9.990e-06
Training loss: 0.000, train NMSE: -1.883e+01
Validation loss: 0.000, valid_NMSE: -1.690e+01
--------------------------------------------------
[INFO]: Epoch 74 of 200
Training
[74,   100] loss: 7.221e-06
[74,   200] loss: 7.246e-06
Validation
[74,   100] loss: 9.969e-06
[74,   200] loss: 9.927e-06
Training loss: 0.000, train NMSE: -1.875e+01
Validation loss: 0.000, valid_NMSE: -1.698e+01

Best validation loss: -16.981990814208984

Saving best model for epoch: 74

--------------------------------------------------
[INFO]: Epoch 75 of 200
Training
[75,   100] loss: 7.065e-06
[75,   200] loss: 7.219e-06
Validation
[75,   100] loss: 9.945e-06
[75,   200] loss: 9.898e-06
Training loss: 0.000, train NMSE: -1.799e+01
Validation loss: 0.000, valid_NMSE: -1.693e+01
--------------------------------------------------
[INFO]: Epoch 76 of 200
Training
[76,   100] loss: 6.999e-06
[76,   200] loss: 7.171e-06
Validation
[76,   100] loss: 9.896e-06
[76,   200] loss: 9.842e-06
Training loss: 0.000, train NMSE: -1.852e+01
Validation loss: 0.000, valid_NMSE: -1.700e+01

Best validation loss: -16.998342514038086

Saving best model for epoch: 76

--------------------------------------------------
[INFO]: Epoch 77 of 200
Training
[77,   100] loss: 7.104e-06
[77,   200] loss: 7.068e-06
Validation
[77,   100] loss: 9.778e-06
[77,   200] loss: 9.726e-06
Training loss: 0.000, train NMSE: -1.816e+01
Validation loss: 0.000, valid_NMSE: -1.697e+01
--------------------------------------------------
[INFO]: Epoch 78 of 200
Training
[78,   100] loss: 7.025e-06
[78,   200] loss: 7.009e-06
Validation
[78,   100] loss: 9.874e-06
[78,   200] loss: 9.836e-06
Training loss: 0.000, train NMSE: -1.869e+01
Validation loss: 0.000, valid_NMSE: -1.703e+01

Best validation loss: -17.033803939819336

Saving best model for epoch: 78

--------------------------------------------------
[INFO]: Epoch 79 of 200
Training
[79,   100] loss: 7.002e-06
[79,   200] loss: 7.004e-06
Validation
[79,   100] loss: 9.719e-06
[79,   200] loss: 9.685e-06
Training loss: 0.000, train NMSE: -1.829e+01
Validation loss: 0.000, valid_NMSE: -1.704e+01

Best validation loss: -17.04047393798828

Saving best model for epoch: 79

--------------------------------------------------
[INFO]: Epoch 80 of 200
Training
[80,   100] loss: 6.763e-06
[80,   200] loss: 7.056e-06
Validation
[80,   100] loss: 9.748e-06
[80,   200] loss: 9.707e-06
Training loss: 0.000, train NMSE: -1.780e+01
Validation loss: 0.000, valid_NMSE: -1.702e+01
--------------------------------------------------
[INFO]: Epoch 81 of 200
Training
[81,   100] loss: 6.858e-06
[81,   200] loss: 6.927e-06
Validation
[81,   100] loss: 9.767e-06
[81,   200] loss: 9.719e-06
Training loss: 0.000, train NMSE: -1.873e+01
Validation loss: 0.000, valid_NMSE: -1.689e+01
--------------------------------------------------
[INFO]: Epoch 82 of 200
Training
[82,   100] loss: 6.802e-06
[82,   200] loss: 6.841e-06
Validation
[82,   100] loss: 9.799e-06
[82,   200] loss: 9.749e-06
Training loss: 0.000, train NMSE: -1.884e+01
Validation loss: 0.000, valid_NMSE: -1.702e+01
--------------------------------------------------
[INFO]: Epoch 83 of 200
Training
[83,   100] loss: 6.834e-06
[83,   200] loss: 6.750e-06
Validation
[83,   100] loss: 9.547e-06
[83,   200] loss: 9.510e-06
Training loss: 0.000, train NMSE: -1.826e+01
Validation loss: 0.000, valid_NMSE: -1.711e+01

Best validation loss: -17.10662078857422

Saving best model for epoch: 83

--------------------------------------------------
[INFO]: Epoch 84 of 200
Training
[84,   100] loss: 6.677e-06
[84,   200] loss: 6.852e-06
Validation
[84,   100] loss: 9.500e-06
[84,   200] loss: 9.457e-06
Training loss: 0.000, train NMSE: -1.843e+01
Validation loss: 0.000, valid_NMSE: -1.715e+01

Best validation loss: -17.1495361328125

Saving best model for epoch: 84

--------------------------------------------------
[INFO]: Epoch 85 of 200
Training
[85,   100] loss: 6.655e-06
[85,   200] loss: 6.745e-06
Validation
[85,   100] loss: 9.619e-06
[85,   200] loss: 9.592e-06
Training loss: 0.000, train NMSE: -1.799e+01
Validation loss: 0.000, valid_NMSE: -1.696e+01
--------------------------------------------------
[INFO]: Epoch 86 of 200
Training
[86,   100] loss: 6.585e-06
[86,   200] loss: 6.766e-06
Validation
[86,   100] loss: 9.490e-06
[86,   200] loss: 9.444e-06
Training loss: 0.000, train NMSE: -1.843e+01
Validation loss: 0.000, valid_NMSE: -1.713e+01
--------------------------------------------------
[INFO]: Epoch 87 of 200
Training
[87,   100] loss: 6.565e-06
[87,   200] loss: 6.642e-06
Validation
[87,   100] loss: 9.621e-06
[87,   200] loss: 9.566e-06
Training loss: 0.000, train NMSE: -1.877e+01
Validation loss: 0.000, valid_NMSE: -1.711e+01
--------------------------------------------------
[INFO]: Epoch 88 of 200
Training
[88,   100] loss: 6.515e-06
[88,   200] loss: 6.649e-06
Validation
[88,   100] loss: 9.394e-06
[88,   200] loss: 9.352e-06
Training loss: 0.000, train NMSE: -1.842e+01
Validation loss: 0.000, valid_NMSE: -1.714e+01
--------------------------------------------------
[INFO]: Epoch 89 of 200
Training
[89,   100] loss: 6.393e-06
[89,   200] loss: 6.689e-06
Validation
[89,   100] loss: 9.416e-06
[89,   200] loss: 9.362e-06
Training loss: 0.000, train NMSE: -1.868e+01
Validation loss: 0.000, valid_NMSE: -1.724e+01

Best validation loss: -17.243247985839844

Saving best model for epoch: 89

--------------------------------------------------
[INFO]: Epoch 90 of 200
Training
[90,   100] loss: 6.475e-06
[90,   200] loss: 6.524e-06
Validation
[90,   100] loss: 9.358e-06
[90,   200] loss: 9.307e-06
Training loss: 0.000, train NMSE: -1.834e+01
Validation loss: 0.000, valid_NMSE: -1.719e+01
--------------------------------------------------
[INFO]: Epoch 91 of 200
Training
[91,   100] loss: 6.439e-06
[91,   200] loss: 6.527e-06
Validation
[91,   100] loss: 9.415e-06
[91,   200] loss: 9.370e-06
Training loss: 0.000, train NMSE: -1.847e+01
Validation loss: 0.000, valid_NMSE: -1.714e+01
--------------------------------------------------
[INFO]: Epoch 92 of 200
Training
[92,   100] loss: 6.381e-06
[92,   200] loss: 6.516e-06
Validation
[92,   100] loss: 9.412e-06
[92,   200] loss: 9.371e-06
Training loss: 0.000, train NMSE: -1.870e+01
Validation loss: 0.000, valid_NMSE: -1.717e+01
--------------------------------------------------
[INFO]: Epoch 93 of 200
Training
[93,   100] loss: 6.265e-06
[93,   200] loss: 6.507e-06
Validation
[93,   100] loss: 9.366e-06
[93,   200] loss: 9.314e-06
Training loss: 0.000, train NMSE: -1.869e+01
Validation loss: 0.000, valid_NMSE: -1.722e+01
--------------------------------------------------
[INFO]: Epoch 94 of 200
Training
[94,   100] loss: 6.310e-06
[94,   200] loss: 6.472e-06
Validation
[94,   100] loss: 9.269e-06
[94,   200] loss: 9.215e-06
Training loss: 0.000, train NMSE: -1.935e+01
Validation loss: 0.000, valid_NMSE: -1.728e+01

Best validation loss: -17.281524658203125

Saving best model for epoch: 94

--------------------------------------------------
[INFO]: Epoch 95 of 200
Training
[95,   100] loss: 6.342e-06
[95,   200] loss: 6.290e-06
Validation
[95,   100] loss: 9.194e-06
[95,   200] loss: 9.130e-06
Training loss: 0.000, train NMSE: -1.844e+01
Validation loss: 0.000, valid_NMSE: -1.724e+01
--------------------------------------------------
[INFO]: Epoch 96 of 200
Training
[96,   100] loss: 6.101e-06
[96,   200] loss: 6.525e-06
Validation
[96,   100] loss: 9.318e-06
[96,   200] loss: 9.258e-06
Training loss: 0.000, train NMSE: -1.870e+01
Validation loss: 0.000, valid_NMSE: -1.716e+01
--------------------------------------------------
[INFO]: Epoch 97 of 200
Training
[97,   100] loss: 6.194e-06
[97,   200] loss: 6.345e-06
Validation
[97,   100] loss: 9.223e-06
[97,   200] loss: 9.166e-06
Training loss: 0.000, train NMSE: -1.897e+01
Validation loss: 0.000, valid_NMSE: -1.720e+01
--------------------------------------------------
[INFO]: Epoch 98 of 200
Training
[98,   100] loss: 6.172e-06
[98,   200] loss: 6.357e-06
Validation
[98,   100] loss: 9.149e-06
[98,   200] loss: 9.093e-06
Training loss: 0.000, train NMSE: -1.832e+01
Validation loss: 0.000, valid_NMSE: -1.729e+01

Best validation loss: -17.294931411743164

Saving best model for epoch: 98

--------------------------------------------------
[INFO]: Epoch 99 of 200
Training
[99,   100] loss: 6.142e-06
[99,   200] loss: 6.231e-06
Validation
[99,   100] loss: 9.200e-06
[99,   200] loss: 9.143e-06
Training loss: 0.000, train NMSE: -1.895e+01
Validation loss: 0.000, valid_NMSE: -1.723e+01
--------------------------------------------------
[INFO]: Epoch 100 of 200
Training
[100,   100] loss: 6.219e-06
[100,   200] loss: 6.140e-06
Validation
[100,   100] loss: 9.049e-06
[100,   200] loss: 8.992e-06
Training loss: 0.000, train NMSE: -1.848e+01
Validation loss: 0.000, valid_NMSE: -1.729e+01
--------------------------------------------------
[INFO]: Epoch 101 of 200
Training
[101,   100] loss: 6.132e-06
[101,   200] loss: 6.110e-06
Validation
[101,   100] loss: 9.053e-06
[101,   200] loss: 9.000e-06
Training loss: 0.000, train NMSE: -1.901e+01
Validation loss: 0.000, valid_NMSE: -1.726e+01
--------------------------------------------------
[INFO]: Epoch 102 of 200
Training
[102,   100] loss: 6.100e-06
[102,   200] loss: 6.044e-06
Validation
[102,   100] loss: 8.980e-06
[102,   200] loss: 8.925e-06
Training loss: 0.000, train NMSE: -1.875e+01
Validation loss: 0.000, valid_NMSE: -1.733e+01

Best validation loss: -17.32864761352539

Saving best model for epoch: 102

--------------------------------------------------
[INFO]: Epoch 103 of 200
Training
[103,   100] loss: 6.037e-06
[103,   200] loss: 6.165e-06
Validation
[103,   100] loss: 9.063e-06
[103,   200] loss: 9.011e-06
Training loss: 0.000, train NMSE: -1.861e+01
Validation loss: 0.000, valid_NMSE: -1.727e+01
--------------------------------------------------
[INFO]: Epoch 104 of 200
Training
[104,   100] loss: 5.926e-06
[104,   200] loss: 6.168e-06
Validation
[104,   100] loss: 8.944e-06
[104,   200] loss: 8.882e-06
Training loss: 0.000, train NMSE: -1.889e+01
Validation loss: 0.000, valid_NMSE: -1.737e+01

Best validation loss: -17.36526870727539

Saving best model for epoch: 104

--------------------------------------------------
[INFO]: Epoch 105 of 200
Training
[105,   100] loss: 5.947e-06
[105,   200] loss: 6.063e-06
Validation
[105,   100] loss: 8.832e-06
[105,   200] loss: 8.778e-06
Training loss: 0.000, train NMSE: -1.849e+01
Validation loss: 0.000, valid_NMSE: -1.742e+01

Best validation loss: -17.4233455657959

Saving best model for epoch: 105

--------------------------------------------------
[INFO]: Epoch 106 of 200
Training
[106,   100] loss: 5.920e-06
[106,   200] loss: 6.066e-06
Validation
[106,   100] loss: 9.053e-06
[106,   200] loss: 9.006e-06
Training loss: 0.000, train NMSE: -1.894e+01
Validation loss: 0.000, valid_NMSE: -1.730e+01
--------------------------------------------------
[INFO]: Epoch 107 of 200
Training
[107,   100] loss: 5.967e-06
[107,   200] loss: 5.921e-06
Validation
[107,   100] loss: 8.977e-06
[107,   200] loss: 8.917e-06
Training loss: 0.000, train NMSE: -1.938e+01
Validation loss: 0.000, valid_NMSE: -1.733e+01
--------------------------------------------------
[INFO]: Epoch 108 of 200
Training
[108,   100] loss: 5.832e-06
[108,   200] loss: 6.045e-06
Validation
[108,   100] loss: 8.827e-06
[108,   200] loss: 8.779e-06
Training loss: 0.000, train NMSE: -1.919e+01
Validation loss: 0.000, valid_NMSE: -1.739e+01
--------------------------------------------------
[INFO]: Epoch 109 of 200
Training
[109,   100] loss: 5.795e-06
[109,   200] loss: 5.994e-06
Validation
[109,   100] loss: 8.811e-06
[109,   200] loss: 8.772e-06
Training loss: 0.000, train NMSE: -1.908e+01
Validation loss: 0.000, valid_NMSE: -1.739e+01
--------------------------------------------------
[INFO]: Epoch 110 of 200
Training
[110,   100] loss: 5.759e-06
[110,   200] loss: 5.971e-06
Validation
[110,   100] loss: 8.807e-06
[110,   200] loss: 8.754e-06
Training loss: 0.000, train NMSE: -1.967e+01
Validation loss: 0.000, valid_NMSE: -1.736e+01
--------------------------------------------------
[INFO]: Epoch 111 of 200
Training
[111,   100] loss: 5.835e-06
[111,   200] loss: 5.873e-06
Validation
[111,   100] loss: 8.878e-06
[111,   200] loss: 8.826e-06
Training loss: 0.000, train NMSE: -1.894e+01
Validation loss: 0.000, valid_NMSE: -1.729e+01
--------------------------------------------------
[INFO]: Epoch 112 of 200
Training
[112,   100] loss: 5.834e-06
[112,   200] loss: 5.801e-06
Validation
[112,   100] loss: 8.775e-06
[112,   200] loss: 8.720e-06
Training loss: 0.000, train NMSE: -1.898e+01
Validation loss: 0.000, valid_NMSE: -1.747e+01

Best validation loss: -17.465103149414062

Saving best model for epoch: 112

--------------------------------------------------
[INFO]: Epoch 113 of 200
Training
[113,   100] loss: 5.716e-06
[113,   200] loss: 5.874e-06
Validation
[113,   100] loss: 8.745e-06
[113,   200] loss: 8.681e-06
Training loss: 0.000, train NMSE: -1.870e+01
Validation loss: 0.000, valid_NMSE: -1.736e+01
--------------------------------------------------
[INFO]: Epoch 114 of 200
Training
[114,   100] loss: 5.671e-06
[114,   200] loss: 5.850e-06
Validation
[114,   100] loss: 8.747e-06
[114,   200] loss: 8.692e-06
Training loss: 0.000, train NMSE: -1.880e+01
Validation loss: 0.000, valid_NMSE: -1.742e+01
--------------------------------------------------
[INFO]: Epoch 115 of 200
Training
[115,   100] loss: 5.590e-06
[115,   200] loss: 5.877e-06
Validation
[115,   100] loss: 8.781e-06
[115,   200] loss: 8.734e-06
Training loss: 0.000, train NMSE: -1.886e+01
Validation loss: 0.000, valid_NMSE: -1.742e+01
--------------------------------------------------
[INFO]: Epoch 116 of 200
Training
[116,   100] loss: 5.712e-06
[116,   200] loss: 5.748e-06
Validation
[116,   100] loss: 8.759e-06
[116,   200] loss: 8.690e-06
Training loss: 0.000, train NMSE: -1.877e+01
Validation loss: 0.000, valid_NMSE: -1.748e+01

Best validation loss: -17.47930145263672

Saving best model for epoch: 116

--------------------------------------------------
[INFO]: Epoch 117 of 200
Training
[117,   100] loss: 5.696e-06
[117,   200] loss: 5.735e-06
Validation
[117,   100] loss: 8.625e-06
[117,   200] loss: 8.565e-06
Training loss: 0.000, train NMSE: -1.910e+01
Validation loss: 0.000, valid_NMSE: -1.751e+01

Best validation loss: -17.505638122558594

Saving best model for epoch: 117

--------------------------------------------------
[INFO]: Epoch 118 of 200
Training
[118,   100] loss: 5.649e-06
[118,   200] loss: 5.708e-06
Validation
[118,   100] loss: 8.728e-06
[118,   200] loss: 8.680e-06
Training loss: 0.000, train NMSE: -1.858e+01
Validation loss: 0.000, valid_NMSE: -1.738e+01
--------------------------------------------------
[INFO]: Epoch 119 of 200
Training
[119,   100] loss: 5.665e-06
[119,   200] loss: 5.612e-06
Validation
[119,   100] loss: 8.574e-06
[119,   200] loss: 8.509e-06
Training loss: 0.000, train NMSE: -1.993e+01
Validation loss: 0.000, valid_NMSE: -1.749e+01
--------------------------------------------------
[INFO]: Epoch 120 of 200
Training
[120,   100] loss: 5.604e-06
[120,   200] loss: 5.684e-06
Validation
[120,   100] loss: 8.594e-06
[120,   200] loss: 8.534e-06
Training loss: 0.000, train NMSE: -1.940e+01
Validation loss: 0.000, valid_NMSE: -1.747e+01
--------------------------------------------------
[INFO]: Epoch 121 of 200
Training
[121,   100] loss: 5.612e-06
[121,   200] loss: 5.641e-06
Validation
[121,   100] loss: 8.549e-06
[121,   200] loss: 8.491e-06
Training loss: 0.000, train NMSE: -1.968e+01
Validation loss: 0.000, valid_NMSE: -1.752e+01

Best validation loss: -17.51780128479004

Saving best model for epoch: 121

--------------------------------------------------
[INFO]: Epoch 122 of 200
Training
[122,   100] loss: 5.527e-06
[122,   200] loss: 5.608e-06
Validation
[122,   100] loss: 8.530e-06
[122,   200] loss: 8.471e-06
Training loss: 0.000, train NMSE: -1.974e+01
Validation loss: 0.000, valid_NMSE: -1.751e+01
--------------------------------------------------
[INFO]: Epoch 123 of 200
Training
[123,   100] loss: 5.479e-06
[123,   200] loss: 5.623e-06
Validation
[123,   100] loss: 8.659e-06
[123,   200] loss: 8.592e-06
Training loss: 0.000, train NMSE: -1.955e+01
Validation loss: 0.000, valid_NMSE: -1.747e+01
--------------------------------------------------
[INFO]: Epoch 124 of 200
Training
[124,   100] loss: 5.453e-06
[124,   200] loss: 5.622e-06
Validation
[124,   100] loss: 8.560e-06
[124,   200] loss: 8.495e-06
Training loss: 0.000, train NMSE: -1.943e+01
Validation loss: 0.000, valid_NMSE: -1.754e+01

Best validation loss: -17.54196548461914

Saving best model for epoch: 124

--------------------------------------------------
[INFO]: Epoch 125 of 200
Training
[125,   100] loss: 5.358e-06
[125,   200] loss: 5.611e-06
Validation
[125,   100] loss: 8.624e-06
[125,   200] loss: 8.556e-06
Training loss: 0.000, train NMSE: -1.896e+01
Validation loss: 0.000, valid_NMSE: -1.749e+01
--------------------------------------------------
[INFO]: Epoch 126 of 200
Training
[126,   100] loss: 5.441e-06
[126,   200] loss: 5.577e-06
Validation
[126,   100] loss: 8.629e-06
[126,   200] loss: 8.563e-06
Training loss: 0.000, train NMSE: -1.960e+01
Validation loss: 0.000, valid_NMSE: -1.743e+01
--------------------------------------------------
[INFO]: Epoch 127 of 200
Training
[127,   100] loss: 5.403e-06
[127,   200] loss: 5.433e-06
Validation
[127,   100] loss: 8.492e-06
[127,   200] loss: 8.413e-06
Training loss: 0.000, train NMSE: -1.969e+01
Validation loss: 0.000, valid_NMSE: -1.756e+01

Best validation loss: -17.556852340698242

Saving best model for epoch: 127

--------------------------------------------------
[INFO]: Epoch 128 of 200
Training
[128,   100] loss: 5.326e-06
[128,   200] loss: 5.533e-06
Validation
[128,   100] loss: 8.530e-06
[128,   200] loss: 8.454e-06
Training loss: 0.000, train NMSE: -1.972e+01
Validation loss: 0.000, valid_NMSE: -1.744e+01
--------------------------------------------------
[INFO]: Epoch 129 of 200
Training
[129,   100] loss: 5.338e-06
[129,   200] loss: 5.521e-06
Validation
[129,   100] loss: 8.460e-06
[129,   200] loss: 8.394e-06
Training loss: 0.000, train NMSE: -2.005e+01
Validation loss: 0.000, valid_NMSE: -1.752e+01
--------------------------------------------------
[INFO]: Epoch 130 of 200
Training
[130,   100] loss: 5.309e-06
[130,   200] loss: 5.412e-06
Validation
[130,   100] loss: 8.392e-06
[130,   200] loss: 8.320e-06
Training loss: 0.000, train NMSE: -1.885e+01
Validation loss: 0.000, valid_NMSE: -1.755e+01
--------------------------------------------------
[INFO]: Epoch 131 of 200
Training
[131,   100] loss: 5.367e-06
[131,   200] loss: 5.402e-06
Validation
[131,   100] loss: 8.481e-06
[131,   200] loss: 8.407e-06
Training loss: 0.000, train NMSE: -1.891e+01
Validation loss: 0.000, valid_NMSE: -1.748e+01
--------------------------------------------------
[INFO]: Epoch 132 of 200
Training
[132,   100] loss: 5.414e-06
[132,   200] loss: 5.385e-06
Validation
[132,   100] loss: 8.528e-06
[132,   200] loss: 8.454e-06
Training loss: 0.000, train NMSE: -1.904e+01
Validation loss: 0.000, valid_NMSE: -1.745e+01
--------------------------------------------------
[INFO]: Epoch 133 of 200
Training
[133,   100] loss: 5.282e-06
[133,   200] loss: 5.397e-06
Validation
[133,   100] loss: 8.364e-06
[133,   200] loss: 8.290e-06
Training loss: 0.000, train NMSE: -1.866e+01
Validation loss: 0.000, valid_NMSE: -1.757e+01

Best validation loss: -17.569711685180664

Saving best model for epoch: 133

--------------------------------------------------
[INFO]: Epoch 134 of 200
Training
[134,   100] loss: 5.247e-06
[134,   200] loss: 5.414e-06
Validation
[134,   100] loss: 8.427e-06
[134,   200] loss: 8.356e-06
Training loss: 0.000, train NMSE: -1.940e+01
Validation loss: 0.000, valid_NMSE: -1.754e+01
--------------------------------------------------
[INFO]: Epoch 135 of 200
Training
[135,   100] loss: 5.286e-06
[135,   200] loss: 5.376e-06
Validation
[135,   100] loss: 8.411e-06
[135,   200] loss: 8.341e-06
Training loss: 0.000, train NMSE: -1.946e+01
Validation loss: 0.000, valid_NMSE: -1.752e+01
--------------------------------------------------
[INFO]: Epoch 136 of 200
Training
[136,   100] loss: 5.257e-06
[136,   200] loss: 5.333e-06
Validation
[136,   100] loss: 8.403e-06
[136,   200] loss: 8.340e-06
Training loss: 0.000, train NMSE: -1.979e+01
Validation loss: 0.000, valid_NMSE: -1.745e+01
--------------------------------------------------
[INFO]: Epoch 137 of 200
Training
[137,   100] loss: 5.233e-06
[137,   200] loss: 5.254e-06
Validation
[137,   100] loss: 8.380e-06
[137,   200] loss: 8.324e-06
Training loss: 0.000, train NMSE: -1.989e+01
Validation loss: 0.000, valid_NMSE: -1.743e+01
--------------------------------------------------
[INFO]: Epoch 138 of 200
Training
[138,   100] loss: 5.194e-06
[138,   200] loss: 5.300e-06
Validation
[138,   100] loss: 8.363e-06
[138,   200] loss: 8.300e-06
Training loss: 0.000, train NMSE: -1.947e+01
Validation loss: 0.000, valid_NMSE: -1.751e+01
--------------------------------------------------
[INFO]: Epoch 139 of 200
Training
[139,   100] loss: 5.114e-06
[139,   200] loss: 5.304e-06
Validation
[139,   100] loss: 8.362e-06
[139,   200] loss: 8.288e-06
Training loss: 0.000, train NMSE: -1.977e+01
Validation loss: 0.000, valid_NMSE: -1.751e+01
--------------------------------------------------
[INFO]: Epoch 140 of 200
Training
[140,   100] loss: 5.228e-06
[140,   200] loss: 5.230e-06
Validation
[140,   100] loss: 8.297e-06
[140,   200] loss: 8.222e-06
Training loss: 0.000, train NMSE: -2.024e+01
Validation loss: 0.000, valid_NMSE: -1.765e+01

Best validation loss: -17.652252197265625

Saving best model for epoch: 140

--------------------------------------------------
[INFO]: Epoch 141 of 200
Training
[141,   100] loss: 5.132e-06
[141,   200] loss: 5.238e-06
Validation
[141,   100] loss: 8.329e-06
[141,   200] loss: 8.239e-06
Training loss: 0.000, train NMSE: -1.931e+01
Validation loss: 0.000, valid_NMSE: -1.746e+01
--------------------------------------------------
[INFO]: Epoch 142 of 200
Training
[142,   100] loss: 5.107e-06
[142,   200] loss: 5.224e-06
Validation
[142,   100] loss: 8.286e-06
[142,   200] loss: 8.221e-06
Training loss: 0.000, train NMSE: -1.953e+01
Validation loss: 0.000, valid_NMSE: -1.759e+01
--------------------------------------------------
[INFO]: Epoch 143 of 200
Training
[143,   100] loss: 5.130e-06
[143,   200] loss: 5.185e-06
Validation
[143,   100] loss: 8.324e-06
[143,   200] loss: 8.251e-06
Training loss: 0.000, train NMSE: -1.975e+01
Validation loss: 0.000, valid_NMSE: -1.749e+01
--------------------------------------------------
[INFO]: Epoch 144 of 200
Training
[144,   100] loss: 5.080e-06
[144,   200] loss: 5.141e-06
Validation
[144,   100] loss: 8.313e-06
[144,   200] loss: 8.252e-06
Training loss: 0.000, train NMSE: -1.994e+01
Validation loss: 0.000, valid_NMSE: -1.756e+01
--------------------------------------------------
[INFO]: Epoch 145 of 200
Training
[145,   100] loss: 5.082e-06
[145,   200] loss: 5.130e-06
Validation
[145,   100] loss: 8.360e-06
[145,   200] loss: 8.294e-06
Training loss: 0.000, train NMSE: -1.951e+01
Validation loss: 0.000, valid_NMSE: -1.754e+01
--------------------------------------------------
[INFO]: Epoch 146 of 200
Training
[146,   100] loss: 5.048e-06
[146,   200] loss: 5.112e-06
Validation
[146,   100] loss: 8.245e-06
[146,   200] loss: 8.168e-06
Training loss: 0.000, train NMSE: -1.995e+01
Validation loss: 0.000, valid_NMSE: -1.759e+01
--------------------------------------------------
[INFO]: Epoch 147 of 200
Training
[147,   100] loss: 5.011e-06
[147,   200] loss: 5.105e-06
Validation
[147,   100] loss: 8.378e-06
[147,   200] loss: 8.309e-06
Training loss: 0.000, train NMSE: -1.931e+01
Validation loss: 0.000, valid_NMSE: -1.750e+01
--------------------------------------------------
[INFO]: Epoch 148 of 200
Training
[148,   100] loss: 5.033e-06
[148,   200] loss: 5.077e-06
Validation
[148,   100] loss: 8.211e-06
[148,   200] loss: 8.148e-06
Training loss: 0.000, train NMSE: -1.961e+01
Validation loss: 0.000, valid_NMSE: -1.752e+01
--------------------------------------------------
[INFO]: Epoch 149 of 200
Training
[149,   100] loss: 4.988e-06
[149,   200] loss: 5.091e-06
Validation
[149,   100] loss: 8.208e-06
[149,   200] loss: 8.148e-06
Training loss: 0.000, train NMSE: -1.940e+01
Validation loss: 0.000, valid_NMSE: -1.759e+01
--------------------------------------------------
[INFO]: Epoch 150 of 200
Training
[150,   100] loss: 5.010e-06
[150,   200] loss: 5.054e-06
Validation
[150,   100] loss: 8.141e-06
[150,   200] loss: 8.069e-06
Training loss: 0.000, train NMSE: -1.954e+01
Validation loss: 0.000, valid_NMSE: -1.765e+01
--------------------------------------------------
[INFO]: Epoch 151 of 200
Training
[151,   100] loss: 4.914e-06
[151,   200] loss: 5.104e-06
Validation
[151,   100] loss: 8.170e-06
[151,   200] loss: 8.102e-06
Training loss: 0.000, train NMSE: -2.031e+01
Validation loss: 0.000, valid_NMSE: -1.762e+01
--------------------------------------------------
[INFO]: Epoch 152 of 200
Training
[152,   100] loss: 4.945e-06
[152,   200] loss: 5.013e-06
Validation
[152,   100] loss: 8.171e-06
[152,   200] loss: 8.100e-06
Training loss: 0.000, train NMSE: -1.937e+01
Validation loss: 0.000, valid_NMSE: -1.758e+01
--------------------------------------------------
[INFO]: Epoch 153 of 200
Training
[153,   100] loss: 4.955e-06
[153,   200] loss: 4.931e-06
Validation
[153,   100] loss: 8.087e-06
[153,   200] loss: 8.023e-06
Training loss: 0.000, train NMSE: -1.939e+01
Validation loss: 0.000, valid_NMSE: -1.769e+01

Best validation loss: -17.690765380859375

Saving best model for epoch: 153

--------------------------------------------------
[INFO]: Epoch 154 of 200
Training
[154,   100] loss: 4.900e-06
[154,   200] loss: 4.998e-06
Validation
[154,   100] loss: 8.272e-06
[154,   200] loss: 8.196e-06
Training loss: 0.000, train NMSE: -1.977e+01
Validation loss: 0.000, valid_NMSE: -1.757e+01
--------------------------------------------------
[INFO]: Epoch 155 of 200
Training
[155,   100] loss: 4.908e-06
[155,   200] loss: 5.073e-06
Validation
[155,   100] loss: 8.168e-06
[155,   200] loss: 8.092e-06
Training loss: 0.000, train NMSE: -1.981e+01
Validation loss: 0.000, valid_NMSE: -1.768e+01
--------------------------------------------------
[INFO]: Epoch 156 of 200
Training
[156,   100] loss: 4.923e-06
[156,   200] loss: 4.992e-06
Validation
[156,   100] loss: 8.151e-06
[156,   200] loss: 8.079e-06
Training loss: 0.000, train NMSE: -1.968e+01
Validation loss: 0.000, valid_NMSE: -1.767e+01
--------------------------------------------------
[INFO]: Epoch 157 of 200
Training
[157,   100] loss: 4.818e-06
[157,   200] loss: 4.907e-06
Validation
[157,   100] loss: 8.122e-06
[157,   200] loss: 8.040e-06
Training loss: 0.000, train NMSE: -2.001e+01
Validation loss: 0.000, valid_NMSE: -1.765e+01
--------------------------------------------------
[INFO]: Epoch 158 of 200
Training
[158,   100] loss: 4.804e-06
[158,   200] loss: 4.933e-06
Validation
[158,   100] loss: 8.084e-06
[158,   200] loss: 8.021e-06
Training loss: 0.000, train NMSE: -1.961e+01
Validation loss: 0.000, valid_NMSE: -1.759e+01
--------------------------------------------------
[INFO]: Epoch 159 of 200
Training
[159,   100] loss: 4.814e-06
[159,   200] loss: 5.011e-06
Validation
[159,   100] loss: 8.094e-06
[159,   200] loss: 8.022e-06
Training loss: 0.000, train NMSE: -1.996e+01
Validation loss: 0.000, valid_NMSE: -1.765e+01
--------------------------------------------------
[INFO]: Epoch 160 of 200
Training
[160,   100] loss: 4.817e-06
[160,   200] loss: 4.930e-06
Validation
[160,   100] loss: 8.180e-06
[160,   200] loss: 8.108e-06
Training loss: 0.000, train NMSE: -1.956e+01
Validation loss: 0.000, valid_NMSE: -1.752e+01
--------------------------------------------------
[INFO]: Epoch 161 of 200
Training
[161,   100] loss: 4.792e-06
[161,   200] loss: 4.890e-06
Validation
[161,   100] loss: 8.110e-06
[161,   200] loss: 8.027e-06
Training loss: 0.000, train NMSE: -1.982e+01
Validation loss: 0.000, valid_NMSE: -1.757e+01
--------------------------------------------------
[INFO]: Epoch 162 of 200
Training
[162,   100] loss: 4.803e-06
[162,   200] loss: 4.840e-06
Validation
[162,   100] loss: 8.145e-06
[162,   200] loss: 8.077e-06
Training loss: 0.000, train NMSE: -1.965e+01
Validation loss: 0.000, valid_NMSE: -1.759e+01
--------------------------------------------------
[INFO]: Epoch 163 of 200
Training
[163,   100] loss: 4.613e-06
[163,   200] loss: 4.931e-06
Validation
[163,   100] loss: 8.000e-06
[163,   200] loss: 7.921e-06
Training loss: 0.000, train NMSE: -1.949e+01
Validation loss: 0.000, valid_NMSE: -1.770e+01

Best validation loss: -17.69771957397461

Saving best model for epoch: 163

--------------------------------------------------
[INFO]: Epoch 164 of 200
Training
[164,   100] loss: 4.748e-06
[164,   200] loss: 4.863e-06
Validation
[164,   100] loss: 8.028e-06
[164,   200] loss: 7.951e-06
Training loss: 0.000, train NMSE: -1.987e+01
Validation loss: 0.000, valid_NMSE: -1.770e+01
--------------------------------------------------
[INFO]: Epoch 165 of 200
Training
[165,   100] loss: 4.710e-06
[165,   200] loss: 4.859e-06
Validation
[165,   100] loss: 8.117e-06
[165,   200] loss: 8.039e-06
Training loss: 0.000, train NMSE: -2.020e+01
Validation loss: 0.000, valid_NMSE: -1.760e+01
--------------------------------------------------
[INFO]: Epoch 166 of 200
Training
[166,   100] loss: 4.744e-06
[166,   200] loss: 4.794e-06
Validation
[166,   100] loss: 7.989e-06
[166,   200] loss: 7.914e-06
Training loss: 0.000, train NMSE: -1.989e+01
Validation loss: 0.000, valid_NMSE: -1.771e+01

Best validation loss: -17.713993072509766

Saving best model for epoch: 166

--------------------------------------------------
[INFO]: Epoch 167 of 200
Training
[167,   100] loss: 4.686e-06
[167,   200] loss: 4.789e-06
Validation
[167,   100] loss: 8.029e-06
[167,   200] loss: 7.952e-06
Training loss: 0.000, train NMSE: -2.005e+01
Validation loss: 0.000, valid_NMSE: -1.764e+01
--------------------------------------------------
[INFO]: Epoch 168 of 200
Training
[168,   100] loss: 4.706e-06
[168,   200] loss: 4.804e-06
Validation
[168,   100] loss: 8.034e-06
[168,   200] loss: 7.955e-06
Training loss: 0.000, train NMSE: -1.996e+01
Validation loss: 0.000, valid_NMSE: -1.759e+01
--------------------------------------------------
[INFO]: Epoch 169 of 200
Training
[169,   100] loss: 4.607e-06
[169,   200] loss: 4.810e-06
Validation
[169,   100] loss: 7.990e-06
[169,   200] loss: 7.912e-06
Training loss: 0.000, train NMSE: -1.937e+01
Validation loss: 0.000, valid_NMSE: -1.761e+01
--------------------------------------------------
[INFO]: Epoch 170 of 200
Training
[170,   100] loss: 4.725e-06
[170,   200] loss: 4.695e-06
Validation
[170,   100] loss: 7.975e-06
[170,   200] loss: 7.888e-06
Training loss: 0.000, train NMSE: -1.982e+01
Validation loss: 0.000, valid_NMSE: -1.770e+01
--------------------------------------------------
[INFO]: Epoch 171 of 200
Training
[171,   100] loss: 4.679e-06
[171,   200] loss: 4.713e-06
Validation
[171,   100] loss: 7.995e-06
[171,   200] loss: 7.906e-06
Training loss: 0.000, train NMSE: -1.989e+01
Validation loss: 0.000, valid_NMSE: -1.767e+01
--------------------------------------------------
[INFO]: Epoch 172 of 200
Training
[172,   100] loss: 4.607e-06
[172,   200] loss: 4.735e-06
Validation
[172,   100] loss: 8.021e-06
[172,   200] loss: 7.943e-06
Training loss: 0.000, train NMSE: -2.036e+01
Validation loss: 0.000, valid_NMSE: -1.763e+01
--------------------------------------------------
[INFO]: Epoch 173 of 200
Training
[173,   100] loss: 4.617e-06
[173,   200] loss: 4.661e-06
Validation
[173,   100] loss: 7.951e-06
[173,   200] loss: 7.880e-06
Training loss: 0.000, train NMSE: -1.993e+01
Validation loss: 0.000, valid_NMSE: -1.769e+01
--------------------------------------------------
[INFO]: Epoch 174 of 200
Training
[174,   100] loss: 4.704e-06
[174,   200] loss: 4.636e-06
Validation
[174,   100] loss: 8.009e-06
[174,   200] loss: 7.924e-06
Training loss: 0.000, train NMSE: -1.960e+01
Validation loss: 0.000, valid_NMSE: -1.764e+01
--------------------------------------------------
[INFO]: Epoch 175 of 200
Training
[175,   100] loss: 4.620e-06
[175,   200] loss: 4.634e-06
Validation
[175,   100] loss: 7.916e-06
[175,   200] loss: 7.829e-06
Training loss: 0.000, train NMSE: -1.955e+01
Validation loss: 0.000, valid_NMSE: -1.772e+01

Best validation loss: -17.722503662109375

Saving best model for epoch: 175

--------------------------------------------------
[INFO]: Epoch 176 of 200
Training
[176,   100] loss: 4.598e-06
[176,   200] loss: 4.681e-06
Validation
[176,   100] loss: 7.935e-06
[176,   200] loss: 7.855e-06
Training loss: 0.000, train NMSE: -2.006e+01
Validation loss: 0.000, valid_NMSE: -1.769e+01
--------------------------------------------------
[INFO]: Epoch 177 of 200
Training
[177,   100] loss: 4.553e-06
[177,   200] loss: 4.655e-06
Validation
[177,   100] loss: 7.970e-06
[177,   200] loss: 7.890e-06
Training loss: 0.000, train NMSE: -1.994e+01
Validation loss: 0.000, valid_NMSE: -1.773e+01

Best validation loss: -17.73232078552246

Saving best model for epoch: 177

--------------------------------------------------
[INFO]: Epoch 178 of 200
Training
[178,   100] loss: 4.630e-06
[178,   200] loss: 4.561e-06
Validation
[178,   100] loss: 8.029e-06
[178,   200] loss: 7.937e-06
Training loss: 0.000, train NMSE: -2.013e+01
Validation loss: 0.000, valid_NMSE: -1.771e+01
--------------------------------------------------
[INFO]: Epoch 179 of 200
Training
[179,   100] loss: 4.573e-06
[179,   200] loss: 4.606e-06
Validation
[179,   100] loss: 7.910e-06
[179,   200] loss: 7.820e-06
Training loss: 0.000, train NMSE: -1.980e+01
Validation loss: 0.000, valid_NMSE: -1.771e+01
--------------------------------------------------
[INFO]: Epoch 180 of 200
Training
[180,   100] loss: 4.544e-06
[180,   200] loss: 4.651e-06
Validation
[180,   100] loss: 7.947e-06
[180,   200] loss: 7.866e-06
Training loss: 0.000, train NMSE: -2.041e+01
Validation loss: 0.000, valid_NMSE: -1.775e+01

Best validation loss: -17.74647331237793

Saving best model for epoch: 180

--------------------------------------------------
[INFO]: Epoch 181 of 200
Training
[181,   100] loss: 4.577e-06
[181,   200] loss: 4.527e-06
Validation
[181,   100] loss: 7.916e-06
[181,   200] loss: 7.839e-06
Training loss: 0.000, train NMSE: -2.035e+01
Validation loss: 0.000, valid_NMSE: -1.772e+01
--------------------------------------------------
[INFO]: Epoch 182 of 200
Training
[182,   100] loss: 4.596e-06
[182,   200] loss: 4.427e-06
Validation
[182,   100] loss: 7.974e-06
[182,   200] loss: 7.888e-06
Training loss: 0.000, train NMSE: -2.038e+01
Validation loss: 0.000, valid_NMSE: -1.774e+01
--------------------------------------------------
[INFO]: Epoch 183 of 200
Training
[183,   100] loss: 4.551e-06
[183,   200] loss: 4.497e-06
Validation
[183,   100] loss: 7.902e-06
[183,   200] loss: 7.806e-06
Training loss: 0.000, train NMSE: -2.067e+01
Validation loss: 0.000, valid_NMSE: -1.773e+01
--------------------------------------------------
[INFO]: Epoch 184 of 200
Training
[184,   100] loss: 4.447e-06
[184,   200] loss: 4.569e-06
Validation
[184,   100] loss: 7.875e-06
[184,   200] loss: 7.786e-06
Training loss: 0.000, train NMSE: -2.076e+01
Validation loss: 0.000, valid_NMSE: -1.775e+01

Best validation loss: -17.75104331970215

Saving best model for epoch: 184

--------------------------------------------------
[INFO]: Epoch 185 of 200
Training
[185,   100] loss: 4.415e-06
[185,   200] loss: 4.553e-06
Validation
[185,   100] loss: 7.951e-06
[185,   200] loss: 7.868e-06
Training loss: 0.000, train NMSE: -2.039e+01
Validation loss: 0.000, valid_NMSE: -1.765e+01
--------------------------------------------------
[INFO]: Epoch 186 of 200
Training
[186,   100] loss: 4.521e-06
[186,   200] loss: 4.499e-06
Validation
[186,   100] loss: 7.860e-06
[186,   200] loss: 7.777e-06
Training loss: 0.000, train NMSE: -2.026e+01
Validation loss: 0.000, valid_NMSE: -1.778e+01

Best validation loss: -17.77873992919922

Saving best model for epoch: 186

--------------------------------------------------
[INFO]: Epoch 187 of 200
Training
[187,   100] loss: 4.457e-06
[187,   200] loss: 4.502e-06
Validation
[187,   100] loss: 7.864e-06
[187,   200] loss: 7.774e-06
Training loss: 0.000, train NMSE: -1.964e+01
Validation loss: 0.000, valid_NMSE: -1.772e+01
--------------------------------------------------
[INFO]: Epoch 188 of 200
Training
[188,   100] loss: 4.382e-06
[188,   200] loss: 4.579e-06
Validation
[188,   100] loss: 7.864e-06
[188,   200] loss: 7.777e-06
Training loss: 0.000, train NMSE: -2.031e+01
Validation loss: 0.000, valid_NMSE: -1.780e+01

Best validation loss: -17.798778533935547

Saving best model for epoch: 188

--------------------------------------------------
[INFO]: Epoch 189 of 200
Training
[189,   100] loss: 4.358e-06
[189,   200] loss: 4.533e-06
Validation
[189,   100] loss: 7.794e-06
[189,   200] loss: 7.712e-06
Training loss: 0.000, train NMSE: -2.030e+01
Validation loss: 0.000, valid_NMSE: -1.770e+01
--------------------------------------------------
[INFO]: Epoch 190 of 200
Training
[190,   100] loss: 4.404e-06
[190,   200] loss: 4.505e-06
Validation
[190,   100] loss: 7.813e-06
[190,   200] loss: 7.727e-06
Training loss: 0.000, train NMSE: -2.105e+01
Validation loss: 0.000, valid_NMSE: -1.779e+01
--------------------------------------------------
[INFO]: Epoch 191 of 200
Training
[191,   100] loss: 4.417e-06
[191,   200] loss: 4.414e-06
Validation
[191,   100] loss: 7.850e-06
[191,   200] loss: 7.766e-06
Training loss: 0.000, train NMSE: -2.013e+01
Validation loss: 0.000, valid_NMSE: -1.779e+01
--------------------------------------------------
[INFO]: Epoch 192 of 200
Training
[192,   100] loss: 4.493e-06
[192,   200] loss: 4.361e-06
Validation
[192,   100] loss: 7.858e-06
[192,   200] loss: 7.778e-06
Training loss: 0.000, train NMSE: -2.066e+01
Validation loss: 0.000, valid_NMSE: -1.770e+01
--------------------------------------------------
[INFO]: Epoch 193 of 200
Training
[193,   100] loss: 4.397e-06
[193,   200] loss: 4.369e-06
Validation
[193,   100] loss: 7.844e-06
[193,   200] loss: 7.750e-06
Training loss: 0.000, train NMSE: -2.065e+01
Validation loss: 0.000, valid_NMSE: -1.778e+01
--------------------------------------------------
[INFO]: Epoch 194 of 200
Training
[194,   100] loss: 4.326e-06
[194,   200] loss: 4.460e-06
Validation
[194,   100] loss: 7.803e-06
[194,   200] loss: 7.710e-06
Training loss: 0.000, train NMSE: -2.016e+01
Validation loss: 0.000, valid_NMSE: -1.779e+01
--------------------------------------------------
[INFO]: Epoch 195 of 200
Training
[195,   100] loss: 4.334e-06
[195,   200] loss: 4.423e-06
Validation
[195,   100] loss: 7.873e-06
[195,   200] loss: 7.762e-06
Training loss: 0.000, train NMSE: -1.952e+01
Validation loss: 0.000, valid_NMSE: -1.783e+01

Best validation loss: -17.82901382446289

Saving best model for epoch: 195

--------------------------------------------------
[INFO]: Epoch 196 of 200
Training
[196,   100] loss: 4.300e-06
[196,   200] loss: 4.423e-06
Validation
[196,   100] loss: 7.864e-06
[196,   200] loss: 7.777e-06
Training loss: 0.000, train NMSE: -1.975e+01
Validation loss: 0.000, valid_NMSE: -1.773e+01
--------------------------------------------------
[INFO]: Epoch 197 of 200
Training
[197,   100] loss: 4.348e-06/home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE
  warn(f"Failed to load image Python extension: {e}")

[197,   200] loss: 4.387e-06
Validation
[197,   100] loss: 7.855e-06
[197,   200] loss: 7.755e-06
Training loss: 0.000, train NMSE: -2.020e+01
Validation loss: 0.000, valid_NMSE: -1.781e+01
--------------------------------------------------
[INFO]: Epoch 198 of 200
Training
[198,   100] loss: 4.330e-06
[198,   200] loss: 4.336e-06
Validation
[198,   100] loss: 7.825e-06
[198,   200] loss: 7.733e-06
Training loss: 0.000, train NMSE: -2.013e+01
Validation loss: 0.000, valid_NMSE: -1.771e+01
--------------------------------------------------
[INFO]: Epoch 199 of 200
Training
[199,   100] loss: 4.308e-06
[199,   200] loss: 4.358e-06
Validation
[199,   100] loss: 7.839e-06
[199,   200] loss: 7.744e-06
Training loss: 0.000, train NMSE: -2.071e+01
Validation loss: 0.000, valid_NMSE: -1.781e+01
--------------------------------------------------
[INFO]: Epoch 200 of 200
Training
[200,   100] loss: 4.324e-06
[200,   200] loss: 4.286e-06
Validation
[200,   100] loss: 7.837e-06
[200,   200] loss: 7.747e-06
Training loss: 0.000, train NMSE: -1.985e+01
Validation loss: 0.000, valid_NMSE: -1.774e+01
--------------------------------------------------
Saving final model
TRAINING COMPLETE
