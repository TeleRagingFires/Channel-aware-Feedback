1.13.1+cu117
inSoftID
Dadicated Mode inSoftID
Dedicated Mode inSoftID
trainset len 112000 valset len 48000
New_trainset len 40000 valset len 48000
2,660,505 training parameters.

2,660,505 training parameters.

[INFO]: Epoch 1 of 200
Training
[1,   100] loss: 8.640e-05
[1,   200] loss: 6.170e-05
Validation
[1,   100] loss: 5.028e-05
[1,   200] loss: 4.940e-05
Training loss: 0.000, train NMSE: -1.008e+01
Validation loss: 0.000, valid_NMSE: -1.045e+01

Best validation loss: -10.451276779174805

Saving best model for epoch: 1

--------------------------------------------------
[INFO]: Epoch 2 of 200
Training
[2,   100] loss: 5.108e-05
[2,   200] loss: 4.046e-05
Validation
[2,   100] loss: 3.618e-05
[2,   200] loss: 3.534e-05
Training loss: 0.000, train NMSE: -1.085e+01
Validation loss: 0.000, valid_NMSE: -1.209e+01

Best validation loss: -12.093950271606445

Saving best model for epoch: 2

--------------------------------------------------
[INFO]: Epoch 3 of 200
Training
[3,   100] loss: 3.455e-05
[3,   200] loss: 3.132e-05
Validation
[3,   100] loss: 3.048e-05
[3,   200] loss: 2.975e-05
Training loss: 0.000, train NMSE: -1.207e+01
Validation loss: 0.000, valid_NMSE: -1.282e+01

Best validation loss: -12.816767692565918

Saving best model for epoch: 3

--------------------------------------------------
[INFO]: Epoch 4 of 200
Training
[4,   100] loss: 2.837e-05
[4,   200] loss: 2.691e-05
Validation
[4,   100] loss: 2.615e-05
[4,   200] loss: 2.559e-05
Training loss: 0.000, train NMSE: -1.379e+01
Validation loss: 0.000, valid_NMSE: -1.353e+01

Best validation loss: -13.534587860107422

Saving best model for epoch: 4

--------------------------------------------------
[INFO]: Epoch 5 of 200
Training
[5,   100] loss: 2.436e-05
[5,   200] loss: 2.308e-05
Validation
[5,   100] loss: 2.280e-05
[5,   200] loss: 2.241e-05
Training loss: 0.000, train NMSE: -1.356e+01
Validation loss: 0.000, valid_NMSE: -1.408e+01

Best validation loss: -14.083457946777344

Saving best model for epoch: 5

--------------------------------------------------
[INFO]: Epoch 6 of 200
Training
[6,   100] loss: 2.104e-05
[6,   200] loss: 2.011e-05
Validation
[6,   100] loss: 2.014e-05
[6,   200] loss: 1.988e-05
Training loss: 0.000, train NMSE: -1.449e+01
Validation loss: 0.000, valid_NMSE: -1.449e+01

Best validation loss: -14.486520767211914

Saving best model for epoch: 6

--------------------------------------------------
[INFO]: Epoch 7 of 200
Training
[7,   100] loss: 1.820e-05
[7,   200] loss: 1.789e-05
Validation
[7,   100] loss: 1.795e-05
[7,   200] loss: 1.780e-05
Training loss: 0.000, train NMSE: -1.488e+01
Validation loss: 0.000, valid_NMSE: -1.496e+01

Best validation loss: -14.961889266967773

Saving best model for epoch: 7

--------------------------------------------------
[INFO]: Epoch 8 of 200
Training
[8,   100] loss: 1.620e-05
[8,   200] loss: 1.575e-05
Validation
[8,   100] loss: 1.609e-05
[8,   200] loss: 1.600e-05
Training loss: 0.000, train NMSE: -1.508e+01
Validation loss: 0.000, valid_NMSE: -1.522e+01

Best validation loss: -15.223388671875

Saving best model for epoch: 8

--------------------------------------------------
[INFO]: Epoch 9 of 200
Training
[9,   100] loss: 1.472e-05
[9,   200] loss: 1.393e-05
Validation
[9,   100] loss: 1.455e-05
[9,   200] loss: 1.451e-05
Training loss: 0.000, train NMSE: -1.577e+01
Validation loss: 0.000, valid_NMSE: -1.567e+01

Best validation loss: -15.666855812072754

Saving best model for epoch: 9

--------------------------------------------------
[INFO]: Epoch 10 of 200
Training
[10,   100] loss: 1.320e-05
[10,   200] loss: 1.261e-05
Validation
[10,   100] loss: 1.327e-05
[10,   200] loss: 1.323e-05
Training loss: 0.000, train NMSE: -1.631e+01
Validation loss: 0.000, valid_NMSE: -1.606e+01

Best validation loss: -16.05690574645996

Saving best model for epoch: 10

--------------------------------------------------
[INFO]: Epoch 11 of 200
Training
[11,   100] loss: 1.190e-05
[11,   200] loss: 1.167e-05
Validation
[11,   100] loss: 1.220e-05
[11,   200] loss: 1.219e-05
Training loss: 0.000, train NMSE: -1.650e+01
Validation loss: 0.000, valid_NMSE: -1.636e+01

Best validation loss: -16.35767364501953

Saving best model for epoch: 11

--------------------------------------------------
[INFO]: Epoch 12 of 200
Training
[12,   100] loss: 1.086e-05
[12,   200] loss: 1.081e-05
Validation
[12,   100] loss: 1.148e-05
[12,   200] loss: 1.147e-05
Training loss: 0.000, train NMSE: -1.691e+01
Validation loss: 0.000, valid_NMSE: -1.654e+01

Best validation loss: -16.537755966186523

Saving best model for epoch: 12

--------------------------------------------------
[INFO]: Epoch 13 of 200
Training
[13,   100] loss: 1.026e-05
[13,   200] loss: 9.769e-06
Validation
[13,   100] loss: 1.078e-05
[13,   200] loss: 1.079e-05
Training loss: 0.000, train NMSE: -1.761e+01
Validation loss: 0.000, valid_NMSE: -1.697e+01

Best validation loss: -16.974754333496094

Saving best model for epoch: 13

--------------------------------------------------
[INFO]: Epoch 14 of 200
Training
[14,   100] loss: 9.280e-06
[14,   200] loss: 9.230e-06
Validation
[14,   100] loss: 9.866e-06
[14,   200] loss: 9.839e-06
Training loss: 0.000, train NMSE: -1.750e+01
Validation loss: 0.000, valid_NMSE: -1.723e+01

Best validation loss: -17.230018615722656

Saving best model for epoch: 14

--------------------------------------------------
[INFO]: Epoch 15 of 200
Training
[15,   100] loss: 8.665e-06
[15,   200] loss: 8.537e-06
Validation
[15,   100] loss: 9.190e-06
[15,   200] loss: 9.194e-06
Training loss: 0.000, train NMSE: -1.687e+01
Validation loss: 0.000, valid_NMSE: -1.747e+01

Best validation loss: -17.471500396728516

Saving best model for epoch: 15

--------------------------------------------------
[INFO]: Epoch 16 of 200
Training
[16,   100] loss: 8.134e-06
[16,   200] loss: 8.004e-06
Validation
[16,   100] loss: 8.597e-06
[16,   200] loss: 8.594e-06
Training loss: 0.000, train NMSE: -1.786e+01
Validation loss: 0.000, valid_NMSE: -1.770e+01

Best validation loss: -17.6990966796875

Saving best model for epoch: 16

--------------------------------------------------
[INFO]: Epoch 17 of 200
Training
[17,   100] loss: 7.566e-06
[17,   200] loss: 7.597e-06
Validation
[17,   100] loss: 8.100e-06
[17,   200] loss: 8.069e-06
Training loss: 0.000, train NMSE: -1.840e+01
Validation loss: 0.000, valid_NMSE: -1.800e+01

Best validation loss: -17.996583938598633

Saving best model for epoch: 17

--------------------------------------------------
[INFO]: Epoch 18 of 200
Training
[18,   100] loss: 7.147e-06
[18,   200] loss: 7.049e-06
Validation
[18,   100] loss: 7.761e-06
[18,   200] loss: 7.742e-06
Training loss: 0.000, train NMSE: -1.861e+01
Validation loss: 0.000, valid_NMSE: -1.812e+01

Best validation loss: -18.12278938293457

Saving best model for epoch: 18

--------------------------------------------------
[INFO]: Epoch 19 of 200
Training
[19,   100] loss: 6.663e-06
[19,   200] loss: 6.725e-06
Validation
[19,   100] loss: 7.392e-06
[19,   200] loss: 7.347e-06
Training loss: 0.000, train NMSE: -1.835e+01
Validation loss: 0.000, valid_NMSE: -1.840e+01

Best validation loss: -18.396747589111328

Saving best model for epoch: 19

--------------------------------------------------
[INFO]: Epoch 20 of 200
Training
[20,   100] loss: 6.300e-06
[20,   200] loss: 6.468e-06
Validation
[20,   100] loss: 7.131e-06
[20,   200] loss: 7.106e-06
Training loss: 0.000, train NMSE: -1.923e+01
Validation loss: 0.000, valid_NMSE: -1.835e+01
--------------------------------------------------
[INFO]: Epoch 21 of 200
Training
[21,   100] loss: 6.066e-06
[21,   200] loss: 6.071e-06
Validation
[21,   100] loss: 6.517e-06
[21,   200] loss: 6.485e-06
Training loss: 0.000, train NMSE: -1.901e+01
Validation loss: 0.000, valid_NMSE: -1.887e+01

Best validation loss: -18.87346076965332

Saving best model for epoch: 21

--------------------------------------------------
[INFO]: Epoch 22 of 200
Training
[22,   100] loss: 5.796e-06
[22,   200] loss: 5.680e-06
Validation
[22,   100] loss: 6.341e-06
[22,   200] loss: 6.307e-06
Training loss: 0.000, train NMSE: -1.929e+01
Validation loss: 0.000, valid_NMSE: -1.906e+01

Best validation loss: -19.055845260620117

Saving best model for epoch: 22

--------------------------------------------------
[INFO]: Epoch 23 of 200
Training
[23,   100] loss: 5.444e-06
[23,   200] loss: 5.439e-06
Validation
[23,   100] loss: 5.920e-06
[23,   200] loss: 5.877e-06
Training loss: 0.000, train NMSE: -1.976e+01
Validation loss: 0.000, valid_NMSE: -1.932e+01

Best validation loss: -19.31894874572754

Saving best model for epoch: 23

--------------------------------------------------
[INFO]: Epoch 24 of 200
Training
[24,   100] loss: 5.229e-06
[24,   200] loss: 5.171e-06
Validation
[24,   100] loss: 5.728e-06
[24,   200] loss: 5.699e-06
Training loss: 0.000, train NMSE: -1.993e+01
Validation loss: 0.000, valid_NMSE: -1.940e+01

Best validation loss: -19.399946212768555

Saving best model for epoch: 24

--------------------------------------------------
[INFO]: Epoch 25 of 200
Training
[25,   100] loss: 4.969e-06
[25,   200] loss: 5.051e-06
Validation
[25,   100] loss: 5.655e-06
[25,   200] loss: 5.596e-06
Training loss: 0.000, train NMSE: -1.986e+01
Validation loss: 0.000, valid_NMSE: -1.935e+01
--------------------------------------------------
[INFO]: Epoch 26 of 200
Training
[26,   100] loss: 4.854e-06
[26,   200] loss: 4.753e-06
Validation
[26,   100] loss: 5.296e-06
[26,   200] loss: 5.260e-06
Training loss: 0.000, train NMSE: -2.077e+01
Validation loss: 0.000, valid_NMSE: -1.980e+01

Best validation loss: -19.804664611816406

Saving best model for epoch: 26

--------------------------------------------------
[INFO]: Epoch 27 of 200
Training
[27,   100] loss: 4.491e-06
[27,   200] loss: 4.627e-06
Validation
[27,   100] loss: 5.071e-06
[27,   200] loss: 5.031e-06
Training loss: 0.000, train NMSE: -2.041e+01
Validation loss: 0.000, valid_NMSE: -1.998e+01

Best validation loss: -19.976654052734375

Saving best model for epoch: 27

--------------------------------------------------
[INFO]: Epoch 28 of 200
Training
[28,   100] loss: 4.356e-06
[28,   200] loss: 4.518e-06
Validation
[28,   100] loss: 4.864e-06
[28,   200] loss: 4.824e-06
Training loss: 0.000, train NMSE: -2.115e+01
Validation loss: 0.000, valid_NMSE: -2.000e+01

Best validation loss: -19.997621536254883

Saving best model for epoch: 28

--------------------------------------------------
[INFO]: Epoch 29 of 200
Training
[29,   100] loss: 4.255e-06
[29,   200] loss: 4.245e-06
Validation
[29,   100] loss: 4.856e-06
[29,   200] loss: 4.824e-06
Training loss: 0.000, train NMSE: -2.084e+01
Validation loss: 0.000, valid_NMSE: -1.998e+01
--------------------------------------------------
[INFO]: Epoch 30 of 200
Training
[30,   100] loss: 4.123e-06
[30,   200] loss: 4.087e-06
Validation
[30,   100] loss: 4.612e-06
[30,   200] loss: 4.566e-06
Training loss: 0.000, train NMSE: -2.093e+01
Validation loss: 0.000, valid_NMSE: -2.022e+01

Best validation loss: -20.215641021728516

Saving best model for epoch: 30

--------------------------------------------------
[INFO]: Epoch 31 of 200
Training
[31,   100] loss: 4.028e-06
[31,   200] loss: 3.918e-06
Validation
[31,   100] loss: 4.306e-06
[31,   200] loss: 4.267e-06
Training loss: 0.000, train NMSE: -2.138e+01
Validation loss: 0.000, valid_NMSE: -2.036e+01

Best validation loss: -20.355449676513672

Saving best model for epoch: 31

--------------------------------------------------
[INFO]: Epoch 32 of 200
Training
[32,   100] loss: 3.806e-06
[32,   200] loss: 3.850e-06
Validation
[32,   100] loss: 4.356e-06
[32,   200] loss: 4.309e-06
Training loss: 0.000, train NMSE: -2.124e+01
Validation loss: 0.000, valid_NMSE: -2.043e+01

Best validation loss: -20.427322387695312

Saving best model for epoch: 32

--------------------------------------------------
[INFO]: Epoch 33 of 200
Training
[33,   100] loss: 3.642e-06
[33,   200] loss: 3.718e-06
Validation
[33,   100] loss: 4.321e-06
[33,   200] loss: 4.276e-06
Training loss: 0.000, train NMSE: -2.086e+01
Validation loss: 0.000, valid_NMSE: -2.058e+01

Best validation loss: -20.582923889160156

Saving best model for epoch: 33

--------------------------------------------------
[INFO]: Epoch 34 of 200
Training
[34,   100] loss: 3.601e-06
[34,   200] loss: 3.571e-06
Validation
[34,   100] loss: 4.007e-06
[34,   200] loss: 3.976e-06
Training loss: 0.000, train NMSE: -2.108e+01
Validation loss: 0.000, valid_NMSE: -2.078e+01

Best validation loss: -20.77985382080078

Saving best model for epoch: 34

--------------------------------------------------
[INFO]: Epoch 35 of 200
Training
[35,   100] loss: 3.427e-06
[35,   200] loss: 3.452e-06
Validation
[35,   100] loss: 3.860e-06
[35,   200] loss: 3.829e-06
Training loss: 0.000, train NMSE: -2.149e+01
Validation loss: 0.000, valid_NMSE: -2.081e+01

Best validation loss: -20.808801651000977

Saving best model for epoch: 35

--------------------------------------------------
[INFO]: Epoch 36 of 200
Training
[36,   100] loss: 3.303e-06
[36,   200] loss: 3.357e-06
Validation
[36,   100] loss: 3.774e-06
[36,   200] loss: 3.738e-06
Training loss: 0.000, train NMSE: -2.167e+01
Validation loss: 0.000, valid_NMSE: -2.090e+01

Best validation loss: -20.900365829467773

Saving best model for epoch: 36

--------------------------------------------------
[INFO]: Epoch 37 of 200
Training
[37,   100] loss: 3.251e-06
[37,   200] loss: 3.248e-06
Validation
[37,   100] loss: 3.686e-06
[37,   200] loss: 3.649e-06
Training loss: 0.000, train NMSE: -2.189e+01
Validation loss: 0.000, valid_NMSE: -2.107e+01

Best validation loss: -21.067398071289062

Saving best model for epoch: 37

--------------------------------------------------
[INFO]: Epoch 38 of 200
Training
[38,   100] loss: 3.127e-06
[38,   200] loss: 3.190e-06
Validation
[38,   100] loss: 3.692e-06
[38,   200] loss: 3.659e-06
Training loss: 0.000, train NMSE: -2.203e+01
Validation loss: 0.000, valid_NMSE: -2.123e+01

Best validation loss: -21.23020362854004

Saving best model for epoch: 38

--------------------------------------------------
[INFO]: Epoch 39 of 200
Training
[39,   100] loss: 3.080e-06
[39,   200] loss: 3.078e-06
Validation
[39,   100] loss: 3.397e-06
[39,   200] loss: 3.365e-06
Training loss: 0.000, train NMSE: -2.224e+01
Validation loss: 0.000, valid_NMSE: -2.139e+01

Best validation loss: -21.387332916259766

Saving best model for epoch: 39

--------------------------------------------------
[INFO]: Epoch 40 of 200
Training
[40,   100] loss: 2.982e-06
[40,   200] loss: 2.977e-06
Validation
[40,   100] loss: 3.461e-06
[40,   200] loss: 3.425e-06
Training loss: 0.000, train NMSE: -2.246e+01
Validation loss: 0.000, valid_NMSE: -2.150e+01

Best validation loss: -21.502553939819336

Saving best model for epoch: 40

--------------------------------------------------
[INFO]: Epoch 41 of 200
Training
[41,   100] loss: 2.913e-06
[41,   200] loss: 2.926e-06
Validation
[41,   100] loss: 3.292e-06
[41,   200] loss: 3.262e-06
Training loss: 0.000, train NMSE: -2.274e+01
Validation loss: 0.000, valid_NMSE: -2.134e+01
--------------------------------------------------
[INFO]: Epoch 42 of 200
Training
[42,   100] loss: 2.850e-06
[42,   200] loss: 2.827e-06
Validation
[42,   100] loss: 3.147e-06
[42,   200] loss: 3.122e-06
Training loss: 0.000, train NMSE: -2.224e+01
Validation loss: 0.000, valid_NMSE: -2.159e+01

Best validation loss: -21.592500686645508

Saving best model for epoch: 42

--------------------------------------------------
[INFO]: Epoch 43 of 200
Training
[43,   100] loss: 2.811e-06
[43,   200] loss: 2.713e-06
Validation
[43,   100] loss: 3.114e-06
[43,   200] loss: 3.085e-06
Training loss: 0.000, train NMSE: -2.268e+01
Validation loss: 0.000, valid_NMSE: -2.164e+01

Best validation loss: -21.642559051513672

Saving best model for epoch: 43

--------------------------------------------------
[INFO]: Epoch 44 of 200
Training
[44,   100] loss: 2.655e-06
[44,   200] loss: 2.682e-06
Validation
[44,   100] loss: 3.043e-06
[44,   200] loss: 3.010e-06
Training loss: 0.000, train NMSE: -2.304e+01
Validation loss: 0.000, valid_NMSE: -2.181e+01

Best validation loss: -21.80937957763672

Saving best model for epoch: 44

--------------------------------------------------
[INFO]: Epoch 45 of 200
Training
[45,   100] loss: 2.651e-06
[45,   200] loss: 2.647e-06
Validation
[45,   100] loss: 2.991e-06
[45,   200] loss: 2.964e-06
Training loss: 0.000, train NMSE: -2.252e+01
Validation loss: 0.000, valid_NMSE: -2.194e+01

Best validation loss: -21.936870574951172

Saving best model for epoch: 45

--------------------------------------------------
[INFO]: Epoch 46 of 200
Training
[46,   100] loss: 2.626e-06
[46,   200] loss: 2.563e-06
Validation
[46,   100] loss: 2.874e-06
[46,   200] loss: 2.850e-06
Training loss: 0.000, train NMSE: -2.265e+01
Validation loss: 0.000, valid_NMSE: -2.187e+01
--------------------------------------------------
[INFO]: Epoch 47 of 200
Training
[47,   100] loss: 2.579e-06
[47,   200] loss: 2.530e-06
Validation
[47,   100] loss: 3.097e-06
[47,   200] loss: 3.079e-06
Training loss: 0.000, train NMSE: -2.310e+01
Validation loss: 0.000, valid_NMSE: -2.138e+01
--------------------------------------------------
[INFO]: Epoch 48 of 200
Training
[48,   100] loss: 2.509e-06
[48,   200] loss: 2.482e-06
Validation
[48,   100] loss: 2.794e-06
[48,   200] loss: 2.770e-06
Training loss: 0.000, train NMSE: -2.236e+01
Validation loss: 0.000, valid_NMSE: -2.201e+01

Best validation loss: -22.012588500976562

Saving best model for epoch: 48

--------------------------------------------------
[INFO]: Epoch 49 of 200
Training
[49,   100] loss: 2.377e-06
[49,   200] loss: 2.447e-06
Validation
[49,   100] loss: 2.696e-06
[49,   200] loss: 2.670e-06
Training loss: 0.000, train NMSE: -2.294e+01
Validation loss: 0.000, valid_NMSE: -2.224e+01

Best validation loss: -22.235048294067383

Saving best model for epoch: 49

--------------------------------------------------
[INFO]: Epoch 50 of 200
Training
[50,   100] loss: 2.327e-06
[50,   200] loss: 2.409e-06
Validation
[50,   100] loss: 2.644e-06
[50,   200] loss: 2.617e-06
Training loss: 0.000, train NMSE: -2.263e+01
Validation loss: 0.000, valid_NMSE: -2.245e+01

Best validation loss: -22.448665618896484

Saving best model for epoch: 50

--------------------------------------------------
[INFO]: Epoch 51 of 200
Training
[51,   100] loss: 2.358e-06
[51,   200] loss: 2.359e-06
Validation
[51,   100] loss: 2.621e-06
[51,   200] loss: 2.603e-06
Training loss: 0.000, train NMSE: -2.298e+01
Validation loss: 0.000, valid_NMSE: -2.227e+01
--------------------------------------------------
[INFO]: Epoch 52 of 200
Training
[52,   100] loss: 2.275e-06
[52,   200] loss: 2.308e-06
Validation
[52,   100] loss: 2.561e-06
[52,   200] loss: 2.536e-06
Training loss: 0.000, train NMSE: -2.297e+01
Validation loss: 0.000, valid_NMSE: -2.254e+01

Best validation loss: -22.53777503967285

Saving best model for epoch: 52

--------------------------------------------------
[INFO]: Epoch 53 of 200
Training
[53,   100] loss: 2.199e-06
[53,   200] loss: 2.291e-06
Validation
[53,   100] loss: 2.524e-06
[53,   200] loss: 2.504e-06
Training loss: 0.000, train NMSE: -2.355e+01
Validation loss: 0.000, valid_NMSE: -2.237e+01
--------------------------------------------------
[INFO]: Epoch 54 of 200
Training
[54,   100] loss: 2.170e-06
[54,   200] loss: 2.216e-06
Validation
[54,   100] loss: 2.458e-06
[54,   200] loss: 2.427e-06
Training loss: 0.000, train NMSE: -2.382e+01
Validation loss: 0.000, valid_NMSE: -2.248e+01
--------------------------------------------------
[INFO]: Epoch 55 of 200
Training
[55,   100] loss: 2.125e-06
[55,   200] loss: 2.119e-06
Validation
[55,   100] loss: 2.503e-06
[55,   200] loss: 2.464e-06
Training loss: 0.000, train NMSE: -2.333e+01
Validation loss: 0.000, valid_NMSE: -2.248e+01
--------------------------------------------------
[INFO]: Epoch 56 of 200
Training
[56,   100] loss: 2.130e-06
[56,   200] loss: 2.095e-06
Validation
[56,   100] loss: 2.409e-06
[56,   200] loss: 2.389e-06
Training loss: 0.000, train NMSE: -2.332e+01
Validation loss: 0.000, valid_NMSE: -2.274e+01

Best validation loss: -22.740955352783203

Saving best model for epoch: 56

--------------------------------------------------
[INFO]: Epoch 57 of 200
Training
[57,   100] loss: 2.078e-06
[57,   200] loss: 2.059e-06
Validation
[57,   100] loss: 2.351e-06
[57,   200] loss: 2.328e-06
Training loss: 0.000, train NMSE: -2.376e+01
Validation loss: 0.000, valid_NMSE: -2.283e+01

Best validation loss: -22.831100463867188

Saving best model for epoch: 57

--------------------------------------------------
[INFO]: Epoch 58 of 200
Training
[58,   100] loss: 2.042e-06
[58,   200] loss: 2.047e-06
Validation
[58,   100] loss: 2.320e-06
[58,   200] loss: 2.277e-06
Training loss: 0.000, train NMSE: -2.387e+01
Validation loss: 0.000, valid_NMSE: -2.286e+01

Best validation loss: -22.858808517456055

Saving best model for epoch: 58

--------------------------------------------------
[INFO]: Epoch 59 of 200
Training
[59,   100] loss: 2.005e-06
[59,   200] loss: 2.024e-06
Validation
[59,   100] loss: 2.254e-06
[59,   200] loss: 2.228e-06
Training loss: 0.000, train NMSE: -2.403e+01
Validation loss: 0.000, valid_NMSE: -2.295e+01

Best validation loss: -22.951946258544922

Saving best model for epoch: 59

--------------------------------------------------
[INFO]: Epoch 60 of 200
Training
[60,   100] loss: 1.930e-06
[60,   200] loss: 1.994e-06
Validation
[60,   100] loss: 2.356e-06
[60,   200] loss: 2.232e-06
Training loss: 0.000, train NMSE: -2.356e+01
Validation loss: 0.000, valid_NMSE: -2.299e+01

Best validation loss: -22.990291595458984

Saving best model for epoch: 60

--------------------------------------------------
[INFO]: Epoch 61 of 200
Training
[61,   100] loss: 1.996e-06
[61,   200] loss: 1.937e-06
Validation
[61,   100] loss: 2.343e-06
[61,   200] loss: 2.237e-06
Training loss: 0.000, train NMSE: -2.375e+01
Validation loss: 0.000, valid_NMSE: -2.308e+01

Best validation loss: -23.081554412841797

Saving best model for epoch: 61

--------------------------------------------------
[INFO]: Epoch 62 of 200
Training
[62,   100] loss: 1.908e-06
[62,   200] loss: 1.928e-06
Validation
[62,   100] loss: 2.441e-06
[62,   200] loss: 2.120e-06
Training loss: 0.000, train NMSE: -2.400e+01
Validation loss: 0.000, valid_NMSE: -2.329e+01

Best validation loss: -23.285924911499023

Saving best model for epoch: 62

--------------------------------------------------
[INFO]: Epoch 63 of 200
Training
[63,   100] loss: 1.909e-06
[63,   200] loss: 1.942e-06
Validation
[63,   100] loss: 2.567e-06
[63,   200] loss: 2.154e-06
Training loss: 0.000, train NMSE: -2.432e+01
Validation loss: 0.000, valid_NMSE: -2.324e+01
--------------------------------------------------
[INFO]: Epoch 64 of 200
Training
[64,   100] loss: 1.911e-06
[64,   200] loss: 1.853e-06
Validation
[64,   100] loss: 2.503e-06
[64,   200] loss: 2.073e-06
Training loss: 0.000, train NMSE: -2.347e+01
Validation loss: 0.000, valid_NMSE: -2.315e+01
--------------------------------------------------
[INFO]: Epoch 65 of 200
Training
[65,   100] loss: 1.856e-06
[65,   200] loss: 1.774e-06
Validation
[65,   100] loss: 2.463e-06
[65,   200] loss: 1.992e-06
Training loss: 0.000, train NMSE: -2.477e+01
Validation loss: 0.000, valid_NMSE: -2.344e+01

Best validation loss: -23.440006256103516

Saving best model for epoch: 65

--------------------------------------------------
[INFO]: Epoch 66 of 200
Training
[66,   100] loss: 1.770e-06
[66,   200] loss: 1.844e-06
Validation
[66,   100] loss: 2.487e-06
[66,   200] loss: 2.010e-06
Training loss: 0.000, train NMSE: -2.468e+01
Validation loss: 0.000, valid_NMSE: -2.338e+01
--------------------------------------------------
[INFO]: Epoch 67 of 200
Training
[67,   100] loss: 1.783e-06
[67,   200] loss: 1.827e-06
Validation
[67,   100] loss: 2.551e-06
[67,   200] loss: 1.979e-06
Training loss: 0.000, train NMSE: -2.469e+01
Validation loss: 0.000, valid_NMSE: -2.324e+01
--------------------------------------------------
[INFO]: Epoch 68 of 200
Training
[68,   100] loss: 1.768e-06
[68,   200] loss: 1.796e-06
Validation
[68,   100] loss: 2.112e-06
[68,   200] loss: 1.967e-06
Training loss: 0.000, train NMSE: -2.409e+01
Validation loss: 0.000, valid_NMSE: -2.361e+01

Best validation loss: -23.612451553344727

Saving best model for epoch: 68

--------------------------------------------------
[INFO]: Epoch 69 of 200
Training
[69,   100] loss: 1.738e-06
[69,   200] loss: 1.761e-06
Validation
[69,   100] loss: 2.251e-06
[69,   200] loss: 1.931e-06
Training loss: 0.000, train NMSE: -2.423e+01
Validation loss: 0.000, valid_NMSE: -2.359e+01
--------------------------------------------------
[INFO]: Epoch 70 of 200
Training
[70,   100] loss: 1.717e-06
[70,   200] loss: 1.736e-06
Validation
[70,   100] loss: 2.412e-06
[70,   200] loss: 1.912e-06
Training loss: 0.000, train NMSE: -2.474e+01
Validation loss: 0.000, valid_NMSE: -2.363e+01

Best validation loss: -23.627893447875977

Saving best model for epoch: 70

--------------------------------------------------
[INFO]: Epoch 71 of 200
Training
[71,   100] loss: 1.671e-06
[71,   200] loss: 1.725e-06
Validation
[71,   100] loss: 2.508e-06
[71,   200] loss: 1.929e-06
Training loss: 0.000, train NMSE: -2.446e+01
Validation loss: 0.000, valid_NMSE: -2.319e+01
--------------------------------------------------
[INFO]: Epoch 72 of 200
Training
[72,   100] loss: 1.666e-06
[72,   200] loss: 1.675e-06
Validation
[72,   100] loss: 2.426e-06
[72,   200] loss: 1.871e-06
Training loss: 0.000, train NMSE: -2.527e+01
Validation loss: 0.000, valid_NMSE: -2.365e+01

Best validation loss: -23.648244857788086

Saving best model for epoch: 72

--------------------------------------------------
[INFO]: Epoch 73 of 200
Training
[73,   100] loss: 1.652e-06
[73,   200] loss: 1.644e-06
Validation
[73,   100] loss: 2.435e-06
[73,   200] loss: 1.824e-06
Training loss: 0.000, train NMSE: -2.427e+01
Validation loss: 0.000, valid_NMSE: -2.386e+01

Best validation loss: -23.86190414428711

Saving best model for epoch: 73

--------------------------------------------------
[INFO]: Epoch 74 of 200
Training
[74,   100] loss: 1.645e-06
[74,   200] loss: 1.657e-06
Validation
[74,   100] loss: 2.614e-06
[74,   200] loss: 1.808e-06
Training loss: 0.000, train NMSE: -2.412e+01
Validation loss: 0.000, valid_NMSE: -2.370e+01
--------------------------------------------------
[INFO]: Epoch 75 of 200
Training
[75,   100] loss: 1.586e-06
[75,   200] loss: 1.660e-06
Validation
[75,   100] loss: 2.518e-06
[75,   200] loss: 1.833e-06
Training loss: 0.000, train NMSE: -2.447e+01
Validation loss: 0.000, valid_NMSE: -2.378e+01
--------------------------------------------------
[INFO]: Epoch 76 of 200
Training
[76,   100] loss: 1.589e-06
[76,   200] loss: 1.643e-06
Validation
[76,   100] loss: 2.663e-06
[76,   200] loss: 2.071e-06
Training loss: 0.000, train NMSE: -2.490e+01
Validation loss: 0.000, valid_NMSE: -2.316e+01
--------------------------------------------------
[INFO]: Epoch 77 of 200
Training
[77,   100] loss: 1.611e-06
[77,   200] loss: 1.585e-06
Validation
[77,   100] loss: 2.440e-06
[77,   200] loss: 1.727e-06
Training loss: 0.000, train NMSE: -2.504e+01
Validation loss: 0.000, valid_NMSE: -2.385e+01
--------------------------------------------------
[INFO]: Epoch 78 of 200
Training
[78,   100] loss: 1.571e-06
[78,   200] loss: 1.551e-06
Validation
[78,   100] loss: 2.671e-06
[78,   200] loss: 1.805e-06
Training loss: 0.000, train NMSE: -2.473e+01
Validation loss: 0.000, valid_NMSE: -2.387e+01

Best validation loss: -23.86634635925293

Saving best model for epoch: 78

--------------------------------------------------
[INFO]: Epoch 79 of 200
Training
[79,   100] loss: 1.574e-06
[79,   200] loss: 1.600e-06
Validation
[79,   100] loss: 2.510e-06
[79,   200] loss: 1.763e-06
Training loss: 0.000, train NMSE: -2.493e+01
Validation loss: 0.000, valid_NMSE: -2.375e+01
--------------------------------------------------
[INFO]: Epoch 80 of 200
Training
[80,   100] loss: 1.568e-06
[80,   200] loss: 1.582e-06
Validation
[80,   100] loss: 2.513e-06
[80,   200] loss: 1.712e-06
Training loss: 0.000, train NMSE: -2.493e+01
Validation loss: 0.000, valid_NMSE: -2.420e+01

Best validation loss: -24.195411682128906

Saving best model for epoch: 80

--------------------------------------------------
[INFO]: Epoch 81 of 200
Training
[81,   100] loss: 1.500e-06
[81,   200] loss: 1.540e-06
Validation
[81,   100] loss: 2.540e-06
[81,   200] loss: 1.663e-06
Training loss: 0.000, train NMSE: -2.450e+01
Validation loss: 0.000, valid_NMSE: -2.420e+01

Best validation loss: -24.201871871948242

Saving best model for epoch: 81

--------------------------------------------------
[INFO]: Epoch 82 of 200
Training
[82,   100] loss: 1.504e-06
[82,   200] loss: 1.517e-06
Validation
[82,   100] loss: 2.459e-06
[82,   200] loss: 1.677e-06
Training loss: 0.000, train NMSE: -2.447e+01
Validation loss: 0.000, valid_NMSE: -2.392e+01
--------------------------------------------------
[INFO]: Epoch 83 of 200
Training
[83,   100] loss: 1.521e-06
[83,   200] loss: 1.459e-06
Validation
[83,   100] loss: 2.609e-06
[83,   200] loss: 1.716e-06
Training loss: 0.000, train NMSE: -2.479e+01
Validation loss: 0.000, valid_NMSE: -2.406e+01
--------------------------------------------------
[INFO]: Epoch 84 of 200
Training
[84,   100] loss: 1.446e-06
[84,   200] loss: 1.488e-06
Validation
[84,   100] loss: 2.648e-06
[84,   200] loss: 1.704e-06
Training loss: 0.000, train NMSE: -2.504e+01
Validation loss: 0.000, valid_NMSE: -2.420e+01

Best validation loss: -24.20214080810547

Saving best model for epoch: 84

--------------------------------------------------
[INFO]: Epoch 85 of 200
Training
[85,   100] loss: 1.464e-06
[85,   200] loss: 1.475e-06
Validation
[85,   100] loss: 2.770e-06
[85,   200] loss: 1.708e-06
Training loss: 0.000, train NMSE: -2.521e+01
Validation loss: 0.000, valid_NMSE: -2.406e+01
--------------------------------------------------
[INFO]: Epoch 86 of 200
Training
[86,   100] loss: 1.489e-06
[86,   200] loss: 1.461e-06
Validation
[86,   100] loss: 2.762e-06
[86,   200] loss: 1.625e-06
Training loss: 0.000, train NMSE: -2.447e+01
Validation loss: 0.000, valid_NMSE: -2.409e+01
--------------------------------------------------
[INFO]: Epoch 87 of 200
Training
[87,   100] loss: 1.487e-06
[87,   200] loss: 1.458e-06
Validation
[87,   100] loss: 2.836e-06
[87,   200] loss: 1.625e-06
Training loss: 0.000, train NMSE: -2.483e+01
Validation loss: 0.000, valid_NMSE: -2.403e+01
--------------------------------------------------
[INFO]: Epoch 88 of 200
Training
[88,   100] loss: 1.421e-06
[88,   200] loss: 1.450e-06
Validation
[88,   100] loss: 2.517e-06
[88,   200] loss: 1.591e-06
Training loss: 0.000, train NMSE: -2.535e+01
Validation loss: 0.000, valid_NMSE: -2.403e+01
--------------------------------------------------
[INFO]: Epoch 89 of 200
Training
[89,   100] loss: 1.441e-06
[89,   200] loss: 1.423e-06
Validation
[89,   100] loss: 3.261e-06
[89,   200] loss: 1.558e-06
Training loss: 0.000, train NMSE: -2.565e+01
Validation loss: 0.000, valid_NMSE: -2.419e+01
--------------------------------------------------
[INFO]: Epoch 90 of 200
Training
[90,   100] loss: 1.402e-06
[90,   200] loss: 2.852e-05
Validation
[90,   100] loss: 1.557e-05
[90,   200] loss: 1.543e-05
Training loss: 0.000, train NMSE: -1.457e+01
Validation loss: 0.000, valid_NMSE: -1.501e+01
--------------------------------------------------
[INFO]: Epoch 91 of 200
Training
[91,   100] loss: 5.950e-06
[91,   200] loss: 2.924e-06
Validation
[91,   100] loss: 2.668e-06
[91,   200] loss: 2.642e-06
Training loss: 0.000, train NMSE: -2.263e+01
Validation loss: 0.000, valid_NMSE: -2.253e+01
--------------------------------------------------
[INFO]: Epoch 92 of 200
Training
[92,   100] loss: 2.336e-06
[92,   200] loss: 2.092e-06
Validation
[92,   100] loss: 2.164e-06
[92,   200] loss: 2.144e-06
Training loss: 0.000, train NMSE: -2.380e+01
Validation loss: 0.000, valid_NMSE: -2.338e+01
--------------------------------------------------
[INFO]: Epoch 93 of 200
Training
[93,   100] loss: 1.894e-06
[93,   200] loss: 1.829e-06
Validation
[93,   100] loss: 2.256e-06
[93,   200] loss: 1.926e-06
Training loss: 0.000, train NMSE: -2.428e+01
Validation loss: 0.000, valid_NMSE: -2.379e+01
--------------------------------------------------
[INFO]: Epoch 94 of 200
Training
[94,   100] loss: 1.703e-06
[94,   200] loss: 1.703e-06
Validation
[94,   100] loss: 2.459e-06
[94,   200] loss: 1.801e-06
Training loss: 0.000, train NMSE: -2.421e+01
Validation loss: 0.000, valid_NMSE: -2.405e+01
--------------------------------------------------
[INFO]: Epoch 95 of 200
Training
[95,   100] loss: 1.662e-06
[95,   200] loss: 1.608e-06
Validation
[95,   100] loss: 2.501e-06
[95,   200] loss: 1.738e-06
Training loss: 0.000, train NMSE: -2.519e+01
Validation loss: 0.000, valid_NMSE: -2.415e+01
--------------------------------------------------
[INFO]: Epoch 96 of 200
Training
[96,   100] loss: 1.562e-06
[96,   200] loss: 1.568e-06
Validation
[96,   100] loss: 2.473e-06
[96,   200] loss: 1.681e-06
Training loss: 0.000, train NMSE: -2.523e+01
Validation loss: 0.000, valid_NMSE: -2.417e+01
--------------------------------------------------
[INFO]: Epoch 97 of 200
Training
[97,   100] loss: 1.542e-06
[97,   200] loss: 1.522e-06
Validation
[97,   100] loss: 2.541e-06
[97,   200] loss: 1.649e-06
Training loss: 0.000, train NMSE: -2.525e+01
Validation loss: 0.000, valid_NMSE: -2.446e+01

Best validation loss: -24.45696258544922

Saving best model for epoch: 97

--------------------------------------------------
[INFO]: Epoch 98 of 200
Training
[98,   100] loss: 1.514e-06
[98,   200] loss: 1.438e-06
Validation
[98,   100] loss: 2.707e-06
[98,   200] loss: 1.652e-06
Training loss: 0.000, train NMSE: -2.531e+01
Validation loss: 0.000, valid_NMSE: -2.420e+01
--------------------------------------------------
[INFO]: Epoch 99 of 200
Training
[99,   100] loss: 1.448e-06
[99,   200] loss: 1.462e-06
Validation
[99,   100] loss: 2.625e-06
[99,   200] loss: 1.648e-06
Training loss: 0.000, train NMSE: -2.495e+01
Validation loss: 0.000, valid_NMSE: -2.432e+01
--------------------------------------------------
[INFO]: Epoch 100 of 200
Training
[100,   100] loss: 1.413e-06
[100,   200] loss: 1.439e-06
Validation
[100,   100] loss: 2.779e-06
[100,   200] loss: 1.601e-06
Training loss: 0.000, train NMSE: -2.537e+01
Validation loss: 0.000, valid_NMSE: -2.415e+01
--------------------------------------------------
[INFO]: Epoch 101 of 200
Training
[101,   100] loss: 1.392e-06
[101,   200] loss: 1.430e-06
Validation
[101,   100] loss: 2.834e-06
[101,   200] loss: 1.548e-06
Training loss: 0.000, train NMSE: -2.505e+01
Validation loss: 0.000, valid_NMSE: -2.440e+01
--------------------------------------------------
[INFO]: Epoch 102 of 200
Training
[102,   100] loss: 1.376e-06
[102,   200] loss: 1.446e-06
Validation
[102,   100] loss: 3.091e-06
[102,   200] loss: 1.612e-06
Training loss: 0.000, train NMSE: -2.529e+01
Validation loss: 0.000, valid_NMSE: -2.417e+01
--------------------------------------------------
[INFO]: Epoch 103 of 200
Training
[103,   100] loss: 1.404e-06
[103,   200] loss: 1.389e-06
Validation
[103,   100] loss: 2.926e-06
[103,   200] loss: 1.567e-06
Training loss: 0.000, train NMSE: -2.525e+01
Validation loss: 0.000, valid_NMSE: -2.426e+01
--------------------------------------------------
[INFO]: Epoch 104 of 200
Training
[104,   100] loss: 1.384e-06
[104,   200] loss: 1.370e-06
Validation
[104,   100] loss: 3.034e-06
[104,   200] loss: 1.536e-06
Training loss: 0.000, train NMSE: -2.522e+01
Validation loss: 0.000, valid_NMSE: -2.450e+01

Best validation loss: -24.50486183166504

Saving best model for epoch: 104

--------------------------------------------------
[INFO]: Epoch 105 of 200
Training
[105,   100] loss: 1.327e-06
[105,   200] loss: 1.384e-06
Validation
[105,   100] loss: 3.002e-06
[105,   200] loss: 1.502e-06
Training loss: 0.000, train NMSE: -2.526e+01
Validation loss: 0.000, valid_NMSE: -2.460e+01

Best validation loss: -24.59549331665039

Saving best model for epoch: 105

--------------------------------------------------
[INFO]: Epoch 106 of 200
Training
[106,   100] loss: 1.339e-06
[106,   200] loss: 1.344e-06
Validation
[106,   100] loss: 3.070e-06
[106,   200] loss: 1.511e-06
Training loss: 0.000, train NMSE: -2.560e+01
Validation loss: 0.000, valid_NMSE: -2.433e+01
--------------------------------------------------
[INFO]: Epoch 107 of 200
Training
[107,   100] loss: 1.335e-06
[107,   200] loss: 1.322e-06
Validation
[107,   100] loss: 3.049e-06
[107,   200] loss: 1.491e-06
Training loss: 0.000, train NMSE: -2.541e+01
Validation loss: 0.000, valid_NMSE: -2.483e+01

Best validation loss: -24.82870101928711

Saving best model for epoch: 107

--------------------------------------------------
[INFO]: Epoch 108 of 200
Training
[108,   100] loss: 1.294e-06
[108,   200] loss: 1.341e-06
Validation
[108,   100] loss: 3.148e-06
[108,   200] loss: 1.480e-06
Training loss: 0.000, train NMSE: -2.560e+01
Validation loss: 0.000, valid_NMSE: -2.471e+01
--------------------------------------------------
[INFO]: Epoch 109 of 200
Training
[109,   100] loss: 1.288e-06
[109,   200] loss: 1.337e-06
Validation
[109,   100] loss: 3.122e-06
[109,   200] loss: 1.467e-06
Training loss: 0.000, train NMSE: -2.570e+01
Validation loss: 0.000, valid_NMSE: -2.498e+01

Best validation loss: -24.983949661254883

Saving best model for epoch: 109

--------------------------------------------------
[INFO]: Epoch 110 of 200
Training
[110,   100] loss: 1.316e-06
[110,   200] loss: 1.315e-06
Validation
[110,   100] loss: 2.892e-06
[110,   200] loss: 1.454e-06
Training loss: 0.000, train NMSE: -2.562e+01
Validation loss: 0.000, valid_NMSE: -2.464e+01
--------------------------------------------------
[INFO]: Epoch 111 of 200
Training
[111,   100] loss: 1.310e-06
[111,   200] loss: 1.293e-06
Validation
[111,   100] loss: 3.039e-06
[111,   200] loss: 1.439e-06
Training loss: 0.000, train NMSE: -2.615e+01
Validation loss: 0.000, valid_NMSE: -2.461e+01
--------------------------------------------------
[INFO]: Epoch 112 of 200
Training
[112,   100] loss: 1.260e-06
[112,   200] loss: 1.309e-06
Validation
[112,   100] loss: 3.130e-06
[112,   200] loss: 1.436e-06
Training loss: 0.000, train NMSE: -2.538e+01
Validation loss: 0.000, valid_NMSE: -2.469e+01
--------------------------------------------------
[INFO]: Epoch 113 of 200
Training
[113,   100] loss: 1.283e-06
[113,   200] loss: 1.329e-06
Validation
[113,   100] loss: 3.177e-06
[113,   200] loss: 1.438e-06
Training loss: 0.000, train NMSE: -2.513e+01
Validation loss: 0.000, valid_NMSE: -2.465e+01
--------------------------------------------------
[INFO]: Epoch 114 of 200
Training
[114,   100] loss: 1.290e-06
[114,   200] loss: 1.245e-06
Validation
[114,   100] loss: 3.182e-06
[114,   200] loss: 1.426e-06
Training loss: 0.000, train NMSE: -2.580e+01
Validation loss: 0.000, valid_NMSE: -2.460e+01
--------------------------------------------------
[INFO]: Epoch 115 of 200
Training
[115,   100] loss: 1.272e-06
[115,   200] loss: 1.272e-06
Validation
[115,   100] loss: 3.213e-06
[115,   200] loss: 1.407e-06
Training loss: 0.000, train NMSE: -2.562e+01
Validation loss: 0.000, valid_NMSE: -2.464e+01
--------------------------------------------------
[INFO]: Epoch 116 of 200
Training
[116,   100] loss: 1.264e-06
[116,   200] loss: 1.253e-06
Validation
[116,   100] loss: 3.082e-06
[116,   200] loss: 1.406e-06
Training loss: 0.000, train NMSE: -2.574e+01
Validation loss: 0.000, valid_NMSE: -2.488e+01
--------------------------------------------------
[INFO]: Epoch 117 of 200
Training
[117,   100] loss: 1.239e-06
[117,   200] loss: 1.238e-06
Validation
[117,   100] loss: 3.065e-06
[117,   200] loss: 1.395e-06
Training loss: 0.000, train NMSE: -2.598e+01
Validation loss: 0.000, valid_NMSE: -2.488e+01
--------------------------------------------------
[INFO]: Epoch 118 of 200
Training
[118,   100] loss: 1.197e-06
[118,   200] loss: 1.258e-06
Validation
[118,   100] loss: 3.176e-06
[118,   200] loss: 1.396e-06
Training loss: 0.000, train NMSE: -2.601e+01
Validation loss: 0.000, valid_NMSE: -2.479e+01
--------------------------------------------------
[INFO]: Epoch 119 of 200
Training
[119,   100] loss: 1.206e-06
[119,   200] loss: 1.220e-06
Validation
[119,   100] loss: 3.078e-06
[119,   200] loss: 1.387e-06
Training loss: 0.000, train NMSE: -2.568e+01
Validation loss: 0.000, valid_NMSE: -2.467e+01
--------------------------------------------------
[INFO]: Epoch 120 of 200
Training
[120,   100] loss: 1.223e-06
[120,   200] loss: 1.239e-06
Validation
[120,   100] loss: 3.141e-06
[120,   200] loss: 1.357e-06
Training loss: 0.000, train NMSE: -2.628e+01
Validation loss: 0.000, valid_NMSE: -2.482e+01
--------------------------------------------------
[INFO]: Epoch 121 of 200
Training
[121,   100] loss: 1.198e-06
[121,   200] loss: 1.215e-06
Validation
[121,   100] loss: 3.174e-06
[121,   200] loss: 1.337e-06
Training loss: 0.000, train NMSE: -2.608e+01
Validation loss: 0.000, valid_NMSE: -2.504e+01

Best validation loss: -25.036237716674805

Saving best model for epoch: 121

--------------------------------------------------
[INFO]: Epoch 122 of 200
Training
[122,   100] loss: 1.211e-06
[122,   200] loss: 1.229e-06
Validation
[122,   100] loss: 3.110e-06
[122,   200] loss: 1.390e-06
Training loss: 0.000, train NMSE: -2.638e+01
Validation loss: 0.000, valid_NMSE: -2.495e+01
--------------------------------------------------
[INFO]: Epoch 123 of 200
Training
[123,   100] loss: 1.194e-06
[123,   200] loss: 1.201e-06
Validation
[123,   100] loss: 3.219e-06
[123,   200] loss: 1.394e-06
Training loss: 0.000, train NMSE: -2.619e+01
Validation loss: 0.000, valid_NMSE: -2.481e+01
--------------------------------------------------
[INFO]: Epoch 124 of 200
Training
[124,   100] loss: 1.202e-06
[124,   200] loss: 1.186e-06
Validation
[124,   100] loss: 3.125e-06
[124,   200] loss: 1.319e-06
Training loss: 0.000, train NMSE: -2.644e+01
Validation loss: 0.000, valid_NMSE: -2.515e+01

Best validation loss: -25.149765014648438

Saving best model for epoch: 124

--------------------------------------------------
[INFO]: Epoch 125 of 200
Training
[125,   100] loss: 1.180e-06
[125,   200] loss: 1.169e-06
Validation
[125,   100] loss: 3.066e-06
[125,   200] loss: 1.316e-06
Training loss: 0.000, train NMSE: -2.622e+01
Validation loss: 0.000, valid_NMSE: -2.507e+01
--------------------------------------------------
[INFO]: Epoch 126 of 200
Training
[126,   100] loss: 1.173e-06
[126,   200] loss: 1.186e-06
Validation
[126,   100] loss: 3.126e-06
[126,   200] loss: 1.301e-06
Training loss: 0.000, train NMSE: -2.604e+01
Validation loss: 0.000, valid_NMSE: -2.534e+01

Best validation loss: -25.337902069091797

Saving best model for epoch: 126

--------------------------------------------------
[INFO]: Epoch 127 of 200
Training
[127,   100] loss: 1.205e-06
[127,   200] loss: 1.175e-06
Validation
[127,   100] loss: 3.101e-06
[127,   200] loss: 1.305e-06
Training loss: 0.000, train NMSE: -2.601e+01
Validation loss: 0.000, valid_NMSE: -2.516e+01
--------------------------------------------------
[INFO]: Epoch 128 of 200
Training
[128,   100] loss: 1.173e-06
[128,   200] loss: 1.174e-06
Validation
[128,   100] loss: 3.070e-06
[128,   200] loss: 1.283e-06
Training loss: 0.000, train NMSE: -2.649e+01
Validation loss: 0.000, valid_NMSE: -2.518e+01
--------------------------------------------------
[INFO]: Epoch 129 of 200
Training
[129,   100] loss: 1.138e-06
[129,   200] loss: 1.152e-06
Validation
[129,   100] loss: 3.134e-06
[129,   200] loss: 1.289e-06
Training loss: 0.000, train NMSE: -2.625e+01
Validation loss: 0.000, valid_NMSE: -2.504e+01
--------------------------------------------------
[INFO]: Epoch 130 of 200
Training
[130,   100] loss: 1.156e-06
[130,   200] loss: 1.150e-06
Validation
[130,   100] loss: 3.037e-06
[130,   200] loss: 1.264e-06
Training loss: 0.000, train NMSE: -2.633e+01
Validation loss: 0.000, valid_NMSE: -2.509e+01
--------------------------------------------------
[INFO]: Epoch 131 of 200
Training
[131,   100] loss: 1.128e-06
[131,   200] loss: 1.196e-06
Validation
[131,   100] loss: 2.800e-06
[131,   200] loss: 1.278e-06
Training loss: 0.000, train NMSE: -2.558e+01
Validation loss: 0.000, valid_NMSE: -2.516e+01
--------------------------------------------------
[INFO]: Epoch 132 of 200
Training
[132,   100] loss: 1.146e-06
[132,   200] loss: 1.146e-06
Validation
[132,   100] loss: 2.790e-06
[132,   200] loss: 1.240e-06
Training loss: 0.000, train NMSE: -2.579e+01
Validation loss: 0.000, valid_NMSE: -2.539e+01

Best validation loss: -25.393482208251953

Saving best model for epoch: 132

--------------------------------------------------
[INFO]: Epoch 133 of 200
Training
[133,   100] loss: 1.098e-06
[133,   200] loss: 1.137e-06
Validation
[133,   100] loss: 2.918e-06
[133,   200] loss: 1.272e-06
Training loss: 0.000, train NMSE: -2.645e+01
Validation loss: 0.000, valid_NMSE: -2.512e+01
--------------------------------------------------
[INFO]: Epoch 134 of 200
Training
[134,   100] loss: 1.095e-06
[134,   200] loss: 1.124e-06
Validation
[134,   100] loss: 3.026e-06
[134,   200] loss: 1.292e-06
Training loss: 0.000, train NMSE: -2.664e+01
Validation loss: 0.000, valid_NMSE: -2.477e+01
--------------------------------------------------
[INFO]: Epoch 135 of 200
Training
[135,   100] loss: 1.077e-06
[135,   200] loss: 1.134e-06
Validation
[135,   100] loss: 2.728e-06
[135,   200] loss: 1.281e-06
Training loss: 0.000, train NMSE: -2.591e+01
Validation loss: 0.000, valid_NMSE: -2.541e+01

Best validation loss: -25.405397415161133

Saving best model for epoch: 135

--------------------------------------------------
[INFO]: Epoch 136 of 200
Training
[136,   100] loss: 1.109e-06
[136,   200] loss: 1.106e-06
Validation
[136,   100] loss: 2.682e-06
[136,   200] loss: 1.252e-06
Training loss: 0.000, train NMSE: -2.664e+01
Validation loss: 0.000, valid_NMSE: -2.491e+01
--------------------------------------------------
[INFO]: Epoch 137 of 200
Training
[137,   100] loss: 1.090e-06
[137,   200] loss: 1.096e-06
Validation
[137,   100] loss: 3.007e-06
[137,   200] loss: 1.240e-06
Training loss: 0.000, train NMSE: -2.622e+01
Validation loss: 0.000, valid_NMSE: -2.552e+01

Best validation loss: -25.52080535888672

Saving best model for epoch: 137

--------------------------------------------------
[INFO]: Epoch 138 of 200
Training
[138,   100] loss: 1.078e-06
[138,   200] loss: 1.091e-06
Validation
[138,   100] loss: 2.807e-06
[138,   200] loss: 1.238e-06
Training loss: 0.000, train NMSE: -2.648e+01
Validation loss: 0.000, valid_NMSE: -2.501e+01
--------------------------------------------------
[INFO]: Epoch 139 of 200
Training
[139,   100] loss: 1.088e-06
[139,   200] loss: 1.081e-06
Validation
[139,   100] loss: 2.990e-06
[139,   200] loss: 1.211e-06
Training loss: 0.000, train NMSE: -2.636e+01
Validation loss: 0.000, valid_NMSE: -2.517e+01
--------------------------------------------------
[INFO]: Epoch 140 of 200
Training
[140,   100] loss: 1.077e-06
[140,   200] loss: 1.072e-06
Validation
[140,   100] loss: 2.563e-06
[140,   200] loss: 1.216e-06
Training loss: 0.000, train NMSE: -2.733e+01
Validation loss: 0.000, valid_NMSE: -2.522e+01
--------------------------------------------------
[INFO]: Epoch 141 of 200
Training
[141,   100] loss: 1.075e-06
[141,   200] loss: 1.073e-06
Validation
[141,   100] loss: 2.457e-06
[141,   200] loss: 1.180e-06
Training loss: 0.000, train NMSE: -2.668e+01
Validation loss: 0.000, valid_NMSE: -2.524e+01
--------------------------------------------------
[INFO]: Epoch 142 of 200
Training
[142,   100] loss: 1.064e-06
[142,   200] loss: 1.068e-06
Validation
[142,   100] loss: 2.468e-06
[142,   200] loss: 1.156e-06
Training loss: 0.000, train NMSE: -2.679e+01
Validation loss: 0.000, valid_NMSE: -2.515e+01
--------------------------------------------------
[INFO]: Epoch 143 of 200
Training
[143,   100] loss: 1.052e-06
[143,   200] loss: 1.077e-06
Validation
[143,   100] loss: 2.679e-06
[143,   200] loss: 1.217e-06
Training loss: 0.000, train NMSE: -2.587e+01
Validation loss: 0.000, valid_NMSE: -2.517e+01
--------------------------------------------------
[INFO]: Epoch 144 of 200
Training
[144,   100] loss: 1.080e-06
[144,   200] loss: 1.038e-06
Validation
[144,   100] loss: 2.310e-06
[144,   200] loss: 1.155e-06
Training loss: 0.000, train NMSE: -2.632e+01
Validation loss: 0.000, valid_NMSE: -2.571e+01

Best validation loss: -25.713651657104492

Saving best model for epoch: 144

--------------------------------------------------
[INFO]: Epoch 145 of 200
Training
[145,   100] loss: 1.045e-06
[145,   200] loss: 1.044e-06
Validation
[145,   100] loss: 2.994e-06
[145,   200] loss: 1.180e-06
Training loss: 0.000, train NMSE: -2.658e+01
Validation loss: 0.000, valid_NMSE: -2.543e+01
--------------------------------------------------
[INFO]: Epoch 146 of 200
Training
[146,   100] loss: 1.056e-06
[146,   200] loss: 1.057e-06
Validation
[146,   100] loss: 2.496e-06
[146,   200] loss: 1.181e-06
Training loss: 0.000, train NMSE: -2.694e+01
Validation loss: 0.000, valid_NMSE: -2.535e+01
--------------------------------------------------
[INFO]: Epoch 147 of 200
Training
[147,   100] loss: 1.028e-06
[147,   200] loss: 1.045e-06
Validation
[147,   100] loss: 2.527e-06
[147,   200] loss: 1.145e-06
Training loss: 0.000, train NMSE: -2.722e+01
Validation loss: 0.000, valid_NMSE: -2.516e+01
--------------------------------------------------
[INFO]: Epoch 148 of 200
Training
[148,   100] loss: 1.018e-06
[148,   200] loss: 1.045e-06
Validation
[148,   100] loss: 2.871e-06
[148,   200] loss: 1.186e-06
Training loss: 0.000, train NMSE: -2.636e+01
Validation loss: 0.000, valid_NMSE: -2.538e+01
--------------------------------------------------
[INFO]: Epoch 149 of 200
Training
[149,   100] loss: 1.049e-06
[149,   200] loss: 1.047e-06
Validation
[149,   100] loss: 2.522e-06
[149,   200] loss: 1.155e-06
Training loss: 0.000, train NMSE: -2.684e+01
Validation loss: 0.000, valid_NMSE: -2.535e+01
--------------------------------------------------
[INFO]: Epoch 150 of 200
Training
[150,   100] loss: 1.018e-06
[150,   200] loss: 1.030e-06
Validation
[150,   100] loss: 2.354e-06
[150,   200] loss: 1.121e-06
Training loss: 0.000, train NMSE: -2.685e+01
Validation loss: 0.000, valid_NMSE: -2.570e+01
--------------------------------------------------
[INFO]: Epoch 151 of 200
Training
[151,   100] loss: 1.006e-06
[151,   200] loss: 1.023e-06
Validation
[151,   100] loss: 2.547e-06
[151,   200] loss: 1.124e-06
Training loss: 0.000, train NMSE: -2.701e+01
Validation loss: 0.000, valid_NMSE: -2.568e+01
--------------------------------------------------
[INFO]: Epoch 152 of 200
Training
[152,   100] loss: 1.053e-06
[152,   200] loss: 1.003e-06
Validation
[152,   100] loss: 2.559e-06
[152,   200] loss: 1.164e-06
Training loss: 0.000, train NMSE: -2.635e+01
Validation loss: 0.000, valid_NMSE: -2.577e+01

Best validation loss: -25.765573501586914

Saving best model for epoch: 152

--------------------------------------------------
[INFO]: Epoch 153 of 200
Training
[153,   100] loss: 1.018e-06
[153,   200] loss: 1.001e-06
Validation
[153,   100] loss: 2.616e-06
[153,   200] loss: 1.137e-06
Training loss: 0.000, train NMSE: -2.733e+01
Validation loss: 0.000, valid_NMSE: -2.570e+01
--------------------------------------------------
[INFO]: Epoch 154 of 200
Training
[154,   100] loss: 9.793e-07
[154,   200] loss: 1.003e-06
Validation
[154,   100] loss: 2.511e-06
[154,   200] loss: 1.129e-06
Training loss: 0.000, train NMSE: -2.740e+01
Validation loss: 0.000, valid_NMSE: -2.563e+01
--------------------------------------------------
[INFO]: Epoch 155 of 200
Training
[155,   100] loss: 1.010e-06
[155,   200] loss: 9.844e-07
Validation
[155,   100] loss: 2.105e-06
[155,   200] loss: 1.125e-06
Training loss: 0.000, train NMSE: -2.676e+01
Validation loss: 0.000, valid_NMSE: -2.565e+01
--------------------------------------------------
[INFO]: Epoch 156 of 200
Training
[156,   100] loss: 9.948e-07
[156,   200] loss: 1.011e-06
Validation
[156,   100] loss: 2.444e-06
[156,   200] loss: 1.176e-06
Training loss: 0.000, train NMSE: -2.700e+01
Validation loss: 0.000, valid_NMSE: -2.536e+01
--------------------------------------------------
[INFO]: Epoch 157 of 200
Training
[157,   100] loss: 9.773e-07
[157,   200] loss: 1.003e-06
Validation
[157,   100] loss: 2.350e-06
[157,   200] loss: 1.088e-06
Training loss: 0.000, train NMSE: -2.655e+01
Validation loss: 0.000, valid_NMSE: -2.559e+01
--------------------------------------------------
[INFO]: Epoch 158 of 200
Training
[158,   100] loss: 9.620e-07
[158,   200] loss: 1.028e-06
Validation
[158,   100] loss: 2.295e-06
[158,   200] loss: 1.150e-06
Training loss: 0.000, train NMSE: -2.646e+01
Validation loss: 0.000, valid_NMSE: -2.524e+01
--------------------------------------------------
[INFO]: Epoch 159 of 200
Training
[159,   100] loss: 9.644e-07
[159,   200] loss: 9.731e-07
Validation
[159,   100] loss: 2.167e-06
[159,   200] loss: 1.103e-06
Training loss: 0.000, train NMSE: -2.666e+01
Validation loss: 0.000, valid_NMSE: -2.523e+01
--------------------------------------------------
[INFO]: Epoch 160 of 200
Training
[160,   100] loss: 9.634e-07
[160,   200] loss: 9.941e-07
Validation
[160,   100] loss: 2.173e-06
[160,   200] loss: 1.083e-06
Training loss: 0.000, train NMSE: -2.704e+01
Validation loss: 0.000, valid_NMSE: -2.522e+01
--------------------------------------------------
[INFO]: Epoch 161 of 200
Training
[161,   100] loss: 9.734e-07
[161,   200] loss: 9.686e-07
Validation
[161,   100] loss: 2.786e-06
[161,   200] loss: 1.137e-06
Training loss: 0.000, train NMSE: -2.723e+01
Validation loss: 0.000, valid_NMSE: -2.559e+01
--------------------------------------------------
[INFO]: Epoch 162 of 200
Training
[162,   100] loss: 9.532e-07
[162,   200] loss: 9.898e-07
Validation
[162,   100] loss: 2.580e-06
[162,   200] loss: 1.078e-06
Training loss: 0.000, train NMSE: -2.702e+01
Validation loss: 0.000, valid_NMSE: -2.577e+01

Best validation loss: -25.77113151550293

Saving best model for epoch: 162

--------------------------------------------------
[INFO]: Epoch 163 of 200
Training
[163,   100] loss: 9.503e-07
[163,   200] loss: 9.642e-07
Validation
[163,   100] loss: 2.331e-06
[163,   200] loss: 1.089e-06
Training loss: 0.000, train NMSE: -2.763e+01
Validation loss: 0.000, valid_NMSE: -2.594e+01

Best validation loss: -25.939720153808594

Saving best model for epoch: 163

--------------------------------------------------
[INFO]: Epoch 164 of 200
Training
[164,   100] loss: 9.727e-07
[164,   200] loss: 9.534e-07
Validation
[164,   100] loss: 2.447e-06
[164,   200] loss: 1.092e-06
Training loss: 0.000, train NMSE: -2.648e+01
Validation loss: 0.000, valid_NMSE: -2.571e+01
--------------------------------------------------
[INFO]: Epoch 165 of 200
Training
[165,   100] loss: 9.406e-07
[165,   200] loss: 9.613e-07
Validation
[165,   100] loss: 1.883e-06
[165,   200] loss: 1.132e-06
Training loss: 0.000, train NMSE: -2.652e+01
Validation loss: 0.000, valid_NMSE: -2.526e+01
--------------------------------------------------
[INFO]: Epoch 166 of 200
Training
[166,   100] loss: 9.282e-07
[166,   200] loss: 9.670e-07
Validation
[166,   100] loss: 1.624e-06
[166,   200] loss: 1.035e-06
Training loss: 0.000, train NMSE: -2.705e+01
Validation loss: 0.000, valid_NMSE: -2.600e+01

Best validation loss: -25.995996475219727

Saving best model for epoch: 166

--------------------------------------------------
[INFO]: Epoch 167 of 200
Training
[167,   100] loss: 9.610e-07
[167,   200] loss: 9.486e-07
Validation
[167,   100] loss: 1.510e-06
[167,   200] loss: 1.058e-06
Training loss: 0.000, train NMSE: -2.759e+01
Validation loss: 0.000, valid_NMSE: -2.593e+01
--------------------------------------------------
[INFO]: Epoch 168 of 200
Training
[168,   100] loss: 9.406e-07
[168,   200] loss: 9.475e-07
Validation
[168,   100] loss: 1.686e-06
[168,   200] loss: 1.048e-06
Training loss: 0.000, train NMSE: -2.692e+01
Validation loss: 0.000, valid_NMSE: -2.566e+01
--------------------------------------------------
[INFO]: Epoch 169 of 200
Training
[169,   100] loss: 9.280e-07
[169,   200] loss: 9.327e-07
Validation
[169,   100] loss: 1.592e-06
[169,   200] loss: 1.054e-06
Training loss: 0.000, train NMSE: -2.665e+01
Validation loss: 0.000, valid_NMSE: -2.597e+01
--------------------------------------------------
[INFO]: Epoch 170 of 200
Training
[170,   100] loss: 9.190e-07
[170,   200] loss: 9.191e-07
Validation
[170,   100] loss: 2.137e-06
[170,   200] loss: 1.060e-06
Training loss: 0.000, train NMSE: -2.679e+01
Validation loss: 0.000, valid_NMSE: -2.564e+01
--------------------------------------------------
[INFO]: Epoch 171 of 200
Training
[171,   100] loss: 9.323e-07
[171,   200] loss: 9.122e-07
Validation
[171,   100] loss: 1.746e-06
[171,   200] loss: 1.030e-06
Training loss: 0.000, train NMSE: -2.692e+01
Validation loss: 0.000, valid_NMSE: -2.577e+01
--------------------------------------------------
[INFO]: Epoch 172 of 200
Training
[172,   100] loss: 9.102e-07
[172,   200] loss: 9.592e-07
Validation
[172,   100] loss: 2.015e-06
[172,   200] loss: 1.087e-06
Training loss: 0.000, train NMSE: -2.707e+01
Validation loss: 0.000, valid_NMSE: -2.590e+01
--------------------------------------------------
[INFO]: Epoch 173 of 200
Training
[173,   100] loss: 9.013e-07
[173,   200] loss: 9.287e-07
Validation
[173,   100] loss: 2.095e-06
[173,   200] loss: 1.087e-06
Training loss: 0.000, train NMSE: -2.697e+01
Validation loss: 0.000, valid_NMSE: -2.578e+01
--------------------------------------------------
[INFO]: Epoch 174 of 200
Training
[174,   100] loss: 9.021e-07
[174,   200] loss: 9.212e-07
Validation
[174,   100] loss: 1.799e-06
[174,   200] loss: 1.017e-06
Training loss: 0.000, train NMSE: -2.727e+01
Validation loss: 0.000, valid_NMSE: -2.598e+01
--------------------------------------------------
[INFO]: Epoch 175 of 200
Training
[175,   100] loss: 9.261e-07
[175,   200] loss: 8.914e-07
Validation
[175,   100] loss: 1.355e-06
[175,   200] loss: 1.025e-06
Training loss: 0.000, train NMSE: -2.684e+01
Validation loss: 0.000, valid_NMSE: -2.575e+01
--------------------------------------------------
[INFO]: Epoch 176 of 200
Training
[176,   100] loss: 9.117e-07
[176,   200] loss: 9.140e-07
Validation
[176,   100] loss: 1.737e-06
[176,   200] loss: 1.041e-06
Training loss: 0.000, train NMSE: -2.697e+01
Validation loss: 0.000, valid_NMSE: -2.594e+01
--------------------------------------------------
[INFO]: Epoch 177 of 200
Training
[177,   100] loss: 8.939e-07
[177,   200] loss: 9.184e-07
Validation
[177,   100] loss: 1.495e-06
[177,   200] loss: 1.058e-06
Training loss: 0.000, train NMSE: -2.668e+01
Validation loss: 0.000, valid_NMSE: -2.583e+01
--------------------------------------------------
[INFO]: Epoch 178 of 200
Training
[178,   100] loss: 9.189e-07
[178,   200] loss: 8.986e-07
Validation
[178,   100] loss: 1.238e-06
[178,   200] loss: 1.010e-06
Training loss: 0.000, train NMSE: -2.736e+01
Validation loss: 0.000, valid_NMSE: -2.593e+01
--------------------------------------------------
[INFO]: Epoch 179 of 200
Training
[179,   100] loss: 8.871e-07
[179,   200] loss: 8.876e-07
Validation
[179,   100] loss: 1.320e-06
[179,   200] loss: 9.919e-07
Training loss: 0.000, train NMSE: -2.762e+01
Validation loss: 0.000, valid_NMSE: -2.576e+01
--------------------------------------------------
[INFO]: Epoch 180 of 200
Training
[180,   100] loss: 8.677e-07
[180,   200] loss: 9.071e-07
Validation
[180,   100] loss: 1.439e-06
[180,   200] loss: 1.016e-06
Training loss: 0.000, train NMSE: -2.654e+01
Validation loss: 0.000, valid_NMSE: -2.587e+01
--------------------------------------------------
[INFO]: Epoch 181 of 200
Training
[181,   100] loss: 8.950e-07
[181,   200] loss: 8.883e-07
Validation
[181,   100] loss: 1.207e-06
[181,   200] loss: 9.786e-07
Training loss: 0.000, train NMSE: -2.698e+01
Validation loss: 0.000, valid_NMSE: -2.621e+01

Best validation loss: -26.21017074584961

Saving best model for epoch: 181

--------------------------------------------------
[INFO]: Epoch 182 of 200
Training
[182,   100] loss: 8.870e-07
[182,   200] loss: 9.060e-07
Validation
[182,   100] loss: 1.075e-06
[182,   200] loss: 1.005e-06
Training loss: 0.000, train NMSE: -2.704e+01
Validation loss: 0.000, valid_NMSE: -2.630e+01

Best validation loss: -26.296892166137695

Saving best model for epoch: 182

--------------------------------------------------
[INFO]: Epoch 183 of 200
Training
[183,   100] loss: 8.694e-07
[183,   200] loss: 8.871e-07
Validation
[183,   100] loss: 1.026e-06
[183,   200] loss: 9.761e-07
Training loss: 0.000, train NMSE: -2.722e+01
Validation loss: 0.000, valid_NMSE: -2.613e+01
--------------------------------------------------
[INFO]: Epoch 184 of 200
Training
[184,   100] loss: 8.808e-07
[184,   200] loss: 8.805e-07
Validation
[184,   100] loss: 1.039e-06
[184,   200] loss: 9.858e-07
Training loss: 0.000, train NMSE: -2.686e+01
Validation loss: 0.000, valid_NMSE: -2.571e+01
--------------------------------------------------
[INFO]: Epoch 185 of 200
Training
[185,   100] loss: 8.726e-07
[185,   200] loss: 8.666e-07
Validation
[185,   100] loss: 1.160e-06
[185,   200] loss: 1.001e-06
Training loss: 0.000, train NMSE: -2.726e+01
Validation loss: 0.000, valid_NMSE: -2.567e+01
--------------------------------------------------
[INFO]: Epoch 186 of 200
Training
[186,   100] loss: 8.836e-07
[186,   200] loss: 9.221e-07
Validation
[186,   100] loss: 1.643e-06
[186,   200] loss: 9.997e-07
Training loss: 0.000, train NMSE: -2.659e+01
Validation loss: 0.000, valid_NMSE: -2.579e+01
--------------------------------------------------
[INFO]: Epoch 187 of 200
Training
[187,   100] loss: 8.796e-07
[187,   200] loss: 8.856e-07
Validation
[187,   100] loss: 1.230e-06
[187,   200] loss: 9.764e-07
Training loss: 0.000, train NMSE: -2.790e+01
Validation loss: 0.000, valid_NMSE: -2.626e+01
--------------------------------------------------
[INFO]: Epoch 188 of 200
Training
[188,   100] loss: 8.748e-07
[188,   200] loss: 8.650e-07
Validation
[188,   100] loss: 1.061e-06
[188,   200] loss: 9.764e-07
Training loss: 0.000, train NMSE: -2.765e+01
Validation loss: 0.000, valid_NMSE: -2.600e+01
--------------------------------------------------
[INFO]: Epoch 189 of 200
Training
[189,   100] loss: 8.527e-07
[189,   200] loss: 8.504e-07
Validation
[189,   100] loss: 1.010e-06
[189,   200] loss: 9.636e-07
Training loss: 0.000, train NMSE: -2.684e+01
Validation loss: 0.000, valid_NMSE: -2.570e+01
--------------------------------------------------
[INFO]: Epoch 190 of 200
Training
[190,   100] loss: 8.770e-07
[190,   200] loss: 8.594e-07
Validation
[190,   100] loss: 1.051e-06
[190,   200] loss: 9.830e-07
Training loss: 0.000, train NMSE: -2.735e+01
Validation loss: 0.000, valid_NMSE: -2.641e+01

Best validation loss: -26.41257095336914

Saving best model for epoch: 190

--------------------------------------------------
[INFO]: Epoch 191 of 200
Training
[191,   100] loss: 8.733e-07
[191,   200] loss: 8.640e-07
Validation
[191,   100] loss: 1.133e-06
[191,   200] loss: 9.865e-07
Training loss: 0.000, train NMSE: -2.739e+01
Validation loss: 0.000, valid_NMSE: -2.625e+01
--------------------------------------------------
[INFO]: Epoch 192 of 200
Training
[192,   100] loss: 8.536e-07
[192,   200] loss: 8.772e-07
Validation
[192,   100] loss: 1.067e-06
[192,   200] loss: 9.936e-07
Training loss: 0.000, train NMSE: -2.711e+01
Validation loss: 0.000, valid_NMSE: -2.616e+01
--------------------------------------------------
[INFO]: Epoch 193 of 200
Training
[193,   100] loss: 8.555e-07
[193,   200] loss: 8.571e-07
Validation
[193,   100] loss: 1.020e-06
[193,   200] loss: 9.868e-07
Training loss: 0.000, train NMSE: -2.720e+01
Validation loss: 0.000, valid_NMSE: -2.593e+01
--------------------------------------------------
[INFO]: Epoch 194 of 200
Training
[194,   100] loss: 8.477e-07
[194,   200] loss: 8.611e-07
Validation
[194,   100] loss: 1.006e-06
[194,   200] loss: 9.599e-07
Training loss: 0.000, train NMSE: -2.807e+01
Validation loss: 0.000, valid_NMSE: -2.639e+01
--------------------------------------------------
[INFO]: Epoch 195 of 200
Training
[195,   100] loss: 8.359e-07
[195,   200] loss: 8.537e-07
Validation
[195,   100] loss: 1.022e-06
[195,   200] loss: 9.677e-07
Training loss: 0.000, train NMSE: -2.704e+01
Validation loss: 0.000, valid_NMSE: -2.637e+01
--------------------------------------------------
[INFO]: Epoch 196 of 200
Training
[196,   100] loss: 8.701e-07
[196,   200] loss: 8.445e-07
Validation
[196,   100] loss: 9.604e-07
[196,   200] loss: 9.376e-07
Training loss: 0.000, train NMSE: -2.734e+01
Validation loss: 0.000, valid_NMSE: -2.611e+01
--------------------------------------------------
[INFO]: Epoch 197 of 200
Training
[197,   100] loss: 8.551e-07
[197,   200] loss: 8.524e-07
Validation
[197,   100] loss: 9.680e-07
[197,   200] loss: 9.359e-07
Training loss: 0.000, train NMSE: -2.749e+01
Validation loss: 0.000, valid_NMSE: -2.608e+01
--------------------------------------------------
[INFO]: Epoch 198 of 200/home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/hzl/anaconda3/envs/pt/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE
  warn(f"Failed to load image Python extension: {e}")

Training
[198,   100] loss: 8.691e-07
[198,   200] loss: 8.238e-07
Validation
[198,   100] loss: 1.017e-06
[198,   200] loss: 9.713e-07
Training loss: 0.000, train NMSE: -2.757e+01
Validation loss: 0.000, valid_NMSE: -2.595e+01
--------------------------------------------------
[INFO]: Epoch 199 of 200
Training
[199,   100] loss: 8.567e-07
[199,   200] loss: 8.397e-07
Validation
[199,   100] loss: 1.004e-06
[199,   200] loss: 9.805e-07
Training loss: 0.000, train NMSE: -2.701e+01
Validation loss: 0.000, valid_NMSE: -2.601e+01
--------------------------------------------------
[INFO]: Epoch 200 of 200
Training
[200,   100] loss: 8.426e-07
[200,   200] loss: 8.564e-07
Validation
[200,   100] loss: 9.637e-07
[200,   200] loss: 9.433e-07
Training loss: 0.000, train NMSE: -2.753e+01
Validation loss: 0.000, valid_NMSE: -2.634e+01
--------------------------------------------------
Saving final model
TRAINING COMPLETE
